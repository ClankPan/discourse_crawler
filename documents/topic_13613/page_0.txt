Chloros88 | 2022-06-08 22:15:07 UTC | #1

Anyone having the same issue? Failed to fetch response on all canisters

-------------------------

oss | 2022-06-08 17:35:52 UTC | #2

Same here, NE USA
Really odd the burn rate spikes since last night

-------------------------

faraz.shaikh | 2022-06-08 17:39:33 UTC | #3

Hello, 

Please provide the exact URL and the approximate geographical location you are having problems with. 

I tested a few canisters, identity, nns, oc from the PST time zone.   They are working fine
-F

-------------------------

Chloros88 | 2022-06-08 17:41:24 UTC | #4

SE United States tested about 5 different canisters all the same issues. Also looks like London having issues too 
![image|231x500](upload://81tvJHT2joTQZZTiu5vmfRVibhK.jpeg)

-------------------------

nicopoggi | 2022-06-08 17:49:24 UTC | #5

Same errors in Latam region, from Chile :chile:

-------------------------

faraz.shaikh | 2022-06-08 17:51:27 UTC | #6

[quote="oss, post:2, topic:13613, full:true"]
Same here, NE USA
Really odd the burn rate spikes since last night
[/quote]

Thanks for the reports folks, we are looking into it.

-------------------------

berestovskyy | 2022-06-08 18:31:17 UTC | #7

@Chloros88 @oss @nicopoggi could you please try now?

-------------------------

nicopoggi | 2022-06-08 18:55:02 UTC | #8

Seems some calls go through, but we're also getting some sort of rate limiting or smth causing a "too many requests" error.

-------------------------

paulyoung | 2022-06-08 19:15:56 UTC | #9

Related?

https://twitter.com/FleekHQ/status/1534608664404889602

-------------------------

faraz.shaikh | 2022-06-08 19:33:29 UTC | #10

We identified and rolled out a fix, that affected access from certain geographies. namely,
1. Latam
2. Western Europe
3. Southeast US

 we checked access from the above locations and confirmed the issue and its fix. 
@nicopoggi  @oss @Chloros88

-------------------------

faraz.shaikh | 2022-06-08 19:43:11 UTC | #11

unlikely. Fleek hosts many other platforms. The issue we found was returning "Internal Server Error 500", fleek's report is about http-429. 

Will keep watch.

EDIT: Might be "another" issue faced by @nicopoggi and Fleek

-------------------------

torates | 2022-06-08 19:45:30 UTC | #12

Same here, In LATAM right now and having problems.
Some calls go through but a lot of them respond with a Too many requests error.

-------------------------

torates | 2022-06-08 19:47:01 UTC | #13

I'm still being affected by the issue.
Specifically on a payment-processing call, trying to submit a tx through plug.

![Screenshot 2022-06-08 at 21.46.08|690x215](upload://qwV04yFMdpF0c1clDhdhjNHAHDe.png)

-------------------------

faraz.shaikh | 2022-06-08 19:50:36 UTC | #14

Can you post your output for the command? It tells you which boundary node you are connecting to. 
`# nslookup ic0.app`

Are plug and fleek related in some way?

-------------------------

torates | 2022-06-08 19:58:58 UTC | #15

Some calls to my canister work perfectly, but on the ones expecting payment of some sort I get the error.
As far as I know both Plug and Fleek are developer by Psychedelic.

This the output from running the command.
![Screenshot 2022-06-08 at 21.51.04|690x200](upload://m8bSXsJaw8iancbM2GQbQx0ea0u.png)

-------------------------

torates | 2022-06-08 19:54:14 UTC | #16

I also get the error when accessing the [icdevs](https://icdevs.org/) site.

-------------------------

faraz.shaikh | 2022-06-08 20:51:51 UTC | #19

@torates we investigated "Too may Request" Http-429 for the nodes you mentioned. 
No issue popped up at our end.   

Let's wait for fleek to resolve/update the status at their end.  We will coordinate with Fleek to fish this up the stack. Thanks for your help.

-------------------------

Daniel-Bloom | 2022-06-08 21:16:30 UTC | #20

The IC itself was actually performing as expected and was not down, however one of the Boundary Nodes (in US-east) which acts as a gateway for the IC experienced intermittent issues that prevented failover. As such users in that geo-area who were DNS routed to that impacted boundary node experienced their requests being dropped by the BN.

Advanced users in the impacted area were technically able to reach the IC by talking to other boundary nodes. The method of targeting specific boundary nodes is a bit opaque, so we will be writing up simple steps on how to do this.

Preventing/mitigating issues like this one are why we are trying to get boundary nodes decentralized as soon as possible.

-------------------------

torates | 2022-06-08 21:49:43 UTC | #21

Thanks a lot for the quick response, to @faraz.shaikh as well.

Would certainly love to learn more about targeting specific BNs.

Cheers!

-------------------------

justmythoughts | 2022-06-08 22:23:03 UTC | #22

[quote="Daniel-Bloom, post:20, topic:13613"]
...As such users in that geo-area who were DNS routed to that impacted boundary node experienced their requests being dropped by the BN.

Advanced users in the impacted area were technically able to reach the IC by talking to other boundary nodes. The method of targeting specific boundary nodes is a bit opaque, so we will be writing up simple steps on how to do this.
[/quote]

Why do I need to be an "advanced" user and consciously target/talk to a different boundary node? Why isn't that kind of regional/node DNS fallback abstracted away and built into the IC's DNS routing?

-------------------------

justmythoughts | 2022-06-08 23:27:26 UTC | #24

This "expected" behavior means that the decentralization of, or even just creation of more Boundary Nodes is one of the most important things DFINITY can focus on in the months to come.

I've created a post to voice my concerns and hopefully spur discussion and some solutions - https://forum.dfinity.org/t/todays-multi-continent-ic-outage-are-boundary-nodes-the-top-attack-vector-for-the-ic/13624

-------------------------

atomikm | 2022-06-09 03:12:12 UTC | #25

Has this issue been resolved? We're still experiencing this issue when calling our canisters through the Plug Wallet. We get the "failed to fetch" error. We're located in the US

-------------------------

Tony89 | 2022-06-09 07:00:20 UTC | #26

![hình ảnh|230x500](upload://pKsRFWKJUAUbcvPNOgQK6dURNma.jpeg)
https://twitter.com/plug_wallet/status/1534627165991493632?s=21&t=Pn0CHor4pVFRjLMUI9v6LA
this is the announcement from Plugwallet

-------------------------

diegop | 2022-06-17 00:46:12 UTC | #27

**Update:** 

@martin_DFN1 has posted an incident retrospective here:

https://forum.dfinity.org/t/north-atlantic-region-boundary-node-outage-incident-retrospective-wednesday-jun-8-2022/13856

-------------------------

velgajski1 | 2024-05-10 01:35:50 UTC | #28

Hi, issues here from Europe - cannot access any canisters or dfinity.org for past 8 hours.

Problem goes away for a short time, but for the most part - IC is down for me.

-------------------------

diegop | 2024-05-10 04:40:54 UTC | #29

I checked and all worked for me. I wonder if there is some boundary  node or last mile problem affecting your experience.

Still having issues?

-------------------------

velgajski1 | 2024-05-10 18:42:24 UTC | #30

Thanks for the answer. Last 12+ hours everything worked normally.

-------------------------

velgajski1 | 2024-06-11 07:17:45 UTC | #31

Hey guys, still getting issues unfortunately. It happens intermittently, and sometimes seemingly after I deploy canisters to IC (not sure about this one).

Any ideas?

-------------------------

rbirkner | 2024-06-11 07:32:01 UTC | #32

Hey @velgajski1 

I followed up in a DM and will report any findings for everyone back here.

-------------------------


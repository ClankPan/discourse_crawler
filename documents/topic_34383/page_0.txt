dsharifi | 2024-08-22 11:45:42 UTC | #1

Hi Everyone!

I want to update you all on the progress DFINITY has made on the [Tokamak](https://internetcomputer.org/roadmap#Compute%20Platform-Tokamak) milestone that aims to reduce end-to-end (E2E) latency of update calls to canister smart contracts. We have completed the implementation of several exciting upcoming features that will lower user-perceived latency when interacting with the Internet Computer. All of these features will greatly improve how users experience the speed of ICP.

### Synchronous Ingress Messages

We have completed the implementation of a new HTTPS endpoint for making update calls, `/v3/…/call`. This new endpoint is synchronous and responds with a certificate. This differs from today’s asynchronous endpoint, `/v2/…/call`, where users submit ingress messages, and must then continuously poll the for ingress message’s status. This polling adds significant latency to every call, so switching to a synchronous endpoint that does not require polling will lower the end-to-end latency.

Figure 1 below illustrates the semantics of the old and new call endpoints. On the left, we see that when a user submits an update call to the old endpoint, they must start polling the ICP for the certified response with the `/read_state` requests. On the right-hand side, we see that the new call endpoint waits to respond until a certificate is ready and sends it back to the user.

![|659x418](upload://kJPIosi3Xd1XK1X52lxw2Due7la.png)
Figure 1

Routing ingress messages to the new call endpoint will just be an implementation detail of user agents such as agent-js and agent-rs. This means your dapp can benefit from the new endpoint by simply upgrading the agent version once the agents support the new endpoint.

### Geo Aware boundary node routing

[Boundary nodes](https://internetcomputer.org/how-it-works/boundary-nodes/) serve as a gateway to the Internet Computer by providing HTTP endpoints that route canister requests to the right subnet.

At the moment, boundary nodes route a request to a random node within the destination subnet. As the nodes are distributed across the globe, some nodes are closer and others further away. This leads to vastly different network latencies per request (from tens to hundreds of milliseconds).

We are proposing to change the boundary nodes' routing behavior for update calls. In particular, we propose that they choose among the closest "third" (f+1). This helps reduce the latency between the boundary nodes and the replica nodes.

### Increasing the Block Rate of subnets.

We also want to increase the rate at which Internet Computer subnets produce blocks. A higher block rate means messages can be included in a block sooner, leading to a lower latency. Note that this change will lead to more variability in the block rate of subnets: under low load, we expect to see more than 2 blocks per second, but under high load, the block rate would likely fall to ~1 block per second. This increased block rate can be achieved by modifying consensus protocol parameters that are part of the subnet settings in the registry (namely, the initial_notary_delay_millis).

The reason we can now lower this notarisation delay is partly due to the new P2P layer of ICP, announced [here](https://forum.dfinity.org/t/new-p2p-layer-for-consensus-related-clients/25680). The new P2P supports a higher throughput between nodes and an optimized protocol for sending messages between nodes. This means that subnets can produce blocks at a faster rate and ensure that all nodes can keep up.

### Next Steps

DFINITY plans to submit proposals to gradually roll out these three features over the coming months, and use this forum thread to keep everybody informed of the progress. We also plan to collect end-to-end latency metrics, so hopefully we will see this number reduce as the new features roll out.

Feel free to comment if you have any questions!

- Daniel

-------------------------

Severin | 2024-08-22 11:54:38 UTC | #2

CC @quint @neeboo @rdobrik @Gekctek @levi @jleni (just re-using a list of agent developers that I found in an older post of mine)

-------------------------

rdobrik | 2024-08-22 12:23:09 UTC | #3

Than you @Severin @dsharifi ! We will start working on Java IC4J Agent implementation ASAP.

-------------------------

0rions | 2024-08-22 14:22:23 UTC | #4

Great work Daniel, super interesting, can't wait to see this live!

-------------------------

TusharGuptaMm | 2024-08-22 15:56:38 UTC | #5

This is going to be epic! The user experience for DApps like RuBaRu will improve significantly. We had planned some UX workarounds for handling update latency, like optimistic updates for a few requests, but it looks like we’ll need to revisit those plans.

Geo-aware update calls sound amazing—are we planning to implement the same for query calls, bringing in Edge capabilities to the network? Query performance is already close to Web2 standards, so I'm curious if this is in place.

Can't wait to see it in action. @neeboo, integrating this into agent_dart would be fantastic. We would love to integrate & test. We can also measure latency improvements and publish them?

-------------------------

lastmjs | 2024-08-22 16:14:25 UTC | #6

I have a question on the synchronous endpoint.

I'm looking for solutions to authentication of raw/pure HTTP requests from clients to canisters. I would like to enable JWTs etc for authentication so that developers can use traditional normal non-ICP-specific HTTP clients.

The problem is that all of these calls are treated as anonymous, and the result is written to a location that can be polled publicly.

Is it possible for the synchronous endpoint to return the result of the call directly and only to the entity making the call? And not write it to a public location that can be polled?

If so this might solve the problem.

Does it work like this? I am afraid not as it looks like the certified state is still written to and thus anyone could call read_state on it. Do I have that correct?

-------------------------

kpeacock | 2024-08-22 16:17:00 UTC | #7

`read_state`  is still the fallback behavior. We can't count on perfect conditions for the boundary nodes or even for clients to have consistent network connections. If the request can't stay open, agents need to be able to confirm the result of an update

-------------------------

Phasma | 2024-08-22 16:32:59 UTC | #8

It’s great to see the latency being reduced—keep up the progress!

-------------------------

Sormarler | 2024-08-22 20:22:22 UTC | #9

Hey @lastmjs ,
I'm curious about your interest in having the synchronous endpoint return results directly without writing them to the blockchain. Could you elaborate a bit more on your specific use case or application?
Are you primarily looking to improve performance and reduce latency, or are there other factors like data privacy or simplifying certain types of queries that are driving this request?

-------------------------

lastmjs | 2024-08-22 21:37:06 UTC | #10

My explanation is what I am after, authentication purposes. It's not that it isn't written to the blockchain but that it isn't written to a public location that any anonymous user can retrieve.

-------------------------

neeboo | 2024-08-23 06:46:40 UTC | #11

It seems like a good approach , let us digest v3 and see what to do next

-------------------------

neeboo | 2024-08-23 06:50:49 UTC | #12

is `agent-js` ready for v3?

-------------------------

dsharifi | 2024-08-23 09:56:46 UTC | #13

[quote="rdobrik, post:3, topic:34383"]
We will start working on Java IC4J Agent implementation ASAP.
[/quote]

That's great! [Here](https://github.com/dfinity/interface-spec/pull/265) is the PR for the IC specification change for the the new endpoint that I believe can be helpful when creating the new agent. You can also use the latest [PocketIC](https://internetcomputer.org/docs/current/developer-docs/smart-contracts/test/pocket-ic) or [dfx](https://internetcomputer.org/docs/current/developer-docs/developer-tools/cli-tools/cli-reference/dfx-parent) (locally) to test against the endpoint.

Keep in mind as @kpeacock mentioned, the fallback behavior is similar to the v2 endpoint. That means if the request can not be processed over some long time threshold, the replica can terminate the connection and reply with `202 Accepted`, meaning the agent must fall back to polling.

-------------------------

dsharifi | 2024-08-23 09:51:38 UTC | #14

[quote="lastmjs, post:6, topic:34383"]
Does it work like this? I am afraid not as it looks like the certified state is still written to and thus anyone could call read_state on it. Do I have that correct?
[/quote]

No, the processing of the update call on the subnet is the exact same as before. This indeed means that the result of the update call is written to the certified state of the subnet.

-------------------------

rbirkner | 2024-08-23 11:01:24 UTC | #15

Hey @TusharGuptaMm 

At the moment, we will go with the update calls and see how it works (e.g., how the load is spread among the nodes etc.). At a later point, we will reconsider that and might even change our routing completely and not just decide randomly or based on latency, but based on the actual load of the different nodes.

-------------------------

dsharifi | 2024-08-23 11:55:58 UTC | #16

Update:

We have submitted an NNS proposal to increase the block rate of the  `io67a-2jmkw-zup3h-snbwi-g6a5n-rm5dn-b6png-lvdpl-nqnto-yih6l-gqe` subnet. Here's the proposal: https://dashboard.internetcomputer.org/proposal/132123.

-------------------------

Lerak | 2024-08-23 15:07:49 UTC | #17

@dsharifi 
Yesterday you said that "We also plan to collect end-to-end latency metrics".  Why did you submit this proposal before the collection of the end-to-end latency metrics?

300ms is too low for nodes on the other side of the world.

This node is in sc1 data centre, an hour north of Brisbane in Australia. I have been monitoring ping times from a server on AWS in Frankfurt to a node on the io67a subnet q3w37-sdo2u-z72qf-hpesy-rgqes-lzflk-aescx-c5ivv-qdbty-s6pgc-jae :

![image|690x308](upload://iKHRPtZKPyOBFHEuvThvEjxQlk0.png)

![image|690x306](upload://axTpLbShmAx2uQS1q8xwBAGydxW.png)

This node won't be able to keep up with European nodes it the timeout is set at 300ms

400ms would be a better number, and a more relavant test, if we want to move all application subnets to a lower number in future.

-------------------------

kpeacock | 2024-08-23 17:01:11 UTC | #18

Just got a couple pieces of feedback from prodsec, but it'll be ready to go out as soon as the endpoint doesn't 404

https://github.com/dfinity/agent-js/pull/906

-------------------------

Lorimer | 2024-08-24 07:27:24 UTC | #19

[quote="dsharifi, post:16, topic:34383"]
We have submitted an NNS proposal to increase the block rate of the `io67a-2jmkw-zup3h-snbwi-g6a5n-rm5dn-b6png-lvdpl-nqnto-yih6l-gqe` subnet. Here’s the proposal: [https://dashboard.internetcomputer.org/proposal/132123](https://dashboard.internetcomputer.org/proposal/132123).
[/quote]

For anyone interested, there's a dedicate thread for changes to the subnet affected by this proposal -> [Subnet Management - io67a (Application) - Developers - Internet Computer Developer Forum (dfinity.org)](https://forum.dfinity.org/t/subnet-management-io67a-application/34393/2)

@Lerak also provided his network latency analysis there. **Great job @Lerak**!

Note that the consensus protocol is designed to be able to cope with network delays that occasionally fall behind the 0-rank block notarization delay.

I am curious as to why this parameter is a fixed value rather than adaptive (adaptive to network conditions that ebb and flow - incrementing when network conditions are bad, and decrementing when better performance can be achieved). An implementation like this would have avoided the need to update the config (the notarization delay would have gradually reduced to an equilibrium point that optimises for throughput) - *just thinking out loud*.

-------------------------

Techgirlkhushi | 2024-08-24 11:45:48 UTC | #20

Wow, it's an amazing update. ICP is getting faster and making the community more bullish about its tech stack. ICP is true love for us.

-------------------------

linkme | 2024-08-24 14:01:50 UTC | #21

[quote="dsharifi, post:1, topic:34383"]
### Block Rate of subnets.

We also want to increase the rate at which Internet Computer subnets produce blocks. A higher block rate means messages can be included in a block sooner, leading to a lower latency. Note that this change will lead to more variability in the block rate of subnets: under low load, we expect to see more than 2 blocks per second, but under high load, the block rate would likely fall to ~1 block per second. This increased block rate can be achieved by modifying consensus protocol parameters that are part of the subnet settings in the registry (namely, the initial_notary_delay_millis).

The reason we can now lower this notarisation delay is partly due to th
[/quote]

how does ICP handle DDOS

-------------------------

rdobrik | 2024-08-25 08:42:22 UTC | #22

Thanks @dsharifi! BTW is current pooling (V2) version of update mechanism going to be still supported in the future? In some cases I would prefer that, especially in Java server->ICP scenarios, where Java developers can control their connection and thread pools. Latency is not such a big issue there.

-------------------------

Lorimer | 2024-08-25 09:52:34 UTC | #23

[quote="linkme, post:21, topic:34383"]
how does ICP handle DDOS
[/quote]

There's rate limiting and message validation for inter-canister calls, but I'm less clear on calls from outside the IC network. Here's an interesting commit from last week that I just came across ->

[chore: add a per-boundary-node rate-limit of 1000 update calls per se… · dfinity/ic@4039ea2 (github.com)](https://github.com/dfinity/ic/commit/4039ea27e3af0ace2c4b8f893d8ab1768cfab750)

^ I'm interested to see this commit at a time where update call performance is being significantly improved. Can I ask what the rate limiting mechanism was prior to this @rbirkner?

-------------------------

rbirkner | 2024-08-25 20:18:21 UTC | #24

Good catch!

What the commit does is to introduce a limit of 1000 update calls per second per subnet and boundary node. 

The subnets have a setting in their subnet record, which is called `max_ingress_messages_per_block` (see [here](https://github.com/dfinity/ic/blob/1e38e12c72e7074b0982f8b7929ce0922194a75f/rs/protobuf/def/registry/subnet/v1/subnet.proto#L41-L42)). This translates to how many update calls can be put into a single block and is currently set to 1000 on all the subnets. 

At the moment, we have in total around 20 boundary nodes and at least 4 boundary nodes in each region. That means even after introducing the rate limit, more than 20k update calls per second could make it to the subnet, which will be more than the subnet can handle.

The idea of this rate-limit is that it shouldn't affect normal usage, but rejects update calls early if there are way too many of them. We have good monitoring and will of course adapt the rate-limits if we realize they are set too low and reject too much.

Initially, there were much lower rate-limits (see [here](https://github.com/dfinity/ic/blob/bfd9bc391bd163b2b406143b65d19bb6f457510c/ic-os/boundary-guestos/rootfs/etc/nginx/conf.d/000-nginx-global.conf#L138-L140) and [here](https://github.com/dfinity/ic/blob/bfd9bc391bd163b2b406143b65d19bb6f457510c/ic-os/boundary-guestos/rootfs/etc/nginx/conf.d/001-mainnet-nginx.conf#L117-L118)), but they were removed around 1-2 years ago they weren't considered necessary anymore. The couple of incidents with the high load, which we had during the beginning of the year, however showed that there is no point in "letting" way too many update calls through and that's why it got reintroduced.

-------------------------

linkme | 2024-08-26 00:04:06 UTC | #25

interesting, it would be nice to build rate limiting features which leverage AI intelligence to figure out if the calls are DDOS versus valid calls because of an app going viral. I am confident these kind of tools will get built in the ICP ecosystem. Such a service can then be leveraged by canisters on a need basis and turned ON or OFF as required.  a.k.a. DDOS prevention as a service provided by another canister, a kind of common good

-------------------------

Lorimer | 2024-08-26 07:22:36 UTC | #26

I love the enthusiasm, but I'm not convinced of the practicality of a solution like that (I'm not sure what *blackbox* AI would be bringing to the table over rigerous, predictable and efficient algorithms that are only as complex as they need to be).

-------------------------

Lorimer | 2024-08-26 07:34:46 UTC | #27

Thanks @rbirkner, this was very informative and useful. Given that the [block rate is being slashed in half](https://forum.dfinity.org/t/subnet-management-io67a-application/34393/2) (from 600ms to 300ms) this would mean that the `max_ingress_messages_per_block` in relative terms is kind of doubled (not per block, but in terms of messages that can be written to **a** block per second).

Can I ask for some more info about the rationale for having it set to 1000 (i.e. why it's not lower or higher)? I'm asking mostly out of curiosity :slight_smile:

-------------------------

dsharifi | 2024-08-26 13:28:02 UTC | #28

As long as there is a use case for the V2 endpoint, we will continue to maintain it.

However, I would note that the V3 endpoint should be able to serve all the use cases one client might have. For example, if you want to batch a large number of update calls to be submitted, there is little overhead for the user client to use the V3 endpoint. The boundary nodes that the client connects to support [HTTP/2](https://http2.github.io/) which means that clients can concurrently send multiple requests on the same TCP connection to a single BN.

-------------------------

dsharifi | 2024-08-26 15:39:41 UTC | #29

Update:

The proposal to change the `initial_notary_delay_millis` for the first subnet, `io67a-2jmkw-zup3h-snbwi-g6a5n-rm5dn-b6png-lvdpl-nqnto-yih6l-gqe,` subnet has been executed, and we are now observing a stable block rate of[ 2.3 blocks/s](https://dashboard.internetcomputer.org/subnet/io67a-2jmkw-zup3h-snbwi-g6a5n-rm5dn-b6png-lvdpl-nqnto-yih6l-gqe)!

-------------------------

Lorimer | 2024-08-26 16:21:25 UTC | #30

Amazing work 👏 

I love being able to observe these metrics and see the difference this has made 😍 

![Screenshot_20240826_171330_Chrome|625x499](upload://bMwJOsvBO458uA85ZfFmsOIIvn3.jpeg)

![Screenshot_20240826_171346_Chrome|627x499](upload://r2nUvG8Z8W41Qv8vio4mOM6qPMv.jpeg)

-------------------------

rdobrik | 2024-08-26 17:05:39 UTC | #31

Thanks Daniel. When I have our V3 implementation ready I can try to test throughput with x number of parallel threads from single JVM to see if there is any difference between V2 and V3. For many applications I would rather sacrifice latency over throughput. It would be good document for Java ICP developers to choose right approach. I will shared our results.

-------------------------

skilesare | 2024-08-26 20:49:42 UTC | #32

This is interesting...the state can be read by anyone? Is this true for all requests, or just anonymous requests?

Are the request IDs at least non-deterministic?(If so, I guess boundary nodes could still publish them, but they'd at least be harder to find.)

-------------------------

lastmjs | 2024-08-26 22:06:00 UTC | #33

My understanding is that it is authorized by principal, so only anonymous requests for this specific state, the result of an ingress message update call (maybe also query call in replicated mode).

-------------------------

rbirkner | 2024-08-27 07:05:58 UTC | #34

The networking team has run extensive tests and they show that the idle block rate improves significantly (basically what you observed after the proposal passed). However, as the load increases, the improvements diminish. That's why we are currently sticking to the 1000 update calls per second per boundary node. We are monitoring the situation and if we see that this limit is too low, we will increase it of course.

-------------------------


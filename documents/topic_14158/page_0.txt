senior.joinu | 2022-07-07 14:06:54 UTC | #1

Hey everyone, I'm here with a new Rust library again.
https://github.com/seniorjoinu/ic-stable-memory

It is called ic-stable-memory and it basically allows you use stable memory as main memory.
 
With this library you can create stable variables - variables that live directly on stable memory and do not require a common serialization/deserialization routine during canister upgrades. Also, you can use stable collections (there are two of them at the moment: stable `vec` and stable `hashmap`) which also live purely in stable memory and are able to hold as many elements as a subnet will allow your canister to allocate. 

Remember - this is still version 0.0.1, so it is a bit limited, a bit unoptimized and a bit buggy. But anyway, I encourage you to give it a shot. Also, this is a pretty complex piece of software (at least for me), so any help is also greatly appreciated: PRs, design proposals, bug reports or any other feedback.

Also,  I published some articles (to this new cool purely web3 blogging platform called [papy.rs](https://papy.rs/)) in order to make it easier to understand what this library is and how to use it:

https://suvtk-3iaaa-aaaal-aavfa-cai.raw.ic0.app/d/ic-stable-memory-library-introduction
https://suvtk-3iaaa-aaaal-aavfa-cai.raw.ic0.app/d/ic-stable-memory-library-under-the-hood
https://suvtk-3iaaa-aaaal-aavfa-cai.raw.ic0.app/d/building-a-token-canister-with-ic-stable-memory-library

Hope you'll like it. 
Have a nice day!

-------------------------

Maxfinity | 2022-07-05 23:01:03 UTC | #2

[quote="senior.joinu, post:1, topic:14158"]
Remember - this is still version 0.0.1, so it is a bit limited, a bit unoptimized and a bit buggy. But anyway, I encourage you to give it a shot. Also, this is a pretty complex piece of software (at least for me), so any help is also greatly appreciated: PRs, design proposals, bug reports or any other feedback.
[/quote]

Fantastic work. I will consider using this in our token standard, looks to be exactly what we need.

-------------------------

ovictor | 2022-07-06 03:26:00 UTC | #3

Well Done! I was lokking for something like this and ended adapting the BtreeMap implemented by dfinity team to use the stable memory.:https://github.com/victorcastro89/Ic-stable-storage, 
Original repo: https://github.com/dfinity/ic/tree/master/rs/stable-structures/src

-------------------------

senior.joinu | 2022-07-06 07:56:12 UTC | #4

Thanks! Feel free to reach out.

-------------------------

senior.joinu | 2022-07-06 08:56:12 UTC | #5

Thank you!
Your work is also looks really good. I tried to implement a BTreeMap, but found it kinda tricky at the moment an gave up. 

Do you think it is possible to somehow integrate the code you have into my library?

-------------------------

domwoe | 2022-07-06 12:05:07 UTC | #6

Thanks a lot for taking the time to write those posts in addition to the implementation. I find this very helpful. 

Would it be practical to implement certified data structures on top of this as well?

-------------------------

Maxfinity | 2022-07-06 12:11:40 UTC | #7

[quote="ovictor, post:3, topic:14158"]
Well Done! I was lokking for something like this and ended adapting the BtreeMap implemented by dfinity team to use the stable memory.:[GitHub - victorcastro89/Ic-stable-storage: Rust Stable Storage Implementation ](https://github.com/victorcastro89/Ic-stable-storage),
[/quote]

B+ tree would be more useful than a Btree IMO.

-------------------------

senior.joinu | 2022-07-06 12:36:56 UTC | #8

Thanks!

[quote="domwoe, post:6, topic:14158"]
Would it be practical to implement certified data structures on top of this as well?
[/quote]

This is what I'm thinking of right now. Such a solution could bring a seamless data certification developer experience, but I need to do some more research before trying to implement it. 

There is a thing in Ethereum called Verkle trees. I would like to try to implement it, but I don't know anything about this type of crypto. If someone could assist me with the theory behind it, it would be awesome.

-------------------------

ovictor | 2022-07-06 12:48:39 UTC | #9

I will take a look, how are you allocating/delocating the memory? It grows as needed or can you set boundaries? If the variable is deleted it creates a fragmentation or you realocate it accondingly?
One major problem I see is how to allocate and deallocate memory.

-------------------------

ovictor | 2022-07-06 12:49:33 UTC | #10

And many thanks for sharing this piece of code and the blog posts as well!

-------------------------

domwoe | 2022-07-06 12:56:30 UTC | #11

[quote="senior.joinu, post:8, topic:14158"]
This is what I’m thinking of right now. Such a solution could bring a seamless data certification developer experience, but I need to do some more research before trying to implement it.
[/quote]

Awesome!

[quote="senior.joinu, post:8, topic:14158"]
There is a thing in Ethereum called Verkle trees. I would like to try to implement it, but I don’t know anything about this type of crypto. If someone could assist me with the theory behind it, it would be awesome.
[/quote]

yeah, just with regular data structures there's a large design space of authenticated data structures (That's the general term for what we'd call certified data structures) with different trade offs. Would be great if someone would have a resource that compares different authenticated data structures. I'm not sure if Verkle trees are the best structure to start with.

-------------------------

senior.joinu | 2022-07-06 13:35:03 UTC | #12

[quote="ovictor, post:9, topic:14158"]
how are you allocating/delocating the memory?
[/quote]

There is a segregation free list based memory allocator. When you ask it to allocate a new memory block of some size it will first search it's free-list, if there is no free block of a requested size, then it will try to find any free-block of bigger size. If there is such a bigger block, it will split it in two. If there is no such bigger block it will try to call `stable_grow(1)`. If the call was successful, it will repeat the previous steps. If the call was unsuccessful, it will return `OutOfMemory` to which you can respond programmatically (e.g. spawn another canister to scale horizontally).

You can't set artificial grow boundaries rn, but it seems like a good idea to add such feature. Thanks!

[quote="ovictor, post:9, topic:14158"]
If the variable is deleted it creates a fragmentation or you realocate it accondingly?
[/quote]
When you delete a variable it frees the memory block. This new free block is added back to the free-list (and possibly joined with it's free neighbors). So, yes, there is a bit fragmentation, but I need to add some tests in order to understand how much of impact does it provide.

-------------------------

lastmjs | 2022-07-07 13:10:46 UTC | #13

Can someone explain to me and ideally point to documentation explaining the current limits of stable memory?

I was under the impression that stable memory was still limited to 8gb per canister.

I assume this might just be an artificial limit by Motoko? Does the Rust CDK not also impose this limit? And where can I go to see how much stable memory a subnet has available to all canisters?

-------------------------

domwoe | 2022-07-07 13:25:24 UTC | #14

[quote="lastmjs, post:13, topic:14158"]
I was under the impression that stable memory was still limited to 8gb per canister.
[/quote]

You're correct. I don't think it's in the docs, but it is in the [code](https://github.com/dfinity/ic/blob/3bd2d654ae6699d0779da6a1eac27ee4fac9784b/rs/types/types/src/lib.rs#L479).

Same case for the [subnet capacity](https://github.com/dfinity/ic/blob/3bd2d654ae6699d0779da6a1eac27ee4fac9784b/rs/config/src/execution_environment.rs#L23).

-------------------------

senior.joinu | 2022-07-07 14:07:31 UTC | #15

Do you know the purpose of this 8gb limit? 
Now It looks like my title is overpromising.

UPD: updated the title and articles

-------------------------

diegop | 2022-07-07 13:49:03 UTC | #16

[quote="domwoe, post:14, topic:14158"]
You’re correct. I don’t think it’s in the docs, but it is in the [code ](https://github.com/dfinity/ic/blob/3bd2d654ae6699d0779da6a1eac27ee4fac9784b/rs/types/types/src/lib.rs#L479).
[/quote]

Following up: When I saw this thread yesterday, I realized the 8GB capacity is too hard to find in the docs, so I am making a PR to update the docs.

-------------------------

domwoe | 2022-07-07 15:52:57 UTC | #17

[quote="senior.joinu, post:15, topic:14158"]
Do you know the purpose of this 8gb limit?
[/quote]

We started with having 4GB just to accommodate the use case of upgrading canisters and I think we are just cautious with increasing it too much because it's always hard to put back a restriction, and thus far no one is close to using the 8GB.

-------------------------

diegop | 2022-07-07 16:26:15 UTC | #18

I think this previous update from the DFINITY team working on execution (Wasm, memory) would help give context:

https://forum.dfinity.org/t/increased-canister-smart-contract-memory/6148/114?u=diegop

-------------------------

lastmjs | 2022-07-07 17:19:29 UTC | #19

Can we start lifting the limit? Keeping it artificially low in my case is kind of preventing me from using it in [Sudograph](https://github.com/sudograph/sudograph). I would like to be able to tell people how much storage they can use in Sudograph, that's a major limitation to people. I also would love to see a schedule to know when we can expect limits to be lifted. If we can really get into the 100s of GB then this might be an all-in solution for Sudograph and any other library that is willing to embrace stable memory data structures.

Keeping it low might be a self-fulfilling prophecy, as people know they can't use it for much thus perhaps they don't.

-------------------------

senior.joinu | 2022-07-11 22:10:05 UTC | #20

ic-stable-memory promoted to v0.1.0!

Features:
* new safer & easier stable variables API
* `SHashSet` collection
* `SBinaryHeap` collection
* bug fixes

-------------------------

simdi.jinkins | 2022-07-15 06:22:38 UTC | #21

Wow, this some really dope work, might completely change my strategy of doing things currently, thanks alot. Really interested in how things work under the hood

-------------------------

senior.joinu | 2022-08-05 22:18:22 UTC | #22

# v0.2.0
`ic-stable-memory` has been promoted to v0.2.0 with huge update and breaking changes!

## Breaking changes
### 1. Bye Candid, hello [Speedy](https://docs.rs/speedy/latest/speedy/)
`Speedy` is a serialization library which is now used by `ic-stable-memory`, instead of `Candid`. 
This has some implications: both good and bad.

Bad:
* Developers are now obligated to use both `Candid` and `Speedy` in their canisters, if they want to use `ic-stable-memory`, which would have a negative impact on module size.
* This is a breaking change, so you have to make your stuctures stored in stable memory compatible with `Speedy`. This is pretty easy though - just switch `CandidType` and `Deserialize` derive macros to `speedy::Readable` and `speedy::Writable`.
* Now the `Motoko` version of `ic-stable-memory` would be very hard to implement. I didn't have a plan to do it anyway, but now, without `Candid`, it would take too much effort to even try.

Good:
* `Speedy` is a lot (up to x10 times in some benchmarks) faster than `serde` and has a better memory footprint (does not store `DIDL` magic string or anything like this) than `Candid`. In other words, it just works better for storage-related operations (but `Candid` is still top choice when it comes to networking and interoperability).
* IMO `Speedy` is easier to work with. It has the same kind of `derive macro` system, but It is easier to implement these macros by hand, when you really need it for some reason.

### 2. "Memory low" handler system
Previously, every function of `ic-stable-memory` allocating new stable memory returned `Result<T, OutOfMemory>`. You could use this return value in order to understand whether the canister's memory is over or not. This worked bad for two reasons:
1. Poor API. Basically, you had to append `.unwrap_or_else(...)` to each allocating method of any stable collection (e.g. `svec.push()`) in order to catch this `OutOfMemory` error. The code looked bloated with this garbage, providing awful readability.
2. On my side, I had to implement stable collections in a transactional fashion, so each method, if it throws a error, would reset to the previous state. For some collections this was really easy to achieve, but for some others (like a btree map) this was a pain.

Now I removed this `OutOfMemory` from a user-faced API completely. Instead, the library will always make sure, that you have some stable memory available. Once your canister reaches the memory limit (but it still has some free memory available), a special user-defined handler update function `on_low_stable_memory()` will be called. In the body of this function you can do anything you want: spawn a new canister, send a e-mail to the developer and so on. Once the memory is really over - the library will just trap, keeping the state safe from corruption.

As a breaking change, this will require some work from you to support. All you have to do is to move your `OutOutMemory` reaction logic to `on_low_stable_memory()` and to clean your code from every `unwrap()` or `expect()` that were following your stable collections functions invocations.

The Github readme file now has a section about this mechanism.

## Other updates
* `SBtreeMap` and `SBtreeSet` are now available as stable collections. They are pretty slow at the moment, but they work. Total list of supported collections: `SVec`, `SBinaryHeap`, `SHashMap`, `SHashSet`, `SBTreeMap` and `SBTreeSet`.
* It is possible to use `ic-stable-memory` with stable Rust channel (nightly is no longer a requirement).
* Optimizations. All stable collections (except for BTree-based ones) are now working 20-40 times faster than before (the repo also contains benchmarks now).
* Stability improvements.

## What's next
* Update tutorials in order to reflect these new details (UPD: done).
* Focus on stability and performance. The goal is to achieve a state, where it is economically reasonable to use `ic-stable-memory` instead of the standard approach with horizontal scaling and `pre_upgrade/post_upgrade` routine.

-------------------------

dymayday | 2022-08-05 22:10:53 UTC | #23

Wow improvements look super nice ! I'll definitely give this lib a try for a new storage project soon !

One question tho : what was the incentive to use [speedy](https://crates.io/crates/speedy) over another serializer like [Message Pack](https://crates.io/crates/rmp) (which Distrikt, OpenChat and Dcvr already use extensively) for example ? Which gives around the same performance improvements in my findings.

-------------------------

senior.joinu | 2022-08-05 22:15:25 UTC | #24

Great to hear that, thanks!

I used benchmarks as a main source of info for this decision making session. For example, [this one](https://github.com/djkoloski/rust_serialization_benchmark), says that speedy is much faster than rmp and has a better memory footprint.

I like this benchmark repo, because they compare against [Abomonation](https://github.com/TimelyDataflow/abomonation). Which I find very reasonable, since you just can't make a faster thing than Abomonation.

But, like the song goes: in the end it doesn't even matter. Any storage-focused library would work just fine and will get its job done. Thanks for your feedback on that one!

-------------------------

diegop | 2022-08-06 03:43:50 UTC | #25

[quote="senior.joinu, post:22, topic:14158"]
`ic-stable-memory` has been promoted to v0.2.0 with huge update and breaking changes!
[/quote]

I’ve been playing with Rust stable memory for some sample dapps, so very eager to add this to my list. Thanks!

-------------------------

saikatdas0790 | 2022-08-06 05:33:57 UTC | #26

Definitely trying this.

Thank you for enabling rust `stable` channel support.

-------------------------

saikatdas0790 | 2022-08-06 11:18:56 UTC | #27

@senior.joinu I tried it and ran into this bug.

![image|550x207](upload://fKRjow4d2XKIf1qARlm9D6tfBEi.png)

Opened an issue for it [here](https://github.com/seniorjoinu/ic-stable-memory/issues/3)

There's a minimal reproduction in the issue. Let me know if there's any other detail I can provide :slight_smile:

-------------------------

senior.joinu | 2022-08-07 11:37:28 UTC | #28

Hey there!

Fixed. Check the issue for more details.

-------------------------

saikatdas0790 | 2022-08-07 16:12:48 UTC | #29

Hi @senior.joinu I ran into another issue with `SPrincipal`. Created a separate issue for it [here](https://github.com/seniorjoinu/ic-stable-memory/issues/4) with a minimal reproduction

Let me know if there's any further details I can provide :slight_smile:

-------------------------

senior.joinu | 2022-08-08 09:27:46 UTC | #30

Hello again!

New version of the library with this issue fixed is available.
Thanks!

-------------------------

saikatdas0790 | 2022-08-08 11:11:57 UTC | #31

Thank you. Works fine as far as I've tested. :slight_smile:

-------------------------

senior.joinu | 2022-10-25 11:25:01 UTC | #32

# 0.4.0-rc1
Hey there! Huge stability, performance & other updates here.
`ic-stable-memory 0.4.0 release candidate #1` is now published.

The goal for this version was to improve the library so it would be reasonable to use it instead of standard collections. Previous versions had a lot of problems with performance (some collections was 1.5k times slower than the standard ones). But this time everything is much better. 

## Cons
First, let's talk about stuff that some might find upsetting.

1. Collections from `0.4.0-rc1` are __not backwards compatible__ with older ones. This is because they now internally use a custom super-fast (up to 5 times faster than Speedy) serialization engine and because of that they store data differently. If you need a migration guide, please let me know (but I hope that most people simply don't use `ic-stable-memory` in production).

2. `ic-stable-memory` is now a __nightly only__ library, because it strongly relies on a couple of unstable features, namely: `generic_const_exprs` and `thread_local`. So now, in order to use the library you have to install `rust 1.66 nightly toolchain` and also append these lines to the beginning of your `lib.rs`:
```rust
#![feature(thread_local)]
#![feature(generic_const_exprs)]
```

3. `ic-stable-memory` no longer takes care of horizontal scaling - I found out that developers themselves should be able to do a much better job doing it for their exact use-case. So `max_allocation_pages` and `max_grow_pages` settings are removed as well as `on_low_stable_memory` hook. See [this thread](https://forum.dfinity.org/t/increased-canister-smart-contract-memory/6148/138?u=senior.joinu) for more info on how to enable horizontal scaling for your canister.

4. Most collections (except `SBTreeMap` and `SBTreeSet`) are no longer "infinite" - they are now limited to `2**32` elements total. I'm planning on adding an "infinite" `SVec` back in a near future.

## Pros
### Performance improvements

#### Vec

Before
```
"Classic vec push" 1000000 iterations: 463 ms
"Stable vec push" 1000000 iterations: 22606 ms (x49 slower)

"Classic vec pop" 1000000 iterations: 406 ms
"Stable vec pop" 1000000 iterations: 11338 ms (x28 slower)

"Classic vec search" 1000000 iterations: 127 ms
"Stable vec search" 1000000 iterations: 2926 ms (x23 slower)
```
After
```
"Classic vec push" 1000000 iterations: 46 ms
"Stable vec push" 1000000 iterations: 212 ms (x4.6 slower)

"Classic vec search" 1000000 iterations: 102 ms
"Stable vec search" 1000000 iterations: 151 ms (x1.4 slower)

"Classic vec pop" 1000000 iterations: 48 ms
"Stable vec pop" 1000000 iterations: 148 ms (x3 slower)
```

#### Hash map
Before
```
"Classic hash map insert" 100000 iterations: 224 ms
"Stable hash map insert" 100000 iterations: 7199 ms (x32 slower)

"Classic hash map remove" 100000 iterations: 123 ms
"Stable hash map remove" 100000 iterations: 3618 ms (x29 slower)

"Classic hash map search" 100000 iterations: 69 ms
"Stable hash map search" 100000 iterations: 2325 ms (x34 slower)
```
After
```
"Classic hash map insert" 100000 iterations: 96 ms
"Stable hash map insert" 100000 iterations: 387 ms (x4 slower)

"Classic hash map search" 100000 iterations: 47 ms
"Stable hash map search" 100000 iterations: 113 ms (x2.4 slower)

"Classic hash map remove" 100000 iterations: 60 ms
"Stable hash map remove" 100000 iterations: 99 ms (x1.6 slower)
```

#### Hash set
Before
```
"Classic hash set insert" 100000 iterations: 209 ms
"Stable hash set insert" 100000 iterations: 5977 ms (x28 slower)

"Classic hash set remove" 100000 iterations: 180 ms
"Stable hash set remove" 100000 iterations: 2724 ms (x15 slower)

"Classic hash set search" 100000 iterations: 125 ms
"Stable hash set search" 100000 iterations: 2007 ms (x16 slower)
```
After
```
"Classic hash set insert" 100000 iterations: 79 ms
"Stable hash set insert" 100000 iterations: 394 ms (x4.9 slower)

"Classic hash set search" 100000 iterations: 54 ms
"Stable hash set search" 100000 iterations: 97 ms (x1.8 slower)

"Classic hash set remove" 100000 iterations: 56 ms
"Stable hash set remove" 100000 iterations: 99 ms (x1.7 slower)
```

#### BTree map
Before
```
"Classic btree map insert" 10000 iterations: 31 ms
"Stable btree map insert" 10000 iterations: 8981 ms (x298 slower)

"Classic btree map remove" 10000 iterations: 17 ms
"Stable btree map remove" 10000 iterations: 19831 ms (x1166 slower)

"Classic btree map search" 10000 iterations: 15 ms
"Stable btree map search" 10000 iterations: 20710 ms (x1380 slower)
```
After
```
"Classic btree map insert" 100000 iterations: 267 ms
"Stable btree map insert" 100000 iterations: 17050 ms (x63 slower)

"Classic btree map search" 100000 iterations: 138 ms
"Stable btree map search" 100000 iterations: 566 ms (x4.1 slower)

"Classic btree map remove" 100000 iterations: 147 ms
"Stable btree map remove" 100000 iterations: 1349 ms (x9.1 slower)
```

#### BTree set
Before
```
"Classic btree set insert" 10000 iterations: 26 ms
"Stable btree set insert" 10000 iterations: 8920 ms (x343 slower)

"Classic btree set remove" 10000 iterations: 13 ms
"Stable btree set remove" 10000 iterations: 19601 ms (x1507 slower)

"Classic btree set search" 10000 iterations: 16 ms
"Stable btree set search" 10000 iterations: 20569 ms (x1285 slower)
```
After
```
"Classic btree set insert" 100000 iterations: 312 ms
"Stable btree set insert" 100000 iterations: 1771 ms (x5.6 slower)

"Classic btree set search" 100000 iterations: 170 ms
"Stable btree set search" 100000 iterations: 600 ms (x3.5 slower)

"Classic btree set remove" 100000 iterations: 134 ms
"Stable btree set remove" 100000 iterations: 1317 ms (x9.8 slower)
```

#### Binary heap
Before
```
"Classic binary heap push" 1000000 iterations: 995 ms
"Stable binary heap push" 1000000 iterations: 29578 ms (x29 slower)

"Classic binary heap pop" 1000000 iterations: 4453 ms
"Stable binary heap pop" 1000000 iterations: 27159 ms (x6 slower)

"Classic binary heap peek" 1000000 iterations: 133 ms
"Stable binary heap peek" 1000000 iterations: 3314 ms (x25 slower)
```
After
```
"Classic binary heap push" 1000000 iterations: 461 ms
"Stable binary heap push" 1000000 iterations: 11668 ms (x25 slower)

"Classic binary heap peek" 1000000 iterations: 62 ms
"Stable binary heap peek" 1000000 iterations: 144 ms (x2.3 slower)

"Classic binary heap pop" 1000000 iterations: 715 ms
"Stable binary heap pop" 1000000 iterations: 16524 ms (x23 slower)
```

As you can see, in some cases performance gains are obvious, but for some (like `SBinaryHeap`) there is not much changed. This is because some algorithms are sensitive to indirect data and some - don't. Let me explain what I mean.

### Direct & indirect storage

Previously, all collections in `ic-stable-memory` were _indirect_ - for each element they were allocating a new portion of stable memory to store it, but inside they were only storing a pointer to that stable memory. This is what allowed these collections to store any kind of dynamically sized data inside and to be able to migrate this data to new version (to add new fields) on-the-fly. But this also was a big problem from the performance perspective, since such a flow requires (de)allocating and (de)serializing each element.

This is why now all stable collections are _optionally indirect_. Now, there is a special trait `StableAllocated`. This trait should only be implemented for fixed-size data (for something that can easily implement `Copy`). If your data implements this trait, you can pass it straight to a stable collection like so:
```rust
let vec = SVec::<MyData>::new();
```
and the collection will work in high-performance _direct_ mode, storing data inline, right inside the collection. In this case your data will be serialized with the custom serialization engine, that I've mentioned before. This engine serializes everything _without leaving the stack_, straight to a fixed-size byte array. Which makes it a lot faster than any other serialization engine, since all of them are serialize into a heap-allocated buffer.

But if your data is dynamically-sized (or you have a plan to update this data to a new version one day, adding new fields) than you have to store it _indirectly_. For that there is a couple of new smart-pointers: `SBox` and `SBoxMut`:
```rust
let vec = SVec::<SBox<MyData>>::new();
```
In that case, the collection will, as before, allocate a new portion of stable memory somewhere else and internally will only store a pointer to that data. You can wrap any data that implements `speedy::Readable` and `speedy::Writable` in `SBox` or `SBoxMut` - `speedy` is responsible for the serialization is this case.

This indirection polymorphism feature was the longest thing to implement for me and this is why performance gains might not yet look like a big deal for some of you. Internally collections are changed drastically. This will allow for more better optimizations in the future, so don't get upset - from now the library will only become faster and faster. 

### Stability
Test coverage is increased up to __95%__ and in reality it is a couple of percent higher, since `cargo tarpaulin` often shows some trivial lines as uncovered, while they are definitely covered (try it out yourself). I found and fixed a lot of bugs during this work and I hope the library now is much more safe to use than it was before.

But it is still a young software, __please don't use it in production yet__!

### Memory fragmentation
The allocator now also works a lot faster and it can reallocate memory in-place, which makes it a lot easier to resist fragmentation. Not much to say here. I ran some tests internally and it appears that fragmentation for a random dataset is not a big issue (around 5%).

### QoL improvements
All collections are now also have `.iter()` method, which returns an iterator over that collection. For most of them this is a zero-cost very efficient abstraction, but not for BTree-based collections - their iterators are pretty heavy and should only be used for small collections.

`SVec` now has a lot of additional methods like `insert()`, `remove()`, `from::<Vec<_>>()` and `binary_search_by()`.

There is also an additional macro for "un-declaring" a stable variable - `s_remove!(Variable)` - it will remove the variable from the registry and return it's content. If the data that was stored there is droppable (if it is a stable collection), then you have to manually release the memory by calling `.stable_drop()` method on it:
```
let vec = s_remove!(MyStableVector);
unsafe { vec.stable_drop() }; 
```

### Refactors
Once you try it out, you'll notice that some methods changed their name (instead of `.drop()` - `.stable_drop()`; instead of `.get_cloned()` - `.get_copy()` and so on). Some methods that were previously safe (`.from_ptr()` or `.drop()`) are now marked as unsafe. This is because I found these new names and signatures more descriptive and decided to change them while it is still possible to do so without hurting too many people. 

## What's next?
I decided to add this `-rc1` postfix in order to focus your attention once again on the fact that this library is not yet ready to be used in production. My goal is to make version `0.4` as good as possible, before actually releasing it. To make it into a suitable replacement for standard collections.

`Release candidate #2` will be focused around some (probably AVL) augmented binary Merkle tree, that will allow users of `ic-stable-memory` to easily certify data they store. 

I also have a plan to add an infinite `SVec` back (probably will be named as `SRope`) as well as to figure out a way to improve `BTree`-based collections and the `BinaryHeap`, since their performance is still seems poor to me. This amount of work looks to me as another release candidate milestone. 

After that there maybe more release candidates, with the main goal to stabilize the library as much as possible before telling everyone: "Yea, you can use it in you canister".

_____________
Thanks for reading this far. Go try it out and tell me what you think!

By the way, the code for `0.4.0-rc1` is in [develop](https://github.com/seniorjoinu/ic-stable-memory/tree/develop), not in master.

-------------------------

saikatdas0790 | 2022-10-25 05:19:27 UTC | #33

Thank you so much for the amazing updates.

A migration path for canisters using `ic-stable-memory` v0.2.* would be amazing :slight_smile:

-------------------------

saikatdas0790 | 2022-10-25 05:22:23 UTC | #34

[quote="senior.joinu, post:32, topic:14158"]
This is what allowed these collections to store any kind of dynamically sized data inside and to be able to migrate this data to new version (to add new fields) on-the-fly
[/quote]

I am not completely sure how this works. An example would be really helpful.

IF I have a struct Profile with name and then want to add another field age, how would already existing Profile structs co-exist with the new Profile with 2 fields in the same stable collection. If I `get` the value of an older struct, what would be returned in the `age` field?

-------------------------

saikatdas0790 | 2022-10-25 05:23:44 UTC | #35

[quote="senior.joinu, post:32, topic:14158"]
Now, there is a special trait `StableAllocated`. This trait should only be implemented for fixed-size data (for something that can easily implement `Copy`). If your data implements this trait, you can pass it straight to a stable collection
[/quote]

I imagine any data structure containing a `String` type can't utilize this, right?

In that case, looking at the scope, shouldn't the dynamically sized data option be the default?

-------------------------

senior.joinu | 2022-10-25 11:19:35 UTC | #36

[quote="saikatdas0790, post:33, topic:14158, full:true"]
Thank you so much for the amazing updates.

A migration path for canisters using `ic-stable-memory` v0.2.* would be amazing :slight_smile:
[/quote]

Thanks! Sure, you can expect such a guide in a couple of days.

[quote="saikatdas0790, post:34, topic:14158"]
I am not completely sure how this works. An example would be really helpful.
[/quote]

You just have to declare your structures a little bit differently. Imagine intitially you have something like this:
```rust
#[derive(Readale, Writable)]
enum User {
  V1(UserV1)
}

#[derive(Readale, Writable)]
struct UserV1 {
  name: String,
  age: u8,
}
```
And you store those structs in some kind of stable collection:
```rust
type UsersMap = SHashMap<SPrincipal, SBox<User>>;
...
let mut users = s!(UsersMap);
let user_box: SBox<User> = users.get_copy(user_principal).unwrap();

// SBox and SBoxMut implement Deref, so you can simply &
match &user_box {
  User::V1(user) => {
    // do stuff
  }
}
```
Since you're storing users indirectly, you can simply declare a new version like this:

```rust
#[derive(Readale, Writable)]
enum User {
  V1(UserV1),
  V2(UserV2),
}

...

#[derive(Readale, Writable)]
struct UserV2 {
  name: String,
  age: u8,
  phone: String,
}
```
And use it in your code like this:
```rust
match &user_box {
  User::V1(user) => {
    // do stuff
  },
  User::V2(user) => {
    // do stuff with phone number also
  }
}
```
This is both safe and pretty easy to do. 

[quote="saikatdas0790, post:35, topic:14158"]
I imagine any data structure containing a `String` type can’t utilize this, right?

In that case, looking at the scope, shouldn’t the dynamically sized data option be the default?
[/quote]

It depends. First of all, if your string is limited in size (for example, it can't be bigger than 128 bytes) than you can simply convert your string to `[u8; 128]` and store it that way. `StableAllocated` is implemented by default for all primitive numeric types and for [u8] arrays with length equal to some power of two up to 4096 bytes (`0, 1, 2, 4, 8, 16, 32, 64 ... 4096`). Once `generic_const_expr` gets more stable it would be possible to implement it for all [u8] arrays of any size generically.

Second, you still can split your struct into a couple of structs - detach a fixed-size part from the dynamically-sized one. Imagine you have these structs:
```rust
struct TransactionHistoryEntryBase {
  from: SPrincipal, // SPrincipal also implements StableAllocated
  to: SPrincipal,
  amount: SNat, // SNat also implements StableAllocated,
}

// there is no derive macro for this yet 
impl StableAllocated for TransactionHistoryEntryBase {
  ...
}

#[derive(Readable, Writable)]
struct TransactionHistoryEntryDetails {
  memo: String,
  refs: Vec<u64>,
}
```
Together they represent a single business entity `TransactionHistoryEntry` but you can store it in different locations:
```rust
type THEBaseLedger = SVec<TransactionHistoryEntryBase>;
type THEDetailsLedger = SVec<SBox<TransactionHistoryEntryDetails>>;
```
and you can access them separately. You'll still be able to update this data to a new version (by modifying the dynamically-sized part as I showed earlier), but at least some part of your data will be optimized.

And the third option is, as you said, to store everything indirectly using `SBox`-es.

About making an indirect flow to be the default one - yes, maybe you're right, but I'm not sure yet. What I   didn't like about `0.2.0` is that this indirection of storage was hidden from the user. I find this very misleading - developers should know what their code is doing and how it works internally, preferably without having to read through the documentation. This is what I always liked about Rust itself - by default it always does things in the most optimal way. 

In rust there is also a notion of indirection. By default, when you allocate some data and if this data is sized, it will be automatically allocated on stack (directly). And only if you explicitly say to allocate this data on heap (to switch to indirect mode) by putting it into a `Box` it will do so. My motivation was to replicate this behavior and to make the library more idiomatic this way.

-------------------------

saikatdas0790 | 2022-10-26 04:08:31 UTC | #37

Thank you for the explanations.

Makes perfect sense :slight_smile:

-------------------------

hpeebles | 2022-10-26 10:46:51 UTC | #38

@senior.joinu this looks amazing!

I'm keen to move all of the data in OpenStorage (OpenChat's storage service) into stable memory.

One option is to use the [StableStructures](https://github.com/dfinity/stable-structures) built by Dfinity, but that doesn't work nicely when your values vary in size massively. I'd need to create buckets of increasing size which I want to avoid due to added complexity + memory wasted.

Our keys are all 256bit hashes and our values are vec's of bytes of varying sizes.
It looks as if your SHashMap fits our use case perfectly.

Would you recommend using this in production yet?

-------------------------

senior.joinu | 2022-10-26 11:02:14 UTC | #39

Hey, great to hear that!

Yea, hashmap would work, but if this collection is infinite, a btreemap should be better in long run.

[quote="hpeebles, post:38, topic:14158"]
Would you recommend using this in production yet?
[/quote]

Unfortunately, not yet. It needs a bit more time for stabilization until I could recommend it for production.

-------------------------

hpeebles | 2022-10-26 11:04:04 UTC | #40

I'm guessing you recommend BTreeMap because HashMap has to rehash all of the values every so often as items are inserted? Or is there another reason?

-------------------------

senior.joinu | 2022-10-26 11:06:47 UTC | #41

Yes, and it is also limited to maximum of 2/3 * 2**32 elements. So, if you have a plan to use all the 32GBs of stable memory, this collection wouldn't help you.

Hashmaps in general are good when you know how many elements it will have. If this number is unbound, then a BTreeMap should be a better alternative.

-------------------------

hpeebles | 2022-10-26 11:51:20 UTC | #42

I think forcing people to use `speedy` isn't ideal.
You could instead expose a trait with `to_bytes (&T -> &[u8]`) and `from_bytes (&[u8] -> T`)
People can then implement the trait however they want.
For example in my use case both my keys and values are already bytes.
In the current version there would be an unnecessary copy of the bytes [here](https://github.com/seniorjoinu/ic-stable-memory/blob/master/src/primitive/s_unsafe_cell.rs#L18).

-------------------------

senior.joinu | 2022-10-26 11:14:32 UTC | #43

Yea, I agree with you. Gonna reiterate on that one day.

-------------------------

hpeebles | 2022-10-26 11:58:05 UTC | #44

Oh and by the way, once the OpenChat SNS is launched, there will be a bucket of CHAT tokens allocated for dev bounties.

So if you get this lib ready for production so that we can use it we'll definitely send you a nice chunk of CHAT! :grinning:

-------------------------

dymayday | 2022-10-28 09:34:06 UTC | #45

Super excited by this ! 
I can't wait to use it in production here at Distrikt !

-------------------------

cymqqqq | 2023-01-18 07:54:41 UTC | #47

Hi there, any updates? Or can we use this, ic stable memory, in production now?

-------------------------

senior.joinu | 2023-01-18 11:01:30 UTC | #48

I'm finishing the current release at the moment.
Planning to release in a week or two. 

A lot of exiting news, please be patient :slight_smile:

-------------------------

dymayday | 2023-01-18 19:39:56 UTC | #49

Oh man, I did not want to pressure you, but I'm super excited by this !!

-------------------------

cymqqqq | 2023-01-19 01:53:20 UTC | #50

I'm glad to hear that, when the new version comes out, I can use it in my own project :grinning:

-------------------------

cymqqqq | 2023-01-30 03:50:31 UTC | #51

Hi there, are there any updates on your project? :grinning:

-------------------------

senior.joinu | 2023-01-30 11:51:33 UTC | #52

Hello there!
Yes, I think I would need another week to release. 

Found a way to finally make the library completely sound - so had to waste some time with the implementation.

-------------------------

dymayday | 2023-01-30 19:04:46 UTC | #53

Please take the time you need, this is a very important building block so it needs to have the best quality that it can get.
And quality takes time.

-------------------------

cymqqqq | 2023-02-11 10:11:51 UTC | #54

Hi, I'm here again, are there any updates this week? :grinning:

-------------------------

senior.joinu | 2023-02-13 22:42:22 UTC | #55

Hey there!
Sorry for taking so long and not standing with my own words.

Once I've implemented this new complete-soundness-feature, it revealed a lot of problems I was previously unaware. Now these problems are successfully solved.

But there are still a couple of things I want to do, before releasing:
1. New certified data structure received a lot of testing already, but I want to double check on it by running it on the main-net.
2. I want to update the documentation to reflect latest changes and to provide more in-depth view of the library.

Hope to finish with this soon! Stay tuned.

And thank you all for your support. Knowing that there are people who really want to use something you've made is an unbelievable motivation!

-------------------------

senior.joinu | 2023-02-22 21:59:16 UTC | #56

It will never be perfect, but now it's good :slight_smile: 

# :exclamation: `ic-stable-memory` library has been promoted to `v0.4.1` :exclamation:

This is the first release that I consider `safe to use`. A lot of work was done to ensure it works properly and the code is sound. I've spent a lot of time trying to eliminate any possibility of memory leaks or unexpected panics. In fact, I'm so sure about it, that I'm going to start a new project, which is a dapp that will use this library to store everything in stable memory.

The library has changed a lot, so let me walk you through the update.

## 1. Enforced Rust's ownership rules
This is the set of changes, that I come up with very recently and nobody was aware I'm doing it, but it is so cool, that I simply can't start from anything but this.

If you remember, previously each data structure in `ic-stable-memory` had a special `stable_drop()` method, that was used to manually release stable memory, when it no longer needed. In other words, stable collections worked like they were written in `C/C++` and not in Rust. This was a serious source of errors for both: library users and me. In fact, the only one team that was using `ic-stable-memory` previously lost all of their data because of a memory leak.

This is no longer an issue though. I've managed to "connect" stable-allocated values with Rust's borrower, so now they follow the same ownership rules as regular values. Let's see an example:

```rust
{
  let mut vec = SVec::<u64>::new();

  for i in 0..100 {
    vec.push(i).expect("out of memory"); // <- more on this below
  }
} // <- `vec` gets stable-dropped, releasing all the memory automatically
```

Another example:
```rust
thread_local! {
  static STATE: RefCell<Option<SVec<SBox<String>>>> = RefCell::default();
}

#[update]
fn push_string(str: String) {
  STATE.with(|s| {
    let boxed_str = SBox::new(str).expect("out of memory"); 
    
    s
      .borrow_mut()
      .as_mut()
      .unwrap()
      .push(boxed_str)          // <- `boxed_str` will NOT get stable-dropped, 
      .expect("out of memory"); // because it is now owned by STATE
  });
}
```

I know this may not sound as impressive as I'm trying to convince you it is, but this is actually a game-changer in my opinion.

This new set of rules is enforced on runtime. Yes, you lose a tiny bit of performance, but in exchange you **can't leak stable memory** anymore. This is it. The library now provides a guarantee, that while you're using only those functions which are not `unsafe`, you can't leak memory.

Also, have you noticed in the example above, how you could easily swap `SVec` with simple `Vec` and it would continue to be a valid program? This is what following the rules also gives for free - the library now looks and feels like something from Rust's ecosystem. It is now a continuation of the language and not an appendix.

In order to contribute even more into this vibe I also introduced a notion of stable reference. Each stable collection now returns a smart-pointer to the data it owns, instead of a copy of that data.

See this example:
```rust
let mut map_of_stuff = SBTreeMap::<u64, u64>::new();

let value: SRefMut<u64> = map_of_stuff.get_mut(&10).unwrap();

*value = 15; // <- this is a valid code
```
These stable references are lifetime-aware, so it is no longer possible to concurrently mutate the same
data structure twice - the compiler simply won't let that happen.

Also, I removed stable variables from the library. Now you don't need to use this ugly `s! {}` syntax anymore, you can simply use the same techniques you use with `std` collections, like using `thread_local!`.

All together these changes make it feel like you're just using common data structures, common Rust, despite the fact that there is a whole custom memory allocator works under the hood and the data is actually not in the stack or not in the heap, but in some other place that only has `read_bytes` and `write_bytes` methods to it.

## 2. New stable memory allocator
By the way, about the allocator. I rewrote it completely from scratch to make it more flexible and efficient. 

The old one was `O(n)` for allocations and `O(1)` for deallocations, where `n` is the amount of free blocks in the free-list. The new one is `O(logn)` for both: allocations and deallocations. This should help with the performance of `SBox`-ed values. Also, this new allocator can allocate stable memory blocks up to `u64::MAX` bytes long, which is important for some optimizations. 

## 3. Ready for horizontal scaling
Two previous changes allowed me to re-introduce programmatic handling of `OutOfMemory` errors. Now, any method of the API, that potentially can allocate stable memory returns `Result`, where `Err` variant means, that your subnet is out of stable memory and you have to do something about it.

This feature was in the library from day `0` (and it is actually one of the main reasons, why I wanted to build it), but was removed, when it became clear, that it is impossible to use in complex projects. This is because, when you catch this error and don't panic, you have to reset the changes that you already did to your canister manually. This was very hard, mainly because of `stable_drop()` that you have to call on each thing that you've created so far. But now, when values stable-drop themselves automatically, this is no longer an issue.

**This means, that you can actually program your canister to automatically scale horizontally, when it occupies all available stable memory!**

```rust
  STATE.with(|s| {
    let boxed_str = SBox::new(str).expect("out of memory"); 
    
    let res = s
      .borrow_mut()
      .as_mut()
      .unwrap()
      .push(boxed_str);

    if res.is_err() {
      scale_horizontally().await;  // <- like this, boxed_str will stable-drop automatically
    }
  });
```

## 4. Stable certified map
`ic-stable-memory` now also provides a certified stable collection `SCertifiedBTreeMap`. This is a Merkle tree built on top of a B+ tree. What's more important is that its proofs are compatible with proofs you get from from Dfinity's `RBTree`. 

I've prepared a demo project that is certified assets canister fork, but using only data structures from `ic-stable-memory`. You can find it [here](https://github.com/seniorjoinu/ic-stable-certified-assets) and play with it yourself. I tried it on main-net and was able to render frontend with valid certificates and stuff.

It supports the following proofs:
* set *(in this case - map)* membership proof
* absence proof
* range proof

Also it is written in such a way, so map mutation and Merkle-tree recalculation are separated. This allows doing multiple update operations in batch, but recompute the underlying Merkle tree only once, which can greatly increase the performance in some cases.

By the way, here are benchmarking metrics in a real canister using `performance counter API` comparing to the `RBTree`:

### Insert `5_000` entries
```
rbtree -> `5627092211`
scertifiedbtreemap -> `9108725043` - x1.6 slower
scertifiedbtreemap (in batches of 10) -> `1354608056` - x4.1 faster
```

### Witness `5_000` entries
```
rbtree -> `3273570622`
scertifiedbtreemap -> `3541619761` - x1.08 slower
```

### Remove `5_000` entries
```
rbtree -> `9359364040`
scertifiedbtreemap -> `6693095737` - x1.4 faster
scertifiedbtreemap (in batches of 10) -> `731156025` - x12.8 faster
```
As we can see, batching is totally killing it.

## 5. Stable data structures tweaks
A lot of work was done to improve stability and performance of existing data structures. You can find actual performance benchmarks [here](https://github.com/seniorjoinu/ic-stable-memory/blob/master/docs/benchmarks.md). Here are some short outlines:

* Completely reworked `SBTreeMap`. It is now only x2-x3 times slower that the `std`'s one.
* `SHashMap` now uses `zwohash` and performs deletions without tombstones, which make it keep the performance in shape and not degrade over time. Also, it is now dangerously close in performance with the `std`'s `HashMap`.
* Added new `SLog` collection, which is an infinite analog to `SVec` very well optimized for the most `recent` entries. Should be very handy for storing logs and histories.
* Removed `SBinaryHeap`, since `SBTreeMap` is now simply way faster than my previous binary heap implementation was and I'm out of capacity at the moment to keep it up with the rest of collections.
* All keyed collections (maps and sets) are now accepting `Borrow`-ed keys for searching. For example, if you have a map like this `SHashMap<SBox<String>>, u64>` you can search it simply by `&String` and not by `&SBox<String>`.

## 6. Goodbye Speedy
Yes, Speedy is no longer used. And you're not longer forced to use any serialization engine. In fact, the library is now uses two types of serialization. You can find out more in [this article](https://github.com/seniorjoinu/ic-stable-memory/blob/master/docs/encoding.md).

## 7. Documentation
Yes, the library is finally covered with documentation. There is a complete API documentation on [docs.rs](https://docs.rs/ic-stable-memory/latest/ic_stable_memory/) and also there are a bunch of tutorials on some important topics like `upgradability` or `horizontal scaling` or `performance`. You can find all of them in the Github repo.

https://github.com/seniorjoinu/ic-stable-memory

## 8. Tests
I never in my life wrote so many tests. There are currently around ~120 tests, many of which are randomized. Some of them are completely fuzzy, randomizing even what kind of action they would do with the data structure next. The whole test suite runs about 20-25 minutes on my machine. 

In other words, I did my best, guys. I really want it to be as safe to use as possible. But I also want it to be clear, that I'm the only one who tested it and I'm just a human and bugs may appear anyway. Please let me know, if you'll find one.

# What's next
As I said earlier, I consider this library as a finished product that can be used as-is. It doesn't mean, that I won't add anything new to it or fix bugs - I will. But from now on my work on this library will be purely **reactive** - if you need something, let me know and together we'll make it happen. If you have questions or want me to create a tutorial on how to handle a particular situation - let me know and we'll figure it out together. 

In other words, in order to improve this library, I now really need your feedback, guys. 

Hope you're having a great day! 
Reach me out here, in this forum thread, or on Github issues.

@domwoe @dymayday @saikatdas0790 @cymqqqq @hpeebles

-------------------------

cymqqqq | 2023-02-23 07:53:09 UTC | #57

Hi, I'm very excited to hear the amazing news!!
And I'm sorry to bother you. :grinning:
Today I haven't read your source code completely, and I see this demo code:
#[init]
fn init() {
  stable_memory_init();

  STATE.with(|s| {
    *s.borrow_mut() = Some(SVec::new());
  });
}

#[pre_upgrade]
fn pre_upgrade() {
  let state: State = STATE.with(|s| s.borrow_mut().take().unwrap());
  let boxed_state = SBox::new(state).expect("Out of memory");

  store_custom_data(0, boxed_state);

  stable_memory_pre_upgrade().expect("Out of memory");
}

#[post_upgrade]
fn post_upgrade() {
  stable_memory_post_upgrade();

  let state = retrieve_custom_data::<State>(0).unwrap().into_inner();
  STATE.with(|s| {
    *s.borrow_mut() = Some(state);
  });
}
I have a question about pre_upgrade, post_upgrade here: do you mean it can support automatically recycling memory now? like motoko, it can automatically recycling memory and no need to manually recycle memory after upgrading canister.

-------------------------

senior.joinu | 2023-02-23 10:20:30 UTC | #58

Hey there!

I'm not quite sure, to what do you mean by saying 

[quote="cymqqqq, post:57, topic:14158"]
no need to manually recycle memory after upgrading canister
[/quote]

These functions: `store_custom_data` and `retrieve_custom_data` change nothing - the data was stored in stable memory all the time. What you do with these functions is you store `pointers` to this data in a known place in stable memory, so you could find this data after the upgrade is done.

And yes, with `ic-stable-memory` you no longer need to manually recycle any memory. Everything will get recycled automatically both: heap and stable memory, but only when the value leaves the scope. 

The idea is that for an observer any code written with `ic-stable-memory` now looks and feels like a code with regular data structures which store data on heap. But under the hood all the data is stored on stable memory.

For you there is no difference now, whether you use `Vec` or `SVec`, `HashMap` of `SHashMap` - the API is the same, ownership rules are the same.

In this particular example, that you've mentioned, actually nothing leaves the scope. In `pre_upgrade` function you take your state (the part of it which lives on stack and not in stable memory) from a static variable and move it to the custom data persistent storage, which now `owns` this data. Then you call `stable_memory_pre_upgrade` and persist the allocator itself in a known location also. Nothing gets released.
Then in `post_upgrade` you restore the allocator by using `stable_memory_post_upgrade` (under the hood the allocator will put itself into the same `thread_local!` static variable), then you retrieve your state from custom data persistent storage and put it back into your own `thread_local!` static variable. Nothing gets realeased, nothing leaves the scope. The data that was in your state never leaves the stable memory and doesn't move inside it. Only pointers move back and forth.

Hope I made it clear.

-------------------------

cymqqqq | 2023-02-23 10:53:56 UTC | #59

Thx for your answer :grinning:
I am ready to dive into your code and maybe have some questions to ask you.
And I plan to develop a dapp based on your project in the future weeks.

-------------------------

senior.joinu | 2023-02-23 11:21:25 UTC | #60

Also, everyone, please notice that old tutorials (from papy.rs) are no longer up-to-date and shouldn't be relied on. 

Tried to remove links from my previous posts, but the forum engine doesn't let me do it.

-------------------------

diegop | 2023-02-23 17:05:57 UTC | #61

[quote="senior.joinu, post:56, topic:14158"]
If you remember, previously each data structure in `ic-stable-memory` had a special `stable_drop()` method, that was used to manually release stable memory, when it no longer needed. In other words, stable collections worked like they were written in `C/C++` and not in Rust. This was a serious source of errors for both: library users and me. In fact, the only one team that was using `ic-stable-memory` previously lost all of their data because of a memory leak.

This is no longer an issue though. I’ve managed to “connect” stable-allocated values with Rust’s borrower, so now they follow the same ownership rules as regular values. Let’s see an example:
[/quote]

I think this is fantastic

-------------------------

senior.joinu | 2023-02-27 10:38:34 UTC | #62

The [documentation](https://github.com/seniorjoinu/ic-stable-memory#documentation)  now has two more sections:
* [Quick start](https://github.com/seniorjoinu/ic-stable-memory/blob/master/docs/quick-start.md) section, which is an entry point for newcomers.
* [Under the hood](https://github.com/seniorjoinu/ic-stable-memory/blob/master/docs/architecture.md) section, which for now only contains diagrams about memory allocation, but in future would be a greater source of inner details.

Hope you'll find them useful.

-------------------------

NS01 | 2023-08-13 10:00:29 UTC | #63

Hello! 

I'm trying to use a SHashMap with [u8, 136] as a key however I'm hitting all sorts of problems. The main issue now seems to be with Candid serialization/ deserialization... which is a bit beyond my rust skills. 

Has anyone got a working example of SHashMap with a [u8, N] type key? 

Code below for context: 

```
#[derive( Deserialize, Serialize, CandidType, StableType, Debug, Hash, Eq, PartialEq)]
struct IDKey([u8; 136]);
impl AsFixedSizeBytes for IDKey {
    const SIZE: usize = 136;
    type Buf = [u8; Self::SIZE]; // use Vec<u8> for generics  
    
    fn as_fixed_size_bytes(&self, buf: &mut [u8]) {
        let key_bytes = self.0.as_slice();
        buf[0] =  key_bytes.len() as u8;
        buf[1..(1 + key_bytes.len())].copy_from_slice(key_bytes);
    }
    
    fn from_fixed_size_bytes(buf: &[u8]) -> Self {
        let key_len = buf[0] as usize;
        let key: &[u8] = &buf[1..(1 + key_len)];
        return IDKey(key.try_into().unwrap());
    }
}

#[derive(AsFixedSizeBytes, Deserialize, StableType, Debug)]
pub struct Directory {
    pub id_to_ref: SHashMap<IDKey, u32>,
    pub ref_to_id: SHashMap<u32, IDKey>,
    pub next_ref: u32,
}
```
 
I know I could use an SBox<String> but I'm trying to avoid this as the Directory will have a lot of lookups/ writes in my code and speed is key.

-------------------------

NS01 | 2023-08-13 15:42:54 UTC | #64

For info folks - Managed to get it to compile.. I didn't realise [u8; Size] was considered a generic as the type was known. I swapped [u8, Size] for Vec<u8> and the errors went away. 

```
#[derive(CandidType, Deserialize, StableType, Hash, Eq, PartialEq, Clone)]
pub struct IDKey(pub Vec<u8>);
impl AsFixedSizeBytes for IDKey {
    const SIZE: usize = 135;
    type Buf =  Vec<u8>; // use for generics  
    
    fn as_fixed_size_bytes(&self, buf: &mut [u8]) {
        let key_bytes = self.0.as_slice();
        buf[0] =  key_bytes.len() as u8;
        buf[1..(1 + key_bytes.len())].copy_from_slice(key_bytes);
    }
    
    fn from_fixed_size_bytes(buf: &[u8]) -> Self {
        let key_len = buf[0] as usize;
        let key: &[u8] = &buf[1..(1 + key_len)];
        return IDKey(key.try_into().unwrap());
    }
}

#[derive(StableType, AsFixedSizeBytes)]
pub struct Directory {
    pub id_to_ref: SHashMap<IDKey, u32>,
    pub ref_to_id: SHashMap<u32, IDKey>,
    pub next_ref: u32,
}
```

-------------------------

senior.joinu | 2023-08-14 10:18:26 UTC | #65

Yea, `AsFixedSizeBytes` is implemented for any `[u8; N]` by default. So you could simply use the derive macro: 
```rust
#[derive(AsFixedSizeBytes, Deserialize, Serialize, CandidType, StableType, Debug, Hash, Eq, PartialEq)]
struct IDKey([u8; 136]);
```

And keep it with an array, instead of vec.

-------------------------

senior.joinu | 2023-08-14 10:43:32 UTC | #66

But it seems like `serde` does not support const generics yet, so in order to implement `CandidType`/`Deserialize` you would have to do something like this:

```rust
#[derive(AsFixedSizeBytes, StableType, Debug, Hash, Eq, PartialEq)]
struct IDKey([u8; 136]);

impl CandidType for IDKey {
    fn _ty() -> candid::types::Type {
        Vec::<u8>::_ty()
    }

    fn idl_serialize<S>(&self, serializer: S) -> Result<(), S::Error>
    where
        S: candid::types::Serializer,
    {
        self.0.idl_serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for IDKey {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let arr = Vec::<u8>::deserialize(deserializer)?.try_into().unwrap();

        Ok(IDKey(arr))
    }
}
```

The serialized is fine, but the deserialized will lose some of the performance due to an allocation.
But this is better in terms of performance, than to use `Vec<u8>` as your key, since most of the time it will work exclusively on stack and only allocate when deserialized (when received as an argument to a canister function).

-------------------------

NS01 | 2023-08-14 13:06:45 UTC | #67

Thats awesome! Thank you 😁

-------------------------

NS01 | 2023-08-14 20:09:42 UTC | #68

Another day another question :rofl:

I've got the stable memory working well however I'm interested in how the stable memory works along with runtime state and if it's possible to persist runtime state over upgrades without overwriting or damaging memory allocated for stable structures. 

Code for reference: 

```
#[derive(StableType, AsFixedSizeBytes, Debug, Default)]
pub struct Main {
    pub canister_data: CanisterSettings,
    pub processed_data: u64,
    pub directory_data: Directory,
}

#[derive(CandidType, Default, Clone)]
pub struct RuntimeState{
    pub latest_txs: BlockHolder,
    pub canister_logs: Vec<LogEntry>,
    pub temp_vec_ptx: Vec<ProcessedTX>,
    pub temp_vec_stx: Vec<SmallTX>
}

thread_local! {
    pub static RUNTIME_STATE: RefCell<RuntimeState> = RefCell::default();
    pub static STABLE_STATE: RefCell<Option<Main>> = RefCell::default();
}

pub fn state_init(){
    stable_memory_init();
    // init stable state
    let mut stable_data = Main::default();
    let default_admin = string_to_idkey(&"2vxsx-fae".to_string()).unwrap();
    let default_canister_name = string_to_idkey(&"Name Me Please!".to_string()).unwrap();
    stable_data.canister_data.authorised.push(default_admin).expect("Out of memory");
    stable_data.canister_data.canister_name = default_canister_name;
    STABLE_STATE.with(|state| {
        *state.borrow_mut() = Some(stable_data);
    });
    
    // init runtime state
    let mut runtime_state = RuntimeState::default();
    runtime_state.latest_txs.init();
    RUNTIME_STATE.with(|state| {
        *state.borrow_mut() = runtime_state;
    });
    log("Canister Initialised");
}

pub fn state_pre_upgrade(){
    let state: Main = STABLE_STATE.with(|s| s.borrow_mut().take().unwrap());
    let boxed_state = SBox::new(state).expect("Out of memory");
    store_custom_data(0, boxed_state);
    stable_memory_pre_upgrade().expect("Out of memory");
}

pub fn state_post_upgrade(){
    stable_memory_post_upgrade();
    let state: Main = retrieve_custom_data::<Main>(0).unwrap().into_inner();
    STABLE_STATE.with(|s| {
      *s.borrow_mut() = Some(state);
    });
}
```

The RUNTIME_STATE structs have a lot of Strings/ Vecs and other dynamically sized stuff which I'd like to keep on the heap rather than in stable memory. Is this possible? 

Thanks in advance! 

Nathan.

-------------------------

senior.joinu | 2023-08-15 08:49:44 UTC | #69

Hey Nathan,

You can store your `RUNTIME_STATE` the same way you're storing your `STABLE_STATE`. 
Just put it inside an `SBox` and use `store_custom_data()` function with another id. 

Since you don't implement `StableType` and `AsDynSizeBytes` for `RuntimeState`, I assume, you can't do that for some reason. So, in this situation, the way you can resolve it is to simply encode/decode it manually, using `candid` encoding functions: `encode_one()` and `decode_one()`. Then you can put the resulting byte array into the `SBox`.

```rust
// I didn't check the following code, before writing it here
// if it doesn't work, please let me know

pub fn state_pre_upgrade(){
    let state: Main = STABLE_STATE.with(|s| s.borrow_mut().take().unwrap());
    let boxed_state = SBox::new(state).expect("Out of memory");
    store_custom_data(0, boxed_state);

    // RefCell supports .take() just like Option does
    let rstate = RUNTIME_STATE.take();
    let bytes = encode_one(rstate).expect("Unable to candid encode");
    let boxed_bytes = SBox::new(bytes).expect("Out of memory");
    store_custom_data(1, boxed_bytes);

    stable_memory_pre_upgrade().expect("Out of memory");
}

pub fn state_post_upgrade(){
    stable_memory_post_upgrade();
    let state: Main = retrieve_custom_data::<Main>(0).unwrap().into_inner();
    STABLE_STATE.with(|s| {
      *s.borrow_mut() = Some(state);
    });

    let bytes: Vec<u8> = retrieve_custom_data(1).unwrap().into_inner();
    let rstate: RuntimeState = decode_one(&bytes).expect("Unable to candid decode");
    RUNTIME_STATE.replace(rstate);
}
```

-------------------------

NS01 | 2023-08-16 07:08:30 UTC | #70

[quote="senior.joinu, post:69, topic:14158"]
```
    let bytes: Vec<u8> = retrieve_custom_data(1).unwrap().into_inner();
    let rstate: RuntimeState = decode_one(&bytes).expect("Unable to candid decode");
    RUNTIME_STATE.replace(rstate);
```
[/quote]

Hey Buddy - Thanks for your help once again! 

I've had a go with this but still hitting a bit of an issue. Got compile errors for take() and replace() being unstable but got around those by using the following code

```
pub fn state_pre_upgrade(){
    // Stable Storage
    let state: Main = STABLE_STATE.with(|s| s.borrow_mut().take().unwrap());
    let boxed_state = SBox::new(state).expect("Out of memory");
    store_custom_data(0, boxed_state);

    // Runtime Storage
    let rstate = RUNTIME_STATE.with(|s|{s.borrow_mut().to_owned()});
    let bytes = encode_one(rstate).expect("Unable to candid encode");
    let boxed_bytes = SBox::new(bytes).expect("Out of memory");
    store_custom_data(1, boxed_bytes);

    stable_memory_pre_upgrade().expect("Out of memory");
}

pub fn state_post_upgrade(){
    stable_memory_post_upgrade();
    let state: Main = retrieve_custom_data::<Main>(0).unwrap().into_inner();
    STABLE_STATE.with(|s| {
      *s.borrow_mut() = Some(state);
    });

    // Runtime Storage 
    let bytes: Vec<u8> = retrieve_custom_data::<RuntimeState>(1).unwrap().into_inner();
    let rstate: RuntimeState = decode_one(&bytes).expect("Unable to candid decode");
    RUNTIME_STATE.with(|s| {
        *s.borrow_mut() = rstate;
      });
}
```
However this then throws an error for .into_inner() for trait bounds not satisfied - AsDynSizeBytes, and StableType. 

So I had a bash at deriving both for RuntimeState. AsDynSizeBytes wasn't a problem as I can use SBoxes to wrap the dynamic stuff, however I hit a bit of a dead end with StableType. 

RuntimeState has a VecDeque which I don't think is supported at all. Removing this from the struct still gives issues with any Vec which contains a struct. I think that StableType only compiles if the type is rust standard type (string etc) or principal type? 

It's not a massive issue if I can't save RUNTIME_STATE during upgrades in this canister.. but would be  a nice-to-have. 

Interested in your thoughts, 

Cheers, 

Nathan.

-------------------------

senior.joinu | 2023-08-16 07:12:45 UTC | #71

The problem is in this line 
```rust
let bytes: Vec<u8> = retrieve_custom_data::<RuntimeState>(1).unwrap().into_inner();
```

Change it like this 
```rust
let bytes: Vec<u8> = retrieve_custom_data(1).unwrap().into_inner();
```

You are no longer storing `RuntimeState` in the stable memory, you are now storing `Vec<u8>`.

-------------------------

NS01 | 2023-08-16 08:04:01 UTC | #72

Slight change.. but yes it works :smiley: :smiley:

```
let bytes: Vec<u8> = retrieve_custom_data::<Vec<u8>>(1).unwrap().into_inner();
```

Thank you!

-------------------------


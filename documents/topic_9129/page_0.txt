lastmjs | 2021-11-27 19:27:45 UTC | #1

I've also discussed this in detail in this Twitter thread: https://twitter.com/lastmjs/status/1464466979386015749

I would love to open up this topic for discussion here, please add your thoughts and corrections if necessary.

The idea is to develop a zero knowledge virtual machine to replace the current IC virtual machine. I'm calling the current virtual machine of the IC the ICVM, and the zero knowledge version the zkICVM.

As I understand it, the ICVM is basically a Wasm runtime ([wasmtime](https://github.com/bytecodealliance/wasmtime), not sure if it's been modified or not) with IC-specific imports allowing canisters to call the IC APIs.

One problem with the current ICVM (or the IC at large) is that it provides no verification of its computations beyond the BFT guarantees of a subnet. This is a major trade-off when you compare the IC to the current version of Ethereum or to Bitcoin.

Bitcoin and Ethereum place a lot of emphasis on allowing their transactions to be verified by all interested parties. They do this by controlling the growth of the blockchain and making all software and blockchain data open. This allows users to use relatively inexpensive computers to download the entire blockchain and run each transaction from genesis.

This is practically impossible to do on the IC for various reasons, and is a major divergence from the long-running blockchain security models of Bitcoin and Ethereum. The point I'm trying to make here is that it's arguable the IC may be giving up a good amount of security in exchange for scalability, based on the unwillingness of the two most successful blockchains to make this trade-off ([though Ethereum may soon be conceding](https://twitter.com/lastmjs/status/1464315882264580101)).

One possible solution to this is to develop a zero knowledge version of the ICVM, which again I'll call the zkICVM. This would provide ZK proofs that would hopefully allow users interacting with subnets to have some verification that both their and others' update calls have been processed correctly, beyond the BFT guarantees of the subnet.

A first step to implementing the zkICVM could be to implement a zkWasm VM. Basically, imagine a zero knowledge version of wasmtime or other Wasm runtimes, that provide proofs of computation in addition to performing the computation. This would hopefully plug into the ICVM with relatively little modification (I assume similar to how wasmtime probably has little modification to be integrated into the IC), thus resulting in the zkICVM.

[zkSync](https://zksync.io/zkevm/), StarkWare, and [Hermez](https://blog.hermez.io/introducing-hermez-zkevm/) I believe are all developing zkEVMs, which are general-purpose turing-complete (or close to it) VMs that provide SNARK or STARK proofs along with execution. I imagine the actual EVM will eventually be replaced with a zkEVM, allowing all Ethereum computation to be verified with natively-generated proofs.

It seems likely that most blockchains will follow this pattern, and perhaps most computation generally. Let's help this along with zkWasm (which will provide benefits even outside of the IC and blockchain) and the zkICVM.

-------------------------

lastmjs | 2021-11-27 20:26:43 UTC | #2

The Ethereum foundation is actually researching the implementation of a native zkEVM:

GitHub: https://github.com/appliedzkp/zkevm-specs
Specs: https://hackmd.io/Hy_nqH4yTOmjjS9nbOArgw

Their reasoning confirms my own:

"At the moment every node on ethereum has to validate every transaction in the ethereum virtual machine. This means that every transaction adds work that everyone needs to do to verify Ethereum’s history. Worse still is that each transaction needs to be verified by every new node. Which means the amount of work a new node needs to do the sync the network is growing constantly. We want to build a proof of validity for the Ethereum blocks to avoid this."

Though we might have to go further than just having one proof per block, since we discard old blocks. If we can somehow maintain a proof that proves old blocks as well, that would be ideal. I'm not sure that's currently possible, as removing the input data might remove the ability to verify the proof.

-------------------------

ildefons | 2021-11-28 01:22:51 UTC | #3

An interesting take on this topic from taken from the Dfinity subreddit: 
https://www.reddit.com/r/dfinity/comments/r0ucfg/comment/hlx9adz/?utm_source=share&utm_medium=web2x&context=3

"L2 ZK rollups do not make sense in context of IC because its whole purpose is to be a scalable blockchain from the beginning. Rollups address the issue of the limited block space of the Ethereum blockchain with low throughput and high fees _as a result_. The block space in IC is practically unlimited as the number of subnets. Rollups are rather "patches" for the design limitations."

-------------------------

lastmjs | 2021-11-28 01:41:45 UTC | #4

Yes, rollups are a separate topic (and I agree aren't really useful on the IC). This thread is about a zero knowledge virtual machine, not zero knowledge rollups.

-------------------------

jzxchiang | 2021-11-30 05:39:01 UTC | #5

Thanks for writing this.

Can you explain why the BFT guarantees of the IC don't allow a subnet to verify computations? My (limited) understanding of Chain Key Technology is that it does.

Here's an excerpt from a great Medium [article](https://medium.com/dfinity/chain-key-technology-one-public-key-for-the-internet-computer-6a3644901e28) about Chain Key Technology:

> For the nodes to jointly generate a signature on a message, a standard threshold signing algorithm is sufficient. For the generation and maintenance of all the keys, the DFINITY team has invented new cryptography that we are going to explain at a high level now. <mark>There are two main procedures that we have built: (1) The formation of new subnets and the generation of the key materials for them is done by the Internet Computer’s Network Nervous System (NNS) which is implemented by canisters that run on the initial subnet that is created at genesis; and (2) Once the nodes that are to form a new subnet have received their key materials from the NNS and started to operate a new subnet, the subnet will manage and maintain its keys itself as per the Internet Computer Protocol.</mark>

> These two procedures are built from a number of cryptographic primitives including threshold signatures, public key encryption, and **non-interactive zero-knowledge proofs**.

> Chain Key cryptography will generate secure key materials as long as a *single* dealer is honest, a criterion which is satisfied if more than one-third of the nodes of the NNS subnet will act as dealers. They each generate a public key, encrypt secret key shares under the encryption keys that the new nodes have made available when registering with the Internet Computer, and then add our tailor-designed **noninteractive zero-knowledge proofs** that they have done all of this correctly. The NNS subnet as a whole verifies these proofs and, if they are correct, makes the information provided by all of the dealers available to the nodes of the new subnet.

In other words, the IC already internally uses ZK proofs.

In fact, the IC's use of ZK proofs allows its subnets to generate catch-up packages, which as a side effect allows subnet blockchains to throw away old state. In other words, the IC has already solved the problem  you mention the Ethereum Foundation is currently researching.

Take all this with a grain of salt... I am no expert on this. Can someone from DFINITY chime in? I too am curious how the IC fits into a ZK-dominated ecosystem, which seems to be the direction Ethereum is heading in. (I am the author of that Reddit post lol)

-------------------------

lastmjs | 2021-11-30 06:29:37 UTC | #6

To the best of my knowledge, and it would be great for DFINITY engineers to discuss:

Notice that the zero knowledge proofs described in those excerpts above are being used to manage the chain key secret key materials, which don't have much to do with canister execution. It is the canister execution that this proposal wishes to add zero knowledge proofs to.

Once a proper chain key is setup for a subnet, we have high assurance that execution is performed correctly only according to the BFT guarantees of that subnet. As for why BFT guarantees are not enough, we're basically blindly trusting that 2/3 of the nodes are honest. The problem is that any 2/3 could collude to push through bad state changes, and you as a user would not necessarily be able to immediately tell, because BFT hasn't been broken.

Zero knowledge proofs of canister execution would provide a proof that the execution was performed correctly, regardless of any BFT guarantees. Even if 2/3 of the nodes were malicious, an incorrect state change would not be able to provide a correct proof. You as a user would then know that something is not correct.

On Ethereum, one defense to a 50% attack is the ability to verify all transactions from genesis for yourself. As soon as a bad transaction came into your node, your node could reject it. Hopefully many other honest nodes would also be rejecting the incorrect state change, and together you may be able to record the correct state of the chain and hopefully restore it once the attack is over. Others have probably thought much more deeply about how local transaction verification provides greater security, but I think that's the general idea.

The Internet Computer provides no such defense to users, they simply trust execution blindly. Chain key signatures mean nothing if 2/3 of the nodes are malicious. Zero knowledge proofs will provide this extra assurance that the IC is working as intended.

-------------------------

lastmjs | 2021-11-30 06:35:53 UTC | #7

[quote="jzxchiang, post:5, topic:9129"]
which as a side effect allows subnet blockchains to throw away old state
[/quote]

The current zero knowledge proofs, chain key, and catch-up packages do not simply allow the IC to throw away old state without a trade-off in security. I feel the materials explainring this have been misleading and incorrect. Dominic Williams seems to finally explain this trade-off in this episode of Epicenter: https://epicenter.tv/episodes/406

Throwing away old state comes with an absolute trade-off in security compared with other blockchains. On the IC you cannot verify the state of the blockchain on your own, you simply trust. This is worse than many other blockchains.

-------------------------

lastmjs | 2021-11-30 06:41:03 UTC | #8

[quote="jzxchiang, post:5, topic:9129"]
In other words, the IC has already solved the problem you mention the Ethereum Foundation is currently researching.
[/quote]

Hopefully it is clearer now that this is not the case.

-------------------------

rubenhorne | 2021-12-01 03:41:08 UTC | #9

It seems like we could substantially increase the trust in computations on the IC by implementing a zero knowledge machine. What can we do to help get such a machine onto the IC? I imagine the implementation would have to come from Dfinity? Or could an independent coder do it?

-------------------------

lastmjs | 2021-12-01 04:49:10 UTC | #10

I don't think DFINITY necessarily has to do it. We can start with a zkWasm VM, which would be generally beneficial outside of the IC and blockchain. I've been reaching out to zk projects to understand if any work is being done on a zkWasm VM. So far I haven't found any indication that a zkWasm VM is in the works. There seem to be plenty of general purpose ZKVMs out there in various stages of development, but nothing as tidy and easy to use as zkWasm would be.

A really practical thing you can all join me in doing is getting on Twitter, Discord, etc with all of the existing ZK projects, and asking them about zkWasm and finding out of there is any appetite to build it.

-------------------------

jzxchiang | 2021-12-01 07:49:58 UTC | #11

> Zero knowledge proofs of canister execution would provide a proof that the execution was performed correctly, regardless of any BFT guarantees. Even if 2/3 of the nodes were malicious, an incorrect state change would not be able to provide a correct proof. You as a user would then know that something is not correct.

Wouldn't any zero-knowledge proof be provided (i.e. jointly signed?) by those same nodes anyways? So if 2/3 of nodes are corrupt, can't they also collude to provide a seemingly correct proof? Not sure how ZK proofs can get around that.

I always thought ZK proof was a way for one blockchain (like a rollup) to tell another blockchain (like Ethereum) that some block generated by the rollup is valid. In other words, I thought it was "inter-chain".

In this case, you're referring to proofs made by nodes in the same subnet, which is "intra-chain". I dunno... would be nice to get clarification by DFINITY on something as fundamental as this.

> I feel the materials explainring this have been misleading and incorrect. Dominic Williams seems to finally explain this trade-off in this episode of Epicenter: [https://epicenter.tv/episodes/406 ](https://epicenter.tv/episodes/406)

Do you mind sharing when in this episode he talks about this? Also, kinda wished these episodes were timestamped... not sure if this was recorded a year ago or last week.

-------------------------

lastmjs | 2021-12-01 09:03:30 UTC | #12

Here's one example of a ZK VM: https://github.com/GuildOfWeavers/distaff#Writing-programs

This project is basically what we would want to develop (perhaps a SNARK/PLONK would be used instead?), but instead of using their DSL bytecode or assembly, we would use Wasm bytecode, thus it would be a zkWasm VM.

Then any program written in Rust, C, Motoko, or anything else that compiles to Wasm could run on the VM, and proofs could be produced!

Here's another similar project: https://github.com/novifinancial/winterfell

-------------------------

spencer | 2021-12-01 13:45:20 UTC | #13

[It’s from august 24th 2021](https://open.spotify.com/episode/7ifLBUNgVqShQanCbz0XjJ?si=wpFVd9HzSmKGSobg3vdVqA)

-------------------------

jzxchiang | 2021-12-02 20:52:50 UTC | #14

This is cool stuff. Right now, zk VMs are like a magic black box to me.

Surely there must be limitations on what programs they can run? It sounds too good to be true for a holder of a zk proof to be able to verify that some output was indeed generated by some input + program given only the program source hash for ANY arbitrary program... how does that even work lol

-------------------------

JensGroth | 2021-12-12 16:21:05 UTC | #15

I'd love to work on this! :slight_smile: 
I'll add the potential benefit of privacy: a single node can do the computation (with some backup mechanism to not lose state if it crashes) and prove the computation is correct, which enables confidential computation where you trust one node (plus backups) instead of every node in a subnet.
The disadvantage is cost. In theory you can do SNARKs for Wasm, in practice it will make execution orders of magnitude slower. So the question is which applications want to make the tradeoff.

-------------------------

Esz14 | 2021-12-13 09:30:46 UTC | #16

How would this work with wasi imports and i/o operations? E.g. if the input is a path and uses the runtime to read the input file? Or the output is actually writing to the file system or uploading to an api?

-------------------------

Maxfinity | 2021-12-13 14:10:20 UTC | #17

I think in terms of scalability the IC is making different trade-offs compared to the roll-up centric ZK world of Ethereum. I don't actually feel as though this is a bad thing. The PBFT style consensus is the way to go as it lets you get the security guarantees without having to do all that work without using snarks and data availability proofs, which I am not sure are all that friendly for the interoperability side. 

Using BLS signatures is actually a beautiful way of handling interoperability, as it means one only needs the signature to verify data cross-chain rather than using the state-roots from snarks. 

Not saying there aren't other advantages to a snark-based VM like privacy. That's a separate topic. But seems the TEE enhancement proposal may also help with privacy as well.

-------------------------

Maxfinity | 2021-12-13 14:14:26 UTC | #18

[quote="Maxfinity, post:17, topic:9129"]
Not saying there aren’t other advantages to a snark-based VM like privacy. That’s a separate topic. But seems the TEE enhancement proposal may also help with privacy as well.
[/quote]

In terms of meeting with the ETH 2.0 roadmap, I actually think that the data-availability proofs would be most useful. If we wanted to archive and verify the prior state of the IC. 

Snarks seem like a substitute for BFT consensus, which is not needed in the current design of the IC IMO, unless it is to enhance specific  applications.

-------------------------

lastmjs | 2021-12-13 23:22:58 UTC | #19

I would love you to work on this.

-------------------------

jzxchiang | 2021-12-16 20:57:35 UTC | #20

After reading this recent [article](https://medium.com/dfinity/the-internet-computer-blockchains-privacy-advantages-73340c6c42db) by @JensGroth on privacy on the IC, I was struck by this part:

> As the Internet Computer grows more sophisticated, we expect transparency to increase. One option is verifiable builds of canisters. Canisters are provided by developers in the form of WebAssembly (Wasm) modules. Deterministic compilers can link the Wasm module directly to the original source code.

I wonder if this is a potential application of zk proofs. For example, some canister build process could generate a proof in addition to the actual compiled wasm binary. Then, others could verify (with the proof) that the binary came from the published source code without repeating the potentially expensive compilation themselves. Of course, like before this still requires the canister be open source.

Not sure if this is actually a step forward... just thinking aloud.

-------------------------

mparikh | 2021-12-16 21:10:16 UTC | #21

Not sure. If the claim is that f(x)=2*x why wouldn't just the proof of computation work? Why would I (as a verifier) need to see the inner workings (open source) if there is a witness to the computation?

-------------------------

jzxchiang | 2021-12-16 21:15:52 UTC | #22

You don't need to see f, but you do need to see x.

In the case of building a canister, the compiler is f and the canister source code is x.

In order to verify a zk proof, I believe you need:

* the input x
* the output f(x)
* some hash of the program hash(f)
* the zk proof itself

The zero-knowledge part means that you don't need to actually run f on x (or perhaps know what f is, just its hash).

Please correct me if I'm wrong here...

-------------------------

mparikh | 2021-12-16 21:20:37 UTC | #23

Yes.

My thinking was around how to get verifiable builds around a closed source system; without "trusted members of community" vouching for the veracity of the build.

-------------------------

jzxchiang | 2021-12-16 21:24:37 UTC | #24

I was thinking about this too, but I'm not sure the word "verifiable" even makes sense for closed source canisters. What is there to verify if you don't know the source code? By definition, "verifiable" usually means to verify that some binary came from some source, in this context.

But perhaps you could verify something else, for example privacy.

Another quote from that same article I linked:

>  Even if some canisters do not want to disclose their source code, there may be help on the way. For instance, there may be verifiably built canisters that offer privacy protection as a service and act as an intermediary between users and closed source canisters to guarantee your privacy. Internet Identity can be seen as an example of a privacy-protection service, offering access to other canisters via a pseudonymous principal.

This is really interesting because now you don't need "trusted" human intermediaries but instead can rely on "trustless" canister intermediaries. Perhaps the closed source canister can somehow "prove" to the trustless canister intermediary that it makes certain privacy guarantees. Not clear on the details here.

-------------------------

lastmjs | 2022-03-11 16:58:22 UTC | #25

I wanted to add something I just learned about STARKs, which is that they appear to be post-quantum secure: https://eprint.iacr.org/2018/046.pdf

I wonder if part of an elegant solution to post-quantum security on the IC would be to implement the zkICVM.

-------------------------

singularity | 2022-06-19 12:03:50 UTC | #26

Is this being worked on?

-------------------------

Omaxus | 2022-06-19 21:31:38 UTC | #27

Sorry, but I dont see any benefits.
If the majority of ethereum nodes are corrupted they can accept any transactions. Zero knowledge will not fix it if the source is corrupted. The majority of the nodes have to accept it.

ZkProofs shall help to speed up the consensus and it is required by ethereum.

Someone has to explain why zk shall help ic to become better / quicker  with respect to scalability etc.

Consensus is general impossible if the number of tolerated  faults are violated independent of what kind of security mechanism is used.

-------------------------

lastmjs | 2022-06-21 23:31:09 UTC | #28

Not that I know of, I'm trying to find people interested and I'm happy to guide where I can

-------------------------

lastmjs | 2022-06-21 23:34:38 UTC | #29

The main benefit I am hoping exists is that users of the IC would be able to verify that the replicas are executing transactions (state updates) correctly, without requiring users to run nodes themselves and perform all state transitions from the beginning (which is not possible given the current design, for scalability).

So it seems like having one validity proof served to you from one node would not be good enough, but perhaps the user could query all nodes in a subnet and compare proofs, or at some check point all nodes could threshold-sign a validity proof proving that the current epoch of state transitions was done correctly.

Consensus is still required, but validity proofs may make verification extremely cheap and decentralized. Hopefully it would become very easy to discover and prove fraud. But right now we just have to trust that 2/3 of the nodes are not malicious, there is no way to verify for ourselves that computations are being performed correctly.

-------------------------

tcpim | 2022-07-08 08:40:48 UTC | #30

When 2/3 of nodes are malicious and take over the subnet, how would NNS know about this immediately and take action? Does NNS slash nodes that are being malicious and have not taken over the subnet yet, and how?

The last paragraph of https://forum.dfinity.org/t/shuffling-node-memberships-of-subnets-an-exploratory-conversation/7478/55?u=tcpim seems to be relative but not completely answer this specific question. @Manu Would you mind clarifying this?

-------------------------

Zane | 2022-07-20 13:43:53 UTC | #31

Seems Polygon has released the first zkEVM with 1:1 feature parity to EVM: 
https://twitter.com/MihailoBjelic/status/1549737067059597313?t=lBXJ5zJH8rxGYeyVwh6oUg&s=19

-------------------------

domwoe | 2022-07-20 14:00:50 UTC | #32

and they're not alone: 

https://twitter.com/Scroll_ZKP/status/1549268276152500225

Announcement from zkSync is also coming soon: https://twitter.com/zksync

-------------------------

lastmjs | 2022-07-20 15:18:40 UTC | #33

A small group of us has formed (about 11 of us right now) to push forward an implementation of zkWasm. If you're interested, please reach out and I can add you to the Telegram group.

Wasm VM is to EVM as zkWasm is to zkEVM.

-------------------------

skilesare | 2022-07-20 15:56:49 UTC | #34

Did they build it in motoko?  Just kidding....seriously though, how realistic would it be to put it in a canister? Is it rust?

-------------------------

jzxchiang | 2022-07-21 06:29:53 UTC | #35

Seems like this week [everybody](https://twitter.com/Scroll_ZKP/status/1549268276152500225) is launching zkEVMs... 

This was a really great [overview](https://hackmd.io/@yezhang/S1_KMMbGt) of what a zkEVM is, the difficulties of implementing one, and why it matters. This [part](https://hackmd.io/@yezhang/S1_KMMbGt#What-else-it-can-bring) in particular is pertinent.

Most projects like Polygon, zkSync, and Scroll are building zkEVMs as part of a L2 rollup to scale Ethereum. Can the IC benefit from the same? If subnets are overloaded with transactions (i.e. update calls), can users submit transactions to some centralized off-chain zkWasm node, which then bundles those transactions into a single update call to the IC? This feature is insane to me... there doesn't seem to be a theoretical limit to how low finality times could go... just add more zkWasm nodes?

But as mentioned in that article, perhaps zk VMs can directly scale L1s. Having users validate proofs themselves off-chain like @lastmjs suggested may be good for security (although it requires the users to maintain state, which means the IC might need to expose that state in a new API??), but I wonder if there are direct performance benefits of a zkWASM as well. Although it would probably require architectural changes to how subnets work.

-------------------------

Sormarler | 2022-08-27 16:36:47 UTC | #36

Any new information or progress on this.

-------------------------

apotheosis | 2022-10-26 03:41:06 UTC | #37

Would also be interesting in learning more about this.

-------------------------

lastmjs | 2022-10-26 04:47:57 UTC | #38

Hey everyone, I'll give an update soon. There are some developments to speak of.

-------------------------

apotheosis | 2022-11-10 01:22:21 UTC | #39

Did you Tweet about this?

-------------------------

apotheosis | 2022-11-10 01:28:08 UTC | #40

Maybe this https://delphinuslab.com/zk-wasm/

-------------------------

cryptodriver | 2022-12-22 02:58:56 UTC | #41

Is this still in discussion? Or already dead?

-------------------------

lastmjs | 2022-12-22 13:42:04 UTC | #42

Yes still in discussions, if anything comes of this it will be a multi-year effort.

-------------------------

paulyoung | 2022-12-22 16:46:21 UTC | #43

I thought this development, the cause, and the proposed solutions might interest people on this thread.

https://twitter.com/kmett/status/1605518640672960512

https://github.com/0xPolygonMiden/miden-vm/issues/605

-------------------------

Sabr | 2022-12-22 17:06:47 UTC | #44

[quote="JensGroth, post:15, topic:9129"]
So the question is which applications want to make the tradeoff.
[/quote]

Blockchain ledgers that actually track a continuity of assets (state) rather than just general application data stored on the IC blockchain. This is critical to protect digital assets like ICP and SNS tokens and to provide a publicly verifiable audit trail of digital asset history. I was frankly shocked to find out that no such independent verification assurance is even possible today.

-------------------------

hokosugi | 2022-12-26 10:34:20 UTC | #45

Given the volume and importance of the data, it would be difficult to apply this to all subnets. Can't we make it so that only the ledger Canister is revalidated?

-------------------------

apotheosis | 2023-03-09 02:30:30 UTC | #46

General conversation happening next week about the state-of-the-art ZKWasm -> https://twitter.com/lastmjs/status/1633631931509121025?s=20

-------------------------

JaMarco | 2023-11-08 14:43:46 UTC | #47

Not sure how relevant this is https://t.co/afCTWYZTbc

-------------------------

Seb | 2023-11-08 14:57:30 UTC | #48

You beat me to it! 
NEAR announced a collaboration with Polygon to build a zkWASM.
 
![WhatsApp Image 2023-11-08 at 14.54.23|666x500](upload://mu8WIY0BMqLufPPRzTQ3CRfHMo.jpeg)

-------------------------

w3tester | 2024-01-10 10:27:50 UTC | #49

Nice post. I have gone through all the contents here. Quick news, [zCloak Network](https://zcloak.network) will deploy a zkVM as a canister in ICP in one or two months. We will use it as a power house for privacy-preserving applications for now (instead of validity proofs). We will show a demo here when the work is done.

-------------------------

lastmjs | 2024-01-10 15:47:38 UTC | #50

Oh wow this is very exciting. If I can ask here, do you have a team/company with a business model for this? I'm always excited about projects that can be sustainable.

-------------------------

w3tester | 2024-01-11 00:52:43 UTC | #51

Thank you @lastmjs! We do have something in mind and would love to talk about the details. For now, we will first make it work :smiley:

-------------------------

apotheosis | 2024-01-17 00:59:57 UTC | #52

Very cool! What proving scheme?

-------------------------

apotheosis | 2024-01-17 01:51:26 UTC | #53

RE: zkWasm. The state of the art zkWasm right now is using Halo2 (slow), with centralized provers mostly focused on 'scaling eth'. A full-fledged zkWasm implementation without those limitations is almost ready for public consumption :slight_smile: Pass it a wasm file and it does the proving, blazing fast, + you can host your verifier anywhere.

p.s. Most proving system today need to compose their proofs into groth16 to get 'on-chain' .....ETH. I think the IC is an obvious solution to this issue, as you can do the compute for the verifiers as-is, no wrapping.

-------------------------

w3tester | 2024-01-17 02:02:52 UTC | #54

We are targeting Polygon Miden VM atm. Will extend to other zkVMs once this approach works out.

-------------------------

lastmjs | 2024-01-17 03:24:54 UTC | #55

How are host imports handled? Is Wasi supported? What are the limitations?

-------------------------

apotheosis | 2024-01-17 03:54:29 UTC | #56

The core opcodes of wasm are supported out of the box. Other functions and also other special proving systems can be added as 'ad-hoc' opcodes. For special provers like those for zkML - we wrap the verifier into a circuit and use it as an opcode. If it works as R1CS it should work well with this system with the caveat that elliptic curved based proving systems will play better together, than those based on hashes.

Host functions are treated as untrusted inputs. So, they should be things you do not mind being public.

-------------------------

w3tester | 2024-02-01 03:23:56 UTC | #57

Hello everyone! We are reporting back. The job is done. Now a Polygon Miden VM for zkSTARK proof verification is live in an ICP canister (beta). For you to easily access it, we have also made a mini maze game on top of it :laughing:

The idea is straightforward:

1. Users run a zk-Program locally in their browser. This can be a calculation of their credit score, an evaluation of their KYC status or, in this case, a proof that they have walked out of a maze. This locally generated ZKP will preserve the privacy of their local data while proving the user meet certain criteria or have some specific attributes.

2. Users send the STARK proof to the zCloak verifier canister to have the proof verified. We have been surprised by the speed and low cost to do this in ICP compared to do it directly in an EVM chain.

3. The verifier canister will sign the verification result with tECDSA and this result can be sent to any EVM chains or even Solana and Sui. As long as the target chain can verify the ECDSA signature, it can consume this ZKP result.

As such, we have a chain abstracted ZKP infrastructure built on ICP.

zCloak Network has only been experimenting building things in ICP for a few months and we are very happy with the results so far. Next up, we will polish the ZKP canister to make it robust and at the same time to use it for our privacy-preserving DID platform.

You can try the game here, and we'd appreciate it if you can like or repost our tweet :smile:
https://twitter.com/zCloakNetwork/status/1752868681313611804

-------------------------

domwoe | 2024-02-01 07:39:37 UTC | #58

This is awesome! Can you roughly compare the cost of verifying on Arbitrum against verifying on ICP + signing + sending + eval on Arbitrum?

-------------------------

w3tester | 2024-02-01 08:16:09 UTC | #59

Thank you @domwoe! We can do a quick breakdown of cost.

If you want to do STARK proof verification in Ethereum or any L2 chain, the main cost would be the call data of your transaction. The average STARK proof we use is around 200KB. You simply cannot send it to the verifier smart contract in one transaction because there is a size limit of call data (around 90KB) in EVM chains. One hack is to split the proof in several transactions and you can put them together later on. But still, you need to pay for the 200KB call data fee in ETH, even you do it in an L2 as they use Ethereum as the DA layer. So basically the cost for one STARK proof verification is several hundred to even a thousand USD, depending on the gas price.

In ICP, the verification itself costs almost nothing. And we just throw the STARK proof away after the verification as there is no need to store the proof data once it gets verified. The generation of the tECDSA will cost about 0.01 USD. Writing the proof result to e.g. Arbitrum will cost 0.02 - 0.2 USD depending on the gas price. 

In conclusion, for a direct STARK proof verification, on average, the ICP approach costs like 10 cents. But if you do it using Ethereum/L2, it will cost hundreds of USD. So we can say that ICP gives us several thousand times fee reduction. :laughing:

-------------------------

icarus | 2024-02-01 13:06:56 UTC | #60

Wow. So what you seem to be telling us is that the Internet Computer is a thousand times more cost efficient as  Zero Knowledge Proof execution platform than  Ethereum and it's L2 chains. More importantly, anyone could run a thousand more proofs per dollar on the IC with cross-chain or off-chain ZKP signature verification thrown in using http out calls and EVM integrations?
What about the runtime efficiency? How many orders of magnitude faster could an IC canister execute process ZKP verifications c.f. Ethereum?

-------------------------

w3tester | 2024-02-02 00:44:50 UTC | #61

I think the answer is yes when we are referring to STARK proofs due to its large size and thus the difficulty to process in Ethereum.

As for runtime efficiency, we did't do the benchmark really. From what we can tell regarding the canister, the verification time is in the order of 0.1 second. We can do some benchmarking later on to find out more.

-------------------------

apotheosis | 2024-02-02 20:15:57 UTC | #62

The next point here is that people need to wrap proving systems so they work on ETH with Groth16, in many case. This takes a lot of work and sometimes does not work at all. Newer proving scheme might be really cool and fast, but it takes a load of effort to make them practical for ETH.

Why not just use them as-is and use tECDSA like is done here? 

In the case of STARKs they either eat the gas fees or use slower provers to make smaller proofs.
ZKP on the IC makes sense all around.

Maybe Dfinity should spend some time preaching at ZK Events? ZKSummit is in Athens this year.

-------------------------

kairos | 2024-02-26 16:49:32 UTC | #63

This is an interesting development from =nil; Foundation that they are calling zkSharding

Also, their zkLLVM compiler allows circuits to be developed straight from C++, Rust, which they used to build their **Type-1** zkEVM.

-------------------------


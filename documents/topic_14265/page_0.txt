domwoe | 2023-03-14 20:41:53 UTC | #1

Hello everyone,

we'd like to announce a new [technical working group](https://forum.dfinity.org/t/announcing-technical-working-groups/11781):

**Topic: Scalability & Performance**
DFINITY lead: @abk
Coordinator: @domwoe
Community Coordinator: @icme 
Discord: [Scalability](https://discord.com/channels/748416164832608337/994942091463512175)
Meeting Notes: [Link](https://drive.google.com/drive/folders/1DADNPf7HJjgu2lzny7ZuzxT1VcVebqtI?usp=sharing)
Cadence: Monthly on the third Thursday of every month at 5:30pm CET
First meeting: July 21, 2022 at 5:30pm CET
The event is part of the regular [calendar for technical working groups](https://calendar.google.com/calendar/u/0?cid=Y19jazBncjc5YmtnY29vaWNuMXA4N21vMWVyb0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t).

The Internet Computer provides a unique blockchain platform for decentralized applications. The actor model allows parallel execution of code in a given subnet and the IC can scale horizontally by adding more subnets. Already today, this allows the building of decentralized applications using smart contracts that aren't possible on other blockchains. However, these are still early days for the Internet Computer, and design patterns for building decentralized applications on a global scale are only starting to emerge. The Internet Computer itself is also continuously maturing with performance improvements, new features, and better tooling. The goal of this working group is to foster a regular exchange between R&D at DFINITY and application developers with the following focus:

* Updates on the relevant R&D roadmap and presentation of ideas
* Collecting and discussing pain points of application developers
* Identification and sharing of best practices and design patterns for building applications on the IC

Thanks a lot to @icme who provided the spark to initiate this working group. We hope that there's interest in the community to participate in this working group. If you think we're missing something important in the scope or you have ideas already for special topics you want to discuss or present please reply in this thread or the [Discord channel](https://discord.com/channels/748416164832608337/994942091463512175).

For the first session of this new working group we'd like to start with an AMA on scalability to get a feeling about the questions and topics that you're pondering with. Please give us a heads up by filling out the following [Typeform](https://dfn.typeform.com/to/SHHsbTg4).

-------------------------

domwoe | 2022-07-12 16:12:18 UTC | #2

Want to bring this to your attention @lastmjs  @paulyoung @Maxfinity @senior.joinu @spnrapp @emilbroman @hassen.saidi @GLdev @C-B-Elite @skilesare 

Probably forgot quite a few (and can't tag more than 10 people in a post as it turns out) so please tag others that might be interested or can contribute :slight_smile:

-------------------------

icme | 2022-07-13 05:07:01 UTC | #3

@quint @Gabriel @jzxchiang 

Also would be great to get some people from the DFINITY Asia community & AstroX @zire @neeboo 

Fee free to tag some people from the gaming community to understand their requirements going forward, as well as @rckprtr @hpeebles to understand their solutions & needs given that they are the top 2 apps on the IC (DSCVR/OpenChat)

-------------------------

domwoe | 2022-07-20 14:32:08 UTC | #4

First meeting is happening tomorrow. Please fill out the [Typeform](https://dfn.typeform.com/to/SHHsbTg4) if you haven't already.

-------------------------

dymayday | 2022-07-20 23:26:46 UTC | #5

Hey Distrikt here 🖖
I'm definitely interested and I will gladly join !
@rckprtr @hpeebles @Maxfinity will you join too ?

-------------------------

hpeebles | 2022-07-21 15:16:21 UTC | #6

I'll be joining! I may be a few minutes late though... (but hopefully I won't be :crossed_fingers:)

-------------------------

domwoe | 2022-07-23 16:15:59 UTC | #7

Thank you all for participating in the first session!

Here are the [notes](https://drive.google.com/drive/folders/1DADNPf7HJjgu2lzny7ZuzxT1VcVebqtI?usp=sharing) and the [recording](https://dfinity.zoom.us/rec/share/WgF0lu16agM3L_-KmwFdwjcbfvEODMW2OKvXlvNh5OyiOcF-pR6itG7SdyiLSzG3.5d9j1Ap8i9y6VAAk).

-------------------------

jzxchiang | 2022-07-22 03:54:41 UTC | #8

Unfortunately, that recording link has expired.

-------------------------

domwoe | 2022-08-16 16:58:33 UTC | #9

Johan is on vacation this week. Hence, we need to postpone the discussion of the roadmap wrt. scalability and performance of the IC. In the survey, the most requested topic was "safe canister upgrades" and two 3/4 of the survey participants are using Rust for canister development. 

One issue that devs encounter in canister upgrades is that the instruction limit gets reached while serializing or deserializing state to/from stable memory. One way to circumvent this is to use stable memory for storing state directly. Additionally, this allows also to use up to 8 GB for canister state currently.

There have been recent developments by Dfinity and the community to increase the usability of stable memory in Rust, and we'll have two presentations on these:

1. @ielashi will present [StableBTreeMap](https://forum.dfinity.org/t/stablebtreemap-in-canisters/14210) which was developed for the Bitcoin Integration
2. @senior.joinu will present [ic-stable-memory](https://forum.dfinity.org/t/ic-stable-memory-rust-library/14158)

I'm looking forward to these presentations and the discussions wrt. the usage of stable memory on the IC.

Please join the session this Thursday (8/18) at 5:30 pm CEST.

-------------------------

icme | 2022-08-18 02:59:24 UTC | #10

Hey everyone,

I've created this [Living Feedback Document](https://docs.google.com/document/d/1aNeMaMELyasAJl0k5aXLIDy16wBk3mdhK6oOtnc4TJo/edit?usp=sharing) for the members of the Scalability and Performance working group and those who are interested.

It contains viewable resource links and content with respect to what we've covered in previous meetings, and members who show up to the meeting will be permitted to comment/suggest questions or feedback to discuss in future meetings. 

If you'd like to suggest a topic to be discussed in future meetings, you can do so by:

 * Commenting in this topic or the #scalability channel in the Developer discord
 * Pinging me to add your topic/feedback to the [Living Feedback Document](https://docs.google.com/document/d/1aNeMaMELyasAJl0k5aXLIDy16wBk3mdhK6oOtnc4TJo/edit?usp=sharing)
 * Attending the meeting :slight_smile: 


<br/>

See you at this Thursdays meeting for some exciting presentations! (See @domwoe's post above)

-------------------------

domwoe | 2022-08-22 09:54:42 UTC | #11

[Notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording](https://dfinity.zoom.us/rec/share/uTpt5-ifluq4x_PCxp_F0ZfyrW53kl9OcwjGaF0adN50d6jmKU62THeAh1UCihTd.MxrNPlizctukvQcf?startTime=1660836822000) for the second session (2022/08/18)

-------------------------

jzxchiang | 2022-08-22 08:40:50 UTC | #12

Thanks for sharing the notes.

I noticed that the notes mention that Johann from DFINITY will soon work on Wasm multiple memories support. Has that been standardized by Wasm yet? (I know it's available in wasmtime with a command-line flag.)

If that is shipped, won't that deprecate most of the libraries that facilitate stable memory access, including `ExperimentalStableMemory` in Motoko? What is the ETA on this? Thanks.

-------------------------

dymayday | 2022-08-22 09:50:02 UTC | #13

Hey thanks for sharing !
I was late for the meeting so I would like to watch what I missed but I get this message when I try to access the recording : `
You cannot view this recording.
No permission.
`

Would you happen to know why @domwoe ?

-------------------------

domwoe | 2022-08-22 09:57:55 UTC | #14

Oh, thanks for the heads up. The permissions were indeed mixed up. Should be working now.

-------------------------

johan | 2022-08-22 11:03:56 UTC | #15

Hi @jzxchiang!

[Multiple memories](https://github.com/WebAssembly/multi-memory/blob/main/proposals/multi-memory/Overview.md) is still in [Phase 3](https://github.com/WebAssembly/proposals), i.e., not fully standardised. But it is already implemented in several engines, including Wasmtime, which the IC uses. Moreover, according to Andreas Rossberg, the proposal's champion, and former principal engineer at DFINITY, the proposal has been unchanged for a long time and is not expected to change. Thus, we are rather comfortable experimenting with using it on the IC. New libraries for Rust and Motoko will be needed to take advantage of multiple memories. We haven't started working on it in earnest, so it is too early to give an ETA. We'll continuously update the Scalability & Performance WG with our progress. Best, Johan.

-------------------------

domwoe | 2022-09-12 09:25:28 UTC | #16

We moved this week's (9/15) Scalability & Performance WG to next week 9/22 same time as usual. If you subscribed to the Technical Working Groups calendar the event should've been updated.

-------------------------

InsaneClownPosse | 2022-09-12 15:10:06 UTC | #17

Didn't know Andreas left Dfinity. Was there a specific reason for this?

-------------------------

esquivada | 2022-09-12 17:50:19 UTC | #19

Andreas Rossberg Still working at Dfinity?

-------------------------

domwoe | 2022-09-13 05:49:09 UTC | #20

No, Andreas left Dfinity a few months ago (maybe the end of June?) but he has been active here in the forum since then.

-------------------------

domwoe | 2022-09-23 14:03:14 UTC | #21

This week is our next Scalability & Performance WG with the following agenda:

- @johan will give a quick update on the plan to increase stable memory on the IC
- @RMCS ([Catalyze](https://catalyze.one/)) will talk about their multi-canister scaling approach and their open issues
 
I'm looking forward to the discussions!

[Link to Recording](https://dfinity.zoom.us/rec/share/wubfxZvXhzw8Oif62rOgktib8t1yZEaNK7AuxD0d9kFsszl7F-_7ZsK0OYKrKBnk.qpM_YpJkNP3c-ajB)

We know that there's a lot of interest in discussing Inter Canister Query Calls (ICQCs) as well, and the plan is to have a discussion on this topic led by @ulan and @dsarlis in the next WG call in October.

-------------------------

domwoe | 2022-10-20 06:51:15 UTC | #22

Reminder: Later **today, at 5:30 pm CEST**, we'll have a discussion on Inter Canister Query Calls and the recent [Composite Queries Proposal](https://forum.dfinity.org/t/proposal-composite-queries/15979)

I'm looking forward to an interesting session!

-------------------------

paulyoung | 2022-10-20 14:36:59 UTC | #23

I won’t be able to make it today due to the meetup in LA.

I think a couple of other people will be there as well.

-------------------------

domwoe | 2022-10-21 07:44:55 UTC | #24

[Link to slides](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording](https://dfinity.zoom.us/rec/share/H5bbsNwkG2tf1Xx3uILbyzhzPWm-pxRjzFExD--KVHAsXN4akjTO-dwpFmjX0Oaa.Nx5Wtsg8JVg_jXL7) of the session on Inter-canister query calls.

-------------------------

JaMarco | 2022-10-21 17:21:47 UTC | #25

How can I view the recording? It says I cannot view the recording because I have no permission.

-------------------------

domwoe | 2022-10-22 18:20:09 UTC | #26

Please try again. I got the permissions wrong.

-------------------------

domwoe | 2022-11-16 13:01:48 UTC | #27

**Tomorrow 11/17 at 5:30pm CET**, the next WG session will happen.

The main topic we'd like to discuss in this session is https://forum.dfinity.org/t/improving-the-utility-of-stable-memory/16210.

Please read the forum post in advance and think about the questions raised.

-------------------------

domwoe | 2022-11-18 10:15:37 UTC | #28

@johan couldn't join the session, so we had a free discussion on stable memory on the IC.

[Updated Meeting Notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [Recording](https://dfinity.zoom.us/rec/share/hNvy_iT9leCFYf6pm2-BsbIex5PBGzE51e0_ZKV3kchocDUZUdJbgCq7Vu6ulqLo.jUpm-o80A9IZqS09).

-------------------------

domwoe | 2022-12-14 10:19:17 UTC | #29

We'll skip this week's Scalability & Performance WG. I already wish you a nice Christmas and see you all in January.

-------------------------

lastmjs | 2022-12-16 14:52:38 UTC | #30

I'd like to follow-up on this question. Will multiple memories do anything that would make stable structures unnecessary?

-------------------------

lastmjs | 2022-12-16 15:05:04 UTC | #31

To specify my question more, will it be possible to create a native data structure (like a Rust struct) and simply tell it which memory to use during instantiation of the data structure? And could one or more memories be set aside as stable, so that we could actually have native stable data structures instead of having to create specialized (and a bit limited) stable data structures?

I'm imagining the main Wasm heap could maintain pointers to native structures in the stable memories, and perhaps on upgrade those pointers can be collected and stored in a stable memory, and then restored to their variables after upgrade.

Is this just crazy talk? @johan @rossberg

-------------------------

ulan | 2022-12-16 16:16:23 UTC | #32

The memory layout of a native data structure is not guaranteed to be stable or backwards compatible. In theory, even if the developer uses the same compiler binary with the same source code, the compiler is still allowed to use a different memory layout of native data structures based on non-deterministic optimizations.

While multi-memories enable fast access to the stable memory, the developer still needs to ensure that data stored in the stable memory is stable and backwards compatible.

-------------------------

domwoe | 2023-01-19 16:24:02 UTC | #33

Hey everybody,

**Tomorrow 01/19 at 5:30pm CET** we'll have the first WG session of 2023.

The main topic for tomorrow will be a discussion on:

*Canister queues (ingress, input and output) overview and case studies of handling large message volumes*

led by @dsarlis.

Looking forward to see many of you!

-------------------------

dymayday | 2023-01-18 19:35:00 UTC | #34

Unfortunately I could not attend this meeting for family reasons. Would you happen to have a recording to share @domwoe please ?

-------------------------

dsarlis | 2023-01-19 09:00:56 UTC | #35

The meeting is actually scheduled for today the 19th (I guess Dominic made a typo on the date that no one noticed :sweat_smile:).

-------------------------

domwoe | 2023-01-19 09:04:08 UTC | #36

[quote="dsarlis, post:35, topic:14265, full:true"]
The meeting is actually scheduled for today the 19th (I guess Dominic made a typo on the date that no one noticed :sweat_smile:).
[/quote]

Oopsie, fixed.

[quote="dymayday, post:34, topic:14265, full:true"]
Unfortunately I could not attend this meeting for family reasons. Would you happen to have a recording to share @domwoe please ?
[/quote]

In any case, I always record and share.

-------------------------

domwoe | 2023-01-19 20:14:39 UTC | #37

Updated [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording](https://dfinity.zoom.us/rec/share/1WQ4WPb-33-_0lZtl_LgqFv06MdPOyrc632NTGSkG98Ajq0kSHCiWIlCKtAcHqBR.SBOnCahfe_KfbbTi).

-------------------------

Samer | 2023-01-21 11:16:06 UTC | #38

Will the recording be uploaded to youtube? Zoom player acting buggy on my side

-------------------------

domwoe | 2023-01-21 19:51:47 UTC | #39

[quote="Samer, post:38, topic:14265"]
Will the recording be uploaded to youtube?
[/quote]

hmm, we haven't uploaded WG sessions to Youtube thus far. I don't think there's a particular blocker but the audience is pretty small at the moment.

-------------------------

skilesare | 2023-01-21 22:07:11 UTC | #40

This would be a great bounty for someone to pursue while exploring these patterns at the library level. Pipelineify already handles a lot of this queuing action, and it would likely need to use some of the libraries that would help with managing input output queues.

https://forum.dfinity.org/t/open-icdevs-org-bounty-43-pipelinify-updates-4-000/17918

-------------------------

blabagastered | 2023-01-22 01:56:22 UTC | #41

I remember reading about throughput limitations of BTC transactions, but can't find it. Something like one transaction per block per subnet. Does anyone know the actual number and whether there is ongoing work to increase it?

Found it: 
[quote="apotheosis, post:1, topic:17767"]
there is a limit of 1 txn/second per subnet
[/quote]

-------------------------

dsarlis | 2023-01-24 12:52:21 UTC | #43

To clarify: the limit you point to is the current throughput of tECDSA signatures per second that a subnet can produce (you need those in order to submit BTC transactions so of course the limit on those sort of implies a limit on the BTC transactions themselves).

AFAIK, the current implementation of tECDSA is not super optimized, so I would expect that this limit can be increased eventually. Likely there is going to be some limit on what a single subnet can do (the protocol is quite complex) but there is always the possibility to allow more subnets to sign using tECDSA which means we can "scale out" the throughput of these operations on the IC as whole.

-------------------------

domwoe | 2023-02-15 10:52:57 UTC | #44

Hey everybody,

we'll be moving this week's session to next week same time: 

**Thursday, February 23rd 5:30pm CET (GMT+1).** 

I've already updated the calendar.

We'll have another session on using storage on the IC. We'll prepare a survey that we'll share before the session and want to discuss the results in the session.

Sorry for the late notice and I hope many of you can join nevertheless.

-------------------------

domwoe | 2023-02-20 14:34:47 UTC | #45

Hey everybody :wave:,

In preparation for the WG session this week, we'd like to invite you to take a quick survey on how you use memory on the IC:

https://dfn.typeform.com/to/VkfeqLPu

Please participate and join the WG on Thursday where we'd like to discuss the results. :pray:

-------------------------

domwoe | 2023-02-23 15:52:02 UTC | #46

Hey everybody :wave:,

The Working Group is happening in about 40 mins (5:30pm GMT+1).

We'll discuss the results of the survey and @senior.joinu will give an update on on the [ic-stable-memory rust library](https://forum.dfinity.org/t/ic-stable-memory-rust-library/14158/56?u=domwoe).

See you soon!

-------------------------

domwoe | 2023-03-07 12:44:39 UTC | #47

Belated update:

[slides](https://docs.google.com/presentation/d/1s1E54d_uD2FRSQMXZaoig7jWjn4fn1o554il9TA3veA/edit?usp=sharing) with the responses from the survey and the [recording](https://dfinity.zoom.us/rec/share/xGNIjUvxEFr1adbxSzTHgXF0m9sO7cMwN0GLll9RDKbhSpyUKDti4tUUIh7JCG3E.GHUtUpqaHopsrLPA).

Some topics from the discussion:

- Discussion on alternative encodings for serializing to stable memory ([bincode]([https://github.com/bincode-org/bincode) and [MessagePack](https://msgpack.org/index.html) instead of Candid)
- Sqlite on the IC. See also https://forum.dfinity.org/t/icsqlite-sqlite-backed-by-stable-memory/16140/17
- Discussion on data structures vs. databases on the IC
- Discussion on cycle limits
- Update on [ic-stable-memory](https://forum.dfinity.org/t/ic-stable-memory-rust-library/14158/56?u=domwoe) which allows dynamic key/value lengths and a certified map compatible with certified assets protocol.

If you watch the recording and have thoughts please feel free to add them here.

**Important**

We have also a request to move the working group from Thursdays at 5:30 pm CET (GMT+1) to Wednesdays at 6:30 pm CET (GMT+1). Are there any objections to that? Note that we'd still use the cadance of every 3rd Wednesday of a month.

@lastmjs @dymayday @skilesare @senior.joinu @icme @dsarlis @claudio @abk @stefan-kaestle @saikatdas0790

-------------------------

dymayday | 2023-03-09 16:45:07 UTC | #48

Hey @domwoe, will the move to 18:30 permanent ?
Sorry for being late on the mater but I feel it is kinda late as it is the time dedicated to the kids for me.

I really enjoy this working group and I don't want to sounds selfish though. This is why I'm asking if this is the permanent schedule from the on.

-------------------------

domwoe | 2023-03-13 15:27:32 UTC | #49

Hey @dymayday,

we wanted to change the date because @abk will take over the DFINITY lead of the working group, and the time didn't really fit for him. However, he read your response and made it work :muscle: .

So **Update**

We won't change the date/time of the Working Group. This means we will have the next session, this Thursday at 5:30pm CET!

-------------------------

abk | 2023-03-15 16:34:10 UTC | #50

Hey everyone,
For the WG tomorrow I'll be presenting some benchmark results comparing the `ic-stable-structures` and `ic-stable-memory` libraries, as well as sharing some tips on efficiently using stable memory. This should be useful for those of you planning to store significant data in stable memory.

-------------------------

domwoe | 2023-03-20 11:17:20 UTC | #51

Updated [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording](https://dfinity.zoom.us/rec/share/hosYjlXEx4Xp3xVrV3_VsN3xr5FbQoyRUwBFo5SjLDcg8o0YXd2036kCMuvOg0Xo.imCiwgOSKPq_cRXz).

**Edit:** Added link to slides to the meeting notes.

-------------------------

josephgranata | 2023-04-05 20:33:03 UTC | #52

@domwoe and @abk we recently joined the forum, and find this Technical Working Group to be really important to everyone who is building, or would like to build an ambitious DAPP.

I will do my best to join the next meeting on Thursday, April 20th.
Have a wonderful Easter everyone, and a good Passover too.

P.S. Thanks so much for sharing the slides and videos!

-------------------------

domwoe | 2023-04-06 06:37:17 UTC | #53

Welcome @josephgranata,

I remember that we already had interactions on Twitter. Good to have you here!

-------------------------

josephgranata | 2023-04-06 18:18:24 UTC | #54

Thanks, the feeling is mutual.

Have a great Holy Week, and Happy Passover too ;-)

-------------------------

domwoe | 2023-04-21 08:15:47 UTC | #55

Join us tomorrow, Thursday, April 20th at 5:30 pm CEST (GMT+2) for the next session of the Scalability & Performance WG. 

We'll have presentations from OpenChat, DSCVR, and Dragginz about their ideas and approaches toward sharding data across canisters.

Pretty exciting, right? Hope to see many of you there for a lively discussion.

[Zoom link](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

Update: [Meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording](https://dfinity.zoom.us/rec/share/OVwPTYpfAT6GX2_JuDhPGd8SnB4ou8dBRV6kvYf8ACaJqLrTT2wEKu9KP9thRLf4.lj_v6CsDeZxBzdi2)

-------------------------

cyberowl | 2023-04-19 10:01:40 UTC | #56

Are any of these sessions recorded?

-------------------------

domwoe | 2023-04-19 10:07:20 UTC | #57

yep, the check the links in the [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing)

-------------------------

domwoe | 2023-05-15 06:01:12 UTC | #58

Hey,

we'll move this month's working group session by one week to **May 25th** because there's a holiday in Switzerland this Thursday.

See you next week!

-------------------------

abk | 2023-05-23 14:10:18 UTC | #59

Hey everyone!
For the session this Thursday @senior.joinu will discuss the design of a new multi-canister storage library and we'll give an overview of the Storage+Scaling ICP.Lab. Hope to see you there!

Adam

Details: Thursday May 25th at 5:30 pm CEST (GMT+2) [Zoom link](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

senior.joinu | 2023-05-25 18:33:36 UTC | #61

In case somebody needs my presentation on union-db:
https://docs.google.com/presentation/d/1YH7BPt2BvwYKOpU_xEGOlbk4relTAxbVYlElAa_Zl6U/edit?usp=sharing

-------------------------

skilesare | 2023-05-25 21:08:24 UTC | #62

Hey @senior.joinu, your presentation is sweet.  I'm sorry I missed the meeting.  I'm pretty sure that canDB gets you 65% of the way to what you want. Transactions are hard and item-level locking is complicated, but it isn't impossible.  CanDB is open source and I'd encourage you to fork, seed pull requests, etc.  I'd love to get @icme 's thoughts on what you put together and how it differed from what you are presenting.

-------------------------

domwoe | 2023-05-25 21:11:31 UTC | #63

I couldn't participate as well, but happy to be able to share the [recording](https://dfinity.zoom.us/rec/share/xZcGQ0d4xMJUGQIgcizbmLufjeOV90xTqFcxekOWa8eTQQn6tH6kKpkDadHyVj9D.7oKrFj5YMYNlQRWo).

-------------------------

skilesare | 2023-05-25 22:04:20 UTC | #64

Ok...I reviewed the video.  Basically, if you add the messaging we've been working on at Origyn with the CanDB stuff and add transactions I think you get this system.  And most of it is already built :slight_smile: 

We need open-source Motoko and rust clients as well.  Right now CanDB mostly assumes that you are working from an outside application and using JS.  But I think we can abstract it to a simple interface...even with transactions.

In addition, we'll be adding icrc_16 candy-like structures that with the proper libraries should allow you to cast back and forth from generic data structures to strongly typed data structures.

Help would be greatly appreciated as we're a bit spread thin at the moment.

-------------------------

abk | 2023-06-14 07:55:27 UTC | #65

New WG Meeting!

This Thursday we'll have @berestovskyy discuss the new Query Caching setup which is leading to big performance improvements. Hope you can make it!

Adam

Details: Thursday June 15th at 5:30 pm CEST (GMT+2) [Zoom link](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

matthewhammer | 2023-06-15 16:14:38 UTC | #66

@berestovskyy Great feature!  I enjoyed the presentation and discussion today.

As I mentioned in the meeting, I think it'd be great to roll out a "trapdoor" to the system-call tracking that's planned in the future.

While the tracking is meant to make each query "correct" (reflect the current system state), there may also be a use case for caching "stale" system state.  If a query uses the trapdoor version of a call, it would get that state, save it, and not invalidate future matches that get a different version from the trapdoor.

The main use case for this feature is for developers to get access to the internal state of the system when a cached call occurs (for whatever purpose that is helpful, e.g., diagnostics or debugging something else) without inhibiting the caching and reuse of that call.

-------------------------

lastmjs | 2023-06-15 16:29:53 UTC | #67

Very impressive work, great presentation. We didn't talk much about the challenges with implementing this for composite queries, I would love to know if that will be difficult or if it's relatively straight-forward.

-------------------------

domwoe | 2023-06-16 13:53:13 UTC | #68

[quote="abk, post:65, topic:14265, full:true"]
New WG Meeting!

This Thursday we’ll have @berestovskyy discuss the new Query Caching setup which is leading to big performance improvements. Hope you can make it!

Adam

Details: Thursday June 15th at 5:30 pm CEST (GMT+2) [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)
[/quote]

Updated [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording](https://dfinity.zoom.us/rec/share/eDMWP2DGXtlwl9lzcXD_cQIoB8GDqttBdN3c7p6Hqj4CHCbvUKEHMNGNYZACesx2.7iSQa90_Wrt9jxgJ).

-------------------------

berestovskyy | 2023-06-19 10:08:48 UTC | #69

[quote="matthewhammer, post:66, topic:14265"]
I think it’d be great to roll out a “trapdoor” to the system-call tracking that’s planned in the future.
[/quote]

I agree. Just to be clear, System API tracking seems like a very lowest hanging fruit for now, and we will focus on that during our next iteration. Later it will be clear if there are still lots of queries which requiring further optimizations...

-------------------------

berestovskyy | 2023-06-19 10:21:00 UTC | #70

[quote="lastmjs, post:67, topic:14265, full:true"]
We didn’t talk much about the challenges with implementing this for composite queries.
[/quote]

AFAIK the initial implementation of the composite queries won't support cross-subnet calls, so it seems quite straightforward to keep the cache coherency.

It will be much easier to prioritize this once we have some numbers in hands. If most of the queries are composite, it might be worth focusing on this even if the engineering effort is significant...

-------------------------

abk | 2023-07-19 06:59:30 UTC | #71

Hello everyone, there's a new WG meeting tomorrow!

DFINITY's own @bogwar will be discussing new plans to support larger canister Wasm modules. Looking forward to seeing you there!

Adam

Details: Thursday July 20th at 5:30 pm CEST (GMT+2) [Zoom link](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

domwoe | 2023-07-21 06:50:16 UTC | #72

[quote="abk, post:71, topic:14265"]
DFINITY’s own @bogwar will be discussing new plans to support larger canister Wasm modules. Looking forward to seeing you there!
[/quote]

Updated [meeting notes ](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) and [recording ](https://dfinity.zoom.us/rec/share/YWB07S9ghWgdui_n-CG7bw6CLW9oF_xJmbEw1ZjIYO3ya6Xysvb-xIIwkxAh0Vls.fAdMfryiT6tYfuNr).

-------------------------

abk | 2023-08-15 12:22:03 UTC | #73

Hello everyone, there’s a new WG Thursday this week!

I'll give a little presentation on how performance changes under horizontal scaling (a multi-canister architecture). Hope you can make it!

Adam

Details: Thursday August 17th at 5:30 pm CEST (GMT+2) [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

domwoe | 2023-08-24 07:22:40 UTC | #74

Recording, meeting notes, and slide deck are available [here](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit).

-------------------------

abk | 2023-09-21 07:26:09 UTC | #75

Hello everyone, there’s a new WG Thursday this week!

@lastmjs will present about performance lessons learned from his work on Kybra and Azle. We're looking forward to having everyone there!

Adam

~~Details: Thursday September 21st at 5:30 pm CEST (GMT+2) [Zoom link](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)~~ (time changed, see next post)

-------------------------

abk | 2023-09-21 07:25:05 UTC | #76

Due to some scheduling conflicts, the working group will actually start 30 minutes later than normal today:

Thursday September 21st at 6:00 pm CEST (GMT+2) [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

domwoe | 2023-09-22 10:55:47 UTC | #77


Recording, (very brief) meeting notes, and transcript are available [here ](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit)

-------------------------

abk | 2023-10-17 13:59:09 UTC | #78

This week we'll have a presentation from OpenChat for the Scalability and Performance WG. They'll talk about some of the tricks they use to keep the UX snappy in OpenChat (both on the frontend and in the canisters).

Thursday October 19th at 5:30 pm CEST (GMT+2) [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

abk | 2023-11-16 07:23:49 UTC | #79

Due to some scheduling issues, the WG won't be happening this month. But we'll be back next month and changing the date to December 14th so that we don't interfere with holiday vacations.

-------------------------

abk | 2023-12-12 09:32:07 UTC | #80

Hi everyone, 
I'm excited to announce that this week we’ll have Timo Hanke(@timo) talking about the [High Performance Ledger](https://forum.dfinity.org/t/annoucement-hpl-a-ledger-for-10k-tps/23951) at the Scalability and Performance WG.

Thursday December 14th at 5:30 pm CEST (GMT+2) [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

domwoe | 2023-12-14 16:21:24 UTC | #81

Working Group is starting in 10min!

-------------------------

timo | 2023-12-14 17:40:45 UTC | #82

The shortcut to the public dashboard mentioned in today's meeting is: http://dashboard.hpl.live/
(not hpl.grafana.net)

-------------------------

domwoe | 2023-12-15 08:52:37 UTC | #83

The [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit?usp=sharing) have been updated with the link to the recording and the slides.

-------------------------

domwoe | 2024-01-17 17:35:47 UTC | #84

We need to reschedule this month's WG by one week to next Thursday, January 25th. Sorry for the inconvenience. The planned agenda is to give an update on Backup & Restore.

As always, please reach out if you have any requests or ideas for upcoming sessions.

Looking forward to see you next week!

-------------------------

abk | 2024-01-24 09:27:55 UTC | #85

Hi everyone,
Tomorrow @Alexandra will be talking about canister Backup & Restore.

Thursday January 25th at 5:30 pm CET [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

abk | 2024-02-13 09:38:04 UTC | #86

Hi everyone,
In two days @free will be discussing the new [Scalable Messaging Model](https://forum.dfinity.org/t/scalable-messaging-model/26920). Hope to see you there!

Thursday February 15th at 5:30 pm CET [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)

-------------------------

domwoe | 2024-02-15 12:43:28 UTC | #87

[quote="abk, post:86, topic:14265, full:true"]
Hi everyone,
In two days @free will be discussing the new [Scalable Messaging Model ](https://forum.dfinity.org/t/scalable-messaging-model/26920). Hope to see you there!

Thursday February 15th at 5:30 pm CET [Zoom link ](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)
[/quote]

@here Reminder that this is happening today.

-------------------------

abk | 2024-02-28 12:44:09 UTC | #88

Recording and transcript of @free's presentation have been added to the [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE).

-------------------------

abk | 2024-03-04 15:18:18 UTC | #89

For the next WG meeting (March 14), we'll have a joint session with the DeAI working group that'll be an open Q&A session (description [here](https://forum.dfinity.org/t/technical-working-group-deai/24621/85?u=abk)).

-------------------------

icpp | 2024-04-15 19:49:07 UTC | #90

I am working on the next version of [ICGPT](https://icgpt.icpp.world/), a playground for on-chain Llama2 models, and I am looking into performance improvements by using horizontal scaling with a load-balancer in front of multiple LLMs.

I was suprised about the non-linear scaling with the experimental load-balancer and would love to get a full understanding of why this is. Would I be able to join one of the upcoming WG meetings to ask some questions?

![image|690x72](upload://weCHtTQ37m7xYEQJr3E4anOQm5I.png)


![image|690x388](upload://tQQMQcssSuhxVG2Uiyq4UAjufqJ.png)

-------------------------

domwoe | 2024-04-16 11:30:31 UTC | #91

This week, we'll have a joint meeting with the new [Inter-canister Canister Event Utility WG](https://forum.dfinity.org/t/technical-working-group-inter-canister-event-utility-working-group/29048).

@skilesare and collaborators will present their first designs and results. We'll have @abk, @ulan, and @free from DFINITY to provide feedback.


@icpp I'm pretty sure that we can also reserve 15min in the end to cover your questions.

Looking forward to seeing you this Thursday, April 18th at 5:30pm CEST ([Zoom link](https://dfinity.zoom.us/j/98492107298?pwd=QlJQNnU5SmhKY01vbTRkYlEyZ2Rzdz09)).

-------------------------

icpp | 2024-04-18 20:02:18 UTC | #92

Thank your for today's review of my scalability tests for [ICGPT](https://icgpt.icpp.world/).

Most important learning is to limit the number of LLMs per subnet to 4.

This because a subnet is using 4 threads for update calls, so going above that will not help.

I reran my tests, and I am now indeed getting very consistent & excellent results up to 8 concurrent users.

In this graph I am plotting the max duration of the story generation, i.e. this is the longest a user will have to wait for their story to be completed. The lower the number the better, and the red curve for 4 LLMs is really good!

![image|690x214](upload://dZ21qV96zjT39Wy6DAnSGum2Wec.jpeg)


I also tried to go to 16 concurrent users but that resulted in timeouts and unsuccessful update calls.

-------------------------

icpp | 2024-04-18 20:24:51 UTC | #93

Hi @ulan,

I'd like to follow up on [this post](https://forum.dfinity.org/t/technical-working-group-deai/24621/110) in the Technical Working Group DeAI. @patnorris mentioned that you had some really exciting news about large improvements in floating point computations that could be factors faster.

If you are interested, I can make my test environment available to you. It is in a private repository right now, with bash scripts to:
- deploy, load & configure the LLMs and the LoadBalancer
- run the test for different number of LLMs and different number of concurrent users.

Or alternatively, if you can give me early access to the new capabilities, I can also run tests and share the results with you.

-------------------------

ulan | 2024-04-19 06:36:32 UTC | #94

Hi @icpp. There will be a presentation in the upcoming Public Global R&D on April 24 about the floating point optimization.

> If you are interested, I can make my test environment available to you.

@patnorris shared a link to this [repository](https://github.com/icppWorld/icpp_llm/tree/main/llama2_c)

I guess I should be able to simple a standalone LLM canister from it, right? If so, I'll give it a try and compare how much improvement the FP optimization brings there.


> if you can give me early access to the new capabilities, I can also run tests and share the results with you.

It would require building a custom replica from the source that uses an un-release version of Wasmtime and then a custom dfx based on the replica. If you're familiar with the build process, then I can send you a patch for the replica code.

-------------------------

domwoe | 2024-04-19 07:02:08 UTC | #95

Great session yesterday. You can find the transcript and the recording in the [meeting notes](https://docs.google.com/document/d/11L9_MvoW12JTWH71T6i3ULskjj9b3Gec0oBPVR83ZsE/edit).

-------------------------

icpp | 2024-04-19 09:46:43 UTC | #96

Hi @ulan ,

> @patnorris shared a link to this [repository ](https://github.com/icppWorld/icpp_llm/tree/main/llama2_c)

Yes, you can indeed build a standalone LLM using the instructions of that repo. Very interested to see the impact of the FP optimization.

> If you’re familiar with the build process, then I can send you a patch for the replica code.

I am not familiar yet with that build process, but am willing to put in the effort to learn it.  Is there a description of the build process ?

-------------------------

icme | 2024-04-19 19:25:32 UTC | #97

@domwoe I tried to watch the recording and got this error
![Screenshot 2024-04-19 at 12.24.41|690x352](upload://GPPaGWolDjlDR3wvceuf1zv3FG.png)

-------------------------

domwoe | 2024-04-19 19:32:02 UTC | #98

Thanks for the heads up. Should be fixed now :pray:

-------------------------

icme | 2024-04-19 19:35:37 UTC | #99

Confirmed, works now!

-------------------------

icpp | 2024-04-22 02:10:05 UTC | #100

@ulan ,

I want to let you know that the icpp_llm repo includes 260K and 15M parameter models and tokenizer. 

If you like, I can also provide you with 42M and 110M parameter models.

They used to run and be able to predict one token before hitting the instructions limit, but after the revamp of how the instructions were being calculated, that was not true anymore. 

I would be very interested in learning if the new approach will allow these larger models to run.

They use the same wasm, but you just upload a different model and tokenizer. I'd be happy to drop them in a shared drive.

And if that works, what about a 7B model. I could prepare that too... It might just fit in memory, but I never tried because of the instructions limit.

-------------------------

ulan | 2024-04-22 08:45:34 UTC | #101

[quote="icpp, post:96, topic:14265"]
I am not familiar yet with that build process, but am willing to put in the effort to learn it. Is there a description of the build process ?
[/quote]

I am not aware of a public doc that describes how to build a custom dfx with custom replica. I'll try to write a doc explaining the steps when I get free time.


> I want to let you know that the icpp_llm repo includes 260K and 15M parameter models and tokenizer.

That's great, thanks a lot! I'll try this first and report here. After that we can discuss larger models.

-------------------------

ulan | 2024-04-22 16:18:26 UTC | #102

@icpp: would you mind building a Wasm binary that has a `run()` endpoint that does some fixed amount of inference with the 260K or 15M model? I tried to do it myself, but you'll probably be much faster since you already know Candid in C++.

Out of curiosity: have you considered using the standard CMake for the C++ CDK?  For many C++ developers a dependency on a custom python package might be a disadvantage.

-------------------------

icpp | 2024-04-22 21:19:39 UTC | #103

Hi @ulan ,

If you call the inference endpoint with the temperature equal to 0, it will always do the same amount of computations.

Like this:

```
dfx canister call llama2_15M new_chat '()'
dfx canister call llama2_15M inference '(record {prompt = "" : text; steps = 60 : nat64; temperature = 0.0 : float32; topp = 0.9 : float32; rng_seed = 0 : nat64;})'
```

Let me know if this is what you're looking for, else I can build a custom run() method for you as well...

-------------------------


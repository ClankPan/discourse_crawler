matthewhammer | 2022-05-17 00:23:13 UTC | #1

I've been talking with @icme about the use case for an imperative data structure for ordered key-value data.  As many recognize, the existing `RBTree` module from `base` is deficient for this use case in that the `delete` operation does not fully recover the space, or remove the key.  Further, the `RBTree` is always a binary tree, using lots of space for pointers, compared to data being stored.

By moving to a B-Tree with a tunable degree parameter, more tuning is possible, and potentially, more efficiency too.  Further, the `delete` operation for a B-Tree is comparatively simpler than that of either a functional or imperative RBTree, and will remove the key completely.  As a result, the B-Tree (but not the existing, functional RBTree) will be space efficient for practical workloads with lots of deletion.

We were both interested in opening the discussion of this data structure to the wider dev community, and @icme suggested posting here.

Questions:

1.  Has this been done in Motoko?  We don't think so, but please correct us if that's mistaken.  There does seem to exist a Rust solution: https://github.com/dfinity/ic/blob/master/rs/stable-structures/src/btreemap.rs

We'd be aiming to do something comparable, but in Motoko, hopefully for inclusion in `base`.

In any case, it would also be a stable data structure for Motoko, in that it would permit `stable` variables to hold their values, somehow.

2. What operations are most essential?

Our list thus far:
* Insertion
* Bulk insertion
* Validation check (is valid B Tree?)
* Search
* Pure iteration: Through a range.
* Map Iteration: Map (and update) values in a key range.
* Deletion

3.  What performance tests?

* Speed of each operation (plot for increasing data sizes)
* Throughput of each operation (i.e. how many insertions per consensus round & cycle limitations) (plot for increasing data sizes)
* Space used (plot for increasing data sizes)
* Cycle usage (plot for increasing data sizes)

-------------------------

C-B-Elite | 2022-05-17 00:28:07 UTC | #2

I didn't see this lib before, but check about this
https://github.com/PrimLabs/Bucket

-------------------------

jzxchiang | 2022-05-17 01:27:33 UTC | #3

> Map Iteration: Map (and update) values in a key range.

This would be awesome! Really important for pagination and not currently part of `RBTree`.

It would also be great if you could talk with @dieter.sommer about the stable Rust data structure that his team is building for the Bitcoin integration.

I believe it directly stores bytes into stable memory. A Motoko equivalent using the ExperimentalStableMemory library would be very useful (as opposed to just declaring a data structure as a stable variable, which runs into the 4 GB heap limit).

-------------------------

icme | 2022-05-17 02:26:23 UTC | #4

[quote="jzxchiang, post:3, topic:13028"]
A Motoko equivalent using the ExperimentalStableMemory library would be very useful (as opposed to just declaring a data structure as a stable variable, which runs into the 4 GB heap limit).
[/quote]

One of the drawbacks of storing this in stable memory (as opposed to using the stable keyword) would be additional performance overhead for various operations. 


One of the goals of this library is to improve upon the performance of the Red-Black tree in terms of operational performance (speed, throughput, space occupied, and cost). 

Hopefully we’ll be at a place in a few months with multi-canister scaling such that developers don’t need to worry as much about the 4GB individual canister size limit and are optimizing for compute, not storage.

-------------------------

skilesare | 2022-05-17 03:30:23 UTC | #5

Other operations that would be nice:

split() - being able to split the tree in half with the lower half on the left and the higher half on the right
slice(n) - Like split but take n elements instead of half

It would also be very helpful to have a parallel implementation that is crypto aware
witness(id) - Calculate the witness of the leaf
root() - get the root hash of the tree.

-------------------------

quint | 2022-05-17 07:16:58 UTC | #6

[quote="C-B-Elite, post:2, topic:13028"]
I didn’t see this lib before, but check about this
[/quote]

You made the library?

---

It seems that it uses the `mo:base/Trie` behind the scenes?

-------------------------

C-B-Elite | 2022-05-17 08:51:59 UTC | #7

No, the bucket lib is a lib for data stable storing and geting

-------------------------

matthewhammer | 2022-05-17 15:43:20 UTC | #8

[quote="C-B-Elite, post:2, topic:13028"]
I didn’t see this lib before, but check about this

https://github.com/PrimLabs/Bucket
[/quote]

Thanks!

[quote="icme, post:4, topic:13028"]
One of the drawbacks of storing this in stable memory (as opposed to using the stable keyword) would be additional performance overhead for various operations.

One of the goals of this library is to improve upon the performance of the Red-Black tree in terms of operational performance (speed, throughput, space occupied, and cost).

Hopefully we’ll be at a place in a few months with multi-canister scaling such that developers don’t need to worry as much about the 4GB individual canister size limit and are optimizing for compute, not storage.
[/quote]

Yes, I was also thinking we'd start by writing a data structure to be stored in `stable` vars.

But I also plan to keep in mind that we eventually want a version of a B Tree in Motoko using stable memory more directly, either through the existing library API (quite slow), or more likely, with additional system and language support for improving the currently slow performance of using the system API (what the library does under the hood).  I believe such support is in the works for all Wasm canisters, not just Motoko-based ones.

[quote="jzxchiang, post:3, topic:13028"]
This would be awesome! Really important for pagination and not currently part of `RBTree` .
[/quote]

Great to know, thanks!

[quote="jzxchiang, post:3, topic:13028"]
It would also be great if you could talk with @dieter.sommer about the stable Rust data structure that his team is building for the Bitcoin integration.
[/quote]

I wonder how it compares to [this one](https://github.com/dfinity/ic/blob/master/rs/stable-structures/src/btreemap.rs)? (also linked above)

In any case, I am interested to do that.  Thanks again!

[quote="skilesare, post:5, topic:13028"]
Other operations that would be nice:
[/quote]

Makes sense!  

Quick check: As this would be imperative, the split operations would only make sense if the original B-Tree is mutated ("destroyed") in the process, right?  (I just want to confirm that we aren't imaging a functional version where the pre and post split versions co-exist.)

[quote="skilesare, post:5, topic:13028"]
It would also be very helpful to have a parallel implementation that is crypto aware
[/quote]

Yes, good point.  This aspect is important too.  (WDYT @icme?)

Is the basic (non-Merkle) version still useful to you @skilesare?

To manage the work, I would do the basic operations and tests first, and move on to "authenticated" use cases after that, where query operations produce witnesses related to the root hash, and update operations update it.

And for performance, I wonder how much extra cycles the Merklized hashing will require?  I assume it will be sizable, and some folks may prefer not to do it at all.  But more experiments will confirm the overhead, and they seem important to answer other questions (e.g., how to best design the authenticated-ness as an optional feature?) .

-------------------------

skilesare | 2022-05-17 17:40:57 UTC | #9

>Quick check: As this would be imperative, the split operations would only make sense if the original B-Tree is mutated (“destroyed”) in the process, right? (I just want to confirm that we aren’t imaging a functional version where the pre and post-split versions co-exist.)

You just went over my head. :grimacing: If it is impossible then it is impossible(Confession: I don't know what imperative means :joy:). My functional programming is a bit sparse.

[quote="matthewhammer, post:8, topic:13028"]
Is the basic (non-Merkle) version still useful to you
[/quote]

Yes! But less useful for returning certified data to HTTP queries.

-------------------------

paulyoung | 2022-05-17 18:31:41 UTC | #10

[quote="matthewhammer, post:1, topic:13028"]
There does seem to exist a Rust solution: [ic/btreemap.rs at master · dfinity/ic · GitHub ](https://github.com/dfinity/ic/blob/master/rs/stable-structures/src/btreemap.rs)
[/quote]

Don’t mean to derail, but curious about using `StableBTreeMap` vs the approach taken here:

https://github.com/dfinity/cdk-rs/blob/d056a9cc8a0eee4a2adda2dd60285d0c8ee1061c/examples/asset_storage/src/asset_storage_rs/lib.rs


[quote="icme, post:4, topic:13028"]
One of the drawbacks of storing this in stable memory (as opposed to using the stable keyword) would be additional performance overhead for various operations.
[/quote]

Wouldn’t the overhead only be during upgrades?

-------------------------

matthewhammer | 2022-05-17 20:40:33 UTC | #11

[quote="skilesare, post:9, topic:13028"]
You just went over my head. :grimacing: If it is impossible then it is impossible(Confession: I don’t know what imperative means :joy:). My functional programming is a bit sparse.
[/quote]

Oops, sorry -- let me try to be more concrete.

Suppose that `t` is a B-Tree that holds some key-value data. 

Suppose that you define `let (t1, t2) = t.splitAt(splitKey)`, so that `t1` and `t2` are each given the left and right portions of data, around `splitKey` (defined somehow).

There are two ways to implement this regarding how `t1` and `t2` relate to `t`:

- Functional: `t` is still valid after the operation, and `t1.append(t2) == t` 
- Imperative: `t` is not valid after the operation; the nodes it uses have been mutated to represent `t1` and `t2`

I think both are possible, and was wondering which you expected?

-------------------------

skilesare | 2022-05-17 20:47:06 UTC | #12

I don't see much difference for me. I'd say do the one that is the most efficient for cycle purposes.

-------------------------

icme | 2022-05-17 20:57:26 UTC | #13

[quote="matthewhammer, post:11, topic:13028"]
There are two ways to implement this regarding how `t1` and `t2` relate to `t` :
* Functional: `t` is still valid after the operation, and `t1.append(t2) == t`
* Imperative: `t` is not valid after the operation; the nodes it uses have been mutated to represent `t1` and `t2`
[/quote]

[quote="skilesare, post:12, topic:13028, full:true"]
I don’t see much difference for me. I’d say do the one that is the most efficient for cycle purposes.
[/quote]

The imperative version will most likely be more efficient in terms of cycles and memory usage. The drawback is then as a programmer you have to be aware that this operation directly mutates the data structure passed into it, so you may have side effects that you did not originally intend to have happen.

For the purposes of permanent data storage, the imperative version is fine. 

However, if you are splitting the data structure just to perform an operation on both haves, this will mutate the underlying data structure. In this case, a map/updateIter/Scan type of operation between two bounds would be best. Something like a combination of the following functions:
* `getMidpoint(bt, compareTo)`
* `mapIter/Scan(bt, compareTo, lowerBound, upperBound, mapFunc)` // midpoint as lowerbound or upperbound

-------------------------

icme | 2022-05-17 23:23:11 UTC | #14

[quote="skilesare, post:5, topic:13028"]
It would also be very helpful to have a parallel implementation that is crypto aware
witness(id) - Calculate the witness of the leaf
root() - get the root hash of the tree.
[/quote]

I don't have a strong opinion on a crypto awareness when it comes to data structures.

Unless it fundamentally changes how the data is stored, it might be nice to build the data structure out first, and then build wrappers around this base data structure that include that added functionality.

I'm not too familiar with merkle trees and the `witness()` and `root()` functionalities, but I'd prefer to keep this BTree data structure library as general purpose and lean as possible. 

@matthewhammer Are you familiar with the `witness()` and `root()` functions and what that would take?

-------------------------

matthewhammer | 2022-05-17 23:29:01 UTC | #15

[quote="paulyoung, post:10, topic:13028"]
Don’t mean to derail, but curious about using `StableBTreeMap` vs the approach taken here:

https://github.com/dfinity/cdk-rs/blob/d056a9cc8a0eee4a2adda2dd60285d0c8ee1061c/examples/asset_storage/src/asset_storage_rs/lib.rs
[/quote]

Perhaps someone who has touched that code can comment more (@chenyan ?), but my first guess is that they indeed do look similar in purpose (the asset one uses text keys, as opposed to byte strings, but that seems minor).  The non-asset-specific one also seems to be engineered differently, in terms of its expression as Rust code.  Without comparing them in a lot more detail, it's hard to say more. 

[quote="paulyoung, post:10, topic:13028"]
Wouldn’t the overhead only be during upgrades?
[/quote]

In my understanding*, the overhead of using the `ExperimentalStableMemory` module comes from the way that the system API is exposed to the canister, where it imposes an overhead for every read and write in that library API.

By contrast, using the `stable` keyword affects upgrade behavior (persisting the data in these vars using stable memory, and but incurring much less overhead during upgrade, due to "bulk operations" used then).  Outside of upgrades, `stable` data structures in Motoko use ordinary memory read and writes,  happening in the ordinary Wasm memory, and do not incur any system call overhead.

(* @claudio @ggreif please correct me if that's inaccurate!)

-------------------------

matthewhammer | 2022-05-17 23:38:22 UTC | #16

[quote="icme, post:14, topic:13028"]
Unless it fundamentally changes how the data is stored, it might be nice to build the data structure out first, and then build wrappers around this base data structure that include that added functionality.
[/quote]

Yes, a layered approach, with nice factoring, would be ideal.  That would be my initial design goal, when the time comes for it.

[quote="icme, post:14, topic:13028"]
I don’t have a strong opinion on a crypto awareness when it comes to data structures.
[/quote]

The need for this comes from needing to relate computations done outside of consensus with those done as part of consensus.  For everything within an update message, consensus means that the IC itself is ensuring a level of authenticity ("tamper proof"!).

For query messages, however, only a single replica replies and in principle, that one machine could be compromised to be deceptive or faulty in some way.  If we could generally certify these quickly (without paying for full consensus), then the technical need for per-application certification would be eased, or eliminated, AFAIK.

Until that time, the role of witnesses and root hashes guards against this possibility of deception for such query responses, since the caller can check this response against a hash that *has* been processed by consensus.

To get a better sense of how this looks in Motoko, [there's an initial example for a single counter value](https://github.com/dfinity/examples/tree/master/motoko/cert-var).  Ideally, some BTree (like this one we are discussing now) would generalize this example, certifying arbitrary sets of key-value data, not just a single 32-bit value (as the example now shows).

-------------------------

matthewhammer | 2022-05-18 02:31:26 UTC | #17

[quote="matthewhammer, post:16, topic:13028"]
not just a single 32-bit value (as the example now shows).
[/quote]

PS: For anyone interested in diving into that code example, I recommend reading [this comment](https://github.com/dfinity/examples/blob/cb2a5eeba4b899256efc666cd5ad5d9a29d0eaad/motoko/cert-var/src/cert_var_assets/src/index.js#L28) that explains the steps briefly.

-------------------------

skilesare | 2022-05-18 03:06:01 UTC | #18

Here is an old example that I did that (I think) is right and a way to do a real tree:  https://m7sm4-2iaaa-aaaab-qabra-cai.raw.ic0.app/?tag=204614974. I'm pretty sure I borrowed liberally from someone but I don't remember who now.

-------------------------

jzxchiang | 2022-05-18 06:53:02 UTC | #19

[quote="matthewhammer, post:15, topic:13028, full:true"]
[quote="paulyoung, post:10, topic:13028"]
Don’t mean to derail, but curious about using `StableBTreeMap` vs the approach taken here:

https://github.com/dfinity/cdk-rs/blob/d056a9cc8a0eee4a2adda2dd60285d0c8ee1061c/examples/asset_storage/src/asset_storage_rs/lib.rs
[/quote]

Perhaps someone who has touched that code can comment more (@chenyan ?), but my first guess is that they indeed do look similar in purpose (the asset one uses text keys, as opposed to byte strings, but that seems minor).  The non-asset-specific one also seems to be engineered differently, in terms of its expression as Rust code.  Without comparing them in a lot more detail, it's hard to say more. 
[/quote]

What's strange is that @paulyoung's example uses the `ic_cdk` storage API to read/write to stable memory, but `StableBTreeMap` doesn't.

Can canisters even use that data structure then? It appears to me that it relies on replica internals, which makes it replica-specific and not canister-general. I'd like to be wrong though.

> By contrast, using the `stable` keyword affects upgrade behavior (persisting the data in these vars using stable memory, and but incurring much less overhead during upgrade, due to “bulk operations” used then). Outside of upgrades, `stable` data structures in Motoko use ordinary memory read and writes, happening in the ordinary Wasm memory, and do not incur any system call overhead.

This sounds correct to me, but there is one huge drawback to Motoko stable variables: they are limited by the size of ordinary wasm memory, which is 4 GB (and in practice much less due to GC).

Compare this to a stable data structure in the mold of `StableBTreeMap`, which can access the entire 8 GB (and soon to be increased) stable memory address space.

I think @icme's point about multi-canister scaling is valid, but I think any data structure developed from here onwards should be "multi-canister-aware". Would an eventual (or even current) `BigMap` replace this? Developers don't want to think about storage restrictions. They just want to read and write data to a data structure that abstracts all of that away. In 2022, I think any newly developed data structure that aims to be scalable should try to be as forward compatible as possible in light of all the changes going on.

-----

With respect to Merkle trees, witnesses, and root hashes, I think it's a great idea to make this library at least optionally "crypto-aware". Certified variables are an incredibly powerful feature of the IC, and right now the biggest barrier to more widespread adoption of certified variables is a lack of simple libraries. Perhaps @nomeata could chime in on whether this would be the right place to do it.

-------------------------

matthewhammer | 2022-05-18 17:33:30 UTC | #20

[quote="skilesare, post:18, topic:13028, full:true"]
Here is an old example that I did that (I think) is right and a way to do a real tree: [Motoko Playground - DFINITY ](https://m7sm4-2iaaa-aaaab-qabra-cai.raw.ic0.app/?tag=204614974). I’m pretty sure I borrowed liberally from someone but I don’t remember who now.
[/quote]

Yep, I recognize that code.  It's from here:
https://github.com/nomeata/motoko-merkle-tree

And while it's a perfectly reasonable starting place for a merklized KV store, it will not work in general, as an attacker that can choose put keys can choose these keys to create arbitrary tree depths, and arbitrarily bad future put/get performance.

OTOH, if the user that chooses put keys is trusted, or if they are always first hashed before being put into the tree, these concerns about balance are not as salient or security critical.

But if we care about security enough to use certification at all, we should also care about this possibility of the attacker controlling put keys too, as it will be severely problematic for data structures that do not treat these choices as potentially adversarial (DoS attack one path in the tree, and future requests there create canister paralysis, basically).

The extra complexity of a BTree (or other self-balancing tree) is that these problematic tree shapes cannot ever happen, due to rebalancing steps that this simpler approach totally lacks.

In a BTree (or RBTree, or other rebalancing tree), the attacker still chooses put keys that are ordered and that determine tree shape, but the tree responds by changing shape when a subtree becomes too deep.

The Trie from `base` solves the problem differently, and does not use ordered keys, but rather their hashes (not controlled by the attacker at all, unless the hash function is broken).

-------------------------

matthewhammer | 2022-05-18 17:43:58 UTC | #21

[quote="jzxchiang, post:19, topic:13028"]
(and in practice much less due to GC).
[/quote]
Yes, but this is not fundamental, it's specific to the current GC approach, and there is more than one at the moment.

Deterministic time slicing for the IC (a feature on the roadmap now) will positively impact this concern by permitting a non-copying GC to run as long as it needs to do a global collection.  By eschewing a copying collector in favor of one without from/to space distinctions, we can get closer to the "real" platform limits.


[quote="jzxchiang, post:19, topic:13028"]
I think any data structure developed from here onwards should be “multi-canister-aware”
[/quote]

I think I understand why one would want this -- I use `Nat` because I do not want to think about my numbers "overflowing".  I would want my data structures to be the same on the IC, by using more canisters.

However, canisters are so complex to manage as a dynamic pool (cycle budgets, async interactions, upgrades, etc) that it seems like there is still some role for traditional, uni-canister data structures, at least until we have better language tech integrated into Motoko for managing such dynamic pools that underlie dynamic data structures.  That's my feeling now, at least.

-------------------------

skilesare | 2022-05-18 17:59:35 UTC | #22

[quote="matthewhammer, post:20, topic:13028"]
But if we care about security enough to use certification at all, we should also care about this possibility of the attacker controlling put keys too, as it will be severely problematic for data structures that do not treat these choices as potentially adversarial (DoS attack one path in the tree, and future requests there create canister paralysis, basically).
[/quote]

I had not considered this...good to know. It seems like maybe hashing is always a good(if expensive) way to deal with things like this.

What kind of trade off are there to using something like a Merkel-patricia tree where the virtual space/structure is all pre allocated according to the key and reorgs aren't needed. I'd imagine reorgs with certified data would be a nightmare of calculations depending on how wholistic the reorg is.

-------------------------

matthewhammer | 2022-05-18 18:53:01 UTC | #23

[quote="skilesare, post:22, topic:13028"]
What kind of trade off are there to using something like a Merkel-patricia tree where the virtual space/structure is all pre allocated according to the key and reorgs aren’t needed. I’d imagine reorgs with certified data would be a nightmare of calculations depending on how wholistic the reorg is.
[/quote]

I share that concern.  It's certainly not very "incremental" to rebalance the tree in stable memory frequently.  Being incremental there seems ideal, if possible.

The need for balancing goes with the need for order-based keys, chosen by external users.  I suspect that this use case is what @icme envisions, and why someone would use a RBTree or a BTree (balanced trees, with order-based keys).

The `Trie` in `base` does not accept order based keys and it may be closer to what you are asking about.  It uses a simplistic, binary variant of a [patricia tree](https://en.wikipedia.org/wiki/Radix_tree), and the binary digits determine the tree shape, not some balancing algorithm.  But if the attacker chooses these binary strings, the same DoS potential exists, where they fill up narrow ranges that they choose and then query them (up to some limit on each key's bit length, if any).  

OTOH, if the canister hashes every key choice and uses these hashes as the binary strings, then no re-balancing is ever needed, and no DoS attack is possible.

But the issue there is that @icme wants to do range-based queries, where keys in a range are actually located near each other in the tree structure.  That way, putting and getting a range of 10, 100 or 1000 keys is more localized, and more efficient.  The BTree fits that need.

-------------------------


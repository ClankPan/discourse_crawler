mariop | 2023-11-29 10:15:39 UTC | #1

Hi,
The Ledger&Tokenization Working Group has finalized the second draft of the ICRC-3 standard to access the Block Log of Ledgers. You can find the rendered document [here](https://github.com/dfinity/ICRC-1/blob/c1cfd5fb2893134d90b48622166203b04c650233/standards/ICRC-3/README.md).

The changes since the first draft are:
1. improved definition of the `icrc3_get_tip_certificate` endpoint to fetch the certified tip of the chain, i.e. the last block index and the last block hash
1. the suggested algorithm to download and verify the blocks of a ledger
1. a new endpoint `icrc3_get_archives` to fetch the archive nodes of the ledger with their ranges of blocks
1. a new generic block schema that is independent from the fungible tokens standard. This provides a base standard to access the block log for _any_ ledger
1. a more precise definition of `Value` and the ri hashing function over `Value` including examples
1. an example for each ICRC-1 and ICRC-2 block schema
1. various improvements based on community feedback

Please have a look and feel free to leave feedback here or better in the [PR](https://github.com/dfinity/ICRC-1/pull/128) itself.

The working group now will proceed with voting and then we will make the NNS motion proposal. The plan is to have the vote on the motion proposal before the end of the year.

-------------------------

kayicp | 2024-02-10 13:54:19 UTC | #2

hi when can i expect the icrc3 to be finalized or moved from draft state?
if it's not in the near future, what interface standard should i follow?

-------------------------

infu | 2024-02-10 15:03:33 UTC | #3

The inner block schemas - couldn't they be Candid as well? Just a binary we can decode later.

Usage will then be:
```
// Where ICRC_Transfer is a custom type
let ?transfer : ICRC_Transfer = from_candid(block.content) else Debug.trap("err");
let from = transfer.tx.from
```
Instead of using it like this:
```
let #Map(m) = block else Debug.trap("err");
let ?tx = Array.find(m, func (k, v) = k == "tx") else Debug.trap("err");
let #Map(txm) = tx else Debug.trap("err");
let ?from = Array.find(m, func (k, v) = k == "from") else Debug.trap("err");
```
I guess that's not only a question for icrc-3, but in general a lot of icrc's are getting these generic variant schemas. By now every CDK should have to_candid and from_candid equivalent. I think in size - they will be equal or Candid version wins. In speed - running multiple Array.find's to get your values out, will probably be slower too and require libraries that make it usable. @claudio Makes me wonder what's the problem with the first way of doing it having binary candid sub schemas.

-------------------------

skilesare | 2024-02-10 18:18:24 UTC | #5

Off the top of my head a couple of reasons:

1. While CDKs may have from/to candid, can you imagine calling `dfx canister call my_sevice icrc3_get_blocks(...)` and getting back binary?
2. My understanding is that the binary representation of candid is NOT guaranteed. It may change from spec to spec. Imagine a blackholed indexing canister scanning logs and the ball of a sudden it stops being able to understand the blob format.
3. Transfers are fairly flat and basic, but future transactions for unknown services may be deeply nested and having a strongly typed language have some method of parsing through records of unknown candid types and making sense of them has long term value.
4. The types in Value have direct parallels to the calculation of the representational independent hash that is used to generate the 'blockchain' of these transaction logs.

One suggestion for dealing with them is that have some solid helper libraries.  This is roughly what I was attempting to do with https://github.com/icdevsorg/candy_library/tree/0.3.0-alpha which is a supertype of Value and should give some nice helper(although there are a to add).  There is also https://github.com/ZhenyaUsenko/motoko-candy-utils which has the beginnings of a path syntax.

```
import Utils "mo:candy_utils/CandyUtils";
import { get; getShared; getAll; getAllShared; path } "mo:candy_utils/CandyUtils";

let #Nat(myAmount) = getShared(block, path("tx.amt")) else D.trap("err");
```

Some work to do on it yet....and I think I may need to add some #Map functions for candy v3. 

And also, yes...for know types...we should likely have a parser that takes the Value and produces a candid version of it.

-------------------------

chenyan | 2024-02-10 19:18:15 UTC | #6

> My understanding is that the binary representation of candid is NOT guaranteed. It may change from spec to spec.

I don't think the binary format will change. We may add some more types in the future, but it won't change the existing format. However, the binary representation of a fixed value is not unique, different implementations can get different raw bytes. So we cannot compute hash based on the binary data.

In Rust, we have a `IDLValue` type which allows to decode the binary data directly without using the subtyping rule. The variant is roughly equivalent to the `Value` type defined here. But manipulating a generic value like `IDLValue`/`Value` is always verbose and inconvenient. Ideally, we can convert the generic value into something native in the host language, which can make access the data easier.

-------------------------

infu | 2024-02-11 10:21:47 UTC | #8

Thanks for taking the time to explain!

Not using `dfx call` myself, but yes that will be a problem. Also it will be a problem for dashboards, but that is fixable - there can be a repository with schema id -> candid and that id is next to the binary. Clients like dfx and the dashboard can fetch schemas and use them automatically. Making a registry will be a problem tough - who governs it, how schemas get added, how to test, etc.


[quote="chenyan, post:6, topic:25132"]
different implementations can get different raw bytes
[/quote]
That's good to know.
Well, hashing could just work the same way—by operating on values after decoding binary Candid blocks. Schema makers need to ensure they do not use unhashable types.
We could probably have a function that decodes unknown Candid to { _23423 : { _634534 : [234,2342] } } and hashes that somehow while guaranteeing invariable uniformity across implementations?.

[quote="chenyan, post:6, topic:25132"]
Ideally, we can convert the generic value into something native in the host language, which can make access the data easier.
[/quote]

Please, let's do that if we are not going for the Candid option. I'm still not convinced that generic values are better, but this will make it a lot less of a problem.

-------------------------

mariop | 2024-02-12 11:13:58 UTC | #9

Hi,
FYI DFINITY has decided to take a bit more time to check the ICRC-3 standard. This means we will wait a bit longer to make the motion proposal. Sorry for the inconvenience.

-------------------------

infu | 2024-02-12 14:10:04 UTC | #10

It will be great if when fetching transaction history a canister only interested in its own history doesn't have to go trough everyone elses.
Something like this could work: We still have the whole log, but if we pass a `slot range` parameter we only get what's in the slot range. There can be 1024 slots. In which slot a transaction gets added depends on the hash of the **from** and **to** owner:Principal. This means every tx gets added to the full log and two slot logs (probably no need for phash in slot logs). Then our canister can just process 1/1024 of the whole log and be certain it's getting all transactions from and to it.
Probably good for the indexer too - it can become multi-canister.

-------------------------

skilesare | 2024-02-12 14:29:09 UTC | #11

I don't think we want to mix up icrc3 and indexing. An indexing icrc is a great idea, and designing in a way that a ledger can host the index would be ideal.

The trade off to be wary of is speed and agility of the head ledger canister vs robust functionality. We've erred on moving functionality off to other canisters, which if given the proper trust assumptions, should be ok as long as the head ledger canister doesn't rely on the extra functionality itself(because you lose atomicity).

Since icrc3 generated an immutable record, it should be able to report an indexing canister tree that is sufficient for reporting back just your transactions.

-------------------------

kayicp | 2024-02-12 14:45:17 UTC | #12

hi Mario
do you think it's a good idea to follow the ICP ledger methods for getting the transaction data for now?

-------------------------

mariop | 2024-02-12 16:34:56 UTC | #13

The ICP Ledger won't be able to support ICRC-3 no matter what because of AccountIdentifier. For ICP Ledger, I suggest to use [`query_encoded_blocks`](https://github.com/dfinity/ic/blob/beb47eef5698fb26190ae9a229fbe36cdf7b88bd/rs/rosetta-api/icp_ledger/ledger.did#L447). If you are fetching them from outside then remember to validate them. The approach is very similar to ICRC-3 except that [the certificate is embedded in the response](https://github.com/dfinity/ic/blob/beb47eef5698fb26190ae9a229fbe36cdf7b88bd/rs/rosetta-api/icp_ledger/ledger.did#L241) of `query_encoded_blocks` when you query a suffix of the Ledger. You can see an example in the ICP Index canister's [`build_index`](https://github.com/dfinity/ic/blob/beb47eef5698fb26190ae9a229fbe36cdf7b88bd/rs/rosetta-api/icp_ledger/index/src/main.rs#L317) function.

For ICRC Ledgers (ckBTC, SNSes, ...) you can use something very similar to ICRC-3 already. The endpoint [`get_blocks`](https://github.com/dfinity/ic/blob/beb47eef5698fb26190ae9a229fbe36cdf7b88bd/rs/rosetta-api/icrc1/ledger/ledger.did#L370) is essentially the same as `icrc3_get_blocks` while [`get_data_certificate`](https://github.com/dfinity/ic/blob/beb47eef5698fb26190ae9a229fbe36cdf7b88bd/rs/rosetta-api/icrc1/ledger/ledger.did#L371C5-L371C25) is the same as [`icrc3_get_tip_certificate`](https://github.com/dfinity/ic/blob/beb47eef5698fb26190ae9a229fbe36cdf7b88bd/rs/rosetta-api/icrc1/ledger/ledger.did#L371C5-L371C25). You can see an example in the ICRC Rosetta prototype's [`sync_from_the_tip`](https://github.com/dfinity/ic/blob/master/rs/rosetta-api/icrc1/rosetta/src/ledger_blocks_synchronization/blocks_synchronizer.rs#L120) function.

-------------------------

infu | 2024-02-12 18:35:22 UTC | #14

It's not really indexing, more like storing tx in 1024 logs instead of one. On each transaction, we will probably have 2 principal->slot and 2 more Vec add operations. If that is taking too many resources - ok.
When another canister (indexer) does the splitting, it will be at least one inter-canister call slower. The indexer has to somehow launch tens of `icrc3_get_blocks` queries simultaneously to be able to keep up. How much it can launch if lagging behind? 50, 100? Splitting the log eliminates the need for that, at least for canisters interested in their own transactions.

-------------------------

mariop | 2024-02-13 13:51:53 UTC | #15

[quote="infu, post:14, topic:25132, full:true"]
It’s not really indexing, more like storing tx in 1024 logs instead of one. On each transaction, we will probably have 2 principal->slot and 2 more Vec add operations. If that is taking too many resources - ok.
[/quote]

The issue is that it adds complexity to the Ledger. Using more resources is fine, adding complexity is not. Our philosophy is to keep the Ledger as simple as possible.

I also see another issue. Some applications/canisters may need to fetch the full log (e.g. Rosetta). How do you serve it? Do you have one additional log containing everything?

[quote="infu, post:14, topic:25132, full:true"]
When another canister (indexer) does the splitting, it will be at least one inter-canister call slower. The indexer has to somehow launch tens of `icrc3_get_blocks` queries simultaneously to be able to keep up. How much it can launch if lagging behind? 50, 100? Splitting the log eliminates the need for that, at least for canisters interested in their own transactions.
[/quote]

If the indexer is in the same subnet then it should work. The index may lag behind but it should catch up after few seconds. For instance, the ICP Index is behind the Ledger by 25 to 150 blocks every second but it quickly catches us. Consider that the ICP Index is simple and queries batches of blocks sequentially so it could be further improved by running multiple requests simultaneously.
The question is whether it matters for a consumer to wait a few more seconds to get newer blocks.

Another advantage of the indexers is that they can be distributed by account.

-------------------------

infu | 2024-02-13 16:34:02 UTC | #16

[quote="mariop, post:15, topic:25132"]
The question is whether it matters for a consumer to wait a few more seconds to get newer blocks.
[/quote]
It's not a problem for us unless there are thousands of tx/s for long periods of time. I guess a problem for another day.
We are currently using get_transactions in our contracts (on another subnet). (Please look it up if you have time - DeVeFi ledger middleware)  The indexer is currently made to fit end-consumer wallets. If it can return information about all subaccounts of a principal and also allow from - to (to be specified) not just get the last N blocks, we can probably use it instead. 
I wonder if it will be a problem if hundreds of canisters send get_transactions/icrc3_get_blocks calls every sec from different subnets.

-------------------------

kayicp | 2024-02-13 23:54:54 UTC | #17

[quote="mariop, post:13, topic:25132"]
The ICP Ledger won’t be able to support ICRC-3 no matter what because of AccountIdentifier.
[/quote]
Can't we make the ICRC-3 to support only AccountIdentifier?

-------------------------

skilesare | 2024-02-14 00:51:43 UTC | #18

We would likely need an alternate schema defined for legacy ICP style ledgers(ICP and OGY are the only two I know).  ICRC3 logs are extensible so we can propose an alternative schema for those that looks a lot like: https://github.com/dfinity/ICRC-1/tree/icrc-3/standards/ICRC-3#icrc-1-and-icrc-2-block-schema but that has and ICRC-57 LegacyAccount is represented as a #Blob of the account id bytes. and ops of 57xfer, 57mint, 57burn.  Whether or not the legacy ledger would support this would be up to DFINITY to decide and support, and would be further complicated by the fact that the current "blockchain" on these ledgers probably doesn't use this schema and thus would take an extraordinary effort to 'replay' the chain and calculate the ICRC-57 certificate which would need to coexist with the classic certificate(which I think we've accounted for in the proposal but is still a bit stinky to think about having to support).

-------------------------

claudio | 2024-02-15 11:17:56 UTC | #19

I don't have enough context here but using a Blob though convenient, seems less safe to me and morally equivalent to using a string.

The producer and consumer need to agree on the format of the encode value, perhaps Candid but could be any binary encoding.

When using candid, the producer and consumer need to further agree on the type of the encoded value. None of that is enforced by the contract, just like when using a text encoding.

I guess once could also contemplate  a mixture of variant format with (candid) blob extensibility point.

And as Yan points out, there are different candid encodings for the same values, which people might not bear in mind when coding, and leads to trouble with hashing, equality testing etc.

-------------------------

mariop | 2024-02-15 12:51:18 UTC | #20

[quote="kayicp, post:17, topic:25132"]
Can’t we make the ICRC-3 to support only AccountIdentifier?
[/quote]

We can but the issue is not just the AccountIdentifier. The ICP Ledger uses its own type of blocks, encoding and hashing which are fundamentally different from the ICRC Ledgers. The reason why ICRC moved away from the approach used by the ICP Ledger is that the approach used by the ICP Ledger is not extensible and difficult to use for clients.

-------------------------

levi | 2024-02-20 02:06:10 UTC | #21

What do you think if we put an put an `account: opt Account` field in the GetBlocksArg type so that when the field is set, it returns the blocks indexed for the specified account. This way the standard is compatible with both kinds of implementations whether the accounts'-blocks-indexes are stored on the ledger itself like @infu mentioned or whether it is on a different canister like the sns index canisters. In the ICRC-3 [GetBlocksResult](https://github.com/dfinity/ICRC-1/blob/2d53c86d30692240e50a25a55e19e9f6e255d0df/standards/ICRC-3/ICRC-3.did#L31), the canister returns blocks that it has and it returns callback functions pointing to where the caller can get the other blocks. This callback is being used to point the caller towards the archive canisters but it can also point back on itself with a next chunk if the ledger canister itself has more blocks than what fits in a single message, or it can point to an index canister which can then point back on itself with the chunks. So ICRC-3 as it is now is compatible with both implementation types of either the ledger holds all the blocks or the ledger creates archive-canisters that hold blocks, so this same compatibility can be with the index-canister functionality by adding the optional field.
![Screenshot from 2024-02-19 20-48-55|690x189](upload://3JjKU6gy1IDfmv09tIOzOPZ5jT8.png)

When the field is set, the canister returns - or points to another canister (like the sns index canister) using the callback in the GetBlocksResponse that can return - the blocks indexed for that account within the range of the `start` and `len`.

-------------------------

skilesare | 2024-02-21 01:17:42 UTC | #22

There are many other possible filters: to, from, date, amount range, memo, schema(approve, xfer, etc)

These would all be interesting. In the token call today we discussed an add on chat would add a filter function. The lift to do this is non-trivial so I'd recommend a separate, optional function with a bit more complexity and leave the straight line function in tact. Not a strong opinion.

-------------------------

infu | 2024-02-21 11:14:21 UTC | #23

If we use icrc-3 for all kinds of logs: Ledger logs, dex logs, app logs, user activity logs, etc. It makes sense if we can have multiple logs inside one canister and not try to get everything out through one single log.

`account: opt Account` could become `channel: opt Blob` and that can fit an account, text path, and many other things, even have filters, range, etc inside. 
I usually have multiple logs in my canisters. The ICRC ledger can just use one, but the spec can allow more.
If we look at something like Linux, it has many logs, and tailing logs separately is essential.
```
tail -f /var/log/syslog
tail -f /var/log/bootlog
tail -f /var/log/auth.log
```
Now imagine all Linux logs were merged inside one and you had to pipe GB of logs through a filter to get what you want.

Also, some logs like the error log won't need certification or hashing. Isn't certification only needed by off-chain consumers? While hashing is helping observers quickly verify that upgrades didn't tamper with the log? If we have another canister that takes the raw logs and certifies and hashes blocks, wouldn't that offload the main canister and result in a modular architecture that provides the same guarantees?
Something like the asset canister, but instead it handles logs, creates archive canisters, hashes, certifies, etc. The main canister that produces them then doesn't have to do any of these.

-------------------------

sea-snake | 2024-02-21 12:43:44 UTC | #24

Let's not forget the ICRC-3 log is more than just a log, it's a single blockchain that represents the first, last and all states in between the ledger has ever been in. The blockchain part guarantees that a block in between cannot be modified without invalidating the whole chain.

I don't think splitting the log into a per user, per sender etc logs makes this less complex, it would actually create multiple sources of truth, which is something you really really want to avoid.

So personally I'm still leaning towards having a single log that has all canister state mutations ever made. If logs are needed for other purpose besides keeping track of all canister state mutations since inception, I suppose this should be something separate. 

As for an index canister that e.g. does allow looking up with filters, I don't think this canister has to be a separate canister from the ledger canister in all cases. Though I would personally opt to make it a separate canister based on the ICRC-3 chain simply because it's something that can evolve, have more features in the long run, index multiple ledgers in combination etc.

-------------------------

infu | 2024-02-22 10:21:33 UTC | #25

Icrc-3 interface being able to output multiple logs/streams/events/blocks in a chain doesn't mean the ledger has to use more than one. It's up to developers. Like @levi mentioned, it can be reused by the indexer. It can also be used by log aggregators.
The question is, are we going to use it as a log retrieval mechanism or it will be just for ledgers?
Because apps do need multiple output logs/streams as a major form of inter-canister communication.

Take this example - your app adds entries, but they are app-specific and not standard. They can be used to replay state, but other parties can't understand these, or are not interested in your custom logs enough, or just don't want to use something that devs can change at their whim and break integrations.
So the app also adds the same events in standardized schemas, which are not used for replaying state, but for communication. Maybe it even pushes out the same information in 3-4 different schemas. Why merge them all in one if icrc-3 is used for these? 

Sometimes it's better to follow a stream with changes: Your app needs to follow 50k ledger accounts. Making 50,000 `icrc1_balance_of` calls every 2 sec will be impossible. If you follow the log you will get this done with 1 call every 2 sec.

-------------------------

kayicp | 2024-02-24 10:55:32 UTC | #26

if the previous `block : Value` of `Map` variant contains `phash` field, do we skip this field during the hashing for the current block's `phash`? or do we hash everything from the previous `block` as the `phash` of the current `block`?

-------------------------

bogwar | 2024-02-24 11:04:24 UTC | #27

We hash everything from the previous block, including `phash` . This is how the ledger chains its internal blocks; skipping `phapsh` is not an option.

-------------------------

kayicp | 2024-02-24 11:11:53 UTC | #28

thanks for the quick answer. one more thing, for the first block `i = 0`, the `phash` won't be set, yeah?

-------------------------

bogwar | 2024-02-24 11:13:02 UTC | #29

Indeed, for the first block `phash` would be `None`

-------------------------

NS01 | 2024-02-24 11:33:35 UTC | #30

I don't think it's specifically mentioned in the ICRC3 standard that ALL transactions (mint/ txfr etc) which change a balance MUST be recorded. I found an issue with a couple of community canisters where they have a pre-mint which is not recorded in the ledger history. 

In practical terms the first transaction of a ledger canister history MUST be a mint transaction? Some canisters however are starting with a transfer which doesn't really make sense and isn't auditable in terms of what balance the account doing the transfer has access to.

-------------------------

skilesare | 2024-02-24 17:11:59 UTC | #31

Yeah....those pre mints should be recorded at genesis as mints.

-------------------------

kayicp | 2024-02-25 08:44:22 UTC | #33

hi. do i have to create a new `hash_tree` (or make it empty) every time I create a new block?

like this
```
// ... creating new block for id = i
hash_tree := HashTree.empty(); // <-- do i need to do this?
hash_tree := HashTree.put(
  hash_tree, 
  [encodeUtf8("last_block_index")], // path from root
  encodeLeb128(current_block_id)
);
hash_tree := HashTree.put(
  hash_tree, 
  [encodeUtf8("last_block_hash")], // path from root
  hashValue(current_block)
);
```

-------------------------

PanIndustrial | 2024-02-26 01:33:09 UTC | #34

It depends on what else you might have in your hash tree. ICRC3 enables you to have both an ICRC3-certified hash for your log as well as other certified data.  To date we've been passing in @nomeata 's cert tree as an environment parameter and adding these items to the tree. Once you've set them you can setCertifiedData.

https://github.com/PanIndustrial-Org/icrc3.mo/blob/109212366f5d36d3d3866687e1ebf975da6d19f9/src/lib.mo#L244

In our Fungible Tokens, when we set up icrc3 we pass this token level tree to the icrc3 module:

https://github.com/PanIndustrial-Org/ICRC_fungible/blob/b019f8a9e185a97ff0cefbd978b47572817969a8/src/Token.mo#L194

-------------------------

domwoe | 2024-02-27 11:48:36 UTC | #35

I'm new to the discussion but see a great opportunity here.

In many ways, a canister can be thought of as a blockchain in a traditional sense, and in the web3 ecosystem, there has been built a lot of infrastructure around consuming and indexing blockchains by transaction or event log data. Some examples would be Dune, Nansen, Dappradar, Tokenterminal, Dexscreener, Dextools, etc. (There are many more).

Dapps on ICP are missing out quite a bit on discoverability and credibility because of this. 

I'm wondering if icrc3 + tooling like https://forum.dfinity.org/t/motoko-rechain-blockchain-middleware-icrc-3-related/27905 could be a great enabler to create a simple and standard mechanism for dapps to expose an event log that off-chain infrastructure can consume. From my perspective, it's also not necessary for each chain to keep the entire log on-chain forever.

For these off-chain integrations, I think, it would also be useful to standardize a `http_request` method to fetch the chain. 

Since, DeFi applications benefit the most from this, I'd be interested to get your thoughts: @ICPSwap, @simpson, @memecake, @dfxjesse, @talkinandy, @OrangeDonut

-------------------------

ICPSwap | 2024-02-28 13:56:00 UTC | #36

Thanks Dominic! 

We believe Rechain would be a highly useful middleware, aiding developers in logging record types and simplifying development processes. It will also facilitate users in querying their records.

We consider several features to be required:

1. Multi-dimensional filtering. For example, taking our transaction records as an example, there are key fields such as the user's principal, transaction token0, transaction token1, type, etc. that need to be filtered.
2. The availability of a unified dashboard for querying. where users can access their relevant transaction (transfer) data from the same dashboard.
3. Performance in storing records. For instance, in swap transactions, many logs are generated. However, considering the memory capacity of canisters, storing these logs would require a separate log canister, However, cross-canister calls are slower, resulting in a poorer user experience. Therefore, for many business logs, we only retain the final results and not the process logs.

If Rechain can achieve low latency, approaching the speed of internal canister calls, we would be willing to store business logs in Rechain.

And we encountered a situation that might or not might related to what you mentioned, but we thought it may be an optimization point for ICRC standards. We encountered some ICRC tokens where the volume of transactions was too high, causing the Archive Canister of the token to exhaust its default cycles, while the Ledger Canister of the token still had cycles. This resulted in uninterrupted token swaps, but transfer records were not recorded, making reconciliation very complex for us. However, for non-SNS tokens, we currently have no way of finding these Archive Canisters of the tokens, so we cannot get warnings that cycles are about to be exhausted.

-------------------------

infu | 2024-02-28 15:51:04 UTC | #37

Thanks for letting us know what you need.
I think Rechain should be kept as simple as possible and just handle reducing state(optional), (ICRC3) transactions, hashing, archives and provide a framework for plugins. 

(1) Anyone can make a module that connects to it and indexes transactions - inside the same canister or another 'index' canister. The delay will be max 2 sec if any - when on the same subnet. RxMoDb can easily index these fields. If placed inside the same canister - maybe won't be a good idea before Motoko gets bigger stable memory.
Something like this will work:
1) `mops add a_custom_module`
2)  import the module, configure it and add it to the array of reducers (plugins)
3) all dispatched transactions will go through it

Rechain in one canister will be able to follow rechain in another, so devs decide where they want to install the reducer plugins.
I am also guessing, nobody will want to rewrite their whole state management and put everything inside reducers, so that is optional. You can just dispatch transactions without any reducers and they will be sent straight to the ICRC-3 chain.

(2) I think multiple dashboards will be made by the community once ICRC3 gets out
(3) The way it works now canisters write blocks inside local memory, so no cross-canister calls and it shouldn't result in poor UX. Indexers are periodically fetching blocks from the main canister and only query archives if they are too far behind.

-------------------------

skilesare | 2024-02-29 06:03:14 UTC | #38

[quote="domwoe, post:35, topic:25132"]
For these off-chain integrations, I think, it would also be useful to standardize a `http_request` method to fetch the chain.
[/quote]

https://github.com/dfinity/ICRC/issues/23

ICRC-23 has the beginnings of a suggestion for this.

-------------------------

kayicp | 2024-03-02 13:32:06 UTC | #39

hi
does the `id` of the first `block` starts from `0` or `1`?

-------------------------

kayicp | 2024-03-02 13:56:09 UTC | #40

![image|690x374](upload://jZ3a2QxSDdqbcp158R4IbfwgiuS.png)

the `log_length` is the total blocks that ever existed/created (from base to tip), yes?

-------------------------

kayicp | 2024-03-04 00:49:00 UTC | #41

![image|689x357](upload://eZ1GAAdgL1b69nwrHHR32kOHbRt.png)
hi
1) why is the callback have to return `{ log_length; blocks; archived_blocks } : GetBlocksResult`, instead of just `[{ id : Nat; block : Value }]`? does this mean all the remote/archive canisters have to keep track of the amount of blocks from base to tip for `log_length` and also keeps track of other remote/archive canisters for `archived_blocks`?

2) how about we make all these query endpoints to be of `composite query` so the archive canisters can query the main ledger for total block size, and the main ledger can query the archive canisters for their `start, end`? this way, `archived_blocks` wont be needed anymore since the main ledger can `query` archive canisters and include the result in `blocks`.

edit: ok for (2) i know why we cant make it `composite query` because composite queries can only be triggered by browser agent or dfx only, while these interfaces are for all including intercanister calls

-------------------------

levi | 2024-03-04 06:11:56 UTC | #42

[quote="levi, post:21, topic:25132"]
What do you think if we put a put an `account: opt Account` field in the GetBlocksArg type so that when the field is set, it returns the blocks indexed for the specified account.
[/quote]

Thanks for the feedback. Looks like the consensus is that it’s better to leave icrc-3 with just the block log and possibly put filters in a different standard. Also there can be implementations of icrc-3 for block logs without accounts, since icrc-3 is generic like that.

-------------------------

levi | 2024-03-04 06:34:15 UTC | #43

[quote="kayicp, post:39, topic:25132, full:true"]
hi
does the `id` of the first `block` starts from `0` or `1`?
[/quote]

Starts from `0`. 

[quote="kayicp, post:40, topic:25132"]
the `log_length` is the total blocks that ever existed/created (from base to tip), yes?
[/quote]
Yes for the response returned by the ledger canister. I don’t know about the response returned by the archive canisters. 

[quote="kayicp, post:41, topic:25132"]
why is the callback have to return `{ log_length; blocks; archived_blocks } : GetBlocksResult`, instead of just `[{ id : Nat; block : Value }]`?
[/quote]
The callback returns the `archived_blocks` field so that the archives can have their own archives (nested archives). 

[quote="kayicp, post:41, topic:25132"]
does this mean all the remote/archive canisters have to keep track of the amount of blocks from base to tip for `log_length` and also keeps track of other remote/archive canisters for `archived_blocks`?
[/quote]
Hmm good question. It could be that an archive canister should return the length of the blocks within that archive-canister, but I’m not sure if that’s how it’s meant to be.

-------------------------

kayicp | 2024-03-04 07:18:54 UTC | #44

[quote="levi, post:43, topic:25132"]
nested archives
[/quote]
what do you mean by this?
I thought the usual design was always the "one main ledger with multiple archive canisters".

-------------------------

mariop | 2024-03-04 09:08:32 UTC | #45

Hi,
I got a couple of requests for change for the ICRC-3 standard from outside the working group. This was the feedback I was waiting for before moving on with ICRC-3. The two suggestions are the following:

1. point 2 of the Generic Block Schema section requires ICRC-3 blocks to have a field `tx: Map` with a field of type `op: Text` inside. The change request is to drop this requirement in favour of having a field `type: Text` at top level which defines the type of the block. This type should follow a schema such as `<standard_number><field_type>` e.g. for ICRC-1 transfer block it would be `1xfer`. We should also propose a schema for custom blocks, e.g. prefix the type with `c` plus a unique code of some sort, so that custom standards could be supported. Note that for this to work `<field_type>` should never start with a digit. For backward compatibility with existing Ledgers (ck, SNS, ...) we should still support the current approach of having `tx: Map` with the `op: Text` field inside but mark the new block style with the type at top level as the favored approach.
2. Add a new endpoint `icrc3_supported_block_types` to list all the supported block types. Given the open nature of ICRC-3 each client will always have to query the supported blocks from the Ledger to understand if they can interpret all the blocks. The original plan was to use the `icrc1_supported_standard` endpoint from ICRC-1 to query this info. Some people proposed to instead have an endpoint in ICRC-3 so that any Ledger, including the ones not supporting ICRC-1, could use ICRC-3. The endpoint `icrc3_supported_block_types` is also more fine grained compared to `icrc1_supported_standards`. Both the name `icrc3_supported_block_types` and the type returned are yet to be clarified.

We could discuss this tomorrow in the working group but I wanted to write it here first so that everybody can have a look.

What do you think?

-------------------------

kayicp | 2024-03-04 11:23:54 UTC | #46

[quote="mariop, post:45, topic:25132"]
<standard_number><field_type>
[/quote]
I'm okay with this, since icrc-7 also is doing the same thing.. eg: `7xfer`

hopefully icrc-3 will start progressing now.

-------------------------

mariop | 2024-03-04 13:30:16 UTC | #47

[quote="kayicp, post:44, topic:25132"]
what do you mean by this?
I thought the usual design was always the “one main ledger with multiple archive canisters”.
[/quote]

ICRC-3 is designed to be used with generic Ledgers and we cannot make assumptions about archives or what not. Therefore ICRC-3 was designed such that any block holder (Ledger, Archive, Index, ...) can either have the blocks locally or know who to ask to.

-------------------------

skilesare | 2024-03-04 14:53:40 UTC | #48

Regarding 1: I don't have a strong prejudice except that I don't want to have to refactor my code :) I guess it does make sense to have this at the top level.

[quote="mariop, post:45, topic:25132"]
Add a new endpoint `icrc3_supported_block_types` to list all the supported block types. Given the open nature of ICRC-3 each client will always have to query the supported blocks from the Ledger to understand if they can interpret all the blocks.
[/quote]

I do like this idea. I don't want to slow down ICRC3 though...could this be a separate ICRC so we can move forward? I'd propose that it also consider something like https://github.com/ZhenyaUsenko/motoko-candy-utils?tab=readme-ov-file#candy-schema so that it can not only reply with a list, but also the schema of those block types. It would really help for indexing canisters.

[quote="mariop, post:45, topic:25132"]
The original plan was to use the `icrc1_supported_standard` endpoint from ICRC-1 to query this info.
[/quote]
 
I guess I just always assumed that this would be used across ICRCs. I guess we should have put that endpoint in its own standard. :/ I guess it should have been icrc0_supported_standard. Hmm....I'm not really sure I want each standard to have its own supports infrastructure(although as mentioned, for ICRC3 being able to return schemas would be nice).

We should certainly use the time tomorrow to talk about it!

-------------------------

Maxfinity | 2024-03-04 22:40:03 UTC | #49

[quote="mariop, post:1, topic:25132"]
* improved definition of the `icrc3_get_tip_certificate` endpoint to fetch the certified tip of the chain, i.e. the last block index and the last block hash
[/quote]

Hey Mario, can we get a certified approval? This will help with DOS attacks.

-------------------------

mariop | 2024-03-05 09:07:37 UTC | #50

[quote="Maxfinity, post:49, topic:25132"]
Hey Mario, can we get a certified approval? This will help with DOS attacks.
[/quote]

Yes, you can (if you are not a canister):
1. make an approval and get back the approval block index
2. get the tip certificate via `icrc3_get_tip_certificate`
3. fetch all blocks from the tip in 2. to the block index received in 1 using ICRC-3
4. send all the data received to the service which then can verify the approval using ICRC-3

There are some drawbacks to this solution though. The first one is that the length of the suffix depends on the blocks/s in the Ledgers. If the Ledger creates a lot of block between 1. and 2. then the suffix may be big and eventually too big to be sent to the service.
More importantly, the certificate verification can be quite expensive which so I'm not sure this approach would solve the issue you mentioned. We would have to test it.
The general question is whether sending certified results to a canister is a good approach or not because checking the certification is expensive.

-------------------------

dieter.sommer | 2024-03-05 13:04:15 UTC | #51

The ICRC-3 topic will be discussed in the WG meeting this afternoon.
https://forum.dfinity.org/t/announcing-token-standard-as-topic-of-the-first-meeting-of-the-ledger-tokenization-working-group/11925/258

-------------------------

levi | 2024-03-06 08:39:44 UTC | #52

[quote="mariop, post:45, topic:25132"]
point 2 of the Generic Block Schema section requires ICRC-3 blocks to have a field `tx: Map` with a field of type `op: Text` inside. The change request is to drop this requirement in favour of having a field `type: Text` at top level which defines the type of the block.
[/quote]

I think this is a great idea, and makes sense for a generic block log. If there is a way to do it and still make it work with existing ledgers that sounds great. 

[quote="mariop, post:45, topic:25132"]
Add a new endpoint `icrc3_supported_block_types` to list all the supported block types. Given the open nature of ICRC-3 each client will always have to query the supported blocks from the Ledger to understand if they can interpret all the blocks.
[/quote]

Since a ledger can upgrade to support more block types, a client that has called `icrc3_supported_block_types` before the ledger upgraded, will still end up getting the new block types when reading the block log. If the client must call `icrc3_supported_block_types` before every time it reads blocks, then it might be the same as just processing the blocks and reading out their types.

-------------------------

mariop | 2024-03-06 08:52:27 UTC | #53

[quote="levi, post:52, topic:25132"]
Since a ledger can upgrade to support more block types, a client that has called `icrc3_supported_block_types` before the ledger upgraded, will still end up getting the new block types when reading the block log. If the client must call `icrc3_supported_block_types` before every time it reads blocks, then it might be the same as just processing the blocks and reading out their types.
[/quote]

That's a great point. My take on this is that Ledgers rarely change the block types and when that happens it's fine for the client to crash and, when restart, give the error to the developer that a new block type was found. The advantage of `icrc3_supported_block_types` is that you get an error as quickly as possible before doing any operation and that it is a well defined error containing e.g. the URL of the supported block so that the dev can immediately understand the work they have to do to support the new block type.

-------------------------

Maxfinity | 2024-03-06 10:11:21 UTC | #54

That works, the certificate verification can be used in inspect message.

-------------------------

levi | 2024-03-09 20:32:19 UTC | #55

[quote="mariop, post:53, topic:25132"]
The advantage of `icrc3_supported_block_types` is that you get an error as quickly as possible before doing any operation and that it is a well defined error containing e.g. the URL of the supported block so that the dev can immediately understand the work they have to do to support the new block type.
[/quote]

If the method returns a URL for each block-type-name then I think it is useful and am in favor of adding the method to the standard.

Something like this: 
```
icrc3_supported_block_types : () -> (vec record { block_type : text; url : text }) query;
```

-------------------------

mariop | 2024-03-11 09:06:55 UTC | #56

Hi,

I pushed the [new draft](https://github.com/dfinity/ICRC-1/blob/be22f710523324d2a4e2574706b5cf5753f5931c/standards/ICRC-3/README.md) of the ICRC-3 standard. Changes:

1. add `icrc3_supported_block_types` as described by @levi 
2. add the top level field `type` for block and removed `tx.op`. Specified that `type` is optional but recomanded and if not set then the type fallbacks to ICRC-1 or ICRC-2 blocks
3. specify the value of `type` for ICRC-1 and ICRC-2 blocks (`1burn`, `1mint`, `1xfer`, `2approve`, `2xfer`)
4. added example of ICRC-1 and ICRC-2 with and without the `type` field

Please have a look.

-------------------------

Saumay-Agrawal | 2024-03-11 15:47:27 UTC | #57

Hi all - Is it possible to add support for something like [solidity events](https://www.alchemy.com/overviews/solidity-events) in this draft? 

I think that would be a great feature for getting updates related to on-chain activities of various canisters.

-------------------------

mariop | 2024-03-11 16:55:36 UTC | #58

ICRC-3 is for the blocks in a Ledger. Events are something else. You could use the `Value` type defined in ICRC-3 to represent events on the IC.

-------------------------

skilesare | 2024-03-11 16:55:37 UTC | #59

I'm hoping to have some conversations around events with a few others in the ecosystem in the next couple of weeks.  Would you be interested in contributing?

@infu has some interesting code you should check out if you want to try to use an ICRC3 log as a type of event log. https://forum.dfinity.org/t/devefi-ledger-icrc-ledger-middleware/27274/12

Which features from solidity are you most interested in?

-------------------------

Saumay-Agrawal | 2024-03-11 18:00:07 UTC | #60

Would love to contribute, let me know how I can help! 

I'm mainly interested in emit events for now because I'm building Ping (https://h7jna-pqaaa-aaaak-afgiq-cai.icp0.io/), a notification delivery system for the dapps in ICP ecosystem. I'll let you know if something else crosses my mind.

-------------------------

mariop | 2024-03-12 10:21:03 UTC | #61

I will leave the draft up for a couple more days and then, unless there are further comments, I'll make the motion proposal for ICRC-3.

-------------------------

mariop | 2024-03-13 13:42:07 UTC | #62

FYI the cycles-ledger will be the first ledger supporting ICRC-3 https://github.com/dfinity/cycles-ledger. I added today the last endpoints.

-------------------------

skilesare | 2024-03-15 19:40:22 UTC | #63

Should these lines and others have async in the definition?

https://github.com/dfinity/ICRC-1/blob/be22f710523324d2a4e2574706b5cf5753f5931c/standards/ICRC-3/README.md?plain=1#L369

-------------------------

skilesare | 2024-03-15 23:25:55 UTC | #64

Blah...found one implementation detail.

In the past, I could dedupe on the tx part of the Value map.  Now that the type is moving out of the TX it isn't as easy. Of course, I can inject it....or in the case of icrc1 and icrc2 put both the type and the op in the block.

-------------------------

skilesare | 2024-03-15 23:27:42 UTC | #65

Shouldn't this be 2approve?

https://github.com/dfinity/ICRC-1/blob/be22f710523324d2a4e2574706b5cf5753f5931c/standards/ICRC-3/README.md?plain=1#L271

-------------------------

skilesare | 2024-03-15 23:28:22 UTC | #66

Would there be anything precluding us from putting both the type at the top and op in the tx?

-------------------------

mariop | 2024-03-18 10:44:42 UTC | #67

I've received a lot of feedback during the weekend (thanks!). I'm going to discard the motion proposal I was writing and make some adjustments to the ICRC-3 draft based on that feedback. SpecificallyL

1. fix typos
2. Change the name of the field `type` to something that is not a keyword in most languages, e.g. `btype` (we have `phash` so...)
3. Explain what happens if both `btype` and `tx.op` are defined (`btype` has priority)
4. Explain what the endpoint `icrc2_supported_block_types` returns in the default (ICRC-1 and ICRC-2) case when the Ledger doesn't support `btype` yet. There are two options: a) the Ledger returns nothing or b) the Ledger returns `1burn`, `1mint`, `2xfer` and `2approve` even if the `btypes` are not set yet in the blocks. I think b) is better because it allows to compose the default behavior with other standards.

Stay tuned :slight_smile: .

-------------------------

Saumay-Agrawal | 2024-03-18 11:00:57 UTC | #68

Hey Austin, can you please share when and where you would be having these conversations? Would love to be part of it.

-------------------------

skilesare | 2024-03-18 14:20:18 UTC | #69

Yes...I will announce it on the forum...likely we'll do a new WG focused around these ideas.

-------------------------

mariop | 2024-03-18 15:53:21 UTC | #70

I've pushed a new version of the draft and replaced `type` with `btype`. You can find the preview [here](https://github.com/dfinity/ICRC-1/blob/1467044471b7ba5853e50b88c183fa2209f6c395/standards/ICRC-3/README.md). Once again I'll wait a couple of days for comments.

-------------------------

skilesare | 2024-03-18 16:24:43 UTC | #71

> If both are specified then `tx.op` should be ignored and `btype` should be used.

Can we be specific about what 'ignored' here means?  Is it ignored when calculating the hash? Or just when calculating the state of a canister from Genesis?

I'd prefer letting it be included in the hash calc if present as including it makes deduplication much easier and removing it when calculating hashes would likely be an expensive operation.

-------------------------

mariop | 2024-03-18 17:43:53 UTC | #72

[quote="skilesare, post:71, topic:25132"]
Can we be specific about what ‘ignored’ here means? Is it ignored when calculating the hash? Or just when calculating the state of a canister from Genesis?

I’d prefer letting it be included in the hash calc if present as including it makes deduplication much easier and removing it when calculating hashes would likely be an expensive operation.
[/quote]

I changed it to say that if both are set then `btype` defines the type of the block. Both should still be used for the hash.

-------------------------

skilesare | 2024-03-18 20:11:13 UTC | #73

> 1. the `btype` field MUST be
 > 1. `"2xfer"` if the Ledger supports ICRC-2
  >2. `"1xfer"` if the Ledger doesn't support ICRC-2

Hmmm....this is confusing to me.  And a bit complex from a library perspective. Ideally, an ICRC1 library should exist without having to have any information about what ICRC2 is. The ICRC2 library is like an add-on.

Is there any reason why icrc1_transfer can't use 1xfer and icrc2_transfer_from use 2xfer?  Theoretically, we shouldn't have a 1xfer with a spender right?

Should they be defined as different blocks with separate schemas?

If my ICRC1 library has to know if it is in ICRC2 mode it kind of creates a circular dependency.

-------------------------

kayicp | 2024-03-19 05:38:40 UTC | #74

[quote="skilesare, post:73, topic:25132"]
Is there any reason why icrc1_transfer can’t use 1xfer and icrc2_transfer_from use 2xfer?
[/quote]
I was thinking the same thing. One `btype` for each method. icrc1_transfer: `1xfer`, icrc2_transfer_from: `2xfer`.

-------------------------

mariop | 2024-03-19 12:51:23 UTC | #75

Good point, I'll change the draft. By the way, today's working group is going to be again about ICRC-3 and the latest updates. If you are interested in the standard then join us!

-------------------------

mariop | 2024-03-19 16:36:28 UTC | #76

@skilesare @kayicp I've made the change. The spec now reads:

> 1. the `btype` field MUST be
>    1. `"2xfer"` for `icrc2_transfer_from` blocks
>    2. `"1xfer"` for `icrc1_transfer` blocks

I've decided to keep one section for both blocks because they contain the same fields minus the `spender`.

-------------------------

mariop | 2024-03-19 17:25:01 UTC | #77

I got no more comments. I'll let the draft up for a couple more days and then I'll make the NNS motion proposal.

-------------------------

mariop | 2024-03-25 16:41:56 UTC | #78

Hi, the [motion proposal for ICRC-3 is live](https://dashboard.internetcomputer.org/proposal/128824) and to be voted by the NNS. Thanks everyone who helped with the standard.

-------------------------

Roman | 2024-03-25 16:47:33 UTC | #79

Marvelous ! Congratulations to you all for this hard and patient work !

-------------------------

gatsby_esp | 2024-03-25 18:23:07 UTC | #80

Rosetta is dependant on ICRC 3 right? How long until rosetta? Got an update?

-------------------------

mariop | 2024-03-25 18:54:21 UTC | #81

Rosetta is not dependent on ICRC-3 and it's using the interface for fetching blocks that the existing canisters provide ([get_blocks](https://dashboard.internetcomputer.org/canister/mxzaz-hqaaa-aaaar-qaada-cai#get_blocks) to be specific). This allowed us to develop Rosetta without having to wait for the standard to be voted.

Rosetta is currently feature complete and we just did the security review. The team is now addressing the findings and then we can release it.

The plan is to eventually move Rosetta to use ICRC-3 to fetch the blocks but that doesn't block the release of Rosetta.

-------------------------

dieter.sommer | 2024-03-26 13:27:01 UTC | #82

Awesome, hope this gets adopted!

-------------------------

skilesare | 2024-04-12 17:53:33 UTC | #83

Does anyone have any thoughts on how one should write a motoko float into an ICRC3 transaction log?

Is there a quick and dirty function to get the components of a float so it can all be put back together again? If so we can do a map of those components.

The options I'm seeing are outputting text with #exact, but I'm not sure how to put the bbs back in the box with that.

Can we not get the sign, exp, and Mantissa exposed to motoko?  Can Prim do it?

-------------------------


q2333gh | 2024-04-11 01:24:00 UTC | #1

Im curious about it .Is it necessary for deAI using parallel GPU empower? 
I have checked ic ai documentation brief.
https://internetcomputer.org/docs/current/developer-docs/ai/overview
If onchain GPU already accessible will be great!

-------------------------

q2333gh | 2024-04-11 01:39:35 UTC | #2

I found that using web2 gpt-api with frontend canister is not very difficult to impl.
https://github.com/peterpeterparker/juno-openai
This got a good example.

Do we have necessary to build fully on chain ai product ?

-------------------------

q2333gh | 2024-04-11 09:51:45 UTC | #3

Since AI is quite trendy these days. guys , do you interesting on this ?

-------------------------

q2333gh | 2024-04-11 15:19:08 UTC | #4

https://www.youtube.com/watch?v=IPCSUI-1dKo

dom talked about AI computation ablity on chain

about 22:00

Explained some canister capability.

But i might missing see the GPUs on chain ?

24:38 mention about wasm vm memory.
wasm32 got 4gb memory.
few month will upgrade to wasm64.

But i got a quesiton :
is this memory on chain got similar performance on a nvidia  B200 GPU  GDDR6 memory ?
And how ic-replica do parallel computation heavy task like a B200 GPU does ?

-------------------------

jennifertran | 2024-04-12 04:41:02 UTC | #5

You can check out DeAI projects on ICP on the [DeAI on ICP Working Group GitHub](https://github.com/DeAIWorkingGroupInternetComputer/DeAIWorkingGroupInternetComputer) and [Internet Computer Ecosystem Page - AI](https://internetcomputer.org/ecosystem?tag=AI).

You will see several on-chain LLMs already on ICP. Most notably [ICPP-LLM](https://github.com/icppWorld/icpp_llm).

Research on and onboarding of GPU-based nodes are ongoing.

-------------------------


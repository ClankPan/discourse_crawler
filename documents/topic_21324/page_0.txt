tokuryoo | 2023-07-13 05:37:04 UTC | #1

Hi everyone,
Is there a way to resolve the lack of CPU or memory resources in a given canister? In some cases, splitting the functions may solve the problem, but in other cases it may not be possible to split the functions. I am interested in the latter.

For example:
* Lack of heap memory
* Lack of stable memory
* Over the instruction limit
* No single request reaches the instruction limit, but the sheer volume of requests is overwhelming.

Or, does using CanDB solve the memory shortage issue?

-------------------------

benji | 2023-07-13 08:12:49 UTC | #2

Optimize your code :joy:

-------------------------

Severin | 2023-07-13 08:56:40 UTC | #3

It depends on how much you need.

The heap is currently probably the hardest one. I don't really have good ideas for that. Sometimes you can write more to stable memory so you don't keep as much data on the heap

Stable memory capacity is slowly growing, for now it's at 64GB. If that's not enough for you, you probably have to scale out to multiple canisters

The instruction limit is also pretty hard to work around. There the only options are to optimise your code, which is hard and often has limited reach. The other one is to split your functions up and do self-calls, since after every `await` the instruction counter is reset

For the volume of requests you again have to scale out to multiple canisters or shift to more query calls. Canisters are single-threaded for update calls. For queries every node can respond on its own without blocking other nodes from responding

-------------------------

tokuryoo | 2023-07-14 06:34:48 UTC | #4

@Severin 
Thanks for your reply. I understood.

It might be difficult  to achieve the kind of auto scaling that BigTech's PaaS offers. I have high hopes for [Subnet Splitting](https://forum.dfinity.org/t/long-term-r-d-subnet-splitting-proposal/9402/4), but I don't see it as a solution to high load canisters.

-------------------------


skilesare | 2023-01-06 18:52:41 UTC | #1

# Motoko StableBTree - #24

## Current Status: Discussion

* Discussion (08/14/2022)
* Ratification 
* Open for application
* Assigned 
* In Review 
* Closed 

[Official Link](https://icdevs.org/bounties/2022/08/14/Motoko-StableBTree.html)

## Bounty Details

* Bounty Amount: $5,000 USD of ICP at award date - $5000 USD of ICP Match Available
* ICDevs.org DFINITY Foundation Grant Match Available: $5000 USD of ICP at award time - (For every ICP sent to 801581b2c8f3303eaeb91892784b2eac99e1128115b0fadf739576d6c94f3c8e, ICDevs.org will add $40 USD of ICP at award date to the bounty, up to the first 125 ICP donated, After 125 ICP, donations to the above address will add .25 ICP to this issue and .75 ICP to fund other ICDevs.org initiatives)
* Project Type: Team
* Opened: 09/02/2022
* Time Commitment: Weeks
* Project Type: Library
* Experience Type: Intermediate - Motoko;

## Description

This Motoko library will allow for more efficient storage and better crypt capabilities of data storage in motoko contracts.

This bounty gives the opportunity to

* learn motoko
* learn about merkleizaton
* learn btrees
* learn about stable memory

This one is pretty simple. Implement the StableBTree library found at https://github.com/ielashi/stable-btreemap-example in Motoko.  Accomplishing this will award 50% of the bounty.

For the second 50%, add a mode(or an alternate library if it is more efficient), That keeps active track of a merkle hash of the root of the data set.  This library will be used to calculate certified data, so the root should be compatible with including in a canister certification.

Please:

1. Duplicate the existing functionality.

2. Provide a set of tests.

3. Publish as a vessel package

4. For the merkle stretch goal, please provide tests and an example of using the tree to store certified data.

## To apply for this bounty you should:

* Include links to previous work writing tutorials and any other open-source contributions(ie. your github).
* Include a brief overview of how you will complete the task. This can include things like which dependencies you will use, how you will make it self-contained, the sacrifices you would have to make to achieve that, or how you will make it simple. Anything that can convince us you are taking a thoughtful and expert approach to this design.
* Give an estimated timeline on completing the task.
* Post your application text to the Bounty Thread

## Selection Process

The ICDevs.org developer's advisors will propose a vote to award the bounty and the Developer Advisors will vote.

## Bounty Completion

Please keep your ongoing code in a public repository(fork or branch is ok). Please provide regular (at least weekly) updates.  Code commits count as updates if you link to your branch/fork from the bounty thread.  We just need to be able to see that you are making progress.

The balance of the bounty will be paid out at completion.

Once you have finished, please alert the dev forum thread that you have completed work and where we can find that work.  We will review and award the bounty reward if the terms have been met.  If there is any coordination work(like a pull request) or additional documentation needed we will inform you of what is needed before we can award the reward.

## Bounty Abandonment and Re-awarding

If you cease work on the bounty for a prolonged(at the Developer Advisory Board's discretion) or if the quality of work degrades to the point that we think someone else should be working on the bounty we may re-award it.  We will be transparent about this and try to work with you to push through and complete the project, but sometimes, it may be necessary to move on or to augment your contribution with another resource which would result in a split bounty.

## Funding

The bounty was generously funded by the DFINITY Foundation. If you would like to turbocharge this bounty you can seed additional donations of ICP to 801581b2c8f3303eaeb91892784b2eac99e1128115b0fadf739576d6c94f3c8e.  ICDevs will match the bounty $40:1 ICP for the first 125 ICP out of the DFINITY grant and then 0.25:1 after that.  All donations will be tax deductible for US Citizens and Corporations.  If you send a donation and need a donation receipt, please email the hash of your donation transaction, physical address, and name to donations@icdevs.org.  More information about how you can contribute can be found at our [donations page](https://icdevs.org/donations.html).


## FYI: General Bounty Process

### Discussion

The draft bounty is posted to the DFINITY developer's forum for discussion

### Ratification

The developer advisor's board will propose a bounty be ratified and a vote will take place to ratify the bounty.  Until a bounty is ratified by the Dev it hasn't been officially adopted. Please take this into consideration if you are considering starting early.

### Open for application

Developers can submit applications to the Dev Forum post.  The council will consider these as they come in and propose a vote to award the bounty to one of the applicants.  If you would like to apply anonymously you can send an email to austin at icdevs dot org or sending a PM on the dev forum.

### Assigned

A developer is currently working on this bounty, you are free to contribute, but any splitting of the award will need to be discussed with the currently assigned developer.

### In Review

The Dev Council is reviewing the submission

### Awarded

The award has been given and the bounty is closed.

# Matches

DFINITY Foundation Grant: - $5000 USD of ICP at award date


[Other ICDevs.org Bounties](https://icdevs.org/bounties.html)

-------------------------

domwoe | 2022-08-17 08:02:50 UTC | #2

Concerning the second part of the bounty, see https://github.com/dfinity/motoko-base/issues/409

-------------------------

senior.joinu | 2022-08-17 09:39:26 UTC | #3

Agree with @domwoe 
It is a better idea to implement a specialized data structure for data certification.

-------------------------

skilesare | 2022-09-06 20:26:31 UTC | #4

This bounty is being pursued by @sardariuss

-------------------------

satya | 2022-09-24 07:31:15 UTC | #5

Hi, Is this bounty already closed and assigned to someone? I still this as open bounty here icdevs[.]org/news

-------------------------

skilesare | 2022-09-24 09:28:10 UTC | #6

@sardariuss Are you still working on this bounty?

-------------------------

sardariuss | 2022-09-24 14:00:49 UTC | #7

Yes I am, I'll be able to show you some progress soon.

-------------------------

satya | 2022-09-24 14:57:33 UTC | #8

In that case is it possible to have it assigned, and not be it in the open bounties section?

-------------------------

sardariuss | 2022-09-28 19:00:35 UTC | #9

I'd like to be able to transform Motoko basic types (essentially the Nat16/Nat32/Nat64 and resp. Int) types into an array of bytes. In rust this is done with to_le_bytes. Also if there is something that exists to convert a struct into such an array of bytes I'm taking it too. I think rust uses the trait #[repr(packed)] that allows to peform a safe cast into a pointer of u8, then converted into a vec. But I doubt something that straightforward is possible in Motoko.

Otherwise I might continue with my tricky structures in my AlignedStruct module for now. But at some point I think I will need to be able to convert everything in a vector of bytes anyway just to be able to test with a "fake" memory (like vec_mem.rs in the Rust implementation). I was curious to test directly with ExperimentalStableMemory, but it crashes at the compilation of the tests, which probably makes sense.

-------------------------

skilesare | 2022-09-28 19:34:03 UTC | #10

I have that logic in https://github.com/skilesare/candy_library/blob/main/src/conversion.mo.  You could adapt it...probably don't need the whole candy library as you are trying to do something fast.

-------------------------

sardariuss | 2022-10-07 18:51:59 UTC | #11

Hey, small update for this bounty, the code is here: https://github.com/sardariuss/MotokoStableBTree

I finished the implementation of the BTreeMap itself, I'll start on the unit tests next week.

And thank you for the candy lib that's exactly what I needed.

-------------------------

sardariuss | 2022-10-21 19:10:52 UTC | #12

Hi Skilesare,

All Rust unit tests have been implemented in Motoko. As suggested by CanScale, I'm gonna continue with these 3 tests before jumping on the merkleizaton:
  1 - A test that does random key insertion for ~ 5000 values
  2 - A test that is always inserting a new value which is the new highest value in the tree ~ 5000 values
  3 - A test that runs an upgrade, and then show they persisted through the upgrade

I have a question though: the conversion from type to bytes are done in little endianin Rust, whereas the conversions from the candy lib are in big endian, so should I convert my types in little endian instead ?

-------------------------

kentosugama | 2022-10-24 18:30:07 UTC | #13

Hey @sardariuss,

Nice to meet you online! I'm on the Motoko team at DFINITY and am working on extending data structures in the base library. I was wondering if you have any interest in contributing this to the `motoko-base` library when it is complete (with potentially some added QOL bells and whistles to make it very user friendly). 

Let me know what you think.

-------------------------

sardariuss | 2022-10-24 19:29:13 UTC | #14

Hi Kentosugama,

Nice to meet you too! Yes for sure, I'd be very happy to do that.

-------------------------

sardariuss | 2022-10-26 18:16:01 UTC | #15

Hi,

I've done the few tests I was talking about before (testing with actual stable memory), it works well, for now it's in a separate repo here: 

https://github.com/sardariuss/MotokoStableBTreeTest

I'm gonna put this in the original repo soon, with CI on top.

@kentosugama I've been thinking a bit on how to improve the public interface to make it more user friendly. As an example the current BTreeMap.init method looks like this:

/// Initializes a `BTreeMap`.
///
/// If the memory provided already contains a `BTreeMap`, then that
/// map is loaded. Otherwise, a new `BTreeMap` instance is created.
public func init<K, V>(
  memory : Memory,
  max_key_size : Nat32,
  max_value_size : Nat32,
  key_converter: BytesConverter<K>,
  value_converter: BytesConverter<V>
) : BTreeMap<K, V> {

First, I could wrap the current BTreeMap class into a new StableBTreeMap (or just StableBTree?) that uses the stable memory as memory. This would remove the memory parameter from the init method. And we could only expose a few methods (e.g. insert, get, remove, size). I want to keep the rest public in the original BTreeMap so I can do unit tests.

Second, it would be great if the key_converter and value_converter could directly be deduced from the type of K and V. But AFAIK it's not possible to do such thing in Motoko. I'm forced to have a method to convert types in bytes because the ExperimentalStableMemory has a specific method for each type. I guess I could create a StableBTreeVK class for each combination of K and V I want to support but this is super ugly. Note that converting in bytes also makes my life way easier to be able to test the BTreeMap with my VecMemory that is a buffer of bytes.
One alternative could be to not template any of this and use always use [Nat8] for keys and values, forcing the user to do the conversion beforehand and afterwards. But IMO I'd  rather just have to give the converters in the init method.

What do you think? Is this some of the improvements you were thinking when talking about "QOL bells and whistles" ?

-------------------------

kentosugama | 2022-10-27 19:23:38 UTC | #16

Hey!

This sounds great.

As a general point, I think it makes sense to fully complete the ICDevs bounty first, and then we can worry about merging into base.

By QOL, I mainly mean adding extra utility functions (e.g. https://github.com/dfinity/motoko-base/blob/master/src/Buffer.mo). I don't think there will be as many functions for maps, but things like finding max value, min value, folding over maps, mapping a higher order function over the kv pairs, producing a text representation of the current entries, etc. 

Serialization seems to be the most thorny problem. Right off the bat, do you think there's a good way to have a non-stable version, where the user doesn't have to pass in a memory (since it's just stored in the normal heap), and there's no max sizes or converters since serialization is not necessary?

As for the stable use case, I agree that having the users pass in the converters is the best approach at the moment. I would definitely not implement every combination of serializer by type :) 

A possible alternative: Not sure if you've considered using `to_candid` and `from_candid` primitives? These are Motoko operators that let you serialize any shareable type to Blobs and back. Could be useful as an out of box serializer, except for the fact that you need to convince the compiler that the generic types are shared. As far as I can tell, this is a bit tricky at the moment. https://forum.dfinity.org/t/motoko-sharable-generics/9021.

-------------------------

sardariuss | 2022-11-18 19:58:47 UTC | #17

Hi guys,

Last updates:
 - The MemoryManager has been added to be able to use many btrees in stable memory. All tests pass, but it seems that using the MemoryManager significantly slows down the execution of the BTree functions. I haven't done any investigation yet.
 - A version of the Btree using the heap instead of the stable memory is now available on the branch "heap_version".
 - Kentosugama will start PRs to gradually put the code (both stable and heap versions) into the motoko-base library. @skilesare Could somebody from ICDevs be involved in the reviews ? That could be a way to validate the first part of the bounty.

-------------------------

skilesare | 2022-11-18 22:08:20 UTC | #18

Awesome!  I'll take a look early next week.  We'll get the bounty closed out.  Great Job!

-------------------------

sardariuss | 2022-11-21 13:53:55 UTC | #19

Hey, icme made me realize I missed a few things: for the stable implementation, I missed a few recent commits from the rust repo, I'm gonna check that out. For example https://github.com/dfinity/stable-structures/commit/53d4f939c7b68f00ca1236c431fbaf9d366cb980 I could do something similar in the motoko version, adding the max_size function in the BytesConverter, and probably exposing the bytesConverter for every common type (Nat8, Nat32, etc.).

Also for the heap_version, I need to use a buffer of the real K, V types instead of bytes, there is no need to convert in bytes indeed.

@kentosugama I will create new branches in my repo to do this to not impact the PR if that's correct with you

-------------------------

sardariuss | 2022-11-23 22:15:33 UTC | #20

Small update: I implemented the max_size() function in the BytesConverter on the main branch and the K, V template arguments for the heap version.

@kentosugama I tried to understand what's happening with the MemoryManager today.

First I noticed that the execution slows down or crashes:
  - around 5k entries when using the MemoryManager (with stable memory)
  - around 25k entries when using directly the stable memory

When it slows down or crashes, I usually have these messages in the console:

> Nov 23 18:36:15.524 WARN s:za6i6-rsijm-wkhfy-76yge-w72zd-2mbch-4hjg5-6ieqy-alrnx-azwgk-iqe/n:evshh-lrotb-t5oeu-psqm7-fqz5h-zfyun-r5wdr-u5ugs-zqhrz-wc7rw-uae/ic_execution_environment/scheduler Finished executing message type "Ingress, method name insertMany," on canister CanisterId(rrkah-fqaaa-aaaaa-aaaaq-cai) after 7.2521542 seconds, messaging: {"round":41,"canister_id":"rrkah-fqaaa-aaaaa-aaaaq-cai","message_id":null}
> Nov 23 18:36:32.719 WARN s:za6i6-rsijm-wkhfy-76yge-w72zd-2mbch-4hjg5-6ieqy-alrnx-azwgk-iqe/n:evshh-lrotb-t5oeu-psqm7-fqz5h-zfyun-r5wdr-u5ugs-zqhrz-wc7rw-uae/ic_consensus/consensus starvation detected: Notary has not been invoked for 4.1307306s

Also when I monitor the RAM, I see some spikes that seem to coincide with the moment these messages are emited. That RAM far exceeds the memory required for my entries to be stored in the btree.

My naïve guess is that the query/update methods I call take too much time (because I call a single canister method insert that inserts 5k entries at once in a motoko loop to reduce test time). This creates problems with the simulated consensus, which then requires more cpu and memory to perform, and ultimatly leads to the crash. But in my tests, when I tried to call the query/updates in 10 batches of 500 entries, it doesn't quite solve the problem.

I'll continue investigate tomorrow, but any feedback will be appreciated!

-------------------------

icme | 2022-11-24 01:48:56 UTC | #21

Maybe try importing the library and using it on the Motoko playground if you think it’s an issue with the local replica and want to reproduce the behavior.

-------------------------

sardariuss | 2022-12-23 16:08:24 UTC | #22

Small update, concerning the limitations observed with the memory manager, the same things happen on the main net. I didn't spend more time investigating because:

After discussing with @kentosugama, it seems that dfinity is or will be working on unifying a memory manager implementation to be able to use different custom stable data structures simultaneously (maybe it will be through a change of the ExperimentalStableMemory api). I don't have much more information about it for now.

Also the merge request to put the BTree in the standard library is still in draft

-------------------------

tomijaga | 2022-12-23 19:53:17 UTC | #23

This is really cool! Having a dedicated memory manager in the base module would make it easier to create stable memory collections.

-------------------------

matthewhammer | 2023-01-30 23:06:59 UTC | #24

[quote="sardariuss, post:22, topic:14867"]
After discussing with @kentosugama, it seems that dfinity is or will be working on unifying a memory manager implementation to be able to use different custom stable data structures simultaneously (maybe it will be through a change of the ExperimentalStableMemory api). I don’t have much more information about it for now.
[/quote]

I'm shifting my focus to this now myself, after coordinating with @kentosugama earlier today.  I am only now catching up on this thread; I apologize for being late to the discussion.

My first impressions are that this BTree implementation in Motoko will be ideal for testing the more modular version of the (currently experimental) stable memory API, which I'll explain briefly here.  I apologize for revisiting what's already discussed above.

In the [current API](https://github.com/dfinity/motoko-base/blob/master/src/ExperimentalStableMemory.mo), there is conceptually a single monolithic array with low-level read and write operations, and a procedure to grow the array into a larger one. Without more work, this only supports a single (monolithic) data structure.

As a first implementation to generalize this, I propose offering a `class` in Motoko that comes with the same API as the current (experimental) module. 
Each constructor call would create a distinct (initially-empty) "memory instance", corresponding to a distinct growable array.

Under the hood, the class would use a dedicated allocator for stable memory to manage the monolithic space and give the abstraction of these distinct arrays, rather than a single shared one (still the reality at that lowest level).  As a first implementation of the allocator, we could reimplement [this Rust implementation of the idea](https://github.com/dfinity/stable-structures/blob/main/src/memory_manager.rs) entirely in Motoko, using the currently-experimental API, with the intention of eventually hiding it entirely behind this new (non-experimental) `class`.

There will still be the same caveats as today: The experimental API is very low-level, and it's still possible to clobber yourself within an array.  The benefit of the new `class` would be that two (or more) stable structures would:

- coexist without clobbering each other
- not consume any space as "reserve" (no padding space is needed)

-------------------------

matthewhammer | 2023-01-30 23:30:48 UTC | #25

[quote="matthewhammer, post:24, topic:14867"]
As a first implementation of the allocator, we could reimplement [this Rust implementation of the idea](https://github.com/dfinity/stable-structures/blob/main/src/memory_manager.rs) entirely in Motoko
[/quote]

Looking more closely at the existing implementation in Motoko by @sardariuss it seems that this route is exactly what's [already done here.](https://github.com/sardariuss/MotokoStableBTree/blob/main/src/memoryManager.mo)

And it seems to give a big slowdown, based on reading comments above and in the repo itself.

Perhaps the next step here is to look more carefully at this implementation, with an eye towards improving the performance, if possible.  Using an RBTree from `base` for the buckets is conceptually clean but could be less than optimal in terms of performance, for instance.

-------------------------

matthewhammer | 2023-01-31 17:39:51 UTC | #26

[quote="matthewhammer, post:25, topic:14867"]
Perhaps the next step here
[/quote]

Update: After more discussion today with my colleagues, it seems like there's a strong interest in pursuing the inclusion of this stable memory allocator feature within the Motoko runtime system itself, to leverage the leaner, lower-level performance available there.  I'll be shifting focus to that now, with more updates to follow.

-------------------------

sardariuss | 2023-02-01 13:46:51 UTC | #27

Thanks for the updates.

Now that I think about it I should have compared the performance of the motoko implementation with the Rust's one. Also I'm curious to see what kind of improvements you will do (e.g. for the RBTree).

-------------------------

matthewhammer | 2023-02-06 18:53:17 UTC | #28

[quote="sardariuss, post:27, topic:14867"]
Also I’m curious to see what kind of improvements you will do (e.g. for the RBTree).
[/quote]

[This PR](https://github.com/dfinity/motoko/pull/3768) gives some initial thoughts.  Specifically, the design proposal in the markdown file reflects some ideas from last week that are still evolving this week as we continue to discuss tradeoffs of different approaches.

While we want to start with something similar to the Rust version, we are also looking towards generalizations of it, though that will come later.

The main generalization of interest is supporting GC-based reclamation of "stable regions" for reuse by others.  That consideration is affecting some of our current thinking, since we want to support it eventually, somehow.

-------------------------

matthewhammer | 2023-03-06 16:00:18 UTC | #29

[quote="matthewhammer, post:28, topic:14867"]
[This PR ](https://github.com/dfinity/motoko/pull/3768) gives some initial thoughts.
[/quote]
The `design/StableRegion.md` document in the PR is now "stable" (no pun intended).

I've moved on to trying to implement the primitives described there.

In the meantime, we can discuss the design and the way it could be used for building things like the StableBtree described in this thread.  If anyone sees issues or has questions, please let us know.

-------------------------

rabbithole | 2023-06-29 09:52:39 UTC | #30

@sardariuss First of all, I would like to thank you for a VERY cool job!

The only reason I couldn't implement this in my project is using Nat8, my data takes up too much space in stable memory. I found [this branch](https://github.com/sardariuss/MotokoStableBTree/compare/main...improvement/useBlob) and at first glance this is exactly what I would like. How reasonable is it to use this branch to import into a project? Or are you planning to add a toggle option for storing to Blob in the main branch? As I understand from the discussion, after the implementation of Region in Motoko, your library will also change and then it is not clear what prospects await the branch that uses Blob.

-------------------------

sardariuss | 2023-06-29 19:22:38 UTC | #31

Hey @rabbithole, thanks for the kind words.

Concerning this lib, I do not advise using it for the following reasons:
 - It has a good test coverage but still, I don't think much people are using it (which is a bit of a red flag to me). And I know @skilesare had an issue once with initializing a btree with nodes of size of 1024kb, I don't know if he gave up using the lib or not.
 - The usage is a bit hard: right now you need to keep memoryIds of the memory chunks allocated for your btrees. Also if you use it as is, you're gonna be bound to use the MemoryManager that comes with it, so if in a potential next version the memory Region are used instead, you won't be able to upgrade your btrees using the memoryManager to the one using the regions.
 - There's probably a better alternative out there, the stable map version from @ZhenyaUsenko : https://github.com/ZhenyaUsenko/motoko-hash-map/tree/master but I'm not quite sure if it fits your need. I think at least in theory btree shall work better to store big blobs? I haven't done any benchmark myself to compare the performance between the stable btree and this motoko-hash-map for example, so I couldn't say.
 - At the end I don't have the time right now to work on it to use the new memory regions myself. But it would be nice to have it implemented someday indeed.

Concerning the changes on the branch you're pointing to they were meant to increase the speed at which the functions are executed (by avoiding uncessary conversions between blob and [nat8] done when reading/writing in stable memory). I don't think it reduces much the size of the data stored in the btree. I might be wrong, I don't know what is the size of a blob compared to a [Nat8] in memory.

-------------------------

matthewhammer | 2023-09-15 17:08:07 UTC | #32

[quote="sardariuss, post:31, topic:14867"]
Also if you use it as is, you’re gonna be bound to use the MemoryManager that comes with it, so if in a potential next version the memory Region are used instead, you won’t be able to upgrade your btrees using the memoryManager to the one using the regions.
[/quote]

FWIW, I am adapting this code to use the `Region` system in the latest version of `moc` (`0.10.0`) and forthcoming in DFX, hopefully very soon.

[See the ongoing PR for details](https://github.com/sardariuss/MotokoStableBTree/pull/4).

-------------------------

sardariuss | 2023-10-02 14:48:36 UTC | #33

I've merged the changes I've done to use the Region instead of the ExperimentalStableMemory in the trunk. I made a few changes in the interfaces of the lib, I was inspired by the Map from @ZhenyaUsenko. The intended usage:


```
  import BTree "mo:StableBTree/BTree"

  // Arbitrary use of (Nat32, Text) for (key, value) types
  let n32conv = BTree.n32conv;
  let tconv = BTree.tconv(64); // Max 16 characters
  stable let _btree = BTree.new<Nat32, Text>(n32conv, tconv);

  let old = BTree.put(_btree, n32conv, 0, tconv, "hello");
  let new = BTree.get(_btree, n32conv, 0, tconv);
  let size = BTree.size(_btree);

  assert Option.isNull(old);
  assert Option.isSome(new);
  assert size == 1;
```
Where the types are as follow:

```
type BTree<K, V> = {
    region: Region;
    key_nonce: K;
    value_nonce: V;
  };

type BytesConverter<T> = {
    from_bytes: (Blob) -> T;
    to_bytes: (T) -> Blob;
    max_size: Nat32;
    nonce: T;
  };
```

The “nonces” (shall probably be renamed) are only useful to keep the initial template parameters, so that when a BTree is loaded from stable memory later, the compilation prevents loading it with different template parameters than the original one. It's kind of a trick, but I don't know how else to do to support template parameters otherwise.
The max_size is used at the initialization of the btree and directly stored in stable memory. If you every give a greater max size later it will have no effect, and inserting a key/value with a greater size than the original one will still trap.
If you guys have better ideas please share.

I'd like to create benchmarks for the lib before releasing it on mops. @ZhenyaUsenko I was wondering how did you come up with your performance metrics for your stable map?

-------------------------

ZhenyaUsenko | 2023-10-02 15:11:34 UTC | #34

That's what I use to track performance

```
public query func testPerf(): async [Text] {
    let map = Map.new<Nat32, Nat32>();

    let startSpace = Prim.rts_heap_size();

    let setCost = IC.countInstructions(func() {
      var i = 0:Nat32;

      while (i != 100000) { Map.set(map, n32hash, i, i); i +%= 1 };
    });

    let setSpace = Prim.rts_heap_size() - startSpace:Nat;

    let getCost = IC.countInstructions(func() {
      var i = 0:Nat32;

      while (i != 100000) { ignore Map.get(map, n32hash, i); i +%= 1 };
    });

    let getSpace = Prim.rts_heap_size() - startSpace:Nat - setSpace:Nat;

    let updateCost = IC.countInstructions(func() {
      var i = 0:Nat32;

      while (i != 100000) { Map.set(map, n32hash, i, i); i +%= 1 };
    });

    let updateSpace = Prim.rts_heap_size() - startSpace:Nat - setSpace:Nat - getSpace:Nat;

    let deleteCost = IC.countInstructions(func() {
      var i = 0:Nat32;

      while (i != 100000) { Map.delete(map, n32hash, i); i +%= 1 };
    });

    let deleteSpace = Prim.rts_heap_size() - startSpace:Nat - setSpace:Nat - getSpace:Nat - updateSpace:Nat;

    var i = 0:Nat32;

    while (i != 100000) { Map.set(map, n32hash, i, i); i +%= 1 };

    let deleteDescCost = IC.countInstructions(func() {
      var i = 100000:Nat32;

      while (i != 0) { i -%= 1; Map.delete(map, n32hash, i) };
    });

    return [
      "set cost - " # debug_show(setCost),
      "get cost - " # debug_show(getCost),
      "update cost - " # debug_show(updateCost),
      "delete cost - " # debug_show(deleteCost),
      "delete desc cost - " # debug_show(deleteDescCost),
      "---",
      "set space - " # debug_show(setSpace),
      "get space - " # debug_show(getSpace),
      "update space - " # debug_show(updateSpace),
      "delete space - " # debug_show(deleteSpace),
    ];
  };
```

-------------------------

timo | 2023-10-19 13:03:14 UTC | #35

[quote="matthewhammer, post:32, topic:14867"]
FWIW, I am adapting this code to use the `Region` system in the latest version of `moc` (`0.10.0`) and forthcoming in DFX, hopefully very soon.
[/quote]

Just to understand, what exactly is the region used for? Is the btree operated on while it is stored in a region? Or does it live on the heap and then is serialized to a region?

And how does it compare to the "changes" mentioned here?

[quote="sardariuss, post:33, topic:14867"]
I’ve merged the changes I’ve done to use the Region instead of the ExperimentalStableMemory in the trunk.
[/quote]

-------------------------

matthewhammer | 2023-10-20 17:19:35 UTC | #36

[quote="timo, post:35, topic:14867"]
Just to understand, what exactly is the region used for?
[/quote]

The `Region` gives an isolated version of the old "experimental" stable memory API.  The `Region` can grow independently of other regions, which have their own "address space".

The rest of the logic of the B Tree closely mimics the Rust version of the same thing.  Both mutate the B tree in stable memory, and do their own customized "memory allocation" to reuse space of old tree nodes when allocating new ones.

> Or does it live on the heap and then is serialized to a region?

It does not do this.

Speaking of which, on Wed at Global R&D, @chenyan presented some performance data comparing these structures across two dimensions:
- Rust vs Motoko
- Heap vs Stable Memory

Maybe he can paste that table of data here.

-------------------------


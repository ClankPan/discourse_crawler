skilesare | 2021-12-02 19:55:48 UTC | #1

by Austin Fatheree(@skilesare) with input from many others in the community. Special thanks to @wpb for laying the groundwork for healthy community debate.

ICDevs.org is launching a new initiative to help coalesce a set of languages around the Internet Computer. These are not programming languages.  The “Languages Project” is an attempt by ICDevs.org to contribute to the adoption of the Internet Computer by creating generative, form, and pattern language to the community that provides a common set of communication tools that foster well-formed, productive, interoperable, and collaborative systems for innovation on and around the Internet Computer ecosystem.

These patterns are open-sourced and we would love community contribution. You can provide pull requests to our repo at https://github.com/icdevs/Icdevs_fleeksite. and read more about the initiative at https://icdevs.org/language_project/index.html.  We are just getting started, so excuse the lack of current content.

The first Pattern in our Pattern Language that we are proposing to the community is a concept called "Namespaced Interfaces".  This topic has been discussed a few times on the forum, specifically [here](https://forum.dfinity.org/t/non-fungible-token-nft-standard-community-consideration/6157/50).

This pattern is not a proposal that we can specifically enforce via code, but it is one that we can adopt as a community and all agree to abide by.  The text of the pattern is below with more discussion below:

-----

### NSP. Namespaced Interfaces

...how do you provide [INT - Interoperability](interoperability.html) across a broad set of interconnected services.

The Internet Computer will eventually host a broad set of interconnected services.  Some of these services are predictable(such as the transferring of funds or tokens) while some applications will not be conceived of for decades. 

When dealing with a broad set of computing endpoints in a diverse, growing, and dynamic system, it is common to run into confusing naming conflicts.

For example, both a fund transfer interface and a messaging system may have the concept of “send”.  If a third, interoperable service is trying to combine the functionality of these two services it will have to make a decision about which “send” functionality it will want to expose and which it will want to abstract.  This problem is further exacerbated by the Internet Computer because function addressing indexes only on the function name and not on the candid signature of the parameters as well.  This seems to be an intended design decision although other blockchains, and specifically, have chosen to include the parameters in the hashing of an addressable function.  

We have one example of this from the early days of the internet computer where an EXT NFT standard was created with a transfer function that takes the form:

```
type TransferRequest = {
  from : User;
  to : User;
  token : TokenIdentifier;
  amount : Balance;
  memo : ?Memo;
  notify : ?Bool;
  subaccount : ?SubAccount;
};
type TransferResponse = Result<Balance, {
  #Unauthorized: AccountIdentifier;
  #InsufficientBalance;
  #Rejected; //Rejected by canister
  #InvalidToken: TokenIdentifier;
  #CannotNotify: AccountIdentifier;
  #Other : Text;
}>;

transfer: shared (request : TransferRequest) -> async TransferResponse;
```

And a departure labs token that has the transfer function that looks like: 

```
transfer(to : Principal, id : Text)
```

The issue arises that if you want to have your NFT service act as an interoperable service and to take advantage of other interoperable services, you are now stuck with a dilemma of picking the ‘right’ or ‘most valuable’ standard. You can either implement the EXT transfer or the Departure transfer but not both.

In order to eliminate this issue, all consumable services should implement namespaced functions.  The EXT token should expose the same functionality at com_ext_nft_transfer and departure should expose com_departure_nft_transfer.  By doing this an NFT builder can expose both functions and then any service that speaks either EXT or departure can consume, transfer, reference, and amplify the value of the developer’s NFT service.

While these namespaces are not “pretty” they do, if selected well, provide some essential information at the point of invocation at least provide improved context for the trade-off in readability.

We should be clear to define what a "consumable" service is.  These are update calls or query calls that you expect external services to use or consume to interact with your service.  These are functions at the edge of your system that you expect, want, and encourage 3rd parties to use.  You do not need to use namespaces between your systems canisters that implement a larger system.  In an ideal world, the signature of these namespaces will not change and they will not 'go away'.  An upgrade of a service should likely add a _v2 or some other version indicator to the function while leaving the former in place with any missing information handled via defaults.  For example, com_ext_token_transfer(address, amount) could become com_ext_token_transfer_v2(address, amount, fee) where the initial version implements a default fee for backwards compatibility.

Further, developers should refuse to implement a ‘standard’ if it is not namespaced.  Any existing services should be retrofitted with a set of namespaced endpoints and any services using unnamespaced endpoints should be upgraded to use the namespaced endpoints.

The sooner this pattern can be adopted and implemented the better.  As more ‘blackeholed’ services are pushed onto the IC this will become a harder and harder pattern to implement.

We include the ICP ledger and NNS in this proposed pattern and suggest that any public functions should be exposed via a namespaced function.  For example:

Ledger:

```
com_icpstandard_send
com_icpstandard_balance
com_icpstandard_get_blocks
```

NNS:

```
com_nns_manage_neuron
Etc
```

By setting an example at the root level, the DFINITY foundation can help extend this pattern throughout the ecosystem.

Therefore:  When authoring standards and creation publicly consumable functions on the Internet Computer, use namespaced functions.  When consuming services, refuse to use non-namespaced functions.  Make and adopt a proposal to add namespaced interfaces to IC management canisters.

---

We'd like to propose that the community adopt this pattern and that the current dapps out there that are using/building interoperable services take the time now to update their interfaces before we have too many blackholed services that cannot be retrofit.

The main goal here is to create an interoperability environment on the IC that encourages Innovation while also supporting Integration.  We may need to produce 15 NFT standards before we find the magic mixture and I've run across far too many projects that feel held back by the fear of launching because they don't yet know what standard will "win out".  Using namespaced interfaces lets everyone run now and backfill later.

Issues for debate:

1. What form of namespace should we use?  We propose com_app_function_version, but we are open to other options as well.  For example, would it be helpful to include if the function is a query or update call in some way?

2. Should DFINITY retrofit the existing canisters(ledger, governance, etc) with namespaced interfaces that pass the call through to the current functions? Keep in mind that the initial function would stay in place, so nothing would break. Instead, we'd ask that docs, tutorials, and other material be updated with references to the proper functions to use.  We propose that they lead and make these changes in the next update of system canisters.

A time period of one week will be provided for deliberation on this proposal in the forum. The final days will be used to wait for quiet on the deliberation. If new, insightful, and actionable comments continue in those final days, then the deliberation period will be extended. Otherwise, seven days after making the forum post the formal NNS proposal will be made on this topic. The exact content of that proposal will be shaped by the ideas presented in this article as well as actionable feedback that occurs during deliberation.

No matter how this vote turns out, our hope is that this proposal generates a high level of participation among IC stakeholders, translating into significant active voter turnout, and ultimately resulting in the IC community collectively learning something useful about decentralized governance on the IC. Please encourage participation in this process. Please vote to Approve or Reject according to what you believe is best for long-term governance of the IC. Please add your comments to this forum post so others will know your opinion. Thank you for your participation.

-------------------------

jzxchiang | 2021-12-02 21:18:16 UTC | #2

I guess the reason for this is that the IC distinguishes functions by [name](https://forum.dfinity.org/t/excuse-me-does-motoko-have-function-overloading/9245/5?u=jzxchiang) only.

I wonder if this can be solved by some sort of ENS on IC, where canisters can register for a human-readable, naturally-namespaced domain name from some registry canister? I suppose there would also need to be some underlying support from the IC system for this to work.

But that seems much more scalable than hoping that every developer renames their functions (which doesn't seem enforceable anyways).

-------------------------

skilesare | 2021-12-03 03:16:10 UTC | #3

A good point to emphasize here is that this is about standards and the expectation of standards is that they will be used from a wide array of canisters with different domain names/canister IDs.  The classic example here is the ERC20 standard on Ethereum. When they published the standard it instructed other devs to use functions named balanceOf, transfer, transferFrom, approve, etc and in return for using the standard you get "free" integration with a wide array of existing infrastructure.  Lots of contracts on ethereum use this standard and as a result, it is super simple to add your token to metamask and other wallets, they just need to know the address and then they can 'speak the language of any token using that standard.

I believe DAB has been doing some of what you suggest by wiring up slightly different standards and mapping the translation of one kind of transfer call to another.  Architecturally we probably don't want to have to be routing our calls through a translations filter(two extra consensus cycles, ~4-5 seconds) and that won't work for query calls right now anyway.

We could also suggest a major change to the IC and ask that the system index on Name + Candid signature, but that would likely break quite a bit and I think that ship has probably sailed for now.

-------------------------

nomeata | 2021-12-03 17:40:38 UTC | #4

It reminds me of similar discussions we had within DFINITY, and yes, this unaesthetic namespace prefix in the method name was the least bad solution we found.

Maybe something prettier than a full domain could be used? Create a simple canister where you can register prefixes? Or leave it free-form and hope that clashes won't happen? (But that seems not good enough)

One alternative in principle is to have proxying helper canisters if one has to provide incompatible interfaces, or possible (extending the system) a scheme where a canister is reachable under multiple IDs (like vhosts). But unfortunately such helper canisters don't always work transparently (e.g. queries, although that lack of compositionality is in a way a telltale sign that our application model isn't that great yet), and I am not sure the complexity of adding “virtual canister ids” will be worth it.

If only we had a capability-based model :-)

-------------------------

skilesare | 2021-12-08 10:38:05 UTC | #5

I've created a pull request for the EXT token standard to show what it would look like and what this would mean for developers:

https://github.com/Toniq-Labs/extendable-token/pull/15

A few notes from along the way:

1. Perhaps we want namepspaced extensions?  And a system like __extentions call?
2. Candid makes typing fairly easy and it is nice that we don’t need to namespace types.  This is enabled because ultimately all types must be stable and they distill down to base times at compile time.
3. com_ is probably too much.  We should simplify that.  I just used ext_ for the namespace
4. Code duplication is annoying, but a "feature" of motoko.  See this playground for why we can't just pass through functions from one top-level function to another:  https://m7sm4-2iaaa-aaaab-qabra-cai.raw.ic0.app/?tag=2116013494. You also can't passthrough query called from a namespace function to a legacy function because queries can't call await.  A more nuanced approach to encapsulation is necessary when you do your upgrade.

-------------------------

paulyoung | 2022-01-06 03:10:35 UTC | #6

[quote="skilesare, post:5, topic:9262"]
com_ is probably too much. We should simplify that. I just used ext_ for the namespace
[/quote]

This reminds me of something I had to deal with years ago with Objective-C where people employed a similar solution.

> All classes in an Objective-C application must be globally unique. Since many different frameworks are likely have some conceptual overlap—and therefore an overlap in names (users, views, requests / responses, etc.)—convention dictates that class names use 2 or 3 letter prefix.

https://nshipster.com/namespacing/

Even then, because this was a convention and not enforceable, Apple released new frameworks which conflicted with existing 3rd-party ones:

https://github.com/Mantle/Mantle/issues/341

-------------------------

paulyoung | 2022-01-06 03:17:24 UTC | #7

Perhaps a better solution would be for Candid to allow duplicate names and disambiguate by type.

-------------------------

paulyoung | 2022-01-06 03:19:59 UTC | #8

@chenyan, is that feasible?

-------------------------

chenyan | 2022-01-06 05:18:06 UTC | #9

Maybe I'm missing something, but can't we use variant type instead of namespaced-function names? In the `transfer` example, the proxy function can take `variant { ext_nft: TransferRequest; departure_nft: (Principal, Text) }`, then we can pattern match on the variant tag to call the corresponding service?

-------------------------

skilesare | 2022-01-06 11:41:24 UTC | #10

You could do this but then you are going to have to keep all users of your service in sync with the types that you use. If you update your type with a new service everyone will have to update their code to use the new types or face compile-time headaches.  With namespaces, the services can add at their leisure and the type signatures shouldn't change.

-------------------------

chenyan | 2022-01-06 18:39:17 UTC | #11

> If you update your type with a new service everyone will have to update their code to use the new types

No, with subtyping, none of the client code needs to update the type. For example, if the client only calls the `ext_nft` service, they can always send `variant { ext_nft: TransferRequest }` type to the proxy. With subtyping, the proxy can decode the value to `variant { ext_nft: TransferRequest; nft2; nft3 }` just fine. Adding new variant tag or changing the type of `nft2` and `nft3` doesn't require update types in the client service that only uses `ext_nft`.

-------------------------

PaulLiu | 2022-01-06 19:16:35 UTC | #12

[quote="nomeata, post:4, topic:9262"]
If only we had a capability-based model :slight_smile:
[/quote]

The hope is not all lost yet. I've not been keeping track of host references in Wasm, but I think now as an external community member, you may have a better chance of making the capability proposal :slight_smile: @nomeata (as you can clearly tell it was not part of the 25 DFINITY proposals)

-------------------------

skilesare | 2022-01-06 19:32:47 UTC | #13

[quote="chenyan, post:11, topic:9262"]
Adding new variant tag or changing the type of `nft2` and `nft3` doesn’t require update types in the client service that only uses `ext_nft` .
[/quote]

That is good to know!  So I guess one option here is to make every public interface only have one variant parameter.  How does that play?  It could certainly simplify things!

-------------------------

chenyan | 2022-01-06 22:38:11 UTC | #14

I think none of the public interface needs to change. Only the proxy service needs to use the variant type, and anyone calling the proxy service will be using the subset of the variant tags they are interested in. For example, if the client only uses the `ext_nft`, they can call `proxy_canister.transfer(variant { ext_nft = ... })` without worrying about if the proxy_canister adds more variant tags or not.

-------------------------

skilesare | 2022-01-06 23:59:03 UTC | #15

Hmm....But the whole point of having a public interface in a Standard is so that Clients know what to expect and all you have to change is the Address you are pointing to and it all "just works".  If a canister has to know that you are a "proxy canister" then interoperability is significantly more complex.  I now need to tell you if the address I'm providing you is an DIP-20 contract or a DIP-20 Proxy canister.

From an integration standpoint, it is easier for me to tell you it is a DIP-20 address and for you to know that you should be calling dip20_transfer().  But this takes discipline from the standard developers.

I guess there is a generic function public interface that could be created for each canister with the signature:
call( {function: text; parameters: variant). That would abstract everything away but make for a big nasty nested switch statement.

-------------------------

chenyan | 2022-01-07 00:45:42 UTC | #16

I see. Then it makes sense to add `opt variant { my_nft }` for each public method. If someone is sending `variant { another_nft }`, we get `null` instead of error on deserialization. The proxy canister will try to collect all different variant tags and do the proper dispatch.

I think variant tag and namespaced functions are essentially the same thing, but with variant, we get some type level guarantee, whereas with naming convention, you cannot really enforce it.

-------------------------

rossberg | 2022-01-12 15:46:57 UTC | #17

My understanding is that unambiguous naming is needed (only) for defining service _interfaces_ that third-party services are supposed to implement (e.g., to support higher-order uses). Because if a given service wants to implement multiple different interfaces, that won't work if there is a name clash between them. Hence, methods in such interfaces need to be distinguishable somehow.

This use case cannot be addressed with variants, I think. So the proposal makes sense to me.

@paulyoung, Candid cannot support overloading, because the IC doesn't. And even if it could, it would be inadequate for multiple reasons:

1. There is no reason to assume that all name clashes in the above scenario happen to have disjoint types, so it would not be a sufficient solution anyway.

2. Overloading tends to be complex and difficult to specify. The presence of rich subtyping rules on arguments makes that much worse and generally ambiguous.

3. It would interact badly with the upgradability mechanism for Candid interfaces, since a type refinement to a method might then turn an unambiguous overload downstream into an ambiguous overload, or worse, route unaware message sends to a different method unexpectedly.

In short, overloading is messy and error-prone. It would not be a good idea to introduce it in a fluid layer like this.

-------------------------

skilesare | 2022-04-09 16:34:43 UTC | #18

After having personally struggled with this I’d like to put forward the following official proposals for discussion.  A more formal representation will be selected once we decide which one to move forward with.

**Proposal A**  Require DFINITY to add a hash of the a standardized representation candid parameters of a function to the function signature to support function overloading.

This would allow a canister to support both .transfer(Principal, amount) (DIP20) and .transfer(TransferEventArgs) (ICP Ledger) and other similar namespace collisions.  The one case this would not cover would be exact parameter matches from different standards.  IE. A canister wants to support notifications from both a Ping service and a Broadcast Standard.  Ping.notify(Text) tells a canister that that text is still active.  Broadcast.notify(Text) broadcasts the text to a set of child canisters.  Under A1 you could not integrate these two standards on the same canister.

**Proposal B**  DFINITY will namespace all ledger functions with _ledger.  DIP20 will add _dip20 to all functions, EXT will add _EXT to all functions, IS20 will add _is20, Dfinity Fungible standard will and _dfs. They shall do so or be mercilessly mocked and shamed. Future standard creators will be challenged to a dual by a randomly selected NNS participant if they should release a standard that is not namespaced.  The NNS selectee will choose the weapon.  

DFX will be updated to warn any user deploying a function without a _ in it that they may be mercilessly mocked and challenged to a dual and that they should only continue if it is a private canister that the public will never consider calling, and even then they should reconsider because they may have stumbled onto an amazing pattern that the border community may want to adopt...better safe than sorry.  A link to documentation, justification, and best practices of sharing a global namespace environment should be provided.

Existing standards may keep existing endpoints for backward compatibility, but new namespaces functions should be created and the legacy functions should be removed from documentation. Failure to remove the legacy functions from documentation will result in taunting a second time.  Namespacing fixes all namespace collision issues unless you are being deliberately hardheaded.

**Proposal C** Make no changes to the way standards handle namespace collisions and let DeFi flounder on the IC until a default standard emerges and everyone has to refactor their code or can finally move forward with the confidence that they aren’t wasting their time on a standard that could be replaced.


-----------
Note: Proposal B is the right solution even if is less enforceable. We need to police ourselves.

Note 2: Having one standard is great(unless it can’t evolve with the tech and we’ve only scratched the surface of what the IC can do).  Having no standard is bad.  Having a few standards that don’t collide is fine. Having conflicting standards is a nightmare.

Note 3:  I’m open to more serious takes on B…I’m felling chippy after a couple months of trying to reconcile DIP20 and the standard ledger.

-------------------------

rossberg | 2022-04-10 07:45:48 UTC | #19

(A) does not work and never will, for the reasons explained in my previous post. I think we can make at least some progress by taking it off the table.

(B) sounds right, except that I still don't understand the reason to use or even enforce name spacing _everywhere_. A canister already is its own name space. When exactly is _cross-canister_ name spacing relevant, except where some form of informal "implements" relation has to be shared across unrelated canisters? The OP talks about "combining" services in an "interoperable" manner, but falls a bit short of explaining the scenario and assumed mechanism for such a combination. So I feel like I'm still missing a more precise problem analysis identifying concrete use cases to develop an informed opinion.

-------------------------

PaulLiu | 2022-04-10 17:40:57 UTC | #20

Does a higher-order interface not work? For example, a method `getDIP20` could return a record of methods that implement DIP20, and so on.

-------------------------

levi | 2022-04-10 19:11:16 UTC | #21

@skilesare it is already possible now to make one transfer public method and then match on the candid-decode of the call-arg-bytes and see which types are being passed and respond according to the types passed. You can fork the rust cdk and make public the arg_data_raw function and the function to return raw bytes and do the candid encode manually.

-------------------------

skilesare | 2022-04-10 20:25:00 UTC | #22

I can give two real-world examples.  Example one shows the issue with having similar but divergent services attempt to share namespaces.  The second shows the issue of accidental overlap that impedes the advancement of services on the IC.

Example one:  Origyn has been trying to get the OGY token listed on a DEX for the last 3 months. They have a pipeline of loaded buyers and sellers that want to participate in trading on the DEX and further distributing the token.  The OGY token was built on the ICP ledger tech.  At the time they deployed the ledger, the public API did not have a .transfer function.  Thus, when Sonic launched their dex and they said that OGY needed to have the DIP20 standard implemented Origin looked at adding that to the ICP Ledger.  Thankfully there was no collision and so Origyn went about attempting this. External geopolitical issues slowed the progress, but finally, they were ready to roll it out and when they merged the latest ICP ledger they discovered that .transfer had been added to the public API.  The .transfer in the DIP20 standard takes (principal, amount) and the ledger takes (TransferArgs).  They now cannot have both in the OGY ledger. Thousands of dollars of work has been wasted, and significant (millions of dollars)value and interest remain on the sideline until the issue is resolved.

The current next best solution is for Origyn to create another canister that implements DIP20 that has "God" status in our ledger.  This second canister can move tokens from one account to any other account.  It also keeps track of allowances and enables a transferFrom workflow(which is a terrible and exploitable flow but what DIP20 and sonic require).  This solution also slows the user experience because we now have to wait for 3 rounds of consensus to do a transferFrom. This solution also has second-order consequences because the Origyn NFT project handles payments and was distinguishing between tokens by using canister ID as part of our primary key. Now the OGY token will have two canisters that are both legitimate methods of transferring tokens.  More work gets more complicated simply because we can't just add the dip20 end points to the main ledger and keep track of allowances in that ledger.

Example two:  The Origyn NFT project is attempting to combine a number of different features into an NFT canister.  One feature is to transfer NFTs from one owner to another.  The EXT-NFT function has a .transfer function that moves an NFT from one owner to another.  The Origyn NFT may also hold a collection-based fungible token for governance as well. If it implements the DIP20 standard or the ledger standard the .transfer function will be impossible to implement because the NFT .transfer function is in the way. We could host the token on another canister but this breaks all kind of interoperability goals that Origyn has.  Origyn wants a super standard that has NFT functions in it and Token functions in it. This super standard should be interoperable with all kinds of tools(NFT marketplaces) that only care about the NFT part and all kinds of tools(wallets, dexs) that only care about the fungible token governance part and we want one canister to handle both of those.  With .transfer_ext_nft; .trasfer_ext_fungible; .transfer_dip20, .transfer_ledger we can support multiple marketplaces, wallets, and dexes even if they only support one of the ledger functions.  With .transfer .transfer .transfer and .transfer Origyn will have to pick and choose and make our lives more complicated.

-------------------------

skilesare | 2022-04-10 21:23:50 UTC | #23

Is that available in motoko?

If I could tell a function it’s parameters were “any” and then pattern match by type, this would work, as long as I could return “any”.

-------------------------

paulyoung | 2022-04-11 05:08:41 UTC | #24

[quote="skilesare, post:22, topic:9262"]
With .transfer_ext_nft; .trasfer_ext_fungible; .transfer_dip20, .transfer_ledger we can support multiple marketplaces, wallets, and dexes even if they only support one of the ledger functions
[/quote]

Could you help me understand why you prefer the above to the following?

```
service {
  transfer : (variant { extNft : … }) -> …
}
```

```
service {
  transfer : (variant { extFungible : … }) -> …
}
```

```
service {
  transfer : (variant { dip20 : … }) -> …
}
```

```
service {
  transfer : (variant { ledger : … }) -> …
}
```

```
type Interface = {
  #extNft : …;
  #extFungible : …;
  #dip20 : …;
  #ledger : …;
  …
};

func transfer(interface : Interface) : … {
  switch interface {
    case (#extNft …) …;
    case (#extFungible …) …;
    case (#dip20 …) …;
    case (#ledger …) …;
    …
};
```

(Edit: `transfer` would probably need to return a variant as well to account for different return types)

-------------------------

skilesare | 2022-04-11 10:17:20 UTC | #25

Because if a users uses a wallet written last month I want it to be compatible with the service I write next November even if the dev that wrote the wallet gets hit by a bus and it is never updated.

I guess if every function took a variant and returned a variant then subtyping would take care of this, but the upgrade headache of marshaling your data from one data structure to the modified one seems a bit frustrating. Adding an endpoint with the namespaced function seems easier.

You could swap out interface namespacing with parameter:return namespacing, but if you end up with one standard having #token{canister:Principal} and another with #token{rootcanister:Principal;dip20:principal} then you are right back at the same place.

-------------------------

AdamS | 2022-04-11 13:32:27 UTC | #26

I for one dislike seeing common characters in names also used as namespace separators. All it takes is for someone to not notice that their backronym, chosen to be a recognizable word, is also a totally reasonable word to use there in a non-namespaced function. I like `::`, personally, but regardless I think having it not be `_` is a good idea. A CDK must already have the facility to represent these functions; the existing usability issue, if one exists, can be changed in an update.

-------------------------

PaulLiu | 2022-04-11 18:51:19 UTC | #27

Let me expand on what I mean:

```
type Dip20 = record {
  transfer: func(Principal, Nat) -> (TxReceipt);
  ...
};

type SNSLedger = record {
  transfer: func(TransferArgs) -> (TransferResponse);
  ...
};

service : {
  interfaceDIP20: () -> (DIP20);
  interfaceSNSLedger: () -> (SNSLedger);
  ...
}
```

It does add one level indirection (only when initially setup to talk to such a canister, not for every call), but there are many benefits, the least of which is that this is already supported on IC and requires no extra change at system level.

-------------------------

skilesare | 2022-04-11 18:58:40 UTC | #28

I think there is something fairly interesting here, but I may be missing it.  This looks like you are defining an Interface that returns function signatures. The remote tool would need to ask for the Interface first and then map the interface to its functions. 

I love this. I need to wrap my brain around how this would work...I think third-party tools would still need to define a change to how they are doing things and never assume a standard and instead ask for the Interface?

A couple of concerns:  Maybe this only works for 1:1 translations...also, motoko's lack of a typeof() modifier might make parsing this challenging.  We need that candid library.

-------------------------

PaulLiu | 2022-04-11 19:07:06 UTC | #29

> motoko’s lack of a typeof() modifier might make parsing this challenging

Like with using all 3rd party canister services, you'll need the did file, which should have all types required for each interface.

I quickly tried this in Motoko:

```
actor Hello {
  public type Hello = {
    hello: shared (Text) -> async Text;
  };
  public func greet(name : Text) : async Text {
    return "Hello, " # name # "!";
  };
  public func interface() : async Hello {
    { hello = greet }
  };
};
```

```
import Hello "canister:hello";

actor Test {
  public func test() : async Text {
    let hello = await Hello.interface();
    await hello.hello("world");
  };
};
```

Seems to work just fine:

```
$ ~/bin/dfx canister call test test
("Hello, world!")
```

-------------------------

skilesare | 2022-04-11 19:36:31 UTC | #30

Can the Interface be a query?

-------------------------

PaulLiu | 2022-04-11 19:43:42 UTC | #31

Sure
[quote="skilesare, post:30, topic:9262, full:true"]
Can the Interface be a query?
[/quote]

Sure, I don't see why not.

-------------------------

skilesare | 2022-04-11 19:47:35 UTC | #32

I'm also guessing that these need to be a known quantity?  Each canister would need to match all or nothing so that the calling canisters get their types right?  I'm a bit confused about subtyping.  Example:

Canister A:

type Dip20 = record {
  transfer: func(Principal, Nat) -> (TxReceipt);
  ...
};

type SNSLedger = record {
  transfer: func(TransferArgs) -> (TransferResponse);
  ...
};

service : {
  interfaceDIP20: () -> (DIP20);
  interfaceSNSLedger: () -> (SNSLedger);
  ...
}


Canister B:

type Dip20 = record {
  transfer: func(Principal, Nat) -> (TxReceipt);
  ...
};

type EXT = record {
  transfer: func(AccountID, Amount) -> (TransferResponse);
  ...
};

service : {
  interfaceDIP20: () -> (DIP20);
  interfaceEXT: () -> (EXT);
  ...
}


This would break things, right? If I had a did file that expected:

service : {
  interfaceDIP20: () -> (DIP20);
  interfaceEXT: () -> (EXT);
  interfaceSNSLedger: () -> (SNSLedger);
  ...
}

It would want them all?  Maybe we put null in front?

service : {
  interfaceDIP20: ?() -> (DIP20);
  interfaceEXT: ?() -> (EXT);
  interfaceSNSLedger: ?() -> (SNSLedger);
  ...
}

-------------------------

PaulLiu | 2022-04-11 20:43:12 UTC | #33

In your examples, canister A only has interfaceDIP20 and interfaceSNSLedger, and canister B only has interfaceDIP20 and interfaceEXT, so I would expect a slightly different did file for each

Are you thinking something like iterating through a list of canisters, and being able to call all of them depending on their interfaces? In this case, A and B can be put into the same list that only has interfaceDIP20.

Also, in motoko it is totally fine to give different types to `actor("...")` in different places using type annotation. In Rust it is even more flexible since actor types are not statically checked.

-------------------------

skilesare | 2022-04-11 22:44:40 UTC | #34

I will play with this a bit and see if I can't get a working example that works across the problem space. I'd much prefer an addition rather than a modification if we are going to push something forward. Thanks for pointing this out!

-------------------------

skilesare | 2022-04-12 15:06:46 UTC | #35

A couple of questions on this one, first for @PaulLiu , do you have any idea what this would look like in rust?

Secondly, for @kpeacock  how would the agent handle a response to this function? How would I call the resulting function that was returned by the interface? For example, if I called interfaceDIP20 below and got back the Dip20 object, What were the JavaScript look like the called the transfer function?

@nicopoggi , how would plug handle this,?Would it know what function was being called and let it pass through?

I’m thinking that this might be the ideal answer, but not until we have innercanister queries.

@ulan  do you know what the current timeline for this is?

If I call this and get back an interface, any idea how we would certify it? If it is an update call, it is fine(and the default if a canister is calling it, but if a client calls it as a query, how to certify? It isn’t data. How would I sign it? Sign the candid? We are back to needing a candid library or reflection over types in motoko. @nomeata  @claudio 

My current thinking is that, as a best practice, never call a canister that implements a standard directly. Always call a __supports query that returns an array of interfaces namespaced by declared namespace in the standard:

```

type Dip20 = record {

transfer: **func** (Principal, Nat) -> (TxReceipt);

...

};

type SNSLedger = record {

transfer: func (TransferArgs) -> (TransferResponse);

...

};

type PeopleRegistey = record {

isMember: func (Text) -> (Bool);

register: func(Principal, Text) -> (Bool);

...

};

public query func __supports() : {

list: [Text]; //list of available interfaces

iDIP20 : ?() -> (DIP20); //null so that if it is missing in candid response it won’t throw an error

iSNSLedger: ?() -> (SNSLedger);

iPeopleRegistry: ?()->(PeopleRegisty);

….// any n number of used standards interfaces

```

-------------------------

jorgenbuilder | 2022-04-12 17:37:29 UTC | #36

I'm going to be a dissenter 😄

To say that we all have a global namespace that we must share is not the most accurate characterization of our development paradigm. Interfaces and function names are scoped to canisters.

Collisions only happen when multiple standards/protocols are being implemented in the same canister.

It seems that if we had a tidier standards landscape, we wouldn't have the problem of ten different standards (which all try to do the same thing) competing for the same `transfer` function namespace. In-canister standards composition seems to be the impetus here, and that would be less of a concern given "one clear standard."

I do think that namespacing makes sense when you're working on a smaller project level, where you know that you your code a) will live alongside an existing standard, b) isn't meant for mass adoption, c) is experimental in nature, etc.

There are certainly examples of protocols conflicting with each other where they probably shouldn't. Recently a marketplace protocol was released which conflicts with dominant marketplace protocol of Entrepot. This does feel to me like a possible failure in the design of the new protocol to consider the broader landscape, but it's also solvable via wrapping.

On the note of composing standards within a canister, for example a fungible and a non fungible token, there's precedent from Ethereum for this type of functionality within a single standard: ERC1155.

In summary, namespacing makes sense sometimes but I would suggest that it's misused as an approach to the problem of fragmented token standards. We should not seek a way to make a plethora of standards that all do the same thing composable with each other, we should seek to unify them. A unified, authoritative token standard would not need to be namespaced.

I'm guilty of not reading this entire thread, but I know that there are some very important considerations in here, such as the fact that we do not have the hash addressing of functions that Ethereum does, which is one less tool in our belt and that may have important consequences that I have not considered, and so on. I would suggest that backwards incompatible changes for the token standard should be very rare, and can be handled via wrapping and migration to new contracts. Not everything needs to be done via canister upgrade (which should reduce the lift that standards interoperability are responsible for.)

-------------------------

skilesare | 2022-04-12 17:54:08 UTC | #37

Thanks for engaging!

[quote="jorgenbuilder, post:36, topic:9262"]
There are certainly examples of protocols conflicting with each other where they probably shouldn’t. Recently a marketplace protocol was released which conflicts with dominant marketplace protocol of Entrepot. This does feel to me like a possible failure in the design of the new protocol to consider the broader landscape, but it’s also solvable via wrapping.
[/quote]

More details coming soon, but we are exploring making wrapping obsolete.  It breaks the ability to enforce your code and we're trying to solve that.

> In summary, namespacing makes sense sometimes but I would suggest that it’s misused as an approach to the problem of fragmented token standards. We should not seek a way to make a plethora of standards that all do the same thing composable with each other, we should seek to unify them. A unified, authoritative token standard would not need to be namespace.

I'd agree, but the realist in me sees that we have two houses of the legislatures in the US and you have to be able to lobby both.  In other words, humans are strange and I don't know that we're going to be able to all get on the same page. While we wait progress is stalling.

I'd argue that having unique names is a net gain for everyone.  If your standard wins it is because it was best, not because it was the first one to claim transfer.  It doesn't preclude us from getting to a single unified standard it just lets us try some different things.

We have mutually exclusive standards already.  The SNS_ledger's public methods are incompatible with DIP20 public methods because DIP20 wants transaction history by principal ID and the SNS_Ledger purposely masks principal in an account ID.

> I would suggest that backwards incompatible changes for the token standard should be very rare, and can be handled via wrapping and migration to new contracts.

To be clear, no standard would have to do away with their current standard, just add a unique namespaced function as well. So DIP20 could have a transfer(principal, amount) for backward compatibility and transfer_dip20(principal, amount) for future compatibility. They could call the same code.

-------------------------

bitbruce | 2022-04-13 07:11:00 UTC | #38

The scheme `token.std_name.method(....) ` looks elegant, the downside is that it requires a refactoring of the did and the interface code, which is invasive.
We use this scheme, https://forum.dfinity.org/t/discussion-on-the-compatibility-of-different-token-standards/11246, which is compatible with the DRC20 and DIP20 standards.

-------------------------

ulan | 2022-04-17 08:08:01 UTC | #39

[quote="skilesare, post:35, topic:9262"]
I’m thinking that this might be the ideal answer, but not until we have innercanister queries.

@ulan do you know what the current timeline for this is?
[/quote]

The timeline is vague at this point. We should be able to propose the options for voting relatively soon (weeks) and then the actual implementation depends on the outcome of voting.

-------------------------

roman-kashitsyn | 2022-07-06 10:52:45 UTC | #40

Unfortunately, this approach is very painful to use in Rust at the moment.

-------------------------

roman-kashitsyn | 2022-07-06 12:32:53 UTC | #41

[quote="AdamS, post:26, topic:9262"]
I like `::`, personally, but regardless I think having it not be `_` is a good idea.
[/quote]

Motoko [doesn't support `::` in method names](https://internetcomputer.org/docs/current/developer-docs/build/languages/motoko/language-manual/#identifiers):

> Identifiers are alpha-numeric, start with a letter and may contain underscores:

```
<id>   ::= Letter (Letter | Digit | _)*
Letter ::= A..Z | a..z
Digit  ::= 0..9
```

If we want to go with a prefix/suffix mechanism and be compatible with Motoko, then using an underscore is pretty much the only choice.

-------------------------

rossberg | 2022-07-06 14:32:38 UTC | #42

[quote="AdamS, post:26, topic:9262"]
I like `::`, personally
[/quote]

You must have been born after the 80s. As a contemporary, I bet you'd still find most C++ syntax hacks from the time atrocious. ;)

-------------------------


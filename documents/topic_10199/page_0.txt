ayjayem | 2022-01-10 21:57:26 UTC | #1

**To execute liquid democracy on the IC, stakers can follow neurons that they believe will vote in their interests.** This has worked because neurons have, in most practical terms, stood in for natural persons or organizations that the staker trusts.

**But the one-to-one correspondence between neurons and their controllers is breaking down, as [Internet Identities (II's) may soon be sold for a fee](https://twitter.com/dfinity/status/1479537574716719104).** If a staker follows a neuron controlled by an II, and that II is sold, then the staker is effectively now following the II's new controller - whom the staker did not choose to follow in the first place.

II transfers can take place without notice and without a trace. So stakers following neurons can never be sure that they are still following the person or organization that they intend to, as the neuron they are following could have been sold with the attached II without stakers' knowledge at any time.

**So how can stakers follow any neuron, knowing that the neuron they are following can be effectively sold, without their knowledge, at any time, to someone they don't want to follow?**

Compounding the problem, people could make good money by gaining a lot followers, and then selling the II at a premium (given its overweighted voting power). **Selling high-follower II's could be quite profitable, so high-follower II-controllers could have a strong incentive to sell their IIs-and-followers for a pretty penny.**

**This problem is also more urgent now that new neurons could soon be named in the NNS dapp as potential followees.** The organizations behind these neurons could well gain many staker-followers quite quickly given additional visibility in the NNS dapp, as they are each (in my view) very competent organizations. But in gaining these followers, these organizations could soon face a very strong private incentive to sell their high-follower-II's at potentially very handsome prices, pitting their private interests against the good of the followers they represent. This reduces the confidence that followers could have in following these by-all-accounts-well-intentioned organizations.

**So in sum: II sales threaten liquid democracy, by undermining stakers' trust that they are following the persons they want to, and who won't sell them out. Without this trust, stakers cannot feel confident in following other neurons. If we want to defend liquid democracy and facilitate decentralization in governance on the IC, we must reduce the likelihood that followers' votes can be sold for a fee, without followers' knowledge.**

There may be some straightforward ways to reduce the likelihood that followers' votes can be sold. But I will leave that for a subsequent post, preferring first to invite comment on the problem as outlined above. Curious to hear others' views on whether this is a problem worth addressing.

-------------------------

talkingant | 2022-01-10 15:56:53 UTC | #2

You can already sell private keys/hardware wallets (funds do this for locked tokens). Dfinity's own Chain Key Crypto will enable trustless sales of private keys. So any measure taken to prevent account sales will become a cat-and-mouse game with no assurance the prevention is working.

Having II sales out in the open is much better than forcing it into the darkness. Neurons could subscribe to II transfer events and automatically unfollow.

Every dapp that assumes locked tokens or accounts stay with the same person is gunna have a bad time. At least until we have on-chain self-sovereign identity.

-------------------------

Roman | 2022-01-10 16:24:14 UTC | #3

By doing so, people will be able to have a traceability of sales and so unfollow any neuron they were following when they will see it sold . Like it has been said, it is better this way rather than in the dark. Maybe a notification of the fact that a neuron you follow has been sold would be useful to prevent any surprise.

-------------------------

ayjayem | 2022-01-10 18:36:17 UTC | #4

Valid points here, I think.

To be clear, I do not mean to say that we must prevent II sales. I mean to say that we must reduce the *likelihood that **followers' votes** can be effectively sold*, and/or the *impact if they are*. Your idea of neurons subscribing to transfer events and automatically unfollowing is one good idea to reduce the effective sale of followers' votes.

Solutions are the ultimate goal. But first, I think it's important to get consensus that there exists a problem. I am especially curious to hear from the community at this stage about whether most believe the situation outlined presents a problem that needs to be addressed.

If so, then we could raise and assess alternatives to address the problem - which can involve *either or both*:
* aiming to prevent sales-of-followers (not the same thing as preventing sales of II's or sales of neurons!); and/or
* reducing the negative consequences if sales-of-followers does occur.

-------------------------

nomeata | 2022-01-10 16:24:12 UTC | #5

The ECDSA signature feature will also make neuron control transferrable, as I keep pointing out there, so far without a response from the DFINITY org:

https://forum.dfinity.org/t/threshold-ecdsa-signatures/6152/106?u=nomeata

In my opinion it's pointless to prevent the inevitable.

-------------------------

Tbd | 2022-01-10 16:36:20 UTC | #6

Wouldnt this break the whole people party idea too if those neurons can just be sold?

-------------------------

Zane | 2022-01-10 16:43:20 UTC | #7

Not really cause from what Dom said the boost is temporary and increases if you  attend many parties in a row, so ideally attending twice with 1 neuron should be more convenient than verifying 2 neurons. I'm afraid it would break the NNS tho, if neurons can just be traded then locking for 8 years isn't a big deal anymore.

-------------------------

Tbd | 2022-01-10 16:56:26 UTC | #8

Meant mostly vote buying (or you could rent them out or smth) but I guess thats a much harder problem to solve

-------------------------

diegop | 2022-01-11 05:55:43 UTC | #9

I may be missing a big thing, but the issue (to me) seems less about technology but about humans trusting one another. If one human is afraid the neuron they are following can be surreptitiously transferred to another party, that is no different than "*not trusting the original human behind the neuron."* 

More simply: 
* Neurons can already get lots of followers and sell their votes or even be swayed in ways in that the followers do not intend (e.g. a neuron votes in X direction because of political, financial incentives)
* If you believe a neuron could surreptitiously transfer ownership without followers knowing then that already shows one does not trust the humans behind that neuron.

Liquid democracy does not break down from transferring neurons. Potential followers still have the same problem: find neurons to follow they believe will vote in their interests. This is not a technology problem.

What I do think is where "technology meets psychology" is that defaults are powerful so I am in the camp supporting that periodically having neurons confirm they are following neuron X is important. That way it refreshes the follower/followee relationship.

-------------------------

ayjayem | 2022-01-11 13:20:06 UTC | #10

First off, many thanks for the opinions offered on this topic so far; I believe the viewpoints shared have the potential to spark a discussion that could lead to productive action.

To the specific contention that this is not a technology problem, but instead a trust problem, I would say this.

Trust doesn’t exist in a vacuum. In general, one has more reason to trust people whose interests are more evidently aligned with yours. And in the governance of the IC, technology plays a pivotal role in shaping incentives and aligning interests.

So regarding liquid democracy in particular: it’s much harder to trust someone who could make perhaps millions by selling their high-follower neuron(s), and never looking back - than it is to trust that same person who doesn’t face a free market to do just this… no matter how well-intentioned that person is at their core.

It’s true that people since Genesis have in theory been able to e.g. lend their follower-votes to others. But the fact that it has been harder to gain follower-votes in the first place (given the limited listing in the NNS dapp until today), and also to sell follower-votes (e.g. needing to search/wait for a buyer to approach directly, needing to equivocate to followers about why you made a dubious vote in the case of vote-lending, etc.) has made follower-vote buying less likely.

Technological mechanisms can change the costs and benefits, the opportunities and challenges, of acting in the interests of the IC’s governance community. This is why I believe it is worth raising this issue here. If the problem outlined is determined to be worth addressing, then I believe it would be worth discussing what role technology may play in mitigating these risks.

…And to be clear, aiming to prevent the sale of neurons or Internet Identities writ large is in all likelihood **not** (part of) the optimal solution to this particular problem. There may be much narrower, more targeted solutions (technological and/or otherwise) that substantially address these risks (some of which ideas are currently under discussion outside this forum with smaller groups interested in this topic).

Again, many thanks for the views voiced so far.

-------------------------

ayjayem | 2022-01-11 13:25:32 UTC | #11

I should add - the idea of followers periodically confirming that they still want to follow given neurons seems to me to be another good possible technological approach to help address this problem.

If this helps followers detect that they are no longer following neurons they trust, this reduces the impact of misplaced followership, by limiting its duration. It also reduces the benefit to a neuron buyer who specifically seeks to buy followers - because followers would be less sticky. And this would probably also reduce the magnitude of follower-vote buying in the first place.

To me, this represents a good example of another possible technological solution that helps align incentives, reinforcing trust in liquid democracy.

-------------------------

aSpace1 | 2022-01-11 23:22:50 UTC | #12

Exactly and no one needs to follow any neurons and can vote manually! Potentially this is a good thing, and if required, trusted parties may emerge for people to follow. If there were no sickness in the first place, there would be no cure for it.

-------------------------

ayjayem | 2022-01-12 14:15:24 UTC | #13

Based on views shared in this thread to date, there doesn’t seem to be consensus that the problem of follower-vote-selling should be addressed in this forum.

No one seems to disagree that follower-vote-selling is undesirable. But most seem unpersuaded that we should look to the IC’s technology to help solve this problem. The main sticking point seems to be the claim that if you are concerned someone could sell you out as a follower, this shows you don’t trust them in the first place. (So this is a trust problem, not a technology problem.)

I disagree with this claim. You can trust a person to do right by you in general, but lose trust in that same person if they stand to make a windfall by selling you out. If systems can be designed to reduce the temptation to do untrustworthy things, or to make this more costly, then technology can be used to reinforce trust.

So trust *is* the central problem here, as @diegop notes; but it’s a problem that I think technology can help solve.

(Indeed, blockchain itself is in large part based on the idea of aligning incentives, so that individuals can be trusted to do on their own what middlemen used to need to do for them. Blockchain technology’s big promise, arguably, is that it can help solve some of the world’s most enduring problems of trust.)

So all who have shared views seem to agree there’s a problem, and I maintain that technology can form part of the solution. Some tech ideas have already been alluded to in this thread - e.g., the idea of requiring reconfirming neuron follows periodically. I’m sure there are many other possible solutions as well, which I would be keen to discuss with this group.

But it would be unproductive to talk about solutions, before first agreeing we have a problem worth solving, and accepting that technology can form part of a solution.

Given this, inviting any further comment on whether follower-vote-selling is a problem worth trying to solve in this forum.

-------------------------

diegop | 2022-01-12 14:21:49 UTC | #14

[quote="ayjayem, post:13, topic:10199"]
If systems can be designed to reduce the temptation to do untrustworthy things, or to make this more costly, then technology can be used to reinforce trust
[/quote]

Fwiw I do think this is reasonable point. I just was not convinced that it selling neurons was the problem, so much as “have system minimize impact of breaking trust” (eg having people Periodically re-affirm the following relationship, even if anually) or “incentivize people to be trustworthy”.

I did not mean to sound as opinionated that your original point was less important. I do suspect I sounded more opinionated (and less open to changing my mind) than I intended.

-------------------------

NS01 | 2022-01-17 10:36:28 UTC | #15

Interesting topic. The 'sellout for $$$' risk is almost inbuilt to human nature and almost impossible to stop. I agree with previous posts that making any sales visible would help. Proof of personhood is also interesting in this context. Will keep watching people's thoughts on this  :popcorn:

-------------------------


senior.joinu | 2021-06-03 01:01:18 UTC | #1

So I was thinking a lot about what exactly should the perfect token standard look like, and now I'm finally ready to declare my opinion on this subject. I thought, it might be more appropriate to share it here and not on the sailfish's github repo.

In short, I believe that we should reject ERCs and come up with something extremely basic, to only support basic operations and to give an ability to extend the implementation from the outside.

Short prelude. Why do people even need application-level standards like ERC? The main answer is ***interoperability***. Since wallets are off-chain entities on Ethereum, the community came up with this idea to make a standard so any wallet which understands this standard could work with any token which implements the standard. 
Is this good? Well, yes, I think. But these guys were limited by the technology and the mindset of their time, and this, in my opinion, made their token standards bad. I want to start a discussion on that topic and to propose an alternative solution which, I believe, could bring another level of value to the system than classic ERCs.

-------------------------

senior.joinu | 2021-06-03 00:33:25 UTC | #2

Let's take a closer look at ERC20 (https://eips.ethereum.org/EIPS/eip-20) - the first and the most famous token standard out there. It is very a simple interface which basically consists of methods each falling in one of four categories:

1 - Basic value management
```
// creates new tokens, usually implemented with some kind of access control
// this one is not a part of the standard, and is listed here just to provide a complete view
mint(toAddress, quantity)

// destroys tokens from caller's balance
burn(quantity)

// destroys tokens from caller's balance and create the same quantity of tokens on recipient's balance
transfer(toAddress, quantity)
```

2 - Basic getters
```
// returns the amount of tokens possessed by the address
balanceOf(address)

// returns the total amount of tokens in circulation
totalSupply()
```

3 - Optional getters
```
// returns the name of the token (e.g. "Internet Computer Voting Token")
name()

// returns the symbol of the token (e.g. "ICP")
symbol()

// returns the denomination of the token (how much cents there are in a dollar)
decimals()
```

4 - Approvals-related methods
```
// lets another entity to spend up to some amount of caller's tokens
approve(operator, quantity)

// spends some of previously approved tokens
transferFrom(ownerAddress, toAddress, quantity)

// how much is someone allowed to transferFrom
allowance(ownerAddress, spenderAddress)
```

-------------------------

senior.joinu | 2021-06-03 00:28:30 UTC | #3

So, why do I think this standard is bad? There are two reasons:

**1 - Abused ERC20 inheritance by other token standards.**
ERC20 specifies an interface for fungible (indistinguishable from each other) and singular (one token type per one smart-contract) tokens, without anything else (no onchain balance history, no partitions, etc.). But to simplify the integration process by various wallets, other token standards often have a very similar interface. 
The worst example of this is ERC721 (https://eips.ethereum.org/EIPS/eip-721) - the famous NFTs. I find this interface absolutely gross and unhealthy for the goal this standard targets to reach. Just look at that:
```
function balanceOf(address _owner) external view returns (uint256);
function approve(address _approved, uint256 _tokenId) external payable;
```
I won't touch the `approve` method for now (this is dedicated to the next section), but `balanceOf`, really? For those not familiar with NFTs - they are intended to represent an ownership of some unique things, like real estate, or cars, or art objects or even cows. In this context the method `balanceOf` seems very inappropriate to me, since I don't really need to keep track of the quantity of houses I have in my wallet, I want to see each of them individually and read some detailed information about them.
I'm not blaming the developers of this standard - they were forced to make it work that way because they wanted out-of-the-box wallet support for these tokens. And what I'm trying to say is ***each token should be implemented in an optimal and a convenient way for the task it's supposed to solve*** and no standard should prevent creativity of such a way.

-------------------------

senior.joinu | 2021-06-03 00:28:49 UTC | #4

**2 - Approvals as a way to automate value flow.**
Someone new to Ethereum and coins in general looking at the interface for ERC20 I've left above might ask: "yea, I understand what are all these `balanceOf()`, `mint()` and `transfer()` for, but why would I ever need to `approve()`?". At least for me, when I was reading about all of these tokens for the first time, it seemed like a very niche mechanics. Like... okay, if I have a friend whom I'd like to allow to spend some of my crypto, I could just send it to them, right?
Let's read the original description for `transferFrom` method.

> The `transferFrom` method is used for a withdraw workflow, allowing contracts to transfer tokens on your behalf. This can be used for example to allow a contract to transfer tokens on your behalf and/or to charge fees in sub-currencies.

So, it is used not like I was first wondering. It is used to let smart-contracts transfer your tokens and automate actions. Okay, but why did they choose to do it this way? 
*Is this the only way?* - No, there is at least one more (we'll talk about it a little later). 
*Is this the most efficient way?* - No, you have to make two transactions to send your tokens to a smart-contract, since they are reactive and only do something when they're told (one to approve an amount and one to trigger a smart-contract to call `transferFrom` for you). 
*Is this the safest way?* - Maybe. Back in those days they were really afraid of famous *re-entrancy attack*, and since the approach with approvals is immune to this attack by default, I believe, they decided to stick with it. But now re-entrancy is studied well and while we write our code [carefully](https://quantstamp.com/blog/what-is-a-re-entrancy-attack) we're good to go. So, I believe, while approvals are safe, ***they are inconvenient to integrate with and misleading to understand***, but that's not the real problem.

-------------------------

senior.joinu | 2021-06-03 00:29:06 UTC | #5


There are several younger standards (like ERC677 and ERC777) which use different mechanics to send tokens to a smart-contract and trigger an action in one transaction. This is very similar to how Ethereum works by itself. When you want to send some ether to a smart-contract to trigger some paid action, you just attach it to the transaction. These standards provide us with something similar:
```
function send(address to, uint256 amount, bytes calldata data) external;
```

Now, Dfinity introduced another mechanics to automate ICP flow - notifications. Since there is much more freedom on the IC and we can implement on-chain ledgers like it's nothing, there is no problem to just say to another canister "hey, I've just sent some tokens to your principal, here is the transfer transaction; would you kindly execute this paid action for me?". 
Why did they do that? Why didn't they chose `approve` nor `sendAndCall` approach? I don't know for sure, but we could speculate on it a little. As you might notice, ICP was first listed on coinbase. This hints us with some kind of relationships between these two organizations. Coinbase is also known as creators of [Rosetta API](https://www.rosetta-api.org/) - a standard which they use to integrate different coins into their exchange fast. Let's look a little closer to this specification. Hm... it looks like your blockchain [should have blocks and transactions](https://www.rosetta-api.org/docs/BlockApi.html#blocktransaction) to implement this standard. But the IC doesn't store blocks - it doesn't need them to provide security guarantees, so blocks are just rejected once there is a consensus reached and there is no chance for fork to appear. So, they had to implement on-chain ledger so they could be listed on coinbase. And since there is already a ledger on chain, I believe, it looked convenient for them to just stick with `notifying` canisters about transactions, instead of using other mechanics.

What I wanna say is that there is no perfect solution for this task - every application has it's own requirements. Sometimes you might want to avoid re-entrancy threat completely, so you stick with the `approve` and `transferFrom` way (which I personally find disgusting, but who knows). Sometimes you want your UX to be as snappy as possible so `transferAndCall` is your case.

-------------------------

senior.joinu | 2021-06-03 00:29:19 UTC | #6

To repeat once again, what are the problems of Ethereum and ERCs: 
* ERC20 inheritance is often inappropriate
* Value flow automation is not abstracted away

As a early community, if we want to create a standard that will survive the time test, we should make it solve the problems of tomorrow. Since we don't know what exactly are those problems, we have two options:

1 - To try to predict these problems and make ultra-mega-super-token-standard-3000 which can handle any problem we can imagine at this moment. Will it work? - I'm not sure. Maybe tomorrow there will be another "DeFi boom" and the paradigm will shift once again, making our standard outdated in one moment.

2 - To do what the agile methodology tells us - to be agile and to reject long-term planning. This is what I want to propose to you.

-------------------------

senior.joinu | 2021-06-03 00:29:41 UTC | #7

------------------------------

**The proposal**

What do we know for sure and what will never change?
* Gas is reverted here on IC - it is safe to build long inter-canister operations, since each canister pays for its own computations
* There is only one wallet on IC and it is on-chain - it is safe to build very different tokens, each serving its own purpose and solving its own task - each app is responsible for proper handling (show, send etc.) of its own tokens. Moreover, in my opinion, this should be encouraged.
* Some tokens are so much different, that it should be discouraged to treat them the same way. For example dollars and cars. Right now there are, I believe, only two such ***clusters***: fungible and non-fungible tokens, but there might be more one day.

These three points might look like "so, we don't need a standard then", but:
* There will be applications which operate over many different tokens. A classic example is DEX or maybe some application that wants to be able to receive donations with different tokens. These applications need a way to treat these tokens and to react when tokens move.

So...
1. If we want to encourage creativity and diversity, but provide interoperability, we need a tiny yet highly agile standard.
2. If we want to emphasize that there are ***clusters*** of tokens, each representing a whole different concept of value, we need a separate idiomatic standard for each such a ***cluster***. 

With that being said:
`ERC20 basics + semantics + subscriptions = perfect token standard`

-------------------------

senior.joinu | 2021-06-03 00:29:57 UTC | #8

*the next notation is given in rust*
```rust
trait IFungibleToken {
  
  // adds a caller's *callback* to the subscriber list, 
  // from now on each time there appears a transfer *from* -> *to*, 
  // the *callback* method will be called asynchronously,
  // without an awaiting
  // 
  //
  // *from* and *to* are filters applied by AND rule:
  //
  // subscribe(Some(Some("aaaa-a")), Some(Some("bbbb-b")), "cb")
  // creates a subscription that is triggered only when there is a transfer
  // from "aaaa-a" to "bbbb-b"
  //
  // subscribe(Some(Some("aaaa-a")), None), "cb")
  // creates a subscription that is triggered only when "aaaa-a" is a sender
  //
  // subscribe(None, Some(Some("bbbb-b")), "cb")
  // creates a subscription that is triggered only when "bbbb-b" is a recipient
  //
  // subscribe(None, None), "cb")
  // creates a subscription that is triggered on each transfer, no matter
  // who are the participants
  fn subscribe(
    from: Option<Option<Principal>>, 
    to: Option<Option<Principal>>,
    callback: String
  );

  // removes the caller's *callback* from the subscriber list
  fn unsubscribe(callback: String);

  // NOT A PART OF THE STANDARD - just for demo purposes
  // calls a subscriber's *callback* method with transfer details as a payload
  fn _publish(
    sub_canister_id: Principal,
    sub_method_name: String,
    from: Option<Principal>,
    to: Option<Principal>,
    qty: u64
  );

  // creates new tokens for *to*
  // calls every callback method subscribed 
  // to *from: Some(None)* or *to: Some(to)*
  fn mint(to: Principal, qty: u64);

  // sends token from caller to *to*
  // calls every callback method subscribed 
  // to *from: Some(caller)* or *to: Some(to)*
  fn send(to: Principal, qty: u64);

  // destroys tokens of the caller
  // calls every callback method subscribed 
  // to *from: Some(caller)* or *to: Some(None)*
  fn burn(qty: u64);

  // returns the balance of *token_holder*
  fn balance_of(token_holder: Principal) -> u64;

  // returns the total amount of tokens in circulation
  fn total_supply() -> u64;

}
```

-------------------------

senior.joinu | 2021-06-03 00:30:20 UTC | #9

> Q: Are you crazy?

No, of course not :crazy_face:

> Q: Why subscriptions?

Subscriptions are a great way to add extendability to our tokens. 

You want to create a ledger of some token(s)? - No problem, subscribe to them and pack your ledger however you want in a separate canister.  
You want to keep track of token balances at each moment in time, to use these tokens for voting? - Just take it, it's yours. 
You want to give your special token to everyone who donates more than $100 to charity? - Yes, please. All you need is to know some `Principal`s of charity organizations wallets.

Every time you want your dapp to react to transfer of some token, you just need to subscribe to it. Moreover, with previous approaches a canister could only react when someone sends tokens to it, but now it can react to anything.

You still can implement `approve` or `transferAndCall` approaches - they will work, but they shouldn't be in the standard. 

And, by the way. This thing with subscriptions transforms our canister from just "a smart-contract" to "Open Internet Service", because now it extends the system, not just exists there.

> Q: Is it safe?

It is, if the token implementation is not awaiting for calls to return result. And if these calls made AFTER state modification to prevent possible re-entrancy.

-------------------------

senior.joinu | 2021-06-03 00:30:41 UTC | #10

> Q: How is it exactly better than ERCXXX?

1. It's smaller. Less code, less errors, easier to understand, easier to implement.
2. It abstracts value automation.

> Q: What about NFTs?

It is obvious that subscriptions would work well with NFTs also. But I'm writing this post for almost 5 hours now and not in condition to provide a decent specification design for them at the moment.

> Q: Was it possible to do the same on Ethereum?

Technically it was. But because of non-reversed gas model, it was vulnerable. Implementing this in your token was meaning to let anybody increase gas costs per transfer of your token holders as much as the attacker likes. On the IC we're immune to this.

Another example when correct and convenient model pushes boundaries of what is possible.

> Q: Why there is u64 everywhere? Where are Nats?

Do we really need so much tokens? This is not critical to me, but if you think there is a strong reason to make them into Nats, feel free to share it.

> Q: What about optional getters from ERC20?

Since they are optional, they are not in the standard.

-------------------------

senior.joinu | 2021-06-03 00:30:54 UTC | #11

> Q: Why do we call subscribers dynamically? Why can't we declare some common interface like `fn on_token_publish(args)`?

Because a single subscriber can have any number of subscriptions for any number of different tokens. We can't just declare a single function and filter inside it for this, because a subscriber might (and should) want to save its cycles, and in this case it can't.

> Q: Is it possible to implement this in Motoko?

Not right now. Now only rust's `ic-cdk` supports dynamically constructed calls. But subscribers can be done in Motoko, since they just need to provide a method name. Anyway, one day Motoko will also get the support for this and everything will be fine.

> Q: What's next?

Let's discuss this guys. I've written the whole 7 parts Medium post here and I'm thrilled to know if you like it. If you guys do, I could implement a reference implementation and we could continue to investigate this topic further.

__________________

That's all. Thanks for reading this far :tada: :tada: :tada:

-------------------------

senior.joinu | 2021-06-03 00:35:41 UTC | #12

Had to split in several posts. Forum engine was not ready for my commitment.

-------------------------

ICVF | 2021-06-03 03:00:59 UTC | #13

Thanks Alexander (senior.joinu :slight_smile:) for sharing your thoughts on the forum... it is an impressive deep dive... irrespective of which path the implementation(s) take from hereon, one thing is for sure - you've got across the message that we should be open-minded and thinking at the root-level. I'm really looking forward to the token standards that will develop on the IC platform. I believe that the core design of the IC platform provides a really wide and open canvas for innovative thinking on this front. Thanks again!

-------------------------

hackape | 2021-06-03 03:26:17 UTC | #14

[quote="senior.joinu, post:8, topic:4694"]
```
  fn subscribe(
    from: Option<Option<Principal>>, 
    to: Option<Option<Principal>>,
    callback: String
  );
```
[/quote]

@senior.joinu  Why `Option<Option<Principal>>` instead of `Option<Principal>`?

-------------------------

hackape | 2021-06-03 07:10:54 UTC | #15

Thanks for sharing your ideas!

I do love your subscription proposal, but I think it should be complementary to `approve`, not deprecating it. 
1. I do think `approve` model is easier to understand and integrate, and
2. existing dev/user base are already familiar with this concept (also analog to credit card UX in real life, less market education needed I guess?) so it's more likely to stay around, just like QWERTY keyboard.

-------------------------

senior.joinu | 2021-06-03 09:00:13 UTC | #16

> Why `Option<Option<Principal>>` instead of `Option<Principal>` ?

When it is `None` - it means 'empty filter' - when any transfer occurs.
When it is `Some(None)` - it means 'filtered by empty principal' - only when tokens are created or burned.
When it is `Some(Some(x))` - it means 'filtered by exact principal' - only when x is a participant of this transfer.

-------------------------

stephenandrews | 2021-06-03 09:22:59 UTC | #17

My man! I support your post in a lot of ways :-) transferAndCall is definitely the way to go.

We should be using AccountIdentifier's as opposed to Principal though, to have parity with ICP Ledger. I've published a motoko library which helps achieve this: https://github.com/stephenandrews/motoko-accountid

Callbacks are the way to go, currently the ICP Ledger notifies recipients via a notify call from the sender, which forwards the tx to the recipient via "transaction_notification" function (i.e. the receive needs to have this function defined). I think this is a good approach, however ICP Ledger does this via a secondary transaction for safety I assume. We could do something similar and force canister developers to include a set defined transaction like "transaction_notification" which is triggered on receipt of a tx.

I do like the subscription method, but I would maybe alter it and leave the different from/to specifics to the canister and not handled by the token canister. So just a simple subscribe method that allows canisters to define the callback that should be notified on receipt of payment, and any logic to do with the sender can be handled internally.

Some ideas, I'll put some more details around a standard that looks similar from what I've got. Liking to look of it. I've been working on a wallet as well, which can be connected via II or using your own mnemonic seed (hardware wallet support is being worked on too). The main purpose is to act as a token standard for other things we are working on. Hoping to release a beta of our wallet very soon, as well as deploy our initial DEX when we can:
![aca930a2-c81c-4847-9e70-8303c84851b3|690x351](upload://3cJJXYfwkcYYtjg6FSIi9qgkKV7.png)
![18fa837d-35e4-4c2e-9b5e-2494d28e89e7|690x490](upload://H10RaOm8878AGubIpcPxz9XtKo.png)

-------------------------

harrison | 2021-06-03 10:20:35 UTC | #18

Hey @senior.joinu . These thoughts are great. We (Fleek) have been jamming on this topic with several of the devs/projects in the community. We recently put out this draft https://github.com/PsychedelicDAO/token-standard - It takes a similar approach to your thinking (keep the base layer extremely simple but make it extendable). The goal was to try to align on something quickly since people are already launching or preparing to launch tokens in the near future (ourselves included). 

Would love to get any thoughts/suggestions/additions you might have on the current draft!

-------------------------

senior.joinu | 2021-06-03 11:27:45 UTC | #19

Thanks.
I don't see anything I could add to my previous words. 

It looks like your draft uses both `notifications` and `approvals`. I believe you should reconsider this design decision and make you draft simpler.

The whole goal of this thread is to encourage other developers to not to follow the same road we took on Ethereum, but rather find another idiomatic ways of solving our tasks.

UPD: And while I really like the idea with `compute_fee`, I don't see if it fits into "extremely simple" vision, since the token could exist without it.

-------------------------

hackape | 2021-06-03 11:53:02 UTC | #20

[quote="senior.joinu, post:16, topic:4694"]
When it is `Some(None)` - it means ‘filtered by empty principal’ - only when tokens are created or burned.
[/quote]

Well, I'd propose use `Some(Principal::management_canister())` instead. `aaaaa-aa` is practically address `0x0`. The semantic looks better this way IMO.

-------------------------

senior.joinu | 2021-06-03 12:10:45 UTC | #21

Yea, this looks nice. I agree.

It would be cool to have something like `Principal::empty()`.

-------------------------

hackape | 2021-06-03 12:20:11 UTC | #22

Agree it's better if we have this alias in SDK.

But even without one, we can still use `Principal::from_str("aaaaa-aa")` for rust and `Principal.fromText("aaaaa-aa")` for motoko.

-------------------------

stephenandrews | 2021-06-03 12:45:33 UTC | #23

With a few changes to what I proposed it's looking like:

    type AccountIdentifier = Text;
    type Balance = Nat;
    type SubAccount = [Nat8];
    type Metadata = {
      name : Text;
      symbol : Text;
      decimals : Nat8;
    };
    //Principal of sender, SubAccount of sender, Balance of transfer
    type Callback = shared (Principal, ?SubAccount, Balance) -> async Bool;

    type Receiver = {
      #account : AccountIdentifier;
      #principal : Principal;
      #canister : {
        principal : Principal;
        callback : Callback;
      };
    };

    type Token = actor {
      totalSupply: query () -> async Balance;

      metadata: query () -> async Metadata;
      
      balanceOf: query (who : AccountIdentifier) -> async Balance;

      transfer: shared (subaccount : ?SubAccount, recipient : Receiver, amount : Balance) -> async Bool;
    };

It's hard because some think we should stick with Principals for token holder IDs, and I would agree if the IPC Ledger also did it this way. But it becomes really hard if the addresses used for sending ICP is different to the addresses used for sending tokens built on the IC.

I ended up going with a callback submitted by the sender of a tx. A way it could work to stop funds being stuck in canisters is this:

1. Alice initiats a transfer with a callback
2. Token canister validates the tx, and puts the balance of the tx "on hold" (so Alice can't spend while we await the callback)
3. Await the callback - canister has to return true or false. If the callback fails because it doesn't exist it will drop the state change anyway, if it proceeds and triggers the await then we continue. This stops funds being locked in canisters (which happens with ethereum)
4. Canister responds with true or false. On true, the balance is added to the receivers account. If false, it is returned to the sender.
5. Transfer responds with a bool as well so the sender knows what happened. Prob best to change this to a proper response type in future though

This to me seems very simple, allowing canisters to decide how they want to treat txs and giving them the ability to reject them if they wish. Is there a group chat/discussion where developers can chat about this? A unified standard is something I think should have some priority and I'm happy to contribute, but hesitant to continue building without something that is somewhat standardized.

EDIT: Actually could probably drop the subaccount from a #canister receiver as it's unlikely that a canister dev will want to use multiple subaccounts...

-------------------------

geokos | 2021-06-03 12:40:09 UTC | #24

@senior.joinu Thanks for sharing your thoughts. Your discussion with @hackape and @stephenandrews is a masterclass for someone like me who is an absolute beginner on blockchain tech. I picked up on ethereum and solidity a month ago with no real dapp programming experience. I will be following this thread and reading it multiple times :)

-------------------------

senior.joinu | 2021-06-03 12:46:28 UTC | #25

> It’s hard because some think we should stick with Principals for token holder IDs, and I would agree if the IPC Ledger also did it this way. But it becomes really hard if the addresses used for sending ICP is different to the addresses used for sending tokens built on the IC.

This is what I said earlier in this thread. I believe, we should not follow the same design decisions, which Dfinity took implementing ICP. Why?

Dfinity provided us with two default tokens on the IC: cycles and ICP. 
Cycles are a stable coin which is by design used as a **fuel for computations**. 
ICP is a volatile coin which is by design used as **voting power on NNS**.

None of them are designed to transfer value. They both have their own purpose. And this is very important. They have their own tasks and do them well. They do not follow any standard or convention, because solving the problem correctly is the first priority thing.

We're, on the other hand, speaking about the standard for tokens which should transfer value and do it well. We're solving another problem here.
So, in my opinion, we should do something that fits our case and serves our tasks and not to try treat any token the same way, like you want to do with ICP.

-------------------------

senior.joinu | 2021-06-03 12:53:48 UTC | #26

Welcome onboard! Good luck on you journey!

-------------------------

stephenandrews | 2021-06-03 13:19:15 UTC | #27

Yep fair point. I think using something like the Receiver type could be a way that caters for both. SubAccount is optional, so if one was to completely ignore SubAccounts and only use the Principal as the identifier it would still work, but it does have backward (or I guess more sideways) compatibility with ICP. e.g.:

    type Receiver = {
      #account : AccountIdentifier;
      #principal : Principal;
      #canister : {
        principal : Principal;
        callback : Callback;
      };
    };

If you only know someone's address used for sending ICP, you can still transfer tokens to them. If you want to transfer to a principal, you can do that as well (and it is just credited to the principals default subaccount which is 0). You could use the entire token canister and only use Principals and it would work (might need to adjust the balanceOf query though to accept Principals).

-------------------------

Hazel | 2021-06-03 13:29:50 UTC | #28

@senior.joinu - Seriously love where your head is at! I went on the warpath advocating for subscriptions / events a few days ago - we should absolutely be leveraging the powerful parts of the IC.

Couple of thoughts for consideration:

1. For subscription I think the candid type `candid::Func` should be used. I've harped about this on twitter - but It facilities exactly what you have envisioned.  I have some rust and motoko examples of that here: https://github.com/SuddenlyHazel/token-standard/pull/1

2. For the primary spec I'm going to toss my voice towards using using Principals. I see too much room for error on the developer side using the Ledger spec. I will say the community should provide an extension format to facilitate playing nicely with the ledger for those who might need to, but I dont see that in the critical path. 

3. I dont care what the scheme looks like, but we need some concept of account operators or allowances. Without this users would only be able to act on their tokens from a single identity, likely the one generated from some token UI. How does this sound : only allow adding operator accounts that have full control of the users account. **Why?** Because this would encourage development of wallets / side contract canisters, likely with their own standards, that could encapsulate all the more funky logic.

-------------------------

Hazel | 2021-06-03 13:35:31 UTC | #29

Wait no scratch that - we might not even need operators at all - I guess this hypothetical "wallet", "account manager" could just be the account controller. Then, canisters wishing to execute a payment could hit some wallet canister method, and then wait for the callback from the "safe" token account.

:boom: - More Dfinity Like

-------------------------

Hazel | 2021-06-03 13:52:11 UTC | #30

The above flow might be made a bit more simple if send accepted something like 
```
public type Metadata = // not sure;
public type Callback = {
  recipients : [shared (Metadata) -> ()]; // allow alerting multiple canisters from one call
  metadata : Metadata;
};
```
So, if we wanted to buy an NFT say:

1. NFT Frontend redirects to this fictitious wallet canister frontend. Wallet frontend extracts payment info from url query param.
2. User executes the transaction on the wallet.
3. Wallet hits the token canister. 
4. Token canister does the transfer magic, and forwards the metadata to the accounts listed on the Callback Object
5. One of those is our NFT Backend, it peeks at the metadata, verifies the transaction occurred (or maybe we just attach the needed info on the Callback Object) and does its own application magic.

Boom pretty seamless checkout flows on the IC. :white_check_mark:

Note : the Metadata passed by the wallet should be **treated as unsecure**. It should just be a hint to the recipient who can then check to make sure everything was valid.

-------------------------

stephenandrews | 2021-06-03 13:55:35 UTC | #31

Yeah I agree with `func`'s for callbacks - I know in Rust you have more flexibility, but it's easier for Motoko to use the `func` type. I do the same with what I proposed and have used it effectively with the initial [wrapped_cycles](https://github.com/Toniq-Labs/wrapped_cycles) work.

I've adjusted what I proposed a few days ago, and it's probably my ideal proposition: https://github.com/Toniq-Labs/ic-fungible-token - the main takeaways:

1. Still supports Account Identifiers, but can be used to only work with Principals so it's essentially sideways compatible. I'm not too concerned if this isn't what the standard uses as I think Principal's are easier to work with anyway
2. Uses a subscription model, but not as open as @senior.joinu proposed with filters - I believe this should be handled by the receiving canister not the token canister. A simple callback with a bool return type allows for this
3. Allows for the use of callbacks being defined in the transaction as well, but I have loosely defined some rules around how this works but open to discussion. It may make sense to remove this from the transaction args and only allow subscribers to receive callbacks?

Hm lots to think about :-)

-------------------------

Hazel | 2021-06-03 14:01:26 UTC | #32

@stephenandrews - I might propose your callback accepts TransactionMetadata so the entire flow is truely reactive. My motivation is we dont just want to tell a canister a transfer happened, we want to tell a canister a transfer happened, and give it a hint "why" is happened so devs can build truly reactive flows.

-------------------------

dostro | 2021-06-03 14:16:02 UTC | #33

Continuing the discussion from [Thoughts on the token standard](https://forum.dfinity.org/t/thoughts-on-the-token-standard/4694/32):

@Hazel @stephenandrews @senior.joinu @geokos @hackape @harrison @ICVF 

What do you think of having conversations on standards and improvement proposals take place on [OpenCan](https://github.com/OpenCan-io/opencan)? 

Reason I make the suggestion is because:
1. We need to start diluting the power of today's two main neurons
2. We need a long-term solution for *where* conversations about standards and improvement proposals take place (unity in collaboration will yield the best options)
3. To be most efficient in regards to taking *action* on those conversations, we need a process for making proposals to the NNS (decentralized governance will help solve #1 and will yield the fastest innovation)

The current idea is to make OpenCan a developer-governed neuron for collaboration on improvement proposals and standards that, once approved within the dapp, get submitted for final voting to the NNS. As this would be its own neuron, it's one we could delegate voting power to and therefore start diluting the power of today's two main neurons.

There are already a couple threads on this token standard, but it will need adoption to work. What do you think of this idea?

-------------------------

Hazel | 2021-06-03 14:21:41 UTC | #34

Sounds good to me! I don't really care what tokens look like, but **we need callback schemes that are going to facilitate reactivity!!**

-------------------------

stephenandrews | 2021-06-03 14:27:10 UTC | #35

>  I might propose your callback accepts TransactionMetadata so the entire flow is truely reactive. My motivation is we dont just want to tell a canister a transfer happened, we want to tell a canister a transfer happened, and give it a hint “why” is happened so devs can build truly reactive flows.

Yes that makes a lot of sense!

-------------------------

stephenandrews | 2021-06-03 14:29:34 UTC | #36

I agree, I started a new issue maybe more can be discussed here: https://github.com/OpenCan-io/opencan/issues/14

-------------------------

paulyoung | 2021-06-03 14:49:53 UTC | #37

[quote="senior.joinu, post:16, topic:4694, full:true"]
> Why `Option<Option<Principal>>` instead of `Option<Principal>` ?

When it is `None` - it means ‘empty filter’ - when any transfer occurs.
When it is `Some(None)` - it means ‘filtered by empty principal’ - only when tokens are created or burned.
When it is `Some(Some(x))` - it means ‘filtered by exact principal’ - only when x is a participant of this transfer.
[/quote]

I’m not sure I fully understand this yet, but rather than nesting I would suggest introducing a new variant with 3 constructors.

Written in Motoko for convenience:

```
type Filter = {
  #None;
  #Empty;
  #Exact Principal;
};
```

or

```
type Transfer = {
  #Any;
  #CreateOrBurn;
  #Participant Principal;
};
```

-------------------------

dmd | 2021-06-03 16:02:22 UTC | #38

I'm really excited to see you all already working on standardizing token interfaces. 

I run the team that designed and built ICP, I hope we can find a standard that can work for you guys and ICP can adopt.

If we agree on a standard, not only will canisters be able to integrate new tokens easily, but also any centralized exchange that currently supports ICP will be able to support any other token with almost no technical work through our Rosetta API node.

I really need to write an article explaining the design of ICP some time because I think it will help people designing their own tokens.

ICP is pretty bare bones in terms of functionality, we put just enough into the contract to allow staking and exchange integration. The idea is that for everything else that you need you should be transferring funds into other canisters, so for example if you want ERC 20 functionality create an ERC 20 canister with the appropriate methods, transfer your tokens to a sub-account of that canister and let it manage them.

One of the big issues when designing a token is the memory limit on a single canister, so you either have to effectively shard your token or work hard to limit the amount of storage your data structures will use. This is why we didn't follow ERC 20 on the ICP canister. I was concerned that an attacker could use approve to use O(number of accounts^2) storage space on the ICP canister.

The account identifier vs principal ID argument is a good one, we did it mainly to keep the cost of storage down, most of our transaction fee is going to go towards the costs of long term storage of transactions and storing Hash(Principal ID, Subaccount) vs (Principal ID, Subaccount) knocked about 25% off the transaction size. I'm not 100% sure it was the right decision because it makes it much less clear what's going on in the ledger and makes integrations a bit more complicated with only a small gain in privacy so don't feel obliged to cargo cult that one. Back of the envelope even on a large subnet ICP transactions should only cost about 0.001c, so 20% on top of that probably isn't worth worrying about.

Oh and if you're planning to deploy a token right now, use Rust. Currently the motoko GC has real problems running lots of small update calls on big heaps which is exactly the kind of workloads that tokens have.

I look forward to seeing this develop and let me know if anyone has any questions!

-------------------------

skilesare | 2021-06-03 17:24:10 UTC | #39

@dmd 

Re: Using the ledger_canister:  I had considered that we all should just use the ledger format in the past, but I still have the concerns in https://forum.dfinity.org/t/defi-with-icp-seems-crippled-on-purpose/4689/9 which would be great if you could address.  Why can canister's send ICP?  Would they also not be able to send tokens built on the same infrastructure?

Re: Motoko: What is the plan to fix the motoko GC? If we can't use it for tokens at the moment, why should we learn it? It is hard to adopt something when you don't know the road map. We also need access to create custom transactions from Motoko to future proof wallets.

-------------------------

Hazel | 2021-06-03 18:10:58 UTC | #40

[quote="dmd, post:38, topic:4694"]
Oh and if you’re planning to deploy a token right now, use Rust. Currently the motoko GC has real problems running lots of small update calls on big heaps which is exactly the kind of workloads that tokens have.
[/quote]

I know you all have the compacting GC in the Pipeline, but if I could be so bold as to give a gentle push on it. [My highly unscientific survey](https://twitter.com/SuddenlyHazel/status/1399430177013313538), suggests most people coming to the IC are looking towards Motoko as the goto language to get hacking with. I've intentionally been doing all my little projects in Motoko for this reason. The Dfinity Developer Discord appears to be very Motoko focused as well - rightfully so - it's a great little purpose built language. Just my 2c :grinning_face_with_smiling_eyes: 

also, would love to get access to the source of Motoko too :eyes:

cc @claudio

Edit 1 : haha GC, Pipeline, get it :sweat_smile:

Edit 2 : Maybe a better indicator on Motoko - https://twitter.com/MotokoSchool

-------------------------

skilesare | 2021-06-03 18:42:25 UTC | #41

These are all great thoughts.  I'll add a few to the mix:

Re: Subscribe - Please don't call it subscribe!  Use notify.  We will soon want to support subscriptions(the ability to take a certain amount of tokens every (x) time period and it will get really confusing. see https://consensys.net/blog/blockchain-explained/subscription-services-on-the-blockchain-erc-948/

Re: Notify(instead of subscribe) - This is a great solution in as much as a canister can notify another canister with some metadata, it may be nice to be able to return something more than a true/false.

Re: OpenCan - I've seen @dostro pushing us over there a good bit. Perhaps if you gave some instructions, best practices, rollout plan, etc. Right now it just looks like a github site that you translate into a static site and push to the IC?  Are we supposed to just use the github issue features?  Who controls the github site?  How does publishing work?  This forum gets a good bit of attention and a lot of people are directed here. It has some great community and notification features.  I'm all for moving onto an IC based system or documenting our findings on OpenCan, but until it has the features that we have here it may not be time yet.

Finally, I'll propose that we don't really need giant standards.  Little pieces of candid interface seem to work well. We could add a meta layer on top as well.

Given the following type:

    //this is the DIPs type file
    module {
        type Meta = actor{
           dip_supports: query (dip_feature: Text) -> async Bool;
        }
        type MetaData = [byte];
        type Payment_Notifiable = actor{
           notify_of_payment: (amount: Nat, metadata: ?MetaData) -> async ?Payment_Notifiable_Response;
        }

        type Payment_Notifiable_Response = ?MetaData
    }

Then you can do something like the following
 
    public shared(msg) func transfer(recipient : Principal, amount : Nat) : async Bool {
      //handle transaction stuff
      //....

      let metaActor : DIP.Meta = actor.fromPrincipal(recipient);

      //figure out if the principal is a subscriber
      let bWantsNotification : Bool = wantsNotification(principal);
        
      if(bWantsNotification and metaActor.dip_supports('DIP_Payment_Notifiable') == true){
        let notifiable : DIP.Payment_Notifiable = actor.fromPrincipal(recipient);
        let response: DIP.Payment_Notifiable_Response = notifiable.notify_of_payment(amount, metadata);
        //do something with the response
      };
    }

The canister requesting notification will need a "dip_supports" function that returns true for the string "DIP_Payment_Notifiable".  I think you'd generally want to say that this should not be a dynamic set of supports, but hardcoded into your canister.

-------------------------

dmd | 2021-06-03 18:45:38 UTC | #43

Yup, this is just a super short term restriction, we’re just rolling everything out in steps hence the restricted and unrestricted subnets.

If you want to start developing, I’d advise just deploying a new ledger canister to a subnet and disabling the whitelist. The ledger doesn’t do anything NNS specific so it runs fine anywhere.

-------------------------

skilesare | 2021-06-03 18:49:00 UTC | #44

You can fill this DIP module with other 'standards' that the community comes up with:

   
I don't think that Motoko supports multiple inheritance right now, but it would be nice if it did so that we could do the following and get compile-time checks:

     //this is the DIPs type file
        module {
            type Meta = actor{
               supports: query (dip_feature: Text) -> async Bool;
            }
            type MetaData = [byte];
            type Payment_Notifiable = actor{
               notify_of_payment: (amount: Nat, metadata: ?MetaData) -> async ?Payment_Notifiable_Response;
            }

            type Payment_Notifiable_Response = ?MetaData

            type Token_Metadata = actor {
              name: query ()  -> async Text;
              symbol: query () -> async Text;
              decimals: query () -> async Nat;
              totalSupply: query () -> async Nat;
              balanceOf: (address: Principal) -> async ?Nat;
            }

            type Token_Transferable = actor {
              transfer: (recipient: Principal, amount: nat) -> async Bool
            }
    type Token_Allowances = actor {
          transferFrom: (sender: Principal, recipient: Principal, amount: nat) -> async Bool;
          approve: (spender : Principal, amount : Nat) : async Bool);
          allowance: (owner : Principal, spender : Principal) : async ?Nat;
        }

        type Token_Mint_And_Burnable = actor {
          mint: (to: Principal, amount: Nat) -> async Bool;
          burn: (amount : Nat) : async Bool);
          canMint: query (controller: Principal) -> async Bool;
          canBurn: query (controller: Principal) -> async Bool;
        }
           updateSubscriptionAddress: (
            subscriptionId: Hash,
            payeeAddress: Principal
          ) -> Bool
          //etc see erc948
        }

I don't think that Motoko supports multiple inheritance right now, but it would be nice if it did so that we could do the following and get compile-time checks:

    shared(msg) actor class CoolCoin(_name : Text, _symbol : Text, _decimals : Nat): async DIP.Token_Transferable, DIP.Token_Allowances, DIP.Token_Metadata {}

-------------------------

skilesare | 2021-06-03 18:50:08 UTC | #45

What is a short term restriction?  That canisters can't send ICP?  This will go away eventually?

-------------------------

dmd | 2021-06-03 19:02:31 UTC | #46

Yup and any tokens they've recieved will become accessible to the canister.

-------------------------

skilesare | 2021-06-03 19:31:50 UTC | #47

Another idea I've had, but not explored too much yet is that what if the token canister didn't actually hold any balances and was just a router to wallet actors that hold the balances?  This way the token canister needs far fewer cycles and people can be in charge of funding their own infrastructure?

-------------------------

dmd | 2021-06-03 19:59:32 UTC | #48

If you make a canister that does delegated identities you can do more than that, you can pick what user or users holds a certain account.
It's the same feature that the Identity Provider uses to share identities on stuff like the NNS UI.

-------------------------

claudio | 2021-06-03 21:08:59 UTC | #49

The compacting GC is about to get merged to master as a command line option to the compiler. I don't think it solves the issue that dmd rightly points out, but will give access to more heap.

Doing less aggressive GC should be possible but we haven't investigated it yet. That isn't a fundamental problem with Motoko the language, just our current GC implementation. 

Motoko will, I think, be open source in a matter of days or small number of weeks. The main issues are degree of history preservation, sorting our CI dependencies so they are publically available and, ideally, ensuring the same experience for Dfinity and external contributors.

-------------------------

jzxchiang | 2021-06-03 22:09:45 UTC | #50

I'm not sure I understand why we can't implement this interface in Motoko.

As this [example](https://sdk.dfinity.org/docs/language-guide/sharing.html) illustrates, we can share functions among actors to allow dynamic calling.

-------------------------

skilesare | 2021-06-03 23:09:27 UTC | #51

This sounds amazing and I don't know that we have a real example of what is happening under the hood with this. Any good examples that would help us understand this paradigm better?

-------------------------

Jessica | 2021-06-03 23:18:37 UTC | #52

[quote="dmd, post:38, topic:4694"]
I really need to write an article explaining the design of ICP some time because I think it will help people designing their own tokens.
[/quote]

Yes please do this.  I would love to know exactly how icp is broken down and how I can set up my own sun governance system
On my own project

-------------------------

wang | 2021-06-04 01:07:47 UTC | #53

Thanks for the enlightenment!

### PrincipalId vs AccountIdentifier

Using AccountIdentifiers could run into composability issues. My token in subaccount 0 doesn't know about tokens in subaccount 1. Slightly better privacy, but at the cost of convenience. I'm used to the Ethereum ecosystem where one account = one account, representing all my assets and transaction history, which can be plugged into any application.

In general, having both PrincipalId and AccountIdentifier increases friction for users and devs - why do I have two IDs? Why can't I just use one? Why does this one have dashes but this one looks like an eth address? and so on...

I believe we should use PrincipalId as the one and only identifier. Would it be possible to upgrade the ICP ledger to support this? The existing entries will have to be migrated and subaccount data could be lost, but I think the tradeoffs are worth it.

Alternatively, if SubAccounts are here to stay, then we'll want a registry to lookup PrincipalId from AccountIdentifier. Or, maybe we can change the implementation of AccountIdentifier to remove hashing.

-------------------------

Ori | 2021-06-04 09:37:07 UTC | #54

[quote="wang, post:53, topic:4694"]
In general, having both PrincipalId and AccountIdentifier increases friction for users and devs - why do I have two IDs? Why can’t I just use one? Why does this one have dashes but this one looks like an eth address? and so on…
[/quote]

This is a hurdle for users, I thought the same. I’ll second that.

-------------------------

jzxchiang | 2021-06-04 17:43:20 UTC | #55

[quote="dmd, post:38, topic:4694"]
The account identifier vs principal ID argument is a good one, we did it mainly to keep the cost of storage down, most of our transaction fee is going to go towards the costs of long term storage of transactions and storing Hash(Principal ID, Subaccount) vs (Principal ID, Subaccount) knocked about 25% off the transaction size.
[/quote]

It was explained by dmd earlier:

"The account identifier vs principal ID argument is a good one, we did it mainly to keep the cost of storage down, most of our transaction fee is going to go towards the costs of long term storage of transactions and storing Hash(Principal ID, Subaccount) vs (Principal ID, Subaccount) knocked about 25% off the transaction size."

-------------------------

stephenandrews | 2021-06-06 00:12:47 UTC | #56

Yeah my preference is Principal - it's a lot easier to work with. Upgrading ledger icp to work with principal would be a good idea.

-------------------------

flyq | 2021-06-10 14:51:47 UTC | #57

FYI, the datastruct used in ledger canister.
![image|415x500, 100%](upload://1NILmioIR7Hl9s8grJ3IWditpmQ.png)
![image|392x500, 100%](upload://8NO8JeLjvYSLBgLec1YQ4eogKSg.png)

-------------------------

PaulLiu | 2021-06-17 08:40:03 UTC | #58

Disclaimer: I've not read all the past discussions, please bear with me if this point is already discussed.

An important difference between the canister messaging model and ethereum/EVM call stack is that the former has a finer granularity on atomicity: it only rolls back one canister state where an exception happens, not the complete call stack like in EVM.

This has consequences. Consider the classical example of transactional behavior: I plan to take a train to see a concert. I'll only go if I can successfully purchase both a train ticket and a concert ticket. If one succeeds and the other fails, I ended up wasting money (unless there is a way to refund, but let's ignore that for a sec). So the desirable behavior is that I either purchase both tickets, or neither.

To do this with Ethereum is easy, but on IC it is not so simple if you have to buy train ticket from canister A and concert ticket from canister B. This difference is due to a conscious design choice in the canister model, because the EVM "roll-back everything" semantics essentially is equivalent to imposing a global lock, which limits scalability. For canisters/actors, it is much natural to limit the atomicity to a single canister, instead of across all canisters.

So IC as a platform does not support cross-canister transactions. If we want to do cross-canister transactions, we'll have to encode this functionality into application logic instead.

The reason I bring it up in this thread is because I think a token standard should leave room to enable cross-canister transactions. An atomic `transfer` function is fine for simple applications, but will have trouble when we want to compose two or more transfers across multiple canisters. So this is something perhaps this discussion group should think about.

A two-phase commit kind of interface (prepare & commit) should not be difficult either, given that each update call is atomic, and we can have both success and failure callbacks when doing inter-canister calls. I won't go into too much detail here, and I'm sure this group will come up with a good solution.

-------------------------

senior.joinu | 2021-06-17 14:35:29 UTC | #59

Yes, and this is a very important remark. Thanks @PaulLiu.

I want to elaborate on this a little and to try to prove you once again that the only thing we need in tokens is `pub/sub`, and we certainly don't need `approvals`.

First, let's see how one could implement such a transaction (a buyer wants to buy a concert ticket, but only with a train ticket to get to this concert in time) on Ethereum, using ERC20 for example. 

We have: 
* a buyer with some amount of ERC20 tokens for payment; 
* a train ticket provider with some NFTs representing train tickets (let's imagine it's ERC721 with the same `approvals` functionality);
* a concert ticket provider with some NFTs representing concert tickets (also ERC721)

It's obvious that we need some kind of a middle-man in this scenario in order to ensure security of the process - a separate smart contract (SC) with publicly available source code which can automate this process for us and provide an escrow.

Note: `approval` in ERC20 is essentially an escrow itself - we lock our assets in a temporary area which is controlled by both: us and the middle-man, until the middle-man ensures validity of this transaction and executes all the needed actions for us to proceed. So, in ERC20 (and ERC721) we have an escrow enabled by default. 

So, what exactly the process could be? Let's walk through it step-by-step:

*Precondition*: the train ticket provider and the concert ticket provider `approve` to the middle-man SC all of their ticket tokens which they're willing to sell.

1. The buyer `approves` to the middle-man SC a quantity of tokens for payment they think is enough to cover all expenses.
2. The buyer creates and sends to the middle-man SC an `application` which is essentially a statement like "I want to buy a ticket on this exact concert and to also buy a ticket on this exact train".
3. The middle-man SC sees the `application` and checks if it has all the required assets `allowed` to fulfill the `application`.
4. If it has - the middle-man SC `transfersFrom` all the tokens participating in this `application` to their destinations (success); if it has not - the middle-man SC simply rejects the application (fail) - in this case no transaction revert is needed, because parties could simply cancel the `approval` of their assets for the middle-man SC right after they see the failed transaction.

Will the same process with `approvals` work on the IC? ___No.___ And this is exactly what @PaulLiu did just said.
Ethereum is __single-threaded__ - only one smart-contract is making progress at any given point of time.
The IC on the other hand is __multi-threaded__ - multiple canisters are making progress simultaneously. It means that step #3 from the above algorithm is useless since it does not guarantee availability of the asset during the whole transaction (because assets are managed by different canisters, which make progress independently). In other words, you could simply fool such a system, `approving` money, sending an application and then quickly `disapproving` them back - there is a chance for you to spot the exact moment when the middle-man canister did already checked their `allowance` of your payment, but did not yet `transferedFrom` it.

How could one implement the same process using `pub/sub`? Let's see:

*Precondition 1*: there exist token canisters to represent all: fungible tokens for payment, non-fungible tokens for train tickets and non-fungible tokens for concert tickets and all of them implement `pub/sub` capabilities like I described in initial posts of this thread.

*Precondition 2*: the middle-man canister is subscribed to all of these token canisters.

*Precondition 3*: the train ticket provider and the concert ticket provider did already transferred their ticket-NFTs to the middle-man canister and the latter acknowledged them (since it is subscribed to their transfers).

*Precondition 4*: the middle-man canister manages its internal balance list of each token it is subscribed to.

1. The buyer transfers to the middle-man canister a quantity of tokens for payment they think is enough to cover all expenses.
2. The buyer creates and sends to the middle-man canister the same `application` as from the Ethereum case.
3. The middle-man canister sees the `application`, checks its own internal balance list if all conditions are met.
4. If everything fine - the middle-man canister transfers all the tokens to their destinations fulfilling the `application` (success); if something wrong - the middle-man canister simply rejects the `application` (fail). No payment spent.
5. If the buyer wants to get their money back, they could simply ask the middle-man canister for it and the latter will transfer them back.

It is something like using Binance - you can deposit some money, use them there any way Binance lets you, and then withdraw them back.

In other words, using `pub/sub` instead of `approvals` on the IC we're moving escrow from multiple smart-contracts into a single smart-contract, which is doing things in a single thread.

-------------------------

senior.joinu | 2021-06-17 15:10:22 UTC | #60

Oh, god. Maybe you're right! My bad.

-------------------------

skilesare | 2021-06-17 16:29:05 UTC | #61

I think you may be able to 'be your own middleman' in this scenario.  If services have 'reserve' with an sla on that reserve then you can get back all your reserves before you commit them.

    if((await a.reserve(concertTicket)) and (await b.reserve(trainTicket) and (c.reserve(hotel)){
       a.commit();
       b.commit();
       c.commit();
    } else {

      await a.forfiet();
      await b.forfiet();
      await c.forfiet();
    }

-------------------------

witter | 2021-07-12 11:04:06 UTC | #62

type Receiver = {
  #account : AccountIdentifier;
  #principal : Principal;
  #canister : {
    principal : Principal;
    before_transfer_callback : Callback ->bool;    
    after_transfer_callback : Callback;
  };
};

token transfer can call before_transfer_callback , if return true ,execute  transfer , if return false ,stop transfer.

-------------------------

stopak | 2021-07-12 18:30:38 UTC | #63

I really like your idea of using `pub/sub` instead of approvals. I've always found them to be somewhat confusing and not really secure (you cannot easily check how many approvals where given). However there is an issue with `pub/sub` model that needs to be addressed before we can use it.

Imagine an malicious actor that would like to exploit pub/sub model. It is possible to write a canister that will make circular `pub/sub`, similar to re-entrancy attack. I think we need to establish additional `authorization` step to public `pub/sub` so that it possible to control which contracts are actually subscribed to notifications. 

Additionally such control is also required if we are to have any control over cycle usage of our canister. Basically cost of `publish` is directly related to number of subscribers, more subscribers means bigger execution cost.

-------------------------

quinto | 2021-07-13 05:22:07 UTC | #64

Before we set token standards, I think we should come to agreement on a cycles transfer standard first. I've started working on such a proposal:

[Internet Computer Cycles Common Initiative (github.com)](https://github.com/CyclesCommon/cycles-common)

[The common cycles interface proposal by quintolet · Pull Request #1](https://github.com/CyclesCommon/cycles-common/pull/1/files)

-------------------------

ililic | 2021-08-02 23:33:15 UTC | #65

Hey folks,

This thread has been a great source of inspiration and I've learned a lot following your code and examples. Clearly there's a lot of community effort going on… many different wallet implementations, many different tokens coming out, NFTs, etc. It's super exciting to see.

I think the discussion of a standard remains very important so I decided to start working on a draft post which I hope to distribute more widely. But before that I wanted to share with this forum and get some feedback and thoughts. The way I see it, a token standard belong to the community - the Foundation's role is to help facilitate the conversation and that's what the post hopes to help encourage. Let me know if I've left something out, if things need more clarification, or if I should try to dive deeper on any specific points.

**The IC Token Standard Discussion**

The Internet Computer developer community has been having ongoing discussions about defining a token standard fit for purpose for the IC blockchain. While other blockchain ecosystems have demonstrated a clear product/market fit for tokens, the IC provides a new paradigm for blockchain computation, and as such there is a strong desire to build a native token standard that can in time scale to the demands of millions of users.

This document will attempt to catalog some of the existing discussions around a standard, highlight key considerations, and generally serve as a resource for the early reference implementations of tokens on the Internet Computer.

All credit is due to the members of the IC developer community. While it would be too difficult to exhaustively list everyone’s contributions, we attempt to recognize all of those who have contributed to the conversation. Special thanks to: senior.joinu, ICVF, hackape, stephenandrews, harrison, geokos, Hazel, dostro, paulyoung, dmd, skilesare, claudio, jzxchiang, Jessica, wang, Ori, flyq, PaulLiu, witter, stopak, quinto, …

# Introduction

## What is a Token?

A token is a type of digital asset that is native to a blockchain ledger. ICP is an example of a token, and serves as a utility token for the Internet Computer blockchain.

Given that blockchains provide general purpose execution environments, developers use tokens as a foundational building block for building their decentralized applications — not only for bootstrapping funding, but also for community engagement and decentralized control of the project.

## Why a Standard?

The topic of token standards has a storied history going all the way back to the days of [colored coins](https://en.bitcoin.it/wiki/Colored_Coins) on Bitcoin. With the advent of Ethereum smart contracts, the token standard discussion really gained prominence because for the first time a general purpose scripting environment was available to developers.

Arguably the most successful token standard is known as [ERC-20](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/), which was the initial catalyst for broad token interoperability on the Ethereum blockchain. The standard defines an interface for basic functionality to transfer tokens, as well as standard token metadata such as balances, token name, symbol, etc.

Tokens are generally considered to be primitives for a blockchain’s community. They act as coordinating mechanisms for projects, and enable many add-on ecosystem services such as decentralized exchanges, lending platforms, marketplaces, launchpads, DAOs, and so forth. A token standard interface allows any token that implements the interface to be re-used by other tools and platforms such as exchanges and wallets.

# Design Considerations

## PubSub

Most popular token implementations that pre-date the Internet Computer are generally designed for single-threaded execution environments such as the Ethereum Virtual Machine. Given the sequential nature of such blockchains, these tokens are rather simplistic interfaces that rely on the blockchain’s native consensus mechanism (generally Proof of Work) to order transactions, execute state transitions, and produce blocks.

Because the Internet Computer provides a truly distributed compute environment as compared to other blockchain systems, developers can find more expressive ways to develop their software architectures. PubSub (or “notifications,” “subscriptions,” “topics,” or “events”) is a common pattern that reduces complexity and creates code that is simpler and easier to extend.

Forum user senior.joinu provides an example PubSub interface (here named subscribe):


```
fn subscribe(

from: Option<Option<Principal>>,

to: Option<Option<Principal>>,

callback: String

);
```

The semantics of this style of subscription adds a callback to the subscription list. From here on, whenever there is a `transfer` *from -> to*, then the callback method will be called asynchronously without awaiting.

Whether or not PubSub should be considered a standard way of implementing tokens on the Internet Computer is a topic that is currently being discussed, and if so, what is the best way to execute on this pattern (naming conventions, extensibility, etc). It is worth noting that the ICP ledger canister implements some methods in the PubSub pattern.

## Atomicity

The canister messaging model creates important differences compared to the Ethereum/EVM messaging model when it comes to the atomicity of transactions.

In the EVM (and other similar blockchains), if there is an exception when processing a transaction, the entire call stack of that transaction is rolled back. That is to say, when an Ethereum transaction is being processed, it has a global lock on the entire state of the EVM and can call in to other smart contracts in order to execute some complex logic. If the transaction is successful, then state transitions are applied to all contracts that were invoked. If the transaction is unsuccessful, then the entire call stack is rolled back as if the transaction had never happened in the first place.

Within the canister messaging model, no such rollback guarantees are provided. If an exception occurs within a canister, it only rolls back that canister’s state, not the entire state of the environment.

This difference means that token implementations on the Internet Computer need to consider designing for atomic, cross-canister transactions within the application logic, whereas token implementations on Ethereum get this atomic behavior “for free” (which is why such use cases as Flash Loans are popular within the Ethereum ecosystem).

Any token standard on the Internet Computer should leave room to enable cross-canister transactions.

## Extensibility

In their simplest form, tokens are used for value transfer: sending the value of a digital asset from A to B. But tokens can also have much richer functionality. Indeed, some functionality can be taken for granted. For instance, developers on the Internet Computer who want to maintain the entire ledger of a given token’s transaction history would need to implement this functionality themselves. Developers on other blockchains such as Ethereum would simply get that functionality for free as a part of the platform’s native functionality.

From a standards perspective, it would be useful to agree on what the most basic form of a token API would look like, and what sorts of extension mechanisms could be implemented on top of that API. Some potential token extensions may be (h/t to [Hazel](https://github.com/SuddenlyHazel/token-standard) & [Toniq Labs](https://github.com/Toniq-Labs/extendable-token/)):

* Burning
* History
* Allowances
* Batching
* Extended Metadata
* Fees
* Etc.

The fact that a token can be extended (and upgraded!) is a compelling and novel addition to the blockchain landscape that is not easily replicable on other blockchain environments.

## Scalability

In other blockchain ecosystems, tokens are as scalable as their underlying systems. Users who are willing to pay larger gas fees are generally given priority in their transactions (edge cases involving concepts such as [Miner Extractable Value](https://research.paradigm.xyz/MEV) are outside of the scope of this document). As the token’s transaction history expands, the underlying blockchain hosts the token state at no additional fee to the users, but at the cost of expanding the global state of the system and therefore limiting scalability (proposals regarding [State Fees](https://ethresear.ch/t/state-fees-formerly-state-rent-pre-eip-proposal-version-3/4996) are outside the scope of this document) of the system.

Canisters in the Internet Computer are given no such “free lunch.” If canisters need to maintain their entire transaction history, then it is the responsibility of the application to implement that functionality. In the case of tokens, this can be achieved by implementing the functionality directly into the canister logic or via extensions, as previously discussed.

The design of the [ICP ledger canister](https://github.com/dfinity/ic/tree/master/rs/rosetta-api/ledger_canister) includes a mechanism for scaling transaction ledger storage beyond the limit of a single canister. The mechanism is implemented by maintaining many archival node canisters. As the current “tip” of the ledger approaches the limit of a single canister, a new canister is created as the tip and the existing canister is added to the collection of archives.

## Immutability (Read-Only Code)

Due to canisters having an ability to be upgraded over time, there exists a possibility that the API of a canister as well as its underlying implementation may change at any time. This is different from other blockchain environments where contracts are immutable upon deployment and upgrade paths require re-deployment and migration of state.

As a result, there exists the potential for malicious token implementers to deploy a canister that seems benign at first but then upgrade the canister at some later date to some implementation that is not to the end users’ expectations, or which manages to steal funds or do other harm to consumers of the canister.

This is an edge case unique to the Internet Computer, and as such a token standard on the IC will require mitigation to prevent malicious token implementers from changing APIs in a manner that causes harm to consumers of the token.

One potential workaround is to imagine the existence of an open internet service that provides a “verified source” type of functionality for canisters. The well-known blockchain explorer [Etherscan](https://etherscan.io/) has a “[contracts with verified source code](https://etherscan.io/contractsVerified)” feature that is an example of this pattern. If such an [open internet service existed](https://www.joachim-breitner.de/blog/779-Verifying_the_code_of_the_Internet_Identity_service), then token contracts could be certified by this open internet service, and any token that changed its interface would need to recertify or risk being delisted from the “accepted” use registry. Alternatively, token contracts may adopt using tools like [Black Hole](https://github.com/ninegua/ic-blackhole) in order to make the canister public and immutable.

In any event, it’s worthy for the community to have a robust conversation about this feature of the Internet Computer and how it differs from other blockchain environments.

## Rosetta API Integration

[Rosetta](https://www.rosetta-api.org/) is an open standard designed to simplify blockchain deployment and interaction. Many exchanges around the world, such as Coinbase, use the Rosetta API and expect blockchain projects to implement the API as a part of an integration and onboarding process.

The design of the [ICP ledger canister](https://github.com/dfinity/ic/tree/master/rs/rosetta-api/ledger_canister) implements the Rosetta API, and so there already exists a token canister with Rosetta API integration in the Internet Computer ecosystem.

It is worth noting that simply implementing the Rosetta API does not guarantee that a token will be listed on any given centralized exchange platform. However, having a well tested, off-the-shelf implementation of the Rosetta API for token canisters may be a boon for the token ecosystem, as tokens may be more readily supported by third-party tools and platforms.

## Other Considerations

### Rust vs Motoko (vs other Wasm-compatible languages)

The two primary programming languages for development on the Internet Computer (as of Summer 2021) are Motoko and Rust. While Motoko has been developed specifically for the Internet Computer, Rust is also a popular choice due to its robust community and extensive collection of libraries.

In an ideal world, the two programming languages would offer near parity in terms of performance characteristics, and choice would ultimately come down to developer preference. In practicality, there may be tradeoffs between the two languages. Further benchmarking may be required to fully understand the performance characteristics of tokens implemented with various languages.

### Principal Identifiers vs Ledger Account Identifiers

Unfortunately, the ICP ledger canister uses a different cryptographic scheme for its account ids than the Internet Computer proper uses for its principal identifiers. The reason for these two different schemes is mostly historic (the keys that were used in the seed round were secp256k1 keys — as a result, they needed to be supported by the ledger canister at genesis).

Through the development phases of the Internet Computer, it was decided that Ed25519 would be used as the main signature scheme for the IC; this made sense as an isolated decision but unfortunately created the current conflict.

There is no clear way to unify these things in the near future, as the roadmap for doing so involves many components and there strictly isn’t enough bandwidth from the Foundation’s roadmap to prioritize such an effort.

Since most industry standards follow secp256k1 (including hardware wallets), perhaps it is a vote in favor of moving toward that direction for canister development in general.

# Security Considerations

This section remains a big to-do. An exhaustive list of security considerations for IC style tokens needs further exploration from the community and from security experts. A few high level topics to consider include:

## Re-entrancy

## Double spend

## Canister upgrade rug pulls

# Appendix I - Existing Implementations

* Senior.joinu’s forum implementation of [IFungibleToken](https://forum.dfinity.org/t/thoughts-on-the-token-standard/4694/8?u=ililic)
* SuddenlyHazel’s [Internet Computer Token Standard](https://github.com/suddenlyHazel/token-standard/)
* ToniqLab’s [Extendable Token](https://github.com/Toniq-Labs/extendable-token)
* Fleek (Psychedelic)’s [Token Interface](https://github.com/Psychedelic/standards/tree/main/standards/token-interface)

# Appendix II - Existing Proposals

* [ICIP1 - Sailfish](https://github.com/sailfish-app/proposals/blob/master/icip-1.md)
* [Toniq Labs - IC Fungible Token](https://github.com/Toniq-Labs/ic-fungible-token)
* [EIP-20: ERC-20 Token Standard (Ethereum)](https://eips.ethereum.org/EIPS/eip-20)
* [Deland Labs - Dfinity Fungible Token Standard](https://github.com/Deland-Labs/dfinity-fungible-token-standard)
* ERC20 Re-implementations
  * [Dfinance IC Token](https://github.com/dfinance-tech/ic-token)
  * [Motoko Token](https://github.com/enzoh/motoko-token)

# Appendix III - Existing Forum Discussions

* [Proposal for a Standard Toke Interface](https://forum.dfinity.org/t/proposal-for-a-standard-token-interface/1304)
* [How to issue icp standard tokens based on ic](https://forum.dfinity.org/t/how-to-issue-icp-standard-tokens-based-on-ic/3898)
* [Does Dfinity plan to support a standard token interface along the lines of ERC20?](https://forum.dfinity.org/t/does-dfinity-plan-to-support-a-standard-token-interface-along-the-lines-of-erc20/2373)
* [Token Security Considerations](https://forum.dfinity.org/t/token-security-considerations/5937)
* [Another potential token standard for the IC](https://forum.dfinity.org/t/another-potential-token-standard-for-the-ic/4500)
* [Thoughts on the token standard](https://forum.dfinity.org/t/thoughts-on-the-token-standard/4694)

-------------------------

Goku | 2021-08-03 19:42:09 UTC | #66

Thanks for putting this together, really great stuff! Here's my thoughts on this:

**PubSub:** Events is the standard nomenclature from other blockchains, so likely the ideal nomenclature for this. Subscriptions might be used for streaming payments for apps in the future, and the mixup might get confusing. Notifications and topics require educating people on the differences with the internet computer.

**Atomicity**: We’ll need a standard two phase commit structure for tokens.

**Extensibility**: EXT-token is a great starting point, maybe we should all focus our efforts on standardising and auditing this.

**Security**: My biggest concerns that would need to be solved before deploying high value tokens are

- Immutable token canisters. We require a 'blackhole' on the issuance/balances canister to be verified, and perhaps token extensions can remain upgradeability.

- A 2-phase commit scheme seems required for cross canister transfers, and also likely requires some a threshold of canisters to approve before releasing. Maybe it could be configurable similar to how Bitcoin exchanges can configure how many confirmations before approving withdrawals.

- MEV is a bit of a black box for me as data center and node operations is private. Seems like this would be much easier to do than on traditional blockchains, since there would be essentially no cost for data centers to do so.

 - Canister balance attack. How do we prevent tokens from becoming frozen by a spam (intentional or not) on the balance canister or some other critical canister?

I'll update this post as other thoughts come to mind on it.

-------------------------

witter | 2021-08-11 23:36:16 UTC | #67

Great discussion.Here’s my thoughts on this:

## Rules of Token Standard Design
ERC20 is the first token standard in the blockchain world, and it has been fully verified and recognized. Therefore, when designing the [Dfinity Fungible Token Standard], it is necessary to refer to the existing ERC20 standard.

At the same time, the formulation of [Dfinity Fungible Token Standard] should meet the following goals:

1. Improving the ERC20 standard
2. Being suitable for Dfinity

## Improve ERC20 standard

### How to improve ERC20

ERC20 was created in the early days of Ethereum. In the process of Eth ecological development, the developer found that ERC20 was not perfect, so the developer designed the ERC223\ERC667\ERC777 standard in an attempt to improve ERC20. We will refer to these standards and develop a one that combines the advantages of these standards.

1. ERC223 tries to solve that the ERC20 transfer recipient (contract) does not support the transfer of Token, the transferred Token will be lost (similar to sending Token to a black hole address)Solution details: Fallback processing method, the recipient (contract) must implement the tokenFallback method to determine whether the recipient supports ERC20 Token
2. ERC667 adds transferAndCall, in order to realize the simultaneous execution of transfer and call, and solve similar problems with ERC223
3. ERC777 uses send as the standard sending method, controls whether the transfer is accepted or not through the hook function, and uses the operator authorization method to replace the approve method as a proxy transfer solution

With reference to the above standards, we have the following considerations:

1. ERC667 and ERC223 solve similar problems, so just keep one of them
2. ERC777 send VS ERC20 transfer is to realize the transfer. Which plan do you choose to keep?ERC20 transfer does not contain other logic besides the transfer;ERC777 send contains transfer and:
  * During the transfer process, if the sender implements the tokenToSend hook function, the function will be called to accept or reject the transfer before the transfer
  * During the transfer process, if the transfer receiver implements the tokensReceived hook function, the function will be called after the transfer to accept or reject the transfer

ERC777 implements the capabilities that ERC20 does not have, allowing the sender/receiver to control whether to accept the transfer. It seems more reasonable to use ERC777 send method. ERC20 is more popular, so the ERC777 scheme is adopted, but using transfer as the method name is easier for ERC20 users to accept.

The implementation of ERC777 relies on the ERC1820 registration contract to register the sender/receiver hook function, so no matter the sender and receiver are ordinary addresses, even the contract address can register hook functions. (This topic will be discussed again in the **[Suitable for Dfinity]** section below)

3. The hook function of the ERC777 receiver realizes a function similar to ERC667, so the function coverage of ERC667 can be completed by adopting the ERC777 standard
4. Operator authorization solution of ERC777 VS ERC20 approve solutionThe operator authorization scheme of ERC777 does not limit the allowance of authorization, and the management granularity is bigger. ERC20 Approve can not only meet the needs of the ERC777 authorization program, but also through the approval allowance Approve program seems to be a more reasonable choice, which can control the credit range available to everyone and achieve more refined management than ERC777
5. ERC777 provides a default precision value of 18 for the token, and supports setting the minimum step unit for tokens.

* Different precision support is more suitable for the needs of different scenes, and the design of keeping decimals seems to be a more reasonable choice
* ERC777 non-granular integer operations will be reverted, which will increase the frequency of abnormal user calls, so this design is abandoned

### Improved standards

Based on the above considerations, the improved draft standard is as follows:

```
service: {
  name: () -> (text) query;
  symbol: () -> (text) query;
  decimals: () -> (nat64) query;
  totalSupply: () -> (nat64) query;

  balanceOf: (owner: principal) -> (nat64) query;
  allowance: (owner: principal, spender: principal) -> (nat64) query;
  approve: (spender: principal, value: nat64) -> (bool);
  transferFrom: (sender: principal, receiver: principal, value: nat64) -> (bool);
  send: (receiver: principal, value: nat64, args:opt vec nat8) -> (bool);
}
```

## Suitable for Dfinity

### Problems to be solved

The design of Token Standard should fully consider the difference between Dfinity and Ethereum, and clarify the problems to be solved:

1. No atomicity similar to EVM cross-contract calls

* Conclusion: It is necessary to refactor the interface；

2. No built-in EVENT support

* Probelm: Historical content such as transaction records needs to be separately for storage
* Consideration: On Forum, there are two ideas (Pubsub/Notify)When the Token is transferred, Notify informs the recipient, which can fill the missing EVENT.When the Token recipient not a canister, which means can not notify, it is necessary to support query transaction records.Token does not have sufficient reason to implement Pubsub to satisfy third parties irrelevant to actual operations
* Conclusion: Notify is a better way; should support query transaction history;

3. Built-in storage support, can store more data content

* Problem: The current storage limit is 4G, which can store more content cheaply, but storage expansion needs to be considered
* consider:tx history, should be stored separately to avoid storage limitationsBuilt-in storage can support Token to store more self-describing information
* Conclusion:Separate storage of transaction history Token implements self-description

4. The call of the contract does not require the caller to pay gas fees (the contract publisher provides gas fees in the contract)

* Problem: Need to consider the cost of DDOS attacks that call the contract
* Conclusion: The charging logic should be designed in the Token

5. There are two different identities in Dfinity, Internet Identity (II for short) and Principal ID

* Problem: which identity to use as the choice of token standard is an important question
* Consideration: Dfinity's II is an implementation of DID, although DID is based on Principal ID
* Conclusion: It is necessary for the Token standard to be compatible with different identities, in order to meet the needs of different identity scenarios

6. No black hole address

* Question: If there is a need to destroy Token, how to deal with it?
* Conclusion: The burn interface should be designed in the Token standard

7. approve/transferFrom (Approve is a pairing function for TransferFrom) keep or remove

* Question: Whether approve/transferFrom is removed is controversial in the Forum discussion
* consider:approve/transferFrom appears in ERC20 mainly because:
> Using Ethereum's native ETH token, you can call the smart contract function and send ETH to the contract at the same time. This is done using payable. But because the ERC20 token itself is a smart contract, it is not possible to directly send the token to the smart contract while calling one of its functions; therefore, the ERC20 standard allows smart contracts to transfer tokens on behalf of the user-using the transferFrom() function. For this, users need to allow smart contracts to transfer these tokens on their behalf
However, in the Dex and lending scenarios of Ethereum, Approve is often accompanied by the possibility of simultaneous operation of two tokens. Approve can avoid the repeated payment problem which transaction brought about, has a good supplementary use scenario for transfer.
* Conclusion: Approve/transferFrom should be supported

8. TransferAndCall vs Receiver Notify

* Probelm: which option is more suitable
* consider:

Notify can meet the basic notification needs. Although it cannot support better flexibility, it is sufficient to meet the transfer scenario

TransferAndCall provides better flexibility, but it depends on the transfer caller to fully understand the method and parameters corresponding to the call, which is not needed for most transfer scenarios

* Conclusion: Both are supported at the same time, integrated in the transfer function

~~If the user specifies the call (specify the target method and parameters), only the call will be executed, and the notification will not be executed;~~

~~If the user does not specify the call (specify the target method and parameters), only execute Notify;~~

Token standard should execute Notify first, and then execute call;

9. approveAndCall VS transferAndCall

* Problem: Some developers support approveAndCall, so we compare it with transferAndCall. Due to problem 1 (atomic problem), methodAndCall and transferAndCall are two sets of non-atomic operations, and there is no difference in essence.
* Consideration: In some scenarios, when multiple Tokens need to be transferred at the same time, transferAndCall can not meet such needs. After approval, execute transferFrom in the final call to pay multiple tokens at once
* Conclusion: Support approveAndCall and transferAndCall to meet the flexible needs of more scenarios.

### What does Dfinity Fungible Token Standard need to achieve?

1. Interface self-description

Dfinity needs to provide a common contract interface registration/query service similar to ERC1820.

Dfinity currently does not have such a service, but because of **[problems to be solved]** economic considerations, no one wants to build such a service.

Dfinity can solve the problem solved by ERC1820 through [Dfinity Self Describing Standard](https://github.com/Deland-Labs/dfinity-self-describing-standard)

2. Information self-describing

Etherscan, MyEthereumWallet, Imtoken, TokenPocket, Dapp all have more information requirements for ERC20, such as Logo, introduction, white paper, social media, official website, contact information, etc. Each place that needs this information needs to be maintained independently, so information appears Inconsistent. It is necessary to solve this problem through the design of **[Dfinity Fungible Token Standard]**

Based on the above problems and requirements, combined with the ERC standard formed in the previous step, the following draft standards are formulated:

```
type ApproveResult = variant { Ok : opt String; Err : String };
type BurnResult = variant { Ok; Err : String };
type CallData = record { method : text; args : vec nat8 };
type Fee = record { lowest: nat; rate :nat32 };
type KeyValuePair = record { k : text; v : text };
type MetaData = record {
  fee : Fee;
  decimals : nat8;
  name : text;
  total_supply : nat;
  symbol : text;
};
type TokenHolder = variant { Account : text; Principal : principal; };
type TransferResult = variant {
  Ok : record { nat; opt vec String };
  Err : String;
};
service : {
  // Return all of the meta data of a token.
  meta: () -> (MetaData) query;

  // Return all of the extend data of a token.
  // Extend data show more information about the token
  // supported keys:
  // OFFICIAL_SITE
  // MEDIUM
  // OFFICIAL_EMAIL
  // DESCRIPTION
  // BLOG
  // REDDIT
  // SLACK
  // FACEBOOK
  // TWITTER
  // GITHUB
  // TEGEGRAM
  // WECHAT
  // LINKEDIN
  // DISCORD
  // WHITE_PAPER
  extend: () -> (vec KeyValuePair) query;

  // Return token logo picture
  logo : () -> (vec nat8) query;

  // Returns the account balance of another account with address owner.
  balanceOf: (holder: text) -> (nat) query;

  // Returns the amount which spender is still allowed to withdraw from owner.
  allowance:(owner: text, spender: text)->(nat) query;

  // Allows spender to withdraw from your account multiple times, up to the value amount. If this function is called again it overwrites the current allowance with value.
  // If calldata is not empty, approveAndCall will be executed.
  approve: (fromSubAccount: opt vec nat8, spender: text, value: nat, calldata: opt CallData) -> (ApproveResult);
  // Transfers value amount of tokens from [address from] to [address to].
  // The transferFrom method is used for a withdraw workflow, allowing canister
  // to transfer tokens on your behalf.
  transferFrom: (spenderSubAccount: opt vec nat8, from: text, to: text,value: nat) ->(TransferResult);

  // receiver's Notify hood function if exist.
  // Transfers of 0 values ​​will be reject.
  // Generates an AccountIdentifier based on the caller's Principal and
  // the provided SubAccount*, and then attempts to transfer amount from the
  // generated AccountIdentifier to recipient, and returns the outcome as TransferResponse.
  // recipient can be an AccountIdentitifer, a Principal (which then transfers to the default subaccount),
  // or a canister (where a callback is triggered).
  // calldata means transferAndCall
  transfer: (fromSubAccount:opt vec nat8,to: text, value: nat, calldata: opt CallData) -> (TransferResult);

  // Destroys `amount` tokens from `account`, reducing the total supply.
  burn: (fromSubAccount: opt vec nat8,amount: nat) -> (BurnResult);


  // Return if canister support interface, for example: supportedInterface("balanceOf:(text)->(nat)")
  // Implement [Dfinity Self Describing Standard](https://github.com/Deland-Labs/dfinity-self-describing-standard)
  supportedInterface : (text) -> (bool) query;
}
```
[Here is a rust-based implementation example](https://github.com/Deland-Labs/dfinity-fungible-token-standard)

-------------------------

witter | 2021-08-12 00:19:57 UTC | #68

[quote="ililic, post:65, topic:4694"]
Atomicity
[/quote]

**Thinking about atomicity**：
Atomicity is a very important matter, but in the traditional distributed development environment, there are two solutions:
1. Distributed transaction, similar to 2-phase commit (or 3-phase commit)
2. [sagas](https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf)

Distributed transactions require each participant to support 2-phase commit, but sagas does not have such a requirement. Based on this situation, saga can reduce the complexity of a single canister implementer and complete the consistency requirements independently of a single canister.

So I think sagas is a better consistency solution

-------------------------

witter | 2021-08-12 00:19:41 UTC | #69

[quote="witter, post:67, topic:4694"]
`Fee`
[/quote]

**Why is fee designed like this?** 
```
type Fee = record { lowest: nat; rate :nat32 };
```
Dfinity should consider the cost of DDOS attacks. The cost design does not appear in the ERC20 standard, but Dfinity is necessary.
The cost design should first consider the minimum handling fee for each update operation to prevent ddos attacks, and some services may be charged according to the rate. The two cost logics are integrated into [lowest + rate] to support different scenarios.

1. Only minimum charge is required x
    fee= record {lowest: x, rate:0}

2. Charged at rate y%, minimum charge x
    fee= record {lowest: x, rate:y%}

-------------------------

witter | 2021-08-12 00:19:32 UTC | #70

**Why do we need approve?**

Approve can improve the possibility of repeated payments. In most payment scenarios, post-payment operations, such as shopping, will be followed by order processing, such as transactions, and there will be exchange operations. In these scenarios, approve is better than transfer:

Approve can actually charge through transferFrom when the next specific operation is performed, but transfer must complete the transfer before the next operation. If the user has multiple transfers, it may lead to repeated payments. Approve x can only transfer x, which can be eliminated Repeat payment.

At the same time, based on approve, many innovations were born, such as [superfluid](https://www.superfluid.finance/home) . Dfinity needs the approve interface to open the window to accept innovations from Ethereum

-------------------------

ccyanxyz | 2021-08-12 03:43:23 UTC | #71

We have made some effort to implement some [token canister templates](https://github.com/dfinance-tech/ic-token).
About 3, currently we have implemented built-in tx storage and separate canister tx storage, ultimately I think we need an auto-scale storage solution for tx history storage.

About 4, fee logic is indeed needed, pay a fixed amount of token for each update call is reasonable.

About 5, I think you mean account id and principal id, here is a picture explains the different, principal id is the unique and native identity on the ic, we choose to use principal in the implementation.
![public-key-principal-account|690x202](upload://akVkiCs40CgJsiCqcGmGmJewUtH.png)

About 6, I think `aaaaa-aa` can be used as the blackhole address, its the ic-management canister id, not an actual canister, just an abstraction of some system level APIs.

-------------------------

witter | 2021-08-12 23:25:31 UTC | #72

thanks for your feedback. @ccyanxyz 
When I designed this token standard, your code was one of my reference codes, thank you for you and your team's work.

About3, I agree with you about auto-scale storage, I choose sudograph as separate canister tx storage（sudograph can provide richer query support, thanks for the work of the sudograph team @lastmjs .

> we need an auto-scale storage solution for tx history storage

Yes, fixed fee can meet the needs of most tokens. 
A common fee model is a fixed fee or rate.
type Fee = record {lowest: nat; rate :nat32 };
Can take care of the above two types of needs.

>About 4, fee logic is indeed needed, pay a fixed amount of token for each update call is reasonable.

Yes, I mean account id and principal id. Before designing the token standard, I saw this picture.
 I don’t know which is the best, and nobody can give a perfect answer, so compatible with both  may be a better choice .

> About5 ,I think you mean account id and principal id

Yes,I have considered this address, but can official developers call this address to perform operations? I did not find a clear answer, so I gave up this choice. Burn has a similar implementation in ERC20, which is a good choice.
> About 6, I think `aaaaa-aa` can be used as the blackhole address, its the ic-management canister id, not an actual canister, just an abstraction of some system level APIs.

-------------------------

ccyanxyz | 2021-08-15 17:32:19 UTC | #73

Just added a token canister template with auto-scale history transaction storage, haven't been thoroughly tested yet, just for reference: https://github.com/dfinance-tech/ic-token/tree/main/motoko/auto-scale-storage, welcome feedback.

-------------------------

wxw1198 | 2021-08-18 08:17:20 UTC | #74

For example, in a scenario, my canisters call the token function: transferfrom(); At this point, my canisters are abnormal. How do I know if my call is successful? Therefore, the standard should provide the ID corresponding to the transaction before sending a transfer。
 use transaction ID, we can query the transaction details afterwards. In addition, it is necessary to provide a transaction (index: nat64): record query interface and a current index (nonce similar to ETH) index (CID: Principal): nat64 query interface;

-------------------------

witter | 2021-08-19 06:27:06 UTC | #75


First of all, dfinity is not eth, which means that your experience in eth cannot be 100% copied to dfinity.

Please learn about the atomicity of dfinity from [here](https://forum.dfinity.org/t/thoughts-on-the-token-standard/4694/65#atomicity-6)

Secondly, Canister’s current largest storage is 4G, so the production environment should store transaction history separately.  [Token Standard implemented by Deland](https://github.com/Deland-Labs/dfinity-fungible-token-standard) implement  separate storage as default:

I try to understand your question:
Scenario: You call transferFrom in your own canister. After calling transferFrom, you deliberately set a trap to make your canister call fail
Question: I can't confirm whether what you want to know is whether the transferFrom call was successful, or whether your own canister method was successfully called?
My answer is:
Once you call transferFrom and the returned result contains TransactionID, it means that your call was successful. If it is unsuccessful, an error message will be returned.

Even if there are exceptions in the execution of other logic of your canister, transferFrom will not be rolled back because of these exceptions, that is, in this case, transferFrom is still successful.

If you want to obtain whether the transferFrom is successful, or want to obtain the details of the transferFrom transaction in the future, you can obtain it in the following way [in the Token Standard implemented by Deland](https://github.com/Deland-Labs/dfinity-fungible-token-standard):

1. Get Token's external storage canister Id: tokenGraphql: () -> (principal) query;

2. Get your tx details through sudograph query: "graphql_query": (text, text) -> (text) query;

for example: dfx canister call graphql  graphql_query '("query { readTx(search:{ txid:{eq:\"your transcation id\"} }) { id,txid,txtype,from,to,value,fee,timestamp} }", "{}")'

-------------------------

witter | 2021-08-19 04:02:23 UTC | #76

Why choose sudograph as separate canister tx storage?

Sudograph can provide richer query support.

You can learn more from [Sudograph book](https://i67uk-hiaaa-aaaae-qaaka-cai.raw.ic0.app)

-------------------------

wxw1198 | 2021-08-19 07:36:13 UTC | #77


let result = await canister.transferFrom(from, to, amount);
let b = 100/0; or other exception occurs here.....I'll never get  transaction ID.

Whether a function should be provided, hashID:(from, to, amount) --> txid; This txid is equal to the ID returned by transferfrom().

The above code should be written as follows：

let txID = hashID(from, to, amount);
writeToRecord(txID); //record transaction id
let result  : Bool = await canister.transferFrom(from, to, amount);
let b = 100/0; exception occurs here,but I got txID。
Then through the query interface, I can determine whether my transaction is successful

-------------------------

witter | 2021-08-19 09:10:03 UTC | #78

As far as I know, the answer is no. 
>Whether a function should be provided, hashID:(from, to, amount) → txid; This txid is equal to the ID returned by transferfrom().

You can do it like this:
```Rust
let transferResult =canister.transferFrom(from, to, amount). await;
match transferResult {
   TransferResult::Ok(txid, inner_errors_opt) => {writeToRecord(txid); },
   _=>{}
};
let b = 100/0;  // exception occurs here,but you can got txID。
```

> The above code should be written as follows：
let txID = hashID(from, to, amount);
writeToRecord(txID); //record transaction id
let result : Bool = await canister.transferFrom(from, to, amount);
let b = 100/0; exception occurs here,but I got txID。
Then through the query interface, I can determine whether my transaction is successful

-------------------------

wxw1198 | 2021-08-19 10:49:36 UTC | #79

let b = 100/0;Just think of an example， What I want to express is: will my own canisters suddenly break the link with other canister or the cycle is suddenly stopped due to lack of cycles. if so ，the following code has no chance to be executed
match transferResult {
   TransferResult::Ok(txid, inner_errors_opt) => {writeToRecord(txid); },
   _=>{}
};

-------------------------

ililic | 2021-08-19 15:03:30 UTC | #80

[quote="witter, post:67, topic:4694"]
```
  // Return all of the extend data of a token.
  // Extend data show more information about the token
  // supported keys:
  // OFFICIAL_SITE
  // MEDIUM
  // OFFICIAL_EMAIL
  // DESCRIPTION
  // BLOG
  // REDDIT
  // SLACK
  // FACEBOOK
  // TWITTER
  // GITHUB
  // TEGEGRAM
  // WECHAT
  // LINKEDIN
  // DISCORD
  // WHITE_PAPER
```
[/quote]

Let's replace these Web2 social platforms with IC Native equivalents:

```
  // Return all of the extend data of a token.
  // Extend data show more information about the token
  // supported keys:
  // OFFICIAL_SITE
  // OFFICIAL_EMAIL
  // DESCRIPTION
  // BLOG
  // DSCVR
  // OPENCHAT
  // DISTRIKT
  // WEACT
  // NUANCE
  // ETC…
  // GITHUB
  // DISCORD
  // WHITE_PAPER
```

-------------------------

witter | 2021-08-20 00:30:56 UTC | #81

[quote="ililic, post:80, topic:4694"]
Let’s replace these Web2 social platforms with IC Native equivalents
[/quote]

Good idea, thanks for your suggestion.
I will add the IC Native equivalent.

-------------------------

witter | 2021-08-20 06:56:52 UTC | #82

[quote="ililic, post:80, topic:4694"]
`WEACT`
[/quote]
We have added DSCVR, OPENCHAT, DISTRIKT, WEACT to the list of keys supported by extend info. 

[Improve: add IC native social media(DSCVR,OPENCHAT,DISTRIKT,WEACT)](https://github.com/Deland-Labs/dfinity-fungible-token-standard/commit/da91d5623b6aa8ca1ce406935f205a07c03f7f1b)

But I didn't find any information about NUANCE, so I haven't added it yet. If I find information about NUANCE, I would like to add NUANCE to the list， and any PRs are welcome.

Thanks @ililic  for the suggestion again.

The token standard is an important basic standard in the dfinity ecosystem. The establishment of a complete standard requires everyone to participate. Anyone is welcome to comment and submit a PR

-------------------------

witter | 2021-08-22 09:12:15 UTC | #83

The motoko implementation has been completed, but the call of approve and transfer has not been implemented for [this reason](https://forum.dfinity.org/t/is-there-a-method-similar-to-ic-cdks-api-call-canisterid-method-args-in-motoko/6578).

https://github.com/Deland-Labs/dfinity-fungible-token-standard/blob/e5c50a45f8b329171a97865ea167290dc3013da1/canisters/dft_motoko/main.mo#L450

**how to test Motoko implementation?**

git clone from [here](https://github.com/Deland-Labs/dfinity-fungible-token-standard)  , then run 
```
make test_motoko
```

-------------------------

senior.joinu | 2021-08-24 11:57:46 UTC | #84

Hey everyone! Consider checking out https://forum.dfinity.org/t/non-fungible-token-nft-standard-community-consideration/6157 this thread if you're interested in some new ideas around token standards.

-------------------------

witter | 2021-09-08 13:56:46 UTC | #85

DeLand Labs [DFT](https://github.com/Deland-Labs/dfinity-fungible-token-standard) latest update：
  1. Dropped [Dfinity Self Describing Standard](https://github.com/Deland-Labs/dfinity-self-describing-standard)

  Motoko canister support default method `__get_candid_interface_tmp_hack` to get did, if rust canister implement this method ,Developer can check canister's interface through `__get_candid_interface_tmp_hack` .

```
candid::export_service!();

#[query(name = "__get_candid_interface_tmp_hack")]
#[candid_method(query, rename = "__get_candid_interface_tmp_hack")]
fn __export_did_tmp_() -> String {
    __export_service()
} 
```
2. Rust implementation has removed` supportedInterface(text) -> (bool)`

Deland Labs will continue to improve DFT.Come on with us to improve it,**any comments, PR are welcome.**

-------------------------

witter | 2021-10-07 10:23:01 UTC | #86

Updates summary:
 - make transaction id unique
 - [add support for DFT transaction history auto-scaling storage](https://forum.dfinity.org/t/fungible-token-standard-community-consideration/6158/11?u=witter)
 - add more useful interface to standard, such as 
```

  owner : () -> (principal);
  setOwner : (principal) -> (bool);
  setExtend : (vec KeyValuePair) -> (bool);
  setFee : (Fee) -> (bool);
  setFeeTo : (text) -> (bool);
  setLogo : (vec nat8) -> (bool);

  allowancesByHolder : (text) -> (vec record { TokenHolder; nat }) query;
  tokenInfo : () -> (TokenInfo) query;

  lastTransactions : (nat64) -> (TxRecordsResult) query;
  transactionById : (text) -> (TxRecordResult) query;
  transactionByIndex : (nat) -> (TxRecordResult) query;
```

The repository is [here](https://github.com/Deland-Labs/dfinity-fungible-token-standard) ,  Leave your comments & advices to make it better , and **any PR are welcome.**.

-------------------------

witter | 2021-10-08 13:13:05 UTC | #87

Updates summary:
- add burnable & mint extension , and example code
- refactor code

## How to use rust to create a fungible token with 1 line of code?
check it out at [here](https://github.com/Deland-Labs/dfinity-fungible-token-standard/blob/86a87b7631c9c075bf02399d75e74de319b8d99d/rust/dft_basic/src/lib.rs#L7)

-------------------------

jzxchiang | 2021-10-27 05:30:59 UTC | #88

> Oh and if you’re planning to deploy a token right now, use Rust. Currently the motoko GC has real problems running lots of small update calls on big heaps which is exactly the kind of workloads that tokens have.

Is this still a problem with Motoko? I wonder if any of the recent updates have fixed this.

-------------------------

jzxchiang | 2021-10-28 07:36:26 UTC | #89

I just went through the entire thread. Here's a (somewhat) condensed summary...

-----

Ethereum and IC are different. Platform differences may require different token standards.

1. **Ethereum cross-contract transactions are atomic. IC cross-canister updates are not.**

This matters if you want the token canister to be able to "notify" other canisters, which is pretty important. Notifications can be implemented with pre-defined callbacks or hooks (see ERC-677 and ERC-777), or with a pub/sub pattern where interested canisters can subscribe to the token canister. Either way, one canister is calling another, which is not atomic in IC. Developers will need to implement two-phase commit or sagas if they want cross-canister atomicity.

2. **Ethereum transaction history is stored and publicly available, both in the event log and in the blocks themselves. Neither is stored in IC.**

IC token canisters will need to keep track of transaction history themselves. This can be in the token canister itself or in separate canisters. But at some point the 8 GB canister storage limit will be reached, meaning a multi-canister solution is probably necessary. For example, the ICP ledger canister maintains a bunch of dynamically created archive canisters.

3. **Ethereum smart contracts are immutable. IC canisters are upgradable by default (but can be made immutable).**

Upgradability is both a blessing and a curse. It's good because a token canister could be upgraded to support future extensions, e.g. minting, burning, batching, etc. It's because because malicious controllers can "rug pull". Either way, source code verifiability is needed. Etherscan provides this in Ethereum, but no service like this currently exists in IC.

4. **Ethereum transactions are "pay-as-you-go". IC updates are paid for with pre-funded cycles.**

How will token canisters be funded? The reverse gas model gives us flexibility here. We can require fees on every update, like in Ethereum, or we can requires fees on only some. We can charge the sender, or we can charge the receiver. There are plenty of possibilities, and they each have different implications on how various payment flows could work with a IC token canister.

5. **Ethereum transactions are run serially (i.e the EVM is "single-threaded"). IC updates can be run in parallel.**

Canisters running in different subnets are effectively running on different blockchains. I'm not too clear on what this means for a token standard. @senior.joinu describes an interesting scenario where this may cause problems when multiple assets are managed by different canisters, each of which makes progress independently.

-----

I'm still trying to better understand the tradeoffs between the different ways for a user to authorize a canister to make transactions on their behalf, e.g. using ERC-20 style `approve` and `transferFrom` or pub/sub. I'll summarize my findings later this week...

-------------------------

jzxchiang | 2021-10-28 07:15:52 UTC | #90

Personally, I think having a great token standard is super important and becoming a more urgent need, especially as the SNS design becomes finalized and as an increasing number of dapps (including ours) look to add token functionality in the near future.

-------------------------

witter | 2021-10-29 04:22:34 UTC | #91

Agree.
More meaningful discussions will help improve the token standard

-------------------------

jzxchiang | 2021-10-29 05:06:13 UTC | #92

Really fascinating read, thanks for writing this.

> In other words, you could simply fool such a system, `approving` money, sending an application and then quickly `disapproving` them back - there is a chance for you to spot the exact moment when the middle-man canister did already checked their `allowance` of your payment, but did not yet `transferedFrom` it.

I don't think this is correct. Standard `transferFrom` implementations [check](https://github.com/ConsenSys/Tokens/blob/bbfa5b3544f19b2464efb05fa3179db4543816f1/contracts/eip20/EIP20.sol#L49) that the allowance is sufficient before modifying any balances. If the check fails, the `transferFrom` call will trap, and the middle-man canister will throw before actually transferring the train and concert tickets to the user.

-------------------------

jzxchiang | 2021-10-30 07:20:34 UTC | #93

The more I think about this, the more difficult I see the problem of atomic cross-canister transactions. (Sorry, this will be a long post.)

-----

Some background...

A common use case of tokens is for a user to spend some tokens to perform some action on the blockchain. For example, a user wants to spend 20 LINK to convert it to BAT on some DEX. This entire flow should be treated as a transaction.

There are 3 parties involved:

* Spender (either user or canister)
* Token canister
* Receiver canister (e.g. the DEX canister in the above example)

Let's abbreviate these parties as S, T, and R, respectively.

S always initiates the transaction, since they own the tokens. So S -> T is the first step. The question is what happens next?

In [ERC-20](https://github.com/ethereum/eips/issues/20), the flow is S -> T (`approve`), S -> R (`startAction`, e.g.), and R -> T (`transferFrom`).
In [ERC-667](https://github.com/ethereum/EIPs/issues/677), the flow is S -> T (`transferAndCall`) and T -> R (`onTokenTransfer`).

Notice that the caller-callee relationship for T and R is inverted in ERC-667 versus ERC-20. The benefit of ERC-667 over ERC-20 is one transaction for the spender instead of two, which means lower gas fees (on Ethereum) and a simpler UX. The drawback is that reentrancy may be an issue if implemented incorrectly.

@senior.joinu's proposal to use pub/sub is an extension of the ERC-667 flow, where T calls multiple Rs and not just the receiver of the spent tokens. Generally speaking, it inherits the same properties as the simpler ERC-667 flow, so I don't talk about it here.

-----

So I tried porting over the `transferAndCall` function from ERC-667 onto IC in Motoko. Since updates that call other canisters are not atomic, I added a rollback in the event of a callback failure.

This is what it looks like:

```
actor Token {

    private stable var balances: Trie.Trie<Principal, Nat> = Trie.empty();

    private func _key(p: Principal) : Trie.Key<Principal> { { key = p; hash = Principal.hash(p) } };
    
    private func _getBalance(p: Principal): Nat {
        let balance = Trie.find(balances, _key(p), Principal.equal);
        switch (balance) {
            case (null) { 0 };
            case (?balance) { balance };
        };
    };

    private func _setBalance(p: Principal, value: Nat): () {
        balances := Trie.put(balances, _key(p), Principal.equal, value).0;
    };

    public shared(msg) func transferAndCall(to: Principal, value: Nat): async () {
        let fromBalance = _getBalance(msg.caller);
        let toBalance = _getBalance(to);

        assert fromBalance >= value;

        _setBalance(msg.caller, fromBalance - value);
        _setBalance(to, toBalance + value);

        // Skip this entire try block if `to` is a user principal and not a canister principal.
        // There may be no good way to determine that...
        try {
             let toActor = actor Principal.toText(to): actor {
                 onTokenTransfer: (from: Principal, value: Nat) -> async ()
             };
             await toActor.onTokenTransfer(msg.caller, value);
        } catch (err) {
            // Rollback in the event of callback error
            _setBalance(msg.caller, fromBalance);
            _setBalance(to, toBalance);

            // Can't assert (i.e. trap) instead of throw, otherwise rollback would be reverted
            throw Error.reject("transferAndCall failed");
        };
    };
};
```

In the distributed transactions world, I think this would be an example of the [saga](https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/saga/saga) pattern, with the rollback called a "compensating transaction".

Here's the problem...

**Isolation is poor.**

For example, let's say `transferAndCall` has updated the balances and is currently `await`-ing on the `onTokenTransfer` callback to complete. In the meantime, either the spender or the receiver queries their balance. Then, `onTokenTransfer` failed and the balances are reverted. The data queried is no longer accurate. This is a dirty read.

Even worse, someone could have tried making illegal transfers during that `await`-ing time, e.g. spending tokens they have at the time but won't after `onTokenTransfer` eventually fails. But if they would've had enough tokens either way (had `onTokenTransfer` failed or succeeded), then their transfer would be reverted by the rollback, leading to a lost update.

How can we solve this?

1. We could move the `onTokenTransfer` call to before we update the balances but after we assert. That way, we don't need to roll anything back, because the balance updating code can't fail and it's also the last thing that happens. The problem is: what if `onTokenTransfer` actually needs to do something with those tokens, e.g. a DEX canister wants to swap those tokens for another type of token? Those tokens wouldn't exist if we made the call before updating the balances.
2. Alternatively, we could keep the current order, but keep tracking of "pending balances" in addition to the actual balances. Initially, we update the pending balances, and then we call `onTokenTransfer`. If that call succeeds, we "finalize" the pending balances by updating the actual balances. If that call fails, we revert the pending balances. This way, dirty reads don't happen because they never see the pending balances, only the actual balances. Lost updates can be prevented by not proceeding if a pending transfer is in progress (not clear on the details here). This general approach is called semantic locking. The issue is that a) locking isn't great, and b) the same issue as above, where the `onTokenTransfer` function wants to do something with its newly received tokens but can't because they are still "pending" and not "finalized" here.

-----

Not really sure what to conclude from all of this...

Am I overcomplicating things? Does an ERC-20 flow with `approve` and `transferFrom` avoid some of these problems with an ERC-667 flow? I'd be really interested to hear what others think.

-------------------------

witter | 2021-10-30 12:29:23 UTC | #94

Hi @jzxchiang,Let me try to understand your concerns:

**transferAndCall** contains two non-atomic operations, you give a way like saga, great, this is the solution I recommend.

 But I think that transfer and call do not need to pursue strong consistency. Transfer is verified by the logic inside the token. Before the call occurs, it will be determined whether the transfer can be successful, but the call should be allowed to fail. Use the call as an alternative pub/sub trigger mechanism or notification mechanism will be great.

Let us think about the application scenario of call in **transferAndCall**:
If the call fails due to a bug, it will be fixed, so ignore this scenario
If the call fails after a successful transfer, the receiver canister (such as the DEX in your example), how to deal with the amount of the transfer should be a matter for the DEX to consider, such as transferring it back to the user or recording a user balance.
Saga should not have a rollback in the strict sense, but different processing branches (such as the above step: successful transaction or transfer back to the user), and the subsequent processing steps belong to the canister of DEX. Token should not consider how to intervene in the subsequent processing steps, you know , the caniter of the subsequent processing can be DEX or other, and their processing steps will be different.

You mentioned the problem of reentrancy. Another option is to use **approveAndCall**, which is similar to the usage of ERC20's approve/transferFrom. In the DEX usage scenario you gave, after approve, the DEX can call transferFrom to get the token when processing the transaction, which can avoid the reentrance problem.

What I mentioned above has been implemented in Deland Labs' fungible token standard, just have a look at [here](https://github.com/Deland-Labs/dfinity-fungible-token-standard)

And the document will be released next week, I will send you a link to the document in a few days.

[quote="jzxchiang, post:93, topic:4694"]
Am I overcomplicating things? Does an ERC-20 flow with `approve` and `transferFrom` avoid some of these problems with an ERC-667 flow? I’d be really interested to hear what others think.
[/quote]

-------------------------

senior.joinu | 2021-10-30 12:17:54 UTC | #95

I believe, this is not a problem at all.

The reason for that is "the island mindset" - once you have that, everything seems reasonable.

If you want to make your action atomic, you should perform it by a single canister. In a DEX workflow this would mean to use DEX canister as a trusted intermediary. Just like Binance asks you to deposit your tokens before you start trading, this DEX canister would do the same maintaining internal balance list.
Once your tokens are there, you can safely exchange them. Once you're done - you withdraw them, transforming them back to a real tokens on a separate canister.

-------------------------

jzxchiang | 2021-10-30 19:07:33 UTC | #96

> If the call fails after a successful transfer, the receiver canister (such as the DEX in your example), how to deal with the amount of the transfer should be a matter for the DEX to consider, such as transferring it back to the user or recording a user balance.

> Saga should not have a rollback in the strict sense, but different processing branches (such as the above step: successful transaction or transfer back to the user), and the subsequent processing steps belong to the canister of DEX.

I'm not sure this is true.

If a user wants to pay for a service, they want to make sure that the service is successfully executed if their tokens are transferred. In other words, the token transfer and the service execution should happen in an atomic transaction.

Trusting the canister executing the service (e.g. DEX canister) to refund the tokens in the event of failure doesn't seem safe, especially in IC where canisters aren't necessarily autonomous.

-------------------------

jzxchiang | 2021-10-30 19:13:50 UTC | #97

> If you want to make your action atomic, you should perform it by a single canister. In a DEX workflow this would mean to use DEX canister as a trusted intermediary.

I'm not sure I follow. In my mind, there's a single "canonical" token canister that keeps track of everyone's balances. How would you deposit tokens to a DEX canister without interacting with the token canister? The internal balances kept by the DEX canister would need to be kept in sync with the canonical token canister anyways. Would this syncing be done in some cronjob? If so, can't it go out of sync, leading to bad situations?

In the future, there will be a wide variety of canisters that depend on the token canister. Some will be autonomous (i.e. a smart contract), others will not. The "island mindset" you describe may be feasible if we assume all depending canisters are autonomous, but the "trusted intermediary" assumption breaks down if that's not true.

-------------------------

senior.joinu | 2021-10-31 00:24:23 UTC | #98

Hmm...
Sorry if I didn't make clear what I mean.

The DEX canister has a principal. One could transfer their tokens to that principal (same way they do for any other person). The DEX could listen for the event emitted by this transfer and account these tokens as a tokens deposited to the DEX by the sender.

Withdraw is the same but backwards - DEX canister transfers tokens to the reciever.

-------------------------

jzxchiang | 2021-10-31 01:33:15 UTC | #99

Yes, but that publish call from token canister to DEX canister should be atomic with the token canister balance updates, which is the same problem I described earlier.

-------------------------

witter | 2021-11-02 01:22:36 UTC | #100

The document: https://dft.delandlabs.com/

-------------------------

senior.joinu | 2021-11-02 12:15:26 UTC | #101

Let me try to reproduce this scenario once again.
Let's imagine, we have:
* Users `A` and `B`
* Token canisters `T1` and `T2`;
  * both tokens have the exact same `transferAndNotify()` mechanics - `transfer` part is performed inside the token canister itself (balances modification) and `notify` part is just a call to another canister;
  * user `A` has some amount of `T1` tokens, user `B` - some amount of `T2`;
  * let's imagine that the exchange rate `T1`:`T2` = `1:1`;
* The `DEX` canister;
  * this canister holds an internal list of balances for each token canister `T1`, `T2`;
  * these internal balances are made only of tokens `transferAndNotify`-ed to `DEX` canister's principal.

Let's imagine the flow now:
1. Both users want to swap their tokens (`A` wants to swap their `T1` for `T2` and vice versa - `B` wants `T2` -> `T1`).
2. They both go to the `DEX`'s frontend and see the `Deposit tokens` button.
3. They select the tokens they want to deposit (`A` goes with `T1`, `B` - with `T2`).
3. They both click on that button and enter the amount they wan't to deposit - `100` tokens each.
4. Once user `A` clicks on that button, the frontend sends a request to canister `T1` - "please `transferAndNotify()` the `DEX` canister 100 tokens".
5. Token canister `T1` subs `100` tokens from the balance of user `A` and adds them to the balance of the `DEX` canister. __(atomic)__
6. Token canister then notifies the `DEX` canister, sending it an inter-canister call: "hey, this principal just transferred some tokens of this token canister (`T1`) to your principal". __(not atomic)__
7. `DEX` canister receives the notification and sets its internal balance of token `T1` of user `A` to `100` tokens. __(atomic)__
8. Steps 4-7 are the same for user `B` and token `T2`.
9. Now both users have "deposited" their tokens to the `DEX`.
10. _We don't care, how the actual swap is performed, but let's imagine it's an order book model._
11. User `A` clicks the button `Create a sell order for token T1 (qty = 100)`.
12. `DEX` canister subs `100` `T1` tokens from the internal balance of user `A` and stores the order in its memory. __(atomic)__
13. User `B` clicks the button `Create a buy order for token T1 (qty = 100)`.
14. `DEX` canister calculates the exchange rate (`1:1`) and subs `100` `T2` tokens for the internal balance of user `B`; then it matches this buy order with the sell order of user `A` and destroys these orders, adding `100 T2` tokens to user `A` and `100 T1` tokens to user `B` (to their internal balances); important. __(atomic)__
15. Both users click the "Withdraw" button (user `A` selects `T2` token, user `B` - `T1`).
16. `DEX` canister __clears their internal balances__ and sends an inter-canister call to token canisters - for user `A` in sends a call to the token `T2`, for user `B` - to the token `T1`.
17. This is the same `transferAndNotify()` call as it was at the beginning, but in reverse - `DEX` canister sends its real tokens back. __(not atomic)__
18. Token `T1` subs 100 tokens from `DEX` balance and adds them to user `B`'s balance. __(atomic)__
19. Token `T2` subs 100 tokens from `DEX` balance and adds them to user `A`'s balance. __(atomic)__
20. The swap is performed, we're arrived at the desired state.

Yes, there are non-atomic actions. But you __can__ imagine a process when they do no affect the security at all. The only thing left is to make sure, that if any inter-canister call fails (due to an error, or a network issue) - state changes are reverted.

-------------------------


lastmjs | 2022-09-01 17:02:32 UTC | #206

Another problem though is that we don't have that many independent node operators. To achieve sufficient levels of decentralization through shuffling, I would think we need many more node operators first.

-------------------------

LightningLad91 | 2022-09-01 17:44:01 UTC | #207

[quote="lastmjs, post:202, topic:6152"]
But when are we going to address the static node operator collusion attack vector? It may be of the absolute utmost importance compared with everything else when you consider the consequences.
[/quote]

I share many of your concerns; but, all node provider identities are public knowledge and I wonder if this offers some protection. I don't think it would be too difficult to identify the guilty parties and initiate some legal action against them. In fact, it seems like a pretty significant deterrence.

That being said; I definitely support the message that we need to prioritize the on-boarding of independent node providers.

-------------------------

Sormarler | 2022-09-01 19:22:38 UTC | #208

Unique node ownership is probably even more important in the short term. The NNS should prioritize unique independent providers for the next batch of nodes coming to the internet computer. It doesn't matter if you will take the nodes if company LLC is still running them.

-------------------------

Zane | 2022-09-01 19:56:32 UTC | #209

I wonder how can the NNS make sure the providers are indipendent though. Dfinity probably knew the genesis providers and had a legal team review their request.

-------------------------

Sormarler | 2022-09-01 20:05:52 UTC | #210

KYC them and have them sign a contract if necessary. sorry

-------------------------

JaMarco | 2022-09-01 22:15:10 UTC | #211

[quote="Zane, post:209, topic:6152, full:true"]
I wonder how can the NNS make sure the providers are indipendent though. Dfinity probably knew the genesis providers and had a legal team review their request.
[/quote]

I feel like IC should just do whatever Chainlink does since everyone trusts their providers.

-------------------------

JaMarco | 2022-09-01 23:46:24 UTC | #212

[quote="lastmjs, post:202, topic:6152"]
tECDSA has worse BFT properties than ICC, only 1/3 of node operators (secret key share holders) are necessary to collude to create a threshold signature.
[/quote]

I would also like to know more why low tECDSA was deemed secure enough and the security features of ICs implementation. 

In the tECDSA CC, Victor Shoup talks about proactive security of the threshold shares being reshared/refreshed frequently, is that currently part of the protocol?
https://www.youtube.com/watch?v=MulbKPwv6_s&t=446s
https://www.youtube.com/watch?v=MulbKPwv6_s&t=791s
https://www.youtube.com/watch?v=MulbKPwv6_s&t=2098s


He also states that high threshold security isn't necessary for ICs protocol and low threshold ECDSA is good enough. I'd like to know more and why that is the case.
https://www.youtube.com/watch?v=MulbKPwv6_s&t=1239s
https://www.youtube.com/watch?v=MulbKPwv6_s&t=2041s
https://www.youtube.com/watch?v=MulbKPwv6_s&t=3069s

-------------------------

LightningLad91 | 2022-09-02 00:53:52 UTC | #213

[quote="JaMarco, post:212, topic:6152"]
In the tECDSA CC, Victor Shoup talks about proactive security of the threshold shares being reshared/refreshed frequently, is that currently part of the protocol?
[/quote]

I asked about this on Twitter and @Manu replied saying that they are only reshared when subnet membership changes. https://twitter.com/manudrijvers/status/1563152150816911362?s=21&t=pGOnr4aqkIFS-QIDw8rKjA

-------------------------

timo | 2022-09-02 08:08:17 UTC | #214

Node shuffling reduces one attack vector but opens another. I would look at it very carefully before jumping to it. With node shuffling new (malicious) node providers could sign up with the sole intention of hoping that they get shuffled on the Bitcoin subnet someday. If you shuffle often enough they might succeed. 

Can you elaborate on the particular scenario that you are worried about? How would the breach unfold? I mean who and at what time decides to collude or gets compromised? I am trying to understand if node shuffling would really help.

To provide some numbers for comparison:
- Three Bitcoin mining pools together have >50% and can perform a large-scale double-spend (not steal)
- Bitcoin's Liquid sidechain requires 11 signers from a static set of known entities. The threshold is better, it is 11 out of 15, but the absolute number isn't.

-------------------------

victorshoup | 2022-09-03 00:08:50 UTC | #215

We already had an extensive conversation on node shuffling: https://forum.dfinity.org/t/shuffling-node-memberships-of-subnets-an-exploratory-conversation/7478

-------------------------

skilesare | 2022-09-03 19:30:36 UTC | #216

One question that would be interesting to explore is to figure out how much the tecdsa signers know what address they are signing for.  For them to conspire to target a specific address they would need to know they are one of the signers of that address. Is that info they know?

I think the concern is that if there is a t-ecdsa account with $200m of btc sitting in it then it becomes awfully attractive to node providers to attempt to sign to spend it. There isn’t much evidence of what happened either…it just looks like a btc transaction. Knowing what it would look like on the IC and what would be necessary to pull it off might help everyone understand the actual risk.

-------------------------

Forreal | 2022-09-03 23:17:10 UTC | #217

Why can't a sub-account request to sign transactions associated with its BTC, so that when the private key is reconstructed, it can only sign transactions for the account that triggered it?

-------------------------

dieter.sommer | 2022-09-09 14:45:53 UTC | #218

[quote="skilesare, post:216, topic:6152"]
One question that would be interesting to explore is to figure out how much the tecdsa signers know what address they are signing for. For them to conspire to target a specific address they would need to know they are one of the signers of that address. Is that info they know?
[/quote]

The t-ECDSA signers know the canister principal id of the canister that requests the signature and the derivation path. Both those together determine the ECDSA key they are signing for.

-------------------------

integral_wizard | 2022-09-19 16:52:40 UTC | #219

The way you phrased I think could bring it home for most. That would be alien tech, true decentralization, yet act as one computer. 
[quote="lastmjs, post:203, topic:6152"]
The obvious solution in my mind is truly weaving the node operators and canisters into one giant logical computer, by making subnet node and maybe even canister membership ephemeral and random. At any time node operators could shuffle and perhaps even canisters, so that subnet membership is not static.
[/quote]

-------------------------

gatsby_esp | 2022-09-19 19:29:37 UTC | #220

Do any of the problems stated mean that we are not going to have BTC integration released on mainnet this year?

-------------------------

Chloros88 | 2022-09-20 00:19:57 UTC | #221

Two more months. Just two more months.

-------------------------

dieter.sommer | 2022-09-21 20:02:33 UTC | #222

Dear community!

Since our most recent update, we have been spending substantial effort on improving the performance of the threshold ECDSA protocol: We could reach a throughput of around 0.5 signatures per second on a reasonably large subnet. The main focus of the team will soon shift towards security-related aspects such as addressing findings of a recent internal security review we have performed.

-------------------------

Zane | 2022-09-21 20:27:43 UTC | #223

[quote="dieter.sommer, post:222, topic:6152"]
We could reach a throughput of around 0.5 signatures per second on a reasonably large subnet
[/quote]

Is there still room for improvement with future optimizations? What do you consider as "reasonably large"?

-------------------------

JaMarco | 2022-09-21 20:50:29 UTC | #224

Can multiple tECDSA subnets be ran in parallel to increase the overall throughput? How would the IC load balance that?

-------------------------

Zane | 2022-09-21 20:57:57 UTC | #225

They can, I'm worried about tokenomics implications tho. A tECDSA subnet has to be as secure as possible, so high node count is a must, that means to for the IC to be deflationary the cycle cost per tx has to be at least expensive enough so that a subnet with 24/7 usage burns more cycles than it mints. But estimating real world usage is not easy and 100% utilization might be a pipedream, so cycle cost has to be higher which could make it less appealing to devs.

-------------------------

victorshoup | 2022-09-21 21:45:33 UTC | #226

We have in fact done an initial analysis of the tokenomics and we feel that this will not be a major problem. Based on the cost of paying node providers, we would have to charge on the order of a few cents per signature to not be inflationary.  Indeed, if we assume a throughput of 1 sig/sec, 35 nodes in a dedicated signing subnet, and $2000 per month per node, we would need to charge about 3 cents per sig to break even.  This is generally in line with what we initially plan to charge. 

You are right that 100% utilization is not realistic. Assuming the IC and this feature really take off, we can fine tune things to aim for something realistic, like 25-30% utilization, and still have some spare capacity for surges.  Over time, we will fine tune the performance and price, as well as build out several signing subnets with load balancing ("horizontal scaling").  As long as everyone is on board with the idea that the price per sig is on the order of cents (rather than, say, hundredths of a cent), this all seems reasonable, at least to me.

-------------------------

skilesare | 2022-09-22 00:45:26 UTC | #227

It does eventually need to be cheap to sign these things. 3 cents sounds cheap until your a service provider signing hundreds of thousands of polygon transactions a day in a gasless model.

-------------------------

victorshoup | 2022-09-22 02:12:42 UTC | #228

Understood. But I don't think the economics of this can be changed much, so dapp developers will have to plan accordingly.

-------------------------

coteclaude | 2022-09-22 02:54:42 UTC | #229

[quote="victorshoup, post:226, topic:6152"]
Based on the cost of paying node providers, we would have to charge on the order of a few cents per signature to not be inflationary.
[/quote]

From what I can see, as of today and excluding all voting rewards, there was 2,777,790 ICP paid to nodes providers and total 92,279 ICP burned.  The the gap towards the providers is constantly increasing.  So I don't really understand the 'not to be inflationary' statement.  Am I missing something?  Should this be an actual issue to be resolved, if possible?  Any plans?

-------------------------

Zane | 2022-09-22 05:52:18 UTC | #230

Usage of the network is still not high enough to create deflation

-------------------------

coteclaude | 2022-09-22 06:32:46 UTC | #231

To my feel, the more you need computing, the more nodes you need, thus more inflation as well.  To be even, it would mean the network is only actually used at 3% (92279 / 2777790).  On top, we all know the usage cannot go to 100%.
But if the network is used at 3%, why adding more nodes now?
Would really be happy to see a plan, expectation from Dfinity on this?
Because for me, numbers don't work and will not work for deflation ever, very far from it. @Kyle_Langham is the expert at numbers but I haven't seen any study on this.
Show me evidence, if there are.
Really hope I am totally wrong but I cannot see how I can be.

-------------------------

victorshoup | 2022-09-22 14:05:38 UTC | #232

I only meant that the threshold ECDSA feature would not make inflation any worse, not that it would do anything by itself to make it any better (unless we charge huge fees for ECDSA sigs so that it would subsidize other costs)

-------------------------

mparikh | 2022-09-22 15:50:22 UTC | #233

Personally, I would like to see more fees for the ECSDA feature; simply because it is a market differentiator. Devs should pay more for such a feature. Or put it in the reverse-gas model context, devs should build dapps that use this feature in a novel enough way that it increases their user base. 

I don't think that we should use fees from ECSDA to "subsidize" other features.

-------------------------

Zane | 2022-09-22 16:22:17 UTC | #234

I disagree, it should be a cheap as possible as long as the tokenomics allow for deflation with realistic usage, this way devs can use it more easily and for more use cases bringing more dApps and users to the ecosystem, which in turn will cause more cycle usage.

-------------------------

Kyle_Langham | 2022-09-22 19:47:11 UTC | #235

Early node providers were paid significantly just after launch, I believe as a result of providing nodes prior to launch and as a reflection of the increased risk at that time.  Recently, the rewards paid to node providers has been much lower than last year.

I don't remember where I documented this a year ago (perhaps Twitter) but my memory is that if the network operated at 100% capacity it would result in a 7x-10x burn to mint ratio.

It's also possible that the NNS decides to charge more for computations in the future to increase the deflationary pressures.  I imagine that wouldn't be considered until there's more growth, however.

-------------------------

Zane | 2022-09-22 19:56:45 UTC | #236

I have 2 concerns:

- Subnets are quite small right now, so the 7-10x ratio isn't just optimistic cause it assumes 100% usage at all time but also the average subnet being made of 13 nodes.

- Subnets can currently handle 300GBs of state, that means at 5$ GB/yr it'd only take 1500$/yr to occupy a subnet and make it unavailable to anyone else, effectively wasting a subnet's capacity and making it inflationary. Has Dfinity thought about a similar scenario?

-------------------------

tsetse | 2022-09-23 03:18:49 UTC | #237

This calculates only storage, not computation, right?

-------------------------

Zane | 2022-09-23 05:35:38 UTC | #238

That's right, but there are no guarantees computation will be done on that data or at all. The space might be used for simple storage or as a mean to attack the IC. 

Currently we have 35~ subnets, so an attacker could spend 52,500$/yr (1500$ x n of subnets) and waste almost the entire computational capabilities of the IC, I say almost cause already existing dApps would still work but they might encounter some issues, e.g inability to spawn new canisters and on top of that make it impossible for the system to become deflationary.

-------------------------

dieter.sommer | 2022-09-23 06:49:30 UTC | #239

[quote="Zane, post:223, topic:6152"]
Is there still room for improvement with future optimizations? What do you consider as “reasonably large”?
[/quote]

I think there is, but it's getting harder and harder the more we have squeezed out performance of the protocol already already.
I don't have the exact size of the testnet that was used for this in my head, but if I recall correctly, it was rather close to 30 nodes, so smaller than the one we want to launch on, but not much.

[quote="JaMarco, post:224, topic:6152, full:true"]
Can multiple tECDSA subnets be ran in parallel to increase the overall throughput? How would the IC load balance that?
[/quote]

Yes, that's possible if there's demand. The feature can scale out horizontally by adding more signing subnets for the same key. The governance for all of this is already part of the initial design and the NNS proposals, but some parts, such as the deterministic load balancing, would still need to be implemented to make this work.
The idea of load balancing would be to determine, for each signing request, deterministically to which signing subnets to send the request to. All signing subnets would be listed in the registry.

-------------------------

hpeebles | 2022-09-23 13:01:51 UTC | #240

Can a single subnet only handle a single signing request at a time?
I'm not a cryptography expert but intuitively it seems like these requests should be able to run in parallel.

-------------------------

Zane | 2022-09-23 16:15:25 UTC | #241

[quote="dieter.sommer, post:239, topic:6152"]
I think there is, but it’s getting harder and harder the more we have squeezed out performance of the protocol already already.
[/quote]

What's the biggest bottleneck consesus or complexity of the cryptography involved? If the latter would it be possible in future to optimize by running specific hardware for ECDSA subnets?

Also considering performance degrades with node count, has Dfinity considered implementing a system similar to the one described in the original whitepaper and have only a subset of nodes chosen via VRF each block to reach consensus?

-------------------------

hokosugi | 2022-10-16 23:56:51 UTC | #242

I have a question that I have been thinking about for a while after reading the statement in the wiki about the "vast number of derivable ECDSA keys."
Can T-ECDSA signatures support multiple private keys? For example, can multiple child private keys(BIP32 should be able to generate) generated in addition to the master key also be managed in the ECDSA subnet, so that private keys can be assigned and signed on a per-Canister basis? Or is there only one master private key?
If you are not familiar with cryptography and the question is off-topic, please feel free to skip it.
![ScShot 2022-10-17 8.40.24|690x418](upload://nGqna8ZPAaqR5HtUnZozzk601ld.png)

-------------------------

diegop | 2022-10-17 21:47:29 UTC | #243

Hey folks,

Here is a relevant security audits for those interested: 

1. https://forum.dfinity.org/t/threshold-ecdsa-integration-and-bitcoin-canisters-security-review-by-trail-of-bits-third-party-security-audit-5/15952

2. https://forum.dfinity.org/t/canister-sandbox-review-by-trail-of-bits-third-party-security-audit-4/15951

-------------------------

Manu | 2022-10-19 08:31:07 UTC | #244

A subnet maintains a single secret ECDSA key, and we can actually use that to derive keys many keys per canister (using BIP32). This means that we only have to maintain one secret key on a subnet, while functionally it's as if every canister has it's own keys.

-------------------------

Manu | 2022-10-21 07:46:59 UTC | #245

Hi everybody! There have been some concerns about the 1/3rd (f+1 out of 3f+1) threshold for the ECDSA keys on the internet computer, and whether this gives sufficient security. We have taken this feedback seriously and took a step back to revisit different approaches to increase the security of threshold ECDSA.

First, some background info. It is very difficult to make threshold ECDSA signatures, much more difficult than eg threshold BLS signatures. We cannot simply set a 2/3rd (i.e., 2f+1 out of 3f+1) threshold for ECDSA signatures like we do for BLS. The best fault tolerance such that we both have liveness and safety from known practical protocols is 1/3rd (i.e., f+1 out of 3f+1). Note that this fault tolerance is actually the same as the consensus protocol ICC uses: even though we use 2/3rd threshold BLS keys, the protocol can only be proven safe and live with up to 1/3rd corruptions, which is also the theoretical optimal threshold for asynchronous consensus. Despite this, you could argue that practical attacks on tECDSA are perhaps easier to perform than attacks on ICC: for tECDSA, you’d have to steal the key material of 1/3rd of the nodes and obtain the full signing key, while for ICC you’d either need an coordinated active attack controlling 1/3rd of the nodes and some control over the network connection between nodes, or you need to steal the key material of 2/3rd of the nodes which would let you sign anything.

So how can we make things even more secure? There are many different approaches:

1. **More nodes & larger subnets**. This is conceptually the simplest approach. Work is in progress on this front, and you can follow the status in [this forum thread](https://forum.dfinity.org/t/the-state-and-direction-of-decentralization-nodes-on-the-internet-computer/9170/120?u=manu).
2. **Shuffle nodes between subnets**. This has been suggested by the community and is an appealing idea: it could mean that an attacker cannot target a specific subnet as the membership constantly changes, and the only way to corrupt a subnet is to compromise a sufficiently large fraction of the overall IC nodes, meaning each subnet becomes more secure as the IC gets bigger. However, I believe that we first need more independent nodes before shuffling actually adds security.
3. **Enable AMD SEV**. Enabling some form of SEV could make it much harder to break into a node. Currently, the current IC nodes are of the [“Gen-1” hardware specifiation ](https://wiki.internetcomputer.org/wiki/Node_provider_hardware)which only support SEV-ES (and is no longer available) while new nodes will have Gen-2 hardware which support SEV-SNP. Gen-2 hardware ([specification](https://forum.dfinity.org/t/draft-motion-proposal-new-hardware-specification-and-remuneration-for-ic-nodes/14202)) is currently available. The relevant point here is that Gen-1 hardware with SEV-ES do not provide the security guarantees we want as they do not protect memory integrity and are thus vulnerable to attack by privileged users while Gen-2 with SEV-SNP does provide memory integrity and the ability for external parties to more easily validate the integrity of the system.
4. **Increase tECDSA security threshold**.While we know that we cannot increase the fault tolerance for both safety and liveness, we could sacrifice some liveness fault tolerance to increase the safety fault tolerance. A concrete example: a 34 node subnet can currently tolerate 11 corrupted nodes, meaning we can still sign, and the secret key is not compromised. We could change the thresholds to tolerate 15 corrupted nodes, making it harder for the attacker to steal the secret key. However, this means we can only tolerate 3 nodes that are unavailable. If a 4th node is offline, the subnet cannot create ECDSA signatures anymore.
Since being unable to sign with a key is almost as bad as an attacker compromising a key, we think that this approach is not the best solution to apply on all subnets. It could be a promising solution to let smaller subnets also maintain the ECDSA key using a higher threshold (such that we can scale out the signing capabilities), while larger subnets still maintain the ECDSA key with a 1/3rd threshold. In this way, if a smaller subnet can no longer create ECDSA signatures due to too many failures, the larger subnets still hold the ECDSA key and can reshare it to other subnets.
5. **Regularly reshare the ECDSA secret key**. The idea is that nodes can regularly update their encryption key used to decrypt their secret key shares in the distributed key generation protocol that maintains the ECDSA key. The ECDSA secret key shares will be reshared every time membership changes or any of the members updated their encryption key.
The result of this approach is that if an attacker steals an ECDSA secret key share or a DKG decryption key from a node, it will only be usable for a limited amount of time, because the keys refresh regularly. This means that an attacker would have to steal the key material of 1/3rd of the subnet nodes within a small time window, which seems much more complicated to pull off.
One caveat is that the node signing key could also be stolen, and an attacker could try to slowly steal node signing keys, and then quickly register malicious encryption keys on behalf of those nodes, such that it can still steal the ECDSA signing key. To avoid this attack, we can limit how frequently node encryption keys can be updated for nodes in one subnet. An attacker can then only slowly try to register malicious keys for nodes. However, this is a very visible attack, and nodes can complain upon seeing a malicious key registered in their name, upon which they can be removed from the subnet.

The first three options all require a bit more time, as it involves new hardware and onboarding new node providers. So while we are actively working on 1 and 3, I do not expect they will help strengthen the ECDSA security this calendar year. Option 4 is mainly helpful to allow smaller subnets to also sign, when we have larger subnets that back up the key with the standard threshold. Initially we plan to only use large subnets, where this idea does not help. Option 5 however meaningfully improves the security of ECDSA and can be implemented more quickly.

**Planned next steps**. 

Our proposal is to implement option 5 now, and then release a “production ready” ECDSA key, which will be maintained on large (e.g., 34 node) subnets. We can further improve the security of this key when more nodes are added and increase the subnet size. However, when a new feature is added that significantly improves the security (eg, SEV enabled replicas), we can also consider creating a new ECDSA key that has always been at this level of security, and applications can then choose whether they want to migrate to this key.

Please let us know what you think!

-------------------------

hokosugi | 2022-11-28 06:46:42 UTC | #246

It clearly states that private key are never reconstructed.
I assume that the private key that would have been generated in the first stage before being distributed as secret shares no longer exists, but how is it destroyed? I assume they are securely deleted without being reconstructed or restored, but I am curious.
I read the White Paper thinking that this applies not only to threshold ECDSA signatures, but also to threshold BLS signatures, but there is no mention of this, so I am asking.
![ScShot 2022-11-28 15.18.04|690x295](upload://t5ktN4VUzYoRRB8eu5WfP7gyq69.png)

-------------------------

timo | 2022-11-28 07:14:00 UTC | #247

The private key never lives in one place, not even temporarily, hence does not need to be destroyed. There is a process called distributed key generation (DKG) which that it is generated in a distributed way, in other words it is "born distributed". That applies to both ECDSA and BLS threshold signature keys.

-------------------------

lastmjs | 2023-02-02 13:27:44 UTC | #248

5 doesn't help much with the collusion attack vector which is what worries me most. The Bitcoin integration is live, and ckBTC is about to be live. Assuming the tECDSA subnet has 34 nodes (can anyone confirm?) Then 12 (11?) node operators can collude to steal everything built on top of that master tECDSA key (right?).

12 known parties, who know each other and do not rotate their membership on a regular basis, can do this.

We're going to try storing $millions or more here?

Update: I'm trying to identify the tECDSA subnet. What is its id? I'm looking through the subnets on the dashboard and there are only a few higher-replication subnets to choose from, the NNS, the one fiduciary, and one other system subnet that is identified as the II subnet.

The unmarked system subnet https://dashboard.internetcomputer.org/subnet/w4rem-dv5e3-widiz-wbpea-kbttk-mnzfm-tzrc7-svcj3-kbxyb-zamch-hqe only has 13 nodes, but it seems most likely to be the tECDSA subnet. Which is it?

I'll update this new thread with the relevant information once known: https://forum.dfinity.org/t/tecdsa-subnet-id-and-takeover-threshold/18336

-------------------------

Manu | 2023-02-02 13:50:33 UTC | #249

Fiduciary subnet [pzp6e](https://dashboard.internetcomputer.org/subnet/pzp6e-ekpqk-3c5x7-2h6so-njoeq-mt45d-h3h6c-q3mxf-vpeq5-fk5o7-yae) is the ECDSA signing subnet, currently consisting of 28 nodes.

-------------------------

lastmjs | 2023-02-02 13:53:28 UTC | #250

Is that 9 or 10 independent nodes necessary for a complete takeover of the master key?

-------------------------

lastmjs | 2023-02-02 13:57:03 UTC | #251

I think it's 10, 3f + 1 = 28, f = 9, f+ 1 = 10 necessary for takeover.

-------------------------

Manu | 2023-02-02 14:01:28 UTC | #252

Exactly, 10 required for takeover.

-------------------------

Maxfinity | 2023-02-02 15:12:18 UTC | #253

[quote="Manu, post:245, topic:6152"]
Our proposal is to implement option 5 now, and then release a “production ready” ECDSA key, which will be maintained on large (e.g., 34 node) subnets. We can further improve the security of this key when more nodes are added and increase the subnet size. However, when a new feature is added that significantly improves the security (eg, SEV enabled replicas), we can also consider creating a new ECDSA key that has always been at this level of security, and applications can then choose whether they want to migrate to this key.
[/quote]
Not really any worse than Solana or BSC, pragmatic. I think this is safe enough as long as there is key refresh, could be made better with TEEs.

-------------------------

ildefons | 2023-02-02 15:40:59 UTC | #254

[quote="Maxfinity, post:253, topic:6152"]
Not really any worse than Solana or BSC, pragmatic
[/quote]

If it is just "not worse" than a traditional bridge, plus it has the added risk of a new technology never used in production, what is the advantage?

-------------------------

skilesare | 2023-02-02 15:56:50 UTC | #255

Is there something to compare this to apples to apples? It is certainly better than one entity(Coinbase, Binance) controlling your BTC, but are there really other non-custodial solutions that we should be using for comparison?

Getting 10 doxed companies to collude in theft is a pretty damn high bar.  I'd think the other options have non-doxed which would be much less safe depending on the replication factor.

Obviously on the other end is bitcoin itself and we won't meet that threshold of security, but what is "enough"?

-------------------------

ildefons | 2023-02-02 16:04:20 UTC | #256

So if we had a traditioal bridge secured with 10 way multi-sig security and the 10 key distributed  among 10 doxed companies, wouldn't that provide the same level of security without the risk of using a new technology never used in production?

-------------------------

skilesare | 2023-02-02 16:17:21 UTC | #257

Sure. The same level of risk, but not the same level of interoperability, computability, and scalability opportunity. You've got to use it in production at some point to overcome your argument. Are you proposing never turning it on because there are risks?  Certainly, no one should move their whole stack over on day 1.  Don't risk what you're not willing to lose and eventually the platform will have secured X million dollars of bitcoin for Y number of days and you'll have a new production-level risk floor.

-------------------------

ildefons | 2023-02-02 16:51:42 UTC | #258

I'm trying to understand what is the final beneffit once we reach the perfect production quality level. 

[quote="skilesare, post:257, topic:6152"]
interoperability, computability, and scalability opportunity
[/quote]

Probably true but It is too generic. It does not say how.

Maybe the "how this new technolgy help reach the higher level of interoperability, computability, and scalability opportunity" is by eliminating the dependency on humans as key keepers? If this is correct, why not exaplaining things by focusing on this unique key benefit?

-------------------------

lastmjs | 2023-02-02 21:08:27 UTC | #259

I think the theory/protocol is very sound, but the current practical implementation limits the actual security in practice.

I am going to start feeling much more comfortable when subnet replications increase, the number of independent node operators increases, we implement node rotation, and have secure enclaves.

The best I can think of for measuring "safe enough" for subnet size is the size of Chainlink oracle networks. Chainlink is one of the most trusted and well-known live production projects in blockchain, and AFAIK secures $billions.

I'm not sure which Chainlink oracle networks are securing what value, but if we look at their data feeds the first two, ETH/USD and BTC/USD are probably the most widely used. Check them out: https://data.chain.link/

They each rely on a 21/31 assumption. So their subnets have 31 nodes, and 21 must come to agreement before a trusted answer can be created.  Seems they have a fault tolerance similar to IC subnets.

But the tECDSA subnet has essentially half of the fault tolerance. So if we extend Chainlink's security model to tECDSA, we would need a subnet of 61 nodes to ensure that it would take 21 colluding node operators to steal everything.

Combine a 61 node subnet with node rotation, secure enclaves, and a healthy level of independent node operators and I think we're reaching quite fantastic levels of security.

I wish DFINITY would put more effort into studying and attempting to quantify sufficient levels of decentralization, no one seems to have any idea what levels are required. Their old consensus paper from 2018 had math explaining probabilities of corruption from colluding attackers based on committee and total population sizes, it was really great stuff. But that seems to have been thrown away.

-------------------------

skilesare | 2023-02-02 21:17:43 UTC | #260

[quote="lastmjs, post:259, topic:6152"]
we implement node rotation
[/quote]

Hasn't Timo shown that rotation actually increases the possibility of corruption because there is a higher probability that a group will eventually get rotated than enough in any one particular group will become corrupted?  I thought I saw a post on that somewhere.

-------------------------

lastmjs | 2023-02-02 21:23:53 UTC | #261

That concern has been brought up multiple times, though depending on your assumptions I don't think the concern plays out. Myself and a few others have dug into the math as well and we can get it to work depending on the underlying assumptions.

I think most people including @Manu are on-board with rotation now, but it probably doesn't make sense until there are many more independent node operators (I would guess that was one of the assumptions, the pool of node operators to choose from, the percent honest/dishonest, and the size of subnets).

It's this kind of math and analysis I would like to see from DFINITY, in addition to all of the other very high quality research they publish.

-------------------------

lastmjs | 2023-02-02 21:33:39 UTC | #262

This thread has some of the math in it: https://forum.dfinity.org/t/shuffling-node-memberships-of-subnets-an-exploratory-conversation/7478

Oh wait, maybe the math didn't show what I thought it showed...see for yourself I suppose. I'm not convinced it's a bad idea, and the fact that others whose opinions I highly regard on the matter seem to agree then I am very much still on board with node rotation.

If we have a conclusive analysis that it's dangerous then I'll be done with the idea, but I highly doubt such an analysis would end up that way considering the fundamental importance of shuffling in other designs e.g. Ethereum.

-------------------------

Zane | 2023-02-02 22:00:40 UTC | #263

[quote="lastmjs, post:262, topic:6152"]
the fundamental importance of shuffling in other designs e.g. Ethereum
[/quote]

The benefits of reshuffling depends on: size of the pool to pick from, size of the subset randomly chosen and time before reshuffling. In the original Dfinity design, which was heavily based on VRF and consensus on random subsets of nodes, the pool was in the order of thousands, subset around 400/500 nodes and reshuffle would happen every block, I believe Eth 2.0 sharding model is similar in this aspect. 
Here are Dfinity's own estimates for the original design: 
https://youtu.be/9HRurPVF3Pg?t=740

With the current design: the pool is still quite small, the subset is 30/40 nodes and reshuffles happen 1-3 to times a day, so it might not do much to increase the subnet's security, infact it could open a new attack vector as Manu stated in the other thread.

-------------------------

lastmjs | 2023-02-02 23:05:54 UTC | #264

Thus node shuffling/rotation is most likely only viable once we have 100s or 1000s of independent node operators to choose from.

-------------------------

Maxfinity | 2023-02-03 01:26:36 UTC | #265


[quote="lastmjs, post:259, topic:6152"]
They each rely on a 21/31 assumption. So their subnets have 31 nodes, and 21 must come to agreement before a trusted answer can be created. Seems they have a fault tolerance similar to IC subnets.
[/quote]

Yeah, the 2018 whitepaper is what brought me to the IC, not sure 100% how it changed. 
Why would Link have half the IC's fault tolerance, should be the same no?

-------------------------

Maxfinity | 2023-02-03 01:31:39 UTC | #266

[quote="lastmjs, post:262, topic:6152"]
Oh wait, maybe the math didn’t show what I thought it showed…see for yourself I suppose. I’m not convinced it’s a bad idea, and the fact that others whose opinions I highly regard on the matter seem to agree then I am very much still on board with node rotation.
[/quote]

Shuffling is good under the assumption of adaptive adversaries, i.e. that a hacker can take a certain amount of time to break into and corrupt a node. 
With non-adaptive adversaries, I believe not shuffling is safer. However, perhaps the adaptive adversary is a more realistic threat model.

-------------------------

lastmjs | 2023-02-03 04:46:09 UTC | #267

> But the tECDSA subnet has essentially half of the fault tolerance.

It's the tECDSA protocol that has half the fault tolerance of Chainlink and regular subnets, essentially. Only 1/3 of participants are needed to sign.

-------------------------

lastmjs | 2023-02-03 04:47:24 UTC | #268

Ah, yes that I think is one of the key considerations and something I'm not sure ICC even addresses.

-------------------------

timo | 2023-02-03 07:42:46 UTC | #269

[quote="skilesare, post:255, topic:6152"]
Is there something to compare this to apples to apples? It is certainly better than one entity(Coinbase, Binance) controlling your BTC, but are there really other non-custodial solutions that we should be using for comparison?
[/quote]

The Liquid side chain holds large value secured by a 11-out-of-15 signing threshold. The 15 entities are well-known (such as exchanges). The significant risk is that 5 loose their keys.

Safety-wise it is equivalent to a 31 node subnet (11 need to collude). But a 31 node subnet can tolerate up to 20 lost keys.

-------------------------

lastmjs | 2023-02-03 15:16:33 UTC | #270

Ah man...I may have misunderstood again.

Subnets only need 1/3 + 1 to collude? I was always under the 2/3 assumption.

I thought that 1/3 faults could be tolerated, and 1/3 + 1 would make it so that the subnet could not come to consensus and would thus halt, but 2/3 could collude and continue consensus without being detected as easily.

Can you help me to understand?

-------------------------

lastmjs | 2023-02-03 16:18:54 UTC | #271

I just counted up the number of independent node operators in the tECDSA subnet, and there are only 19 independent node operators out of 28 total nodes.

I would guess that shrinks the tolerance down to 6 out of 19, so 7 independent node operators can collude to sign whatever they want.

7 colluding or hacked node operators.

-------------------------

Denis | 2023-02-06 04:47:44 UTC | #272

Perhaps we should start thinking of the IC not as a blockchain like others but as something between the cryptosphere on the one hand and Web 2 / real world on the other. Seen in this light, ckBTC security is underpinned by two factors. There is the replication that makes stealing funds difficult, but as @lastmjs points out, the replication factor is pretty low. However, node providers, though relatively few, are fully doxxed, and will face immediate real world consequences if they collude to steal funds. This is not the case with traditional chains. The two factors *together* provide better security than any other BTC defi initiative. 
Thinking in pure crypto terms, we discount the second factor and want everything to be secured in a trustless, permissionless manner. But I am gradually giving up on the idea that the IC will ever be a truly decentralised, transparent and permissionless chain. It just doesn't seem to be on the Foundation's roadmap or list of priorities judging by many discussions on this forum. The Foundation only takes baby steps and considers those favours done to the community. 
Anyway, maybe this middle ground between crypto and Web2 / real world holds promise, we shall see.

-------------------------

Zane | 2023-02-03 16:15:39 UTC | #273

[quote="Denis, post:272, topic:6152"]
However, node providers, though relatively few, are fully doxxed, and will face immediate real world consequences if they collude to steal funds
[/quote]

I'm not so sure about this, node providers simply have to convince the NNS they are legit and there are many ways bad actors could exploit that, if banks can be fooled so can the NNS. 

Even assuming an ideal system that can't be cheated are providers actually legally liable? They don't sign any binding document and reside in different jurisdictions so starting legal action and proving they willingly stole the funds won't be easy, after all it's in the realm of possibility that a skilled group could hack 7 independent entities to steal possibly millions of dollars.

-------------------------

lastmjs | 2023-02-03 16:18:16 UTC | #274

Yes and if we open up the floodgates fo independent node operators, unless our verification process is excellent, then the risk of Byzantines increases. So far the node operators have been a relatively small and vetted group. It's of extreme importance to figure out how to continue vetting them

-------------------------

Zane | 2023-02-03 16:45:50 UTC | #275

Even with more independent providers the risk still remains, I very much doubt the vetting process will ever become good enough to filter out competent bad actors, so the only real safety provided by more providers will be the increased amount of money they need to invest in node hardware to take over at least 1 subnet.

I was hoping the "declaration of good intent" could at least make it harder to fool the NNS cause at least figure heads would be legally liable and therefore it'd be less appealing to be part of a coordinated attack, but that isn't the case as the declaration is just a piece of paper with no real legal weight nor there is a defined course of action in case it were to be violated. 

To be fair I'm not a huge fan of using the law to guarantee safety of what is supposed to be a decentralized protocol, but all things considered it might be best to acknowledge ICP's hybrid nature as @Denis said and take a page out of centralized cloud's book.

-------------------------

victorshoup | 2023-02-03 16:58:52 UTC | #276

I am not sure where the idea that the IC withstands 2/3 corruptions even comes from. Let me say this once and for all:  *The Internet Computer Protocol withstands 1/3 corruptions and no more* -- that is the way it is and the way it always has been. If 1/3+1 nodes are corrupt, then the safety property of the consensus protocol may be broken, which means a subnet can permanently fork into two inconsistent states. 

This is not an accident -- achieving liveness and safety in consensus with greater than 1/3 corruption in an asynchronous network is theoretically impossible.

While it is true that the protocol (and a million other consensus protocols) uses a 2/3+1 threshold for various quorum sizes, these thresholds are designed to withstand 1/3 corrupt parties, not 2/3. I think the fact that these thresholds are 2/3+1 has led to the misconception that the protocol withstands 2/3 corruptions, but that is just a fallacy.

What is also true is this: if 2/3+1 parties are corrupt, then it is trivial to break the protocol, but if 1/3+1 are corrupt, it can still be broken, even though it is a bit more challenging (but still feasible enough that nobody would seriously consider the protocol to be secure in that setting).

See https://eprint.iacr.org/2022/087 for more details.

This was one reason why tECDSA protocol was designed with withstand 1/3 corruptions: this is exactly the same corruption level as the IC consensus protocol. Also note that our tECDSA protocol relies on consensus for its security: in fact, if you break the safety property for consensus, you can steal the ECDSA signing key (this is true of almost any threshold ECDSA protocol, due to the inherent fragility of ECDSA signatures themselves). While it is true that if you corrupt 1/3+1 nodes you can steal the ECDSA signing keys by stealing the key shares, we have implemented various mitigations, such as proactive resharing of the secret key. But even if we took other mitigations, it would still be possible to steal the secret key with 1/3+1 corruptions via other means (e.g., the above-mentioned attack via breaking consensus). 

See https://eprint.iacr.org/2022/506 for more details.

We are currently exploring some options of trading off liveness vs security, so that we boost somewhat the threshold for breaking security, at the cost of lowering the threshold for breaking liveness (and possibly losing the secret key completely). This same tradeoff would also have to be applied to consensus (at least for ECDSA enabled subnets). This would bring us to a security threshold closer to 1/2. This is a WIP.

-------------------------

diegop | 2023-02-03 17:24:22 UTC | #277

Fwiw, @victorshoup helped me grok this over a conversation once. An ELI5 from that convo is:

*Forget about quorum sizes and thresholds. Here is the main thing: IC assumes less than 1/3 of actors are bad. If that assumption is broken, all bets are off.*

Every chain has a security **assumption** of how many malicious actors it can function well with (ranging from 1/2 to 1/3, or even less). If that assumption is broken, so is the rest of any protocol. 

I found myself often forgetting this simple fact until Victor once helped me focus and not get too distracted by the other numbers floating around (which I was).

-------------------------

lastmjs | 2023-02-03 17:40:08 UTC | #278

Thanks for the detailed explanation. I knew the fault tolerance was 1/3, but assumed that after 1/3 it would simply become unclear which group of participants had the consensus state. So essentially a subnet would fork at that point, and confusion would ensue as to which state to trust. All forks could continue executing state transitions, but none would be trusted as the consensus state machine.

The only way for state changes to be trusted as consensus would be for 2/3 of participants to say so. Thus to truly pull off a catastrophic attack where state could be changed without competing forks you would need 2/3 dishonest parties.

Thus it seems to me that any number of corrupt parties under 2/3 is desirable to 2/3 dishonest parties, because then consensus could be reached possibly without detection or forking.

Is this a correct understanding or should I just assume 1/3 + 1 and it's all over?

-------------------------

lastmjs | 2023-02-03 17:47:05 UTC | #279

<= 1/3 corrupt parties = consensus is reached, honest state machine is consensus
\> 1/3 corrupt parties = consensus is not reached, forks ensue, unclear which state machine is consensus
\>= 2/3 corrupt parties = consensus is reached, dishonest state machine is consensus

Is the description above materially flawed?

-------------------------

skilesare | 2023-02-03 18:36:03 UTC | #280

This is one more reason the in the future we will likely have to move to a staking/slashing model for node providers. My understanding is that currently the "investment" in hardware is considered enough skin in the game to keep providers honest, but I doubt that is sufficient for the long run.

Perhaps there is a stake reveal game that can be added to tecdsa that would make it more profitable to pretend to collude but backstab the colluders at the time of signing so that the cheaters suffer financially. Getting a bit out of my depth here, but skin in the game can help with these security guarantees. The entire NNS is predicated on the concept.

-------------------------

victorshoup | 2023-02-03 21:22:40 UTC | #281

If 1/3+1 parties are corrupt, then there could be two different states, each certified with 2/3+1 participants saying so (because corrupt parties can vote both ways). That seems pretty catastrophic to me. I agree that if 2/3+1 parties are actually corrupt, the situation is much worse -- so an even bigger catastrophe. So the difference between 1/3+1 corruptions and 2/3+1 corruptions is catastrophe vs an even bigger catastrophe. Maybe in the first instance, through heroic and probably very centralized and ad hoc methods, one could somehow reset the Internet Computer back to some reasonable and consistent state....maybe....but I would not want to contemplate that situation

-------------------------

lastmjs | 2023-02-03 21:41:11 UTC | #283

[quote="victorshoup, post:281, topic:6152"]
If 1/3+1 parties are corrupt, then there could be two different states, each certified with 2/3+1 participants saying so (because corrupt parties can vote both ways)
[/quote]

I don't understand this scenario.

13 node subnet can handle 1/3 corrupt parties = 4 corrupt parties. So a minimum of 9 parties must agree to certify a state.

If 1/3 + 1 parties are corrupt = 5 corrupt parties and 8 honest parties. How could 5 corrupt parties ever sign two states that have at least 9 parties agreeing? The 5 could add at least 1 agreement to the 8 to get the correct honest state, but the 8 would never agree to anything the 5 proposed dishonestly and thus the dishonest state could never get 9 votes.

I'm not seeing how 1/3 + 1 can do this attack. I'm only seeing that you need at least 2/3 corrupt parties, 9 in this case, to certify a state. Otherwise the honest parties would never vote on a dishonest state and thus there would simply be many uncertified states.

I would really like to understand.

-------------------------

lastmjs | 2023-02-03 21:43:35 UTC | #284

Hmmm...maybe it depends on the nature of the state changes. The dishonest participants could propose valid state changes that for example double-spend, and depending on the order of messages received, network conditions, honest participants wouldn't be able to tell. Is it along those lines?

-------------------------

lastmjs | 2023-02-03 21:47:17 UTC | #285

[quote="victorshoup, post:281, topic:6152"]
very centralized and ad hoc methods
[/quote]

DFINITY already engages often in this kind of activity with subnets. They essentially have write access because of follower relationships, and they use it.

I assume it's mostly done with proposals, but couldn't the same mechanism be used to restore a subnet? and if I'm not mistaken subnets have already ceased finalization in the past and have had to be reset.

-------------------------

Denis | 2023-02-04 03:42:31 UTC | #286

[quote="Zane, post:273, topic:6152"]
Even assuming an ideal system that can’t be cheated are providers actually legally liable?
[/quote]

I hope node providers do have some legal liability, but legal liability is not the only disincentive to acting badly in the real world :slight_smile:   Do you think that Sam Bankman-Fried will be taking walks in the park, even if fully acquitted? 
I am not condoning retributive violence, just pointing out that if people steal a lot of money, some of the victims will find the thieves and make them regret it. The threat of retributive violence IRL is as distant as you can get from cryptographic security but is pretty effective as a deterrent. It will certainly be in the minds of the IC's node providers. If node providers were anonymous, I would never put money in a 34 node subnet, no matter how rigorous the maths underpinning it.

-------------------------

victorshoup | 2023-02-04 14:25:49 UTC | #287

Suppose n=3f+1 and let C be a set of f+1 corrupt parties. Partition the remaining set of 2f honest parties into two sets A and B, each of size f. C+A can sign and certify state_1 while C+B can sign and certify state_2. This is how we end up with two different certified states, each signed by 2f+1 parties.

-------------------------

skilesare | 2023-02-04 15:38:00 UTC | #288

I have a half finished book somewhere with a number of thoughts that propose that voluntary submission to financial violence is a solution to eliminate physical violence (which we've see through rule of law for decades so it isn't really new thoughts). Crypto doesn't make this new, but it makes it enforceable by math rather than the whims of human enforcement.

The NNS sort of reverts this back to mob mentality over math.  The one thing that tips it to a workable system is the locking mechanism. It works because people generally won't vote to make decisions that will hurt the value of the network because their exposure to the network is locked in.(this is why a neuron marketplace would tip the scales back to mob mentality).

For some reason node providers aren't subjected to this. Why isn't there a significant stake explicitly tied to hosting a node?  While the cpus/system provided are specialized, they are hardly axis with only one purpose and could easily be repurposed to other productive economic activity.

My understanding is that a bit of a sweetheart deal was offered to get the network off the ground which is completely understandable, but we should have a timeline for that being corrected even if the first movers are grandfathered in for stability. Eventually those should be dwarfed by new nodes and they should be exposed to the network value volatility. Note: we may have to pay for this through additional rewards. It has to be profitable to contribute in an honest way.  Perhaps a slowly increasing percentage of node rewards should be paid as locked neurons in a way that makes economic sense for the providers.

-------------------------

Denis | 2023-02-04 17:31:59 UTC | #289

[quote="skilesare, post:288, topic:6152"]
Eventually those should be dwarfed by new nodes and they should be exposed to the network value volatility.
[/quote]

I absolutely agree this should happen, but I believe the situation is considerably worse than you have painted when it comes to BTC integration. The NNS could, at best, ensure node providers have skin in the ICP game and are therefore incentivised not to tank that token's price. But these node providers will potentially have the opportunity to steal millions worth of BTC. Since BTC value will be relatively unaffected by a crisis in ICP, they can happily plot to make off with enough BTC to outweigh what they will lose through the drop in value of ICP consequent to the steal.
Which means we fall back on two ways to protect the network that do not involve crypto. Firstly, binding contracts which make node providers severely liable in their respective jurisdictions for any breach of trust. Second the hope that node providers are kept honest by the fear that a lot of bad hombres have invested in both ICP and ckBTC.

-------------------------

skilesare | 2023-02-04 18:27:09 UTC | #290

Yep....agree 100%: https://twitter.com/afat/status/1621937408248791041?s=46&t=FZtVUtaHF1hzcKNomLlzbg

Perhaps tecdsa needs its own collateral/rewards mechanism.

-------------------------

senior.joinu | 2023-05-04 12:55:33 UTC | #291

Hello everyone!

I have a practical question. How do I verify that a public key was derived from a canister_id non-interactively? 

An example in Rust would be much appreciated. Thanks in advance!

-------------------------

andrea | 2023-05-05 12:53:08 UTC | #292

Is your question about:
* How to derive subkeys of a canister given its "master canister public key" and a chain-code?
* How to verify the master public key of a canister?

For the first point, you can derive sub keys using extended BIP32 derivation path. You can find a rust crate for the extended bip32 [here](https://github.com/dfinity/ic/tree/master/rs/crypto/extended_bip32) and the method implementing the derivation [here](https://github.com/dfinity/ic/blob/master/rs/crypto/extended_bip32/src/lib.rs#L72). To use this you need the canister "master public key" and a chain code. These can be obtained by calling (once) the `ecdsa_public_key` API using the canister ID and an empty derivation path. TLDR, if you can get hold of the master key of a canister you can verify every other canister key using the extended bip32 library. 

The second question it is a bit more complicated. If you had the master public key of the subnet available, then you could use the extended-BIP32 derivation to compute every canister master public key (and thus any other subkey). This is done by using the `canister_id` as derivation path and using the 0* string as the initial chain code. However, the subnet master key is not directly accessible to canisters at the moment. The registry actually contains the IDKG dealings that were used to generate the keys, so one could actually try to recompute the subnet master public key from there, but it would require some extra work.

-------------------------

senior.joinu | 2023-05-05 13:20:06 UTC | #293

The question is "having a message `M`, a principal `P` and a signature `S`, verify that `P` is the issuer of `S`". 

I'm working on a way to certify data with an alternative certification flow that uses tECDSA instead of `set_certified_data` API. So, the second question is what I was initially asking. 

My motivation for this is that ECDSA libraries are much more accessible, comparing to BLS, which will make it much easier to create client-side verification libraries for these alternative certificates in other languages. 

Plus, `set_certified_data` API is a little bit inconvenient, since it requires us to use two separate canister calls (first, you have to execute an update call, to add a certificate to the state tree, then you have to use a query call to fetch the new certificate). With tECDSA this can be done in a single update call, that signs the certificate and immediately returns it to the user. 

What is missing now is the ability to pack the certificate with everything you need in order to verify it off-chain, which is the subnet's master key, as I see from your answer. 

I'm not blocked by this, since there are alternative solutions. 
1. I can verify signatures interactively, asking a canister to fetch the public key by canister_id for me.
2. All the canisters which issue signatures are currently in my project's perimeter, so I can have a root-of-trust canister that will issue delegations to other canisters and each delegation can have this `principal -> public key` mapping embedded. Basically mimicking the same flow you do with the chain-key.

But it would be easier if that functionality was available out of the box.

Thank you for your answer!

-------------------------

andrea | 2023-05-05 15:33:25 UTC | #294

Your approach seems reasonable! One way to address this could be to have the ECDSA subnet to add the master key to the certified state, so that users could have a reliable way to obtain the key. In your application you could then either directly use the subnet key as root of trust, or potentially even chain it back to the NNS public key (although this may partially collide with some of your motivations).

-------------------------

andrea | 2023-05-12 18:00:47 UTC | #295

After some more thought, I think the easiest for now would be for us to manually compute the master public key and then provide some code to check that the derivation is correct. I'll post an update in this thread in the next days with the public key and some example code.

-------------------------

andrea | 2023-05-25 13:00:43 UTC | #296

Hey @senior.joinu, I was able to get the master ECDSA public keys from mainnet:

```
let production_public_key = "02121bc3a5c38f38ca76487c72007ebbfd34bc6c4cb80a671655aa94585bbd0a02";
let test_public_key = "02f9ac345f6be6db51e1c5612cddb59e72c3d0d493c994d12035cf13257e3b1fa7"
```

You can derive any canister key from the master key using something along these lines:

```
fn derive_public_key(
    canister_id: Principal,
    derivation_path: Vec<Vec<u8>>,
) -> Result<EcdsaPublicKeyResponse, String> {
    use ic_crypto_extended_bip32::{
        DerivationIndex, DerivationPath,
    };
    let master_key_hex = "02121bc3a5c38f38ca76487c72007ebbfd34bc6c4cb80a671655aa94585bbd0a02";

    let master_key = hex::decode(master_key_hex).expect("Master key could not be deserialized");
    let master_chain_code = [0u8; 32];
    

    let mut path = vec![];
    let derivation_index = DerivationIndex(canister_id.as_slice().to_vec());
    path.push(derivation_index);

    for index in derivation_path {
        path.push(DerivationIndex(index));
    }
    let derivation_path = DerivationPath::new(path);

    let res = derivation_path
        .key_derivation(
            &master_key,
            &master_chain_code,
        )
        .map_err(|err| format!("Internal Error: {:?}", err))?;

    Ok(EcdsaPublicKeyResponse {
        public_key: res.derived_public_key,
        chain_code: res.derived_chain_code,
    })
}
````

I also wrote a small test to verify the derivation of the ckbtc master public key and chain-code (which you could see from the first lines of the logs in [here](https://mqygn-kiaaa-aaaar-qaadq-cai.raw.ic0.app/dashboard)):

```
#[test]
fn check_ckbtc_key_locally() {
    let ckbtc_minter_id = Principal::from_str("mqygn-kiaaa-aaaar-qaadq-cai").unwrap();
    let ckbtc_public_key = "0222047a81d4f8a067031c89273d241b79a5a007c04dfaf36d07963db0b99097eb";
    let ckbtc_chain_code = "821aebb643bd97d319d2fd0b2e483d4e7de2ea9039ff67568b693e6abc14a03b";

    let derived_key = derive_public_key(ckbtc_minter_id, vec![]);

    assert!(derived_key.is_ok(), "{}", derived_key.unwrap_err());
    let derived_key = derived_key.unwrap();

    assert_eq!(hex::encode(derived_key.public_key), ckbtc_public_key);
    assert_eq!(hex::encode(derived_key.chain_code), ckbtc_chain_code);
}

```

Hope this helps!

Andrea

-------------------------

senior.joinu | 2023-05-25 15:30:06 UTC | #297

This is awesome! 
Thank you so much for this!

-------------------------

senior.joinu | 2023-05-25 18:27:01 UTC | #298

By the way @saikatdas0790 - this is the way you can use to differentiate between canisters from your project and other canisters.

Just introduce a publicly known root canister and make this root issue certificates to each of your canisters. Then check for these certificates, when you want to restrict access.

You can even implement capabilities this way.

-------------------------

andrea | 2023-06-10 10:13:18 UTC | #299

I wrote a simple example [canister](https://a4gq6-oaaaa-aaaab-qaa4q-cai.raw.icp0.io/?id=izvnm-aiaaa-aaaal-acorq-cai) that let you do the public key derivation from the master key exactly as the replicas do on mainnet. `compute_public_key_locally` does the computation using the master public key, while `get_public_key_from_ic` forwards the call to the IC. So you can call both API to check that the keys derived by the canister are consistent with the one derived using the system API on mainnet. You can find the source code [here](https://github.com/andreacerulli/extended-bip32-canister).

-------------------------

senior.joinu | 2023-06-12 09:45:47 UTC | #300

Thank you very much for that!
This is very helpful!

-------------------------

dieter.sommer | 2023-10-07 20:30:30 UTC | #301

A discussion of a proposal on a price reduction for threshold ECDSA has been published. We would be grateful for feedback.

https://forum.dfinity.org/t/proposal-50x-price-reduction-for-chain-key-ecdsa-signing-threshold-ecdsa-signing/23560

-------------------------

lastmjs | 2024-07-26 05:38:00 UTC | #302

[quote="Manu, post:245, topic:6152"]
**Regularly reshare the ECDSA secret key**. The idea is that nodes can regularly update their encryption key used to decrypt their secret key shares in the distributed key generation protocol that maintains the ECDSA key. The ECDSA secret key shares will be reshared every time membership changes or any of the members updated their encryption key.
The result of this approach is that if an attacker steals an ECDSA secret key share or a DKG decryption key from a node, it will only be usable for a limited amount of time, because the keys refresh regularly. This means that an attacker would have to steal the key material of 1/3rd of the subnet nodes within a small time window, which seems much more complicated to pull off.
One caveat is that the node signing key could also be stolen, and an attacker could try to slowly steal node signing keys, and then quickly register malicious encryption keys on behalf of those nodes, such that it can still steal the ECDSA signing key. To avoid this attack, we can limit how frequently node encryption keys can be updated for nodes in one subnet. An attacker can then only slowly try to register malicious keys for nodes. However, this is a very visible attack, and nodes can complain upon seeing a malicious key registered in their name, upon which they can be removed from the subnet.
[/quote]

Once 1/3 of key shares are stolen, how are they ever invalidated? Why couldn't an attacker use old key shares? Could dishonest nodes keep copies of old key shares that could be used at a later date, if a sufficient number of nodes did this?

-------------------------

Manu | 2024-08-08 09:04:54 UTC | #303

> Once 1/3 of key shares are stolen, how are they ever invalidated?

They are not strictly "invalidated", it's just that they can only be combined with other key shares from that period, and honest nodes should have deleted those. 

> Could dishonest nodes keep copies of old key shares that could be used at a later date, if a sufficient number of nodes did this?

Yes, so the security requirement is "within any epoch, < 1/3rd of the nodes must be honest".

-------------------------


lastmjs | 2023-12-19 16:36:39 UTC | #1

X thread: https://twitter.com/lastmjs/status/1737149036241563910

I'm in the process of deeply pondering what ICP is missing at and around the protocol level, and what I think we need from ICP in 2024.

I usually do this through private conversations, but I would love to get as much feedback from the general ICP developer community as possible.

So please, what do you need from ICP to succeed with your applications? What's missing? What's frustrating? What's blocking?

If this makes it easier: If you could snap your fingers and have one feature implemented on ICP in 2024, just one, what would it be?

-------------------------

Roman | 2023-12-19 17:57:31 UTC | #2

Maybe I am a little off topic, but : 
‚Äì get USDC natively through CCTP
‚Äì full integration within Ledger Live (staking first, then buying, CL Card, etc.)

-------------------------

Jonathan | 2023-12-19 18:01:30 UTC | #3

I have a design for a dapp and the backend logic and primary algorithm are already written, but it's been decades since I've coded and I don't have time to relearn new languages right now. If there were some combination of AI and developer kits that could do the heavy lifting I'd probably find time to build it on the IC.

-------------------------

evanmcfarland | 2023-12-20 16:36:28 UTC | #4

- Data storage/backup method/standard that Traditional DB people can understand, and push upgrades without mini heart attacks. (Re-ignite this abandoned idea: https://forum.dfinity.org/t/union-db-lets-build-an-infinite-database-together/21142?u=evanmcfarland)

And this ones are more selfish, but I think will be generally important. AI stuff:
- Low-replication subnet for LLMs.
- VectorDB that scales.

-------------------------

senior.joinu | 2023-12-20 18:55:55 UTC | #5

[quote="evanmcfarland, post:4, topic:25726"]
(Re-ignite this abandoned idea: [[union-db] Let's build an infinite database together!](https://forum.dfinity.org/t/union-db-lets-build-an-infinite-database-together/21142))
[/quote]

Wanna build it together?

[quote="evanmcfarland, post:4, topic:25726"]
VectorDB that scales.
[/quote]

This is easier than the one above. I could help, if you want.

-------------------------

evanmcfarland | 2023-12-20 20:13:20 UTC | #6

Thank You! Messaged you.

-------------------------

Samer | 2023-12-20 22:59:40 UTC | #8

Cycles ledger

And canister backups

-------------------------

hpeebles | 2023-12-21 08:59:16 UTC | #9

1. Idle canisters being handled more efficiently by the replica

    Currently an idle canister still adds a non-trivial amount of computation cost to the replica.
    If this could be handled more efficiently then the limiting factor would be the number of active canisters rather than the total number of canisters.
    This would allow apps using the 1 canister per user model to have potentially millions of canisters per subnet since only a small portion of them will ever be active at any given time.


2. Wasm deduplication

    For apps using the 1 canister per user model, the replica ends up storing the same wasm thousands of times. If the wasms could be deduplicated the storage space used up would be reduced massively.

-------------------------

skilesare | 2023-12-21 16:44:18 UTC | #10

Derived Canister IDs: https://forum.dfinity.org/t/derived-canister-ids/17434

AMDSev for computing inside a canister.

-------------------------

icme | 2023-12-22 02:27:46 UTC | #11

I'd love to see:

All IC
* [Canister Logging](https://forum.dfinity.org/t/canister-logging/21300)
* Increased limit of [Deterministic Time Slicing](https://forum.dfinity.org/t/deterministic-time-slicing/10635), allowing for "compute" canisters to perform intensive/heavy tasks
* [Canister Lifecycle Hooks](https://forum.dfinity.org/t/canister-lifecycle-hooks/17089)

Motoko
* Stable release of the incremental GC
* Abstracted/enhanced stable memory (`stable` keyword means the data lives in stable memory at all times)
  * Ability to use this enhanced stable memory to easily interact with the full memory available to a canister (without needing to manage memory directly or use a specialized library like Region.mo)

-------------------------

Bonobo | 2023-12-22 05:25:31 UTC | #12

This is going to be my very first post on this forum. I've been a long-time lurker. However, can we please address this? NNS proposals are nonsensical to people who are not from a computer science background. This is literally Latin to me. I usually just vote yes on most of these because I want the rewards. Can the proposals be simplified so that everyone can understand what they're actually voting on? It's such a simple idea. You can't expect mass adoption if normal people can't get past the jargon and technicalities of a project. I follow you on X, and you're one of the few individuals who breaks down complex ideas into understandable bits. Perhaps incorporating plain language summaries or providing accessible explanations alongside technical terms in proposals could make a significant difference. This way, even those not from an engineering background can make informed decisions and contribute meaningfully to the development of the project. 

Edit - In this case, I can at least tell something at one of the Node Operators end is being updated (please correct me if I'm wrong). But a lot of these proposals are just gibberish to an outsider like me. 

![ICP|690x375](upload://bJ6CxmU2PPw3tiXsXnuQUUbCOzl.jpeg)

-------------------------

sergeybykov85 | 2023-12-22 13:56:09 UTC | #13

I would like to see
1. Support of the ICRC7 nft standard in mobile wallets
2. Support of ICP token in Trustwallet or so.
3. Data export / import opportunities between canisters
4. Sdk to build SSI applications. framework for DID, DIDDoc, verified credentials, selective disclosure etc. 
5. News from any product where ICP token ICRC2 (or ICRC1) was listed by any centralized exchanges (like Binance, OKX, etc). 
6. Opportunity to specify the subnet for any nested canister when it is deployed by the parent canister.
7. Increased ICP token price by 4 (at least) or 14 times till the end of 2024!

-------------------------

Seers | 2023-12-22 14:04:25 UTC | #14

1 - Canister backups.
2 - Crypto **AI** Cloud. üôè

-------------------------

miadey | 2023-12-22 17:27:57 UTC | #16

Fullstack Motoko! Wasm is a first class citizen on the browser, would be great to have Motoko on the browser interacting with the DOM using JSInterop, something like Blazor.

-------------------------

kristofer | 2023-12-22 18:23:28 UTC | #17

We need a standard protocol for canister responses on top of the low level layer that exists today. Something that would pave the way for more composable applications. If my canister calls a function on another canister and is not authorised to do so, I want a standardised error code. It makes the integration and interoperability so much easier. Similar to an HTTP 403 code. Perhaps we could even adopt the HTTP codes directly.  Why invent something new when a standard already exists.

So. HTTP wrappers for canister responses!

I do believe IC uses some HTTP error codes for low level errors - problems with the subnet, that kind of thing. This would be used for the layer above that, for application specific errors and messages.

-------------------------

kristofer | 2023-12-22 18:30:16 UTC | #18

And.. 
- vetKeys
- ckERC20
- Calls where the caller pays for the cycles 
- Signing of arbitrary data with delegated identities
- Give one identity/principal access to many canisters - user approves connection and scope. "Allow identity X to do Y on canister Z"

and some other things.. :slight_smile:

-------------------------

skilesare | 2023-12-22 21:21:23 UTC | #19

https://forum.dfinity.org/t/completed-icdevs-org-bounty-34-wasmer-motoko-10-000/17887

We already retried to start! But some better bindings would be nice.

-------------------------

ckMood | 2023-12-23 06:24:02 UTC | #20

I feel like the AI computing that has been introduced on the Internet Computer Website would be very useful & good for this task. On the IC website, you can ask the AI internet computer related questions and it will answer based on references from the internet computer database. This type of simplification of jargon should be no problem for an IC-trained linguistic AI.

-------------------------

Bonobo | 2023-12-23 08:13:05 UTC | #21

Yes, I've used that AI chat function on the homepage and it's pretty good. But for proposals, a simple one liner is also enough to explain what's being proposed. It doesn't have to be complicated, as long as it gets the job down. Just dumb it down so it's easy for everyone to follow.

-------------------------

ckMood | 2023-12-23 10:03:27 UTC | #22

There is a way to see some one liners that explain the code and what it does that will sometimes be provided but I actually have the same problem in that case and still wish I understood more specifically what it means lol

-------------------------

dfisher | 2023-12-23 12:49:08 UTC | #23

One word: **COMPLIANCE**

Finance has been regulated from the beginning of time. For crypto, Web3, and RWA to take off, and be used in the real world, we need compliant DeFi. I do not believe this to be an opinion. It is a fact. And if you don't like it, it doesn't change the fact. Look at your dollar bill. There's probably a president there. And if you look at British Pounds, you'll probably find the Queen. Compliance isn't optional. It is a feature of money, and it is a feature of money movement. Just because you're a crypto bro who likes annoymity doesn't change a damn thing. 

Now that we have acknowledge the real world that we all live in, what are the barriers to Web3 adoption?

1. Lack of regulatory clarity from primarily the US regulators
2. Lack of Web3 tools to come into compliance

Point 1 is out of our control, but is a matter of time. Point 2 is rapidly evolving. The IC has the potential to the leader in compliant DeFi if we build the tools. We have the best tech after all. 

I am really excited to see verifiable credentials launch in 2024, and I am really excited to see Helix launch in 2024. Helix will enable self-custodied, yet KYC'd, wallets to transact on a decentralized orderbook. I am also super excited to see the GDPR compliant European subnet and subnet renting, with the Swiss subnet as the first, as this will enable projects with strict compliance to launch. 

I would like the Foundation to think about other ways to push forward ways for dApps to create compliance tools. Let's work with the Swiss government to be first to market. Lets go ICP!

@aned-dfinity1 @dostro @dieter.sommer

-------------------------

ckMood | 2023-12-23 14:58:11 UTC | #24

[quote="dfisher, post:23, topic:25726"]
Just because you‚Äôre a crypto bro who likes annoymity doesn‚Äôt change a damn thing.
[/quote]

I think about this a lot. Decentralization is possible but it is going to be a VERY DIFFICULT road to try and have an unregulated & completely anonymous system and market on a massive scale. Pseudonymity with the possibility for seemingly anonymous movement is optimal at best. In almost any place in the world you will find government to some degree. I sometimes think people who aggressively value anonymity in crypto really just don‚Äôt trust themselves to not do something illegal.

-------------------------

icpp | 2023-12-23 20:29:35 UTC | #26

Full support of the Windows platform by dfx.

That is where many enterprises live.

-------------------------

icpp | 2023-12-23 20:33:57 UTC | #27

Remove 2MB wasm limit

-------------------------

Sal_Paradise | 2023-12-25 18:53:54 UTC | #28

Internet Identity still needs to be improved where it's VERY simple to make a new account. It's still far to complicated for the average user. We need UAT where a nontechnical person is able to navigate it easily

-------------------------

justmythoughts | 2023-12-29 00:58:14 UTC | #29

Implement and deliver code for these two proposals to the NNS:

* Index all ICP Neurons
  * [Forum topic post](https://forum.dfinity.org/t/motion-request-for-neuron-indexing/11183/18)
  * [NNS Vote](https://dashboard.internetcomputer.org/proposal/48491) (Passed March 2022)
* Implement Periodic Confirmation of Neuron Followees
  * [Forum topic post](https://forum.dfinity.org/t/periodic-confirmation-of-neuron-followees/12109/)
  * [NNS Vote](https://dashboard.internetcomputer.org/proposal/55651) (Passed April 2022)


Both of these proposals were passed by the community by a wide margin in 2022. DFINITY voted **YES** on both proposals.

<br/>

If you would like to see either of these features prioritized, please make your voice heard in the respective forum topic post thread.

-------------------------

Sormarler | 2023-12-29 01:20:40 UTC | #30

![1000005672|230x500](upload://7BW05V0f3vKrO6LE2EZm7EKQUO6.png)


Easy way to solve that is do it like Cosmos ecosystem governance. Embed ICP AI with each proposal that give it a summary. The voter can further quiz the AI with more questions if necessary. The tool is already there.

-------------------------

ckMood | 2023-12-29 03:57:24 UTC | #32

This is what I'd like to see.

-------------------------

Bonobo | 2023-12-29 05:39:56 UTC | #33

I wasn't aware ATOM is already doing this. I'm disappointed such a basic concept is missing.

-------------------------

dieter.sommer | 2024-01-04 08:23:45 UTC | #34

Happy new year!

Thank you for your thoughtful post on compliance! I fully agree with you that compliance is a cornerstone of Web3 adoption and that having mechanisms / tools to enable dapps to help be compliant can be a big advantage. This is definitely something we will think more about for the Internet Computer's roadmap in 2024 and beyond.

Do you already have specific things in mind in this domain that you can share with us?

-------------------------

barolukluk | 2024-01-04 08:37:22 UTC | #35

Cross subnet composite query calls.

-------------------------

dieter.sommer | 2024-01-04 08:38:26 UTC | #36

Thank you for triggering this excellent discussion and many thanks to everyone who has contributed their thoughts. An update of the public roadmap is currently in the making and the discussions here will help to further shape it. Some of the items mentioned here are already contained in the roadmap, others are great ideas to consider. Hope the great discussion here is continuing like this!

-------------------------

lastmjs | 2024-01-04 15:54:43 UTC | #37

ZK or other identity solutions that prove sanctions compliance, country of origin, uniqueness, accredited investor status, etc without compromising egregiously on privacy.

Gitcoin Passport, Coinbase Verifications, Ethereum Attestation Service, Reclaim Protocol, etc.

My dream is to be able to just attach a cryptographic string to a transaction and have that transaction thus be compliant. Simple simple simple for developers, as little burden as possible for users, replicating the pii as little as possible.

-------------------------

lastmjs | 2024-01-04 16:13:55 UTC | #38

I would like my 2024 wishlist to be part of this thread, I'm going to post my list...I encourage everyone else to do the same, so I hope I don't just dominate the conversation.

All taken from: https://x.com/lastmjs/status/1742635444700094834

-------------------------

lastmjs | 2024-01-04 16:15:44 UTC | #39

# Drastically increase Wasm binary limit/dfx chunk uploading

Since genesis canisters have been severely limited in their total Wasm binary size (total size of code and data essentially), and this limit has been essentially priority #1 for [@demergentlabs](https://twitter.com/demergentlabs) to remove to enable the full glory of TypeScript, JavaScript, Python, and GraphQL applications on the IC.

We must finish increasing the Wasm binary limit! This limit was lifted partially in 2023, but developers still can't directly deploy large Wasm binaries with dfx, making the changes somewhat useful but still cumbersome and difficult.

Luckily [@dfinity](https://twitter.com/dfinity) seems very close to delivering an initial solution to this problem.

-------------------------

lastmjs | 2024-01-04 16:16:13 UTC | #40

# dfx extensions

Rust and Motoko devs have a very nice dfx.json experience. They get tidy and small dfx.json files with "type": "rust" or "type": "motoko", and much of the underlying complications are abstracted away.

Azle and Kybra and other language CDKs don't have these benefits yet, but dfx extensions promises to provide a solution so that they can be on par with Rust and Motoko.

We've been pushing for this since 2022, and development on it seems slow or stalled, so I'm putting this at a medium likelihood of shipping.

Would be so nice...

-------------------------

lastmjs | 2024-01-04 16:17:35 UTC | #41

# Wasi improvements

Wasi stands for WebAssembly System Interface. It's a low-level standard for Wasm modules that essentially allows OS-level API access. This provides standard access to things like the file system, environment variables, and (tcp?) sockets.

We have a nice polyfill of Wasi working on ICP right now, it's powering both Azle and Kybra. It works well.

I would like to see it improved though. I want to see the missing Wasi functions implemented, especially the socket functions. There will be pushback on this, but I wonder if there is a way to implement sockets at least if scoping their functionality down to provide HTTP functionality only.

I would also like to see the polyfill bumped up to an official integration into the replica or Rust CDK...I don't know, something more than just a polyfill.

Wasi lays the foundation for allowing Azle and Kybra and other CDKs to support as many OS APIs as possible, opening the door to as many PyPI and npm packages as possible.

-------------------------

lastmjs | 2024-01-04 16:18:04 UTC | #42

# Robust database solutions

I'm not sure I can overstate the importance of this one...various people have brought this up, it has come up relatively often in the forum, I've been heavily involved in building one of these things for ICP that unfortunately has dropped out of traction...

WE NEED A DATABASE ON ICP.

Not an ICP-specific database that is immature, not severely limited data structures with some features of a database...no we need an actual database that people have already heard of, that's trusted, that's robust and mature.

We need Postgres, MySQL, MongoDB, SQLite, vector DBs, etc etc etc.

Even Sudograph, the GraphQL database I built specifically for ICP, is something that I'm rethinking. We've definitely deprioritized it for the moment.

Instead we're aiming to enable as many JavaScript/Python databases that already exist as possible, that's why Wasi and other low-level API support is so crucial to us.

We want people to be able to grab their favorite DB off-the-shelf.

Once that is a reality, of course we will look into the benefits of an ICP-specific DB. I still think Sudograph could provide one of the best developer experiences possible, but a good-enough experience is better than that in the short-term I believe, and there still isn't a good-enough DB experience on ICP that I know of.

This needs to be done.

-------------------------

lastmjs | 2024-01-04 16:18:29 UTC | #43

# HTTP improvements

Look...ICP has some pretty "neat" HTTP funtionality. It does work for some use cases, maybe a good amount of use cases. But both incoming and outgoing HTTP functionality is still limited.

I don't have many detailed specifics for this, but reducing latencies, cycle costs, allowing HTTP outcall queries, and essentially moving towards the most full-featured HTTP capabilities possible (think browser/Node.js fetch, or the most popular HTTP client library of your favorite language)...that should be the goal.

If ICP is to be adopted as a mainstream backend technology, we need to improve the HTTP capabilities so that the trade-offs aren't so appalling.

-------------------------

lastmjs | 2024-01-04 16:19:26 UTC | #44

# The rise of JSON and the decline of Candid

I want to push as far as possible on this new JSON-centric (or maybe Candid uncentric) philosophy. You can read more about this here: [https://x.com/lastmjs/status/1735690729723195808‚Ä¶](https://twitter.com/lastmjs/status/1735690729723195808)

I'm still not sure what this will look like, as Candid is so integral to the ecosystem as it is now.

But perhaps there are ways for JSON and Candid to interoperate, and abstractions that could be built to remove as much developer complexity away from the end developer as possible.

Let's make ICP a decentralized server environment, letting devs use the tools and technologies they already know and love.

-------------------------

lastmjs | 2024-01-04 16:20:29 UTC | #45

# Trusted Execution Environments/Secure Enclaves

Finally to a high probability of shipping! I think this is it, this is the year that we get a major boost in private computation from TEEs/SEs.

If you aren't familiar with the benefits here, just take a quick think: right now all canister data is stored in plain text on subnets comprised of various node providers. There's not much stopping them from reading all of that data, if they were motivated to do it.

Thus we are cutting out a large number of use cases because the privacy story is just too poor right now.

TEEs/SEs increase privacy by providing a secure hardware environment for private computation. It's not perfect, but an improvement to the status quo.

See this thread for more info: [https://x.com/lastmjs/status/1736088865541103617](https://twitter.com/lastmjs/status/1736088865541103617)

-------------------------

lastmjs | 2024-01-04 16:25:04 UTC | #46

# Verifiably Encrypted Threshold Key Derivation (VetKeys)

This is a similar technology to TEEs/SEs (kind of), in that it also helps to improve privacy on ICP. VetKeys are focused on end-to-end encryption though, not general-purpose private computation.

Still, VetKeys will open various use cases, and in combination with TEEs/SEs may provide some compelling privacy capabilities hard to find elsewhere, even in traditional centralized cloud environments.

You can check out this same thread for more info: [https://twitter.com/lastmjs/status/1736088865541103617‚Ä¶](https://twitter.com/lastmjs/status/1736088865541103617)

Medium probability of shipping because there seems to be some debate about its priority over Threshold Schnorr.

-------------------------

lastmjs | 2024-01-04 16:26:04 UTC | #47

# Threshold EdDSA

If you're not already aware, ICP currently has a threshold ECDSA signature scheme that allows it to custody in a more decentralized manner, Bitcoin and Ethereum private keys. This is one of ICP's most useful/unique features IMO.

This allows ICP to provide general-purpose decentralized application capabilities to other chains that embrace ECDSA as their signature scheme.

Unfortunately (or rather, it's just the way things are), ECDSA is not the signature scheme of every blockchain that might matter.

Some use EdDSA, for example: Solana, Algorand, Cardano, Stellar, Elrond, Waves, and others (according to this handy chart: [http://ethanfast.com/top-crypto.html](https://t.co/TrFOXNiCdE))

ICP as a platform for decentralizing the blockchain infrastructure of other chains is IMO one of the most powerful value propositions of ICP in the short-medium term.

Extending its capabilities to sign for some of these other chains may be warranted.

-------------------------

lastmjs | 2024-01-04 16:27:13 UTC | #48

# Threshold Schnorr

Schnorr is another digital scheme, used in blockchains like ECDSA and EdDSA, but might be especially relevant to ICP because of its utility in providing decentralized infrastructure to Bitcoin itself. 

I'm not too deep into the benefits that Schnorr would provide, perhaps [@BobBodily](https://twitter.com/BobBodily) or others can chime in.

But basically, adding EdDSA and Schnorr to the threshold suite of ICP could increase its capability and potentially dominance as a premier solution for decentralized compute across many different blockchains.

-------------------------

lastmjs | 2024-01-04 16:28:55 UTC | #49

# Robust decentralized identity/kyc solution

You might not like giving up your personal information, you might not like being surveiled by companies and governments, you might not like complying with what can seem like arbitrary or harmful laws...but sorry we live in a society and the rule of law is pretty important for its functioning.

That doesn't mean we have to put up with the same low quality and harmful way of doing things. Decentralized compliance solutions could provide a very nice compromise, where our privacy risks are minimized and our freedom and autonomy is maximized.

Decentralized identity and kyc are very promising technologies that have been gaining some momentum in the last year or so.

Gitcoin Passport, Coinbase Verifications, Ethereum Attestation Service, etc are all examples of this.

[@dfinity](https://twitter.com/dfinity) has started work incorporating verifiable credentials into Internet Identity.

With some combination of all of these technologies, I'm feeling rather confident we'll have some compelling solutions going by the end of 2024.

You can read a tiny bit about Internet Identity's plans for verifiable credentials here: [https://forum.dfinity.org/t/verifiable-credentials-in-icp/24966‚Ä¶](https://t.co/n0iUcEu5nF)

P.S. it's also not all about compliance, but proving unique personhood (sybil resistance) is just plain important in general

-------------------------

lastmjs | 2024-01-04 16:49:59 UTC | #50

# ckUSDC (ckERC20)

Do we need to go over again how important stablecoins are? I'm highly confident we will get bridged stablecoins on ICP in 2024. I imagine that ckUSDC will be prioritized, but others will probably follow relatively easily.

Once we have ckUSDC, we're on a path to native issuance of UCDS from [@circle](https://twitter.com/circle). Of course it's up to them in the end, but having a thriving ckUSDC ecosystem on ICP will help persuade them to eventually issue USDC natively, which is the best we can hope for from [@circle](https://twitter.com/circle) and USDC.

-------------------------

lastmjs | 2024-01-04 16:50:36 UTC | #51

# Canister logging and monitoring

Canisters pushed to the production network have been somewhat difficult to monitor for errors, bugs, memory leaks, etc.

If we want ICP to be a compelling alternative to centralized cloud environments, we're really going to need to be able to debug complex issues that may crop up in production.

At least for canister logging, I am very confident we'll see some solutions out this year.

And as for monitoring, I haven't thought too deeply about what is needed here and what currently exists to meet those needs, but monitoring live things like cycle usage and memory consumption seem pretty important.

We also need to figure out automatic top-up of canisters that are running low on cycles, using credit cards or other traditional payment rails.

-------------------------

lastmjs | 2024-01-04 16:51:45 UTC | #52

# Canister backup and restore

It's pretty scary to deploy canisters and upgrade them right now...every time you deploy new code, the heap is wiped and the canister is essentially restarted from scratch. Stable memory must be used to store data across these upgrades.

Stable structures and variables (Motoko?) help with this process...but what if something goes wrong? What if you try to migrate a stable structure or your stable memory and you mess up?

Canister backup and restore would help to alleviate these concerns. You can read up on the latest proposal for this here, it seems more in the design and discussion phase right now: [https://forum.dfinity.org/t/canister-backup-and-restore-community-consideration/22597](https://t.co/HYeTeKjgar)

-------------------------

lastmjs | 2024-01-04 16:52:39 UTC | #53

# Increase all instruction limits

ICP imposes a number of limits on how many Wasm instructions can execute depending on the type of call. You can see these limits here: [https://internetcomputer.org/docs/current/developer-docs/production/resource-limits‚Ä¶](https://t.co/Yg3wgBCbjS)

These limits are often too low! We hit them regularly, and can foresee hitting them much more especially once we get into complex database queries that rely on query calls for low latency.

Query calls have a 5 billion instruction limit currently, which is about 1 second of computation (very rough heuristic). Update calls are 20 billion instructions which is about 4 seconds of computation.

I'm telling you it's not enough, it's not enough for all of the many use cases we want to enable on ICP.

If we don't remove these limits we'll have to reimplement algorithms to chunk them across multiple calls, and the dream of pip/npm installing any package and having it just work will be very hard if not impossible to achieve.

-------------------------

lastmjs | 2024-01-04 16:53:11 UTC | #54

# Reduce call latencies (query calls, update calls, cross-canister calls, http outcalls, etc)

This is similar to the instruction limits, these latencies provide a general drain on the use case potential of ICP. The latencies are just too much sometimes, it makes for a general slow and sluggish experience that is just not as good as the Web2 alternative.

We really need to optimize these latencies...I have hope that we can cut them in half, but what's scary is what comes after that. ICC (Internet Computer Consensus), similar to other consensus mechanisms, requires a two-phase commit that requires multiple rounds of communication to achieve consensus. This is difficult to optimize, there is an obvious floor on the latency.

We may need to embrace certain optimistic trade-offs to reduce latencies, they're just not acceptable for what ICP is trying to achieve.

-------------------------

lastmjs | 2024-01-04 16:53:38 UTC | #55

# Increase or abstract away all message size limits

Similar to instruction limits and call latencies, message size limits are a pain to deal with. Depending on what you're doing, the limit is somewhere in the low MiBs...so if you try to upload anything of a reasonable size, like a 1 GiB file, you're pounded with having to implement chunking complexity custom to your canister.

Asset canisters have some nice abstractions, as will dfx deploy soon for the Wasm binary, but this problem needs a general solution. We either need to get rid of the message size limits (difficult if not impossible), or provide more generalized abstractions.

-------------------------

lastmjs | 2024-01-04 16:54:17 UTC | #56

# Full Inter-Canister Query Calls

Right now a canister is allowed to query another canister with low latency given certain limitations. This opens the door for some use cases, but the limitations are not ideal.

It would be wonderful to have full unrestricted Inter-Canister Query Calls, bringing cross-canister queries to be a first-class communication method just like update calls are.

P.S. on full Inter-Canister Query Calls, this may be incredibly important to implementing extremely scalable databases in the future, as these DBs must be able to provide complex querying across multiple canisters for the ultimate scaling to be possible.

-------------------------

lastmjs | 2024-01-04 16:54:37 UTC | #57

# Atomic cross-canister calls

This one might be...impossible?

Just imagine if cross-canister calls were atomic. Imagine if at any point in a chain of calls, that if one thing went wrong that all of the state changes across all canisters were automatically cleaned up.

This would help enormously in implementing a scalable multi-canister database, and would probably solve a number of other issues and use cases as well.

The fundamental issue I believe is how to do this without sacrificing ICP's scalability...but perhaps we can work towards this by using techniques similar to what Solana or other chains are doing (from my brief listenings-in), where state could somehow be separated out into isolated threads of execution, and the performance penalty perhaps limited in that way.

-------------------------

lastmjs | 2024-01-04 16:57:01 UTC | #58

# Ensure ICP is credibly neutral

Look I feel that one of the main weaknesses of ICP from a blockchain-focused angle is it's lack of credible neutrality.

ICP is definitely on a journey towards decentralization. Various components are currently in various stages of decentralization.

But what is clear is that [@dfinity](https://twitter.com/dfinity) has write access to the protocol, essentially allowing them to change anything about the protocol at will.

The process is very transparent though, and many ICP holders follow [@dfinity](https://twitter.com/dfinity) (this has a debate because of genesis neurons and automatic following though), and [@dfinity](https://twitter.com/dfinity) has a reputation and a lot of reason to not perform maliciously.

But that's not really the point, it's not about [@dfinity](https://twitter.com/dfinity) or whoever else is currently the majority followee...to be credibly neutral I believe that the protocol should never allow one entity to have write access to the protocol.

ICP lacks checks and balances. It uses a simple liquid democracy that allows for massive centralization of power without much of a check on that power.

I would like to see various groups gain more power in the protocol, more stringent decentralization checks on proposals for passing, and...really just checks and balances, mutiple independent groups with power, we shouldn't be allowed to vote in an all-powerful entity.

I would love to debate this more to get to some good solutions, I used to engage heavily on this topic but it seems unproductive, so now I'm focused more on just building and getting adoption for ICP.

I do think the issue of credible neutrality needs to be addressed before certain major projects will be willing to trust themselves to ICP, as the NNS is always the ultimate risk at the end of the day.

-------------------------

rossberg | 2024-01-05 11:00:46 UTC | #59

[quote="lastmjs, post:52, topic:25726"]
It‚Äôs pretty scary to deploy canisters and upgrade them right now‚Ä¶every time you deploy new code, the heap is wiped and the canister is essentially restarted from scratch. Stable memory must be used to store data across these upgrades.

[...]

Canister backup and restore would help to alleviate these concerns.
[/quote]

The reason why the heap can't survive a code upgrade isn't that the memory image could not technically be kept alive, the reason is that the memory image usually is incompatible with the new code ‚Äì even the smallest seemingly innocent program change, or just a compiler update, can easily invalidate the complete memory layout.

Backup and restore cannot solve this problem, it is unsolvable in general.

Expect no magic here, the only adequate solution is that applications move towards a more traditional separation of short-term vs persistent data. That is, make sure that all permanent data is explicitly written to stable memory, like you would write to a file or database on a conventional platform. For that, we need higher-level libraries for managing data storage in stable memory. (Developing the right patterns for this might also go a long way towards dealing with non-atomic message rounds and explicit commits.)

-------------------------

lastmjs | 2024-01-05 15:29:31 UTC | #60

But if something goes wrong in the slightest like you're saying, and it's detected after a deploy, wouldn't it help to be able to restore everything back to a previous stable memory/heap and Wasm binary?

-------------------------

rossberg | 2024-01-05 16:27:41 UTC | #61

Perhaps, but when and how do you expect to discover that?

If you're checking post-upgrade integrity systematically, through some kind of validation, then you should probably do that in the post-upgrade hook ‚Äì in that case, failure can automatically trigger a roll-back to the pre-upgrade state. Nothing new is needed.

If, on the other hand, you discover a problem only incidentally, then likelihood is that it happens too late for a clean revert, since some state changes may already have happened in the meantime. True, it could still serve as an additional safety net for worst-case scenarios, but I suspect in practice it would be rather difficult to recover even with that.

(Of course, you should also take all the help you can get from the compiler, like, Motoko's warnings about lossy changes to stable variable types.)

-------------------------

dfisher | 2024-01-05 21:35:51 UTC | #62

Yes please meaningfully enter the race to be the technology behind CBDCs through private blockchain tech / subnet rental tech. 

Perhaps can work with Swiss banks to launch a stablecoin with subnet rental. 

See here, missing major opportunity to not throw hat in the ring. Big governments spending big money. 

https://www.dlnews.com/articles/regulation/ecb-to-pay-more-than-one-billion-euros-for-digital-euro/?tpcc=NL_Marketing

-------------------------

josephgranata | 2024-01-06 18:03:08 UTC | #63

Here is my wish list for ICP in 2024 after working with the stack for about a year, not trading, actually developing on it, first on Motoko and next on Rust.

The IC wants to become the crypto cloud, amazing, let DFINITY do this in 2024 please:

1. Bring REST to the IC, modify Candid accordingly
2. Bring Actix, one of the most powerful Rust frameworks to the IC. We should not be rebuilding this every time we do a DAPP.
3. Give us a working file system. We should not emulate one, or build it from scratch. This is by the way a requirement for #4 below.
4.  Give us a way to upload files to the IC with 10 lines of code, no excuses. Python can do this easily.
5. Port a major database to the IC and make it work first for one canister, and later for multi canister apps.

That would make me quite happy, I hope at least some of this get done.

Happy New Year everyone!

-------------------------

Sormarler | 2024-01-06 18:01:48 UTC | #64

@dfinity, let's make this happen. If not, what are the technical reasons preventing these features?

-------------------------

w3tester | 2024-01-11 11:51:27 UTC | #65

Nice post! Indeed, regulation will come one way or another. The best we can do is to prepare for it, exploring a method to do e.g. KYC the Web3 way while meeting regulatory requirements.

One possible solution we are building using [Legit ID](https://legit3.id) is to combine W3C DID/VC and ZKP to prove identity attributes while preserving user privacy, e.g. proving one is a qualified adult investor from EU without disclosing one's PII. 

We will explore how to integrate this function into ICP using the II in early 2024.

-------------------------

infu | 2024-01-12 20:31:10 UTC | #66

Motoko wishlist, some practical things that can save time:
- Errors "expression of type ... cannot produce expected type ..." could pinpoint the problem. In some cases, they just output both objects and let you wonder what's wrong.
- public functions being able to return objects that have 'var' inside - some kind of auto-conversion.
- Luc's stable memory. Luc ftw

Other:
- NNS Dapp - able to sign IC calls, perhaps with the new Identity WG standards. 
- NNS  & SNS - sign 3rd party messages with neurons, so they can send signals not only to proposals but to anyone who wants their signal.

-------------------------

cryptoschindler | 2024-01-17 13:29:07 UTC | #67

Did you try this already? If so, are there any shortcomings you experienced?

https://github.com/froghub-io/ic-sqlite/tree/main/examples/backend

-------------------------

lastmjs | 2024-01-17 14:42:03 UTC | #68

I had been in contact with someone who was using this heavily, I believe there were still a number of limitations, though I'm not sure on the current status.

-------------------------

dfx-json | 2024-01-18 20:37:53 UTC | #69

Love the discussion on this thread. I would like to share the draft Motoko roadmap for 2024 and get your inputs on how we should prioritize our work. 

To accomplish this, I've put together a typeform survey. You can fill it out here: https://ynfsok7ybmn.typeform.com/to/Oogyp649

I also plan to review this thread in it's entirety and do my best to commit to what the community wants most!

Looking forward to your feedback, thank you.

-------------------------

skilesare | 2024-01-18 22:09:14 UTC | #70

These are great!  I had some questions though:

3 - Don't really understand the benefit of this...sounds cool though.
4 - Is this basically reflection?  If I'll be able to do typeof(x) == MyType then I'm all for it. :)
5 - Is there something about the current certification library that is lacking? Is this basically optimization on @nomeata 's library?  Or something more aligned with v2 certification?
6 - I have some concerns about pushing too much into base.  This could be seen as....not necessarily coopting work, but we do want to support 3rd party library development. If everything has to go into base it could dissuade that small part of ego that devs sometimes have and/or put out an external facing view that looks like 'just wait for dfinity to do it'.  I think that can be overcome! Perhaps with reward bounties for things that make it into base...we could even do some fun NFT thing for devs that get code into base.
7 - Why not IC based debugging :grimacing: (other than it is harder).  This is mostly targeted at base library devs right?  The second you start doing async you'd lose the ability to debug?
8 - I don't understand this one at all.  Would these be type annotations to my types? (so could I use #ok in my motoko class but it looks like #Ok to external programs?(And why didn't the motoko team sync the Result object with how System Canisters were doing #Ok?
9 - A nice to have, but any serious work likely needs an IDE of some kind?  Maybe? Probably?  Can't someone like github or VSCode Online draw on more resources to do this kind of online editing?
10 - I'd encourage Motoko devs to write tests in Motoko and not ICRepl. It makes you a better motoko dev!
11 - Is this just like type MyType =  "mo:myclass/lib/MyType"?  What would this look like?
12 - I'd actually love to get a broader opinion on this thought:  I know it is best practice to split things up, but as I begin to rely more and more on bootstrapping things with AI, it is actually really beneficial to have as much context in One file as possible.  I've never started keeping my types together some times.  Don't throw rocks!
13 - I thought this was already in? What would be the "more comprehensive" part?
14 - Now you've peaked my interest. Is this a bitfinity EVM type thing?  In what way would solidity be able to call motoko?  Or is this a bootstrapping mechanism that could take a solidity contract and try to shell out a motoko contract from it?
15 - What makes something 'unreachable'?  My use of memory in the past has been write and forget and only read when the program looks it up.  Maybe this is related to the more advanced stable evolution...in that case, yes I want GC :slight_smile: 
17 - What are you doing here reading this post...go work on that immediately..üöÄüöÄüöÄüöÄüöÄ
18 - I'm not sure what extra this gets you...maybe it is wonderful, but I'd encourage all motoko devs to build their integration tests in motoko to get better at motoko and to better understand how the IC canister to canister interaction works.  I'm sure there are use cases and I'd love to hear them! Maybe if you have to do main net testing?
19 - This would be awesome especially if we could download our canister state.
20 - I'm not sure I understand this one?  Would this be like secure enclave access? or encryption at rest? Something like that?
21 - I'd prefer to keep this at ingress and have things handled internally as candid....maybe the boundary node could take a translation file or something?  I think newer devs would love to just send json to their canisters. I do think some way to bootstrap from a swagger file to a motoko template would be very cool. 
23 - Huge for adoption!!!

I probably need to resubmit my responses after better understanding these. :slight_smile:

-------------------------

kpeacock | 2024-01-18 23:48:03 UTC | #71

Commenting just to indicate I've read this thread and like the discussion

-------------------------

rvanasa | 2024-01-19 18:42:50 UTC | #72

Here is some quick clarification for a few of the survey items:

13 - The concrete goal here is to add a file system API to the WASI runtime. 

14 - I was thinking that we could create a command-line tool which generates Solidity smart contract bindings as a Motoko module (converting ABI to Candid and generating code for calling the [EVM RPC canister](https://github.com/internet-computer-protocol/ic-eth-rpc)). For example, if you wanted to call a contract in Motoko, you could run a command to generate the bindings and then call the contract from Motoko as though it's any regular async function. This would also give us momentum for doing something similar the other way around (i.e. calling IC canisters from Solidity).

18 - If you've come across the `ic-state-machine-tests` crate for the Rust canister ecosystem ([example usage](https://github.com/internet-computer-protocol/ic-eth-rpc/blob/71f957c057faf939f70addd32c5ebe9306fd0d26/tests/tests.rs#L1459)), this would be an equivalent for Motoko. It would essentially be a way to deploy canisters, mock HTTP outcalls, etc. in a simulated replica with all tests written purely in Motoko. We're currently gauging interest for this, since it's more powerful but has a lot of overlap with [ic-repl](https://github.com/dfinity/ic-repl#readme) and other existing integration testing tools.

Cheers!

-------------------------

dfx-json | 2024-01-19 18:59:37 UTC | #73

Hope it's okay to co-opt this thread a bit @lastmjs 

I'd like to also share the SDK Roadmap Community Survey and get your opinions on what the SDK team should focus on this year. We want to know what you'd like to see in your tooling! You can find the survey here: https://ynfsok7ybmn.typeform.com/to/O3J8OIeJ

-------------------------

claudio | 2024-01-19 19:40:50 UTC | #74

> 3 - Don‚Äôt really understand the benefit of this‚Ä¶sounds cool though.
*Graph Copy*

*Related to the orthogonal persistence, offer a mechanism for flexibly changing the memory layout in the future. For such rare cases, implement a scalable heap serialization that also supports 64-bit representations.*

This is basically fixing the long standing issue with serialization and deserialization of stable variables that: 
1) doesn't handle value graphs properly, exploding them to trees and duplicating large value (text/blobs).
2) can't deal with large amounts of data
3) can stack overflow on moderately deep data-structures (e.g. linked lists).

These limitations are artifacts of using an inappropriate Candid-derived serialization format that can and should  be avoided by using better serialization techniques (when needed). Candid is great as a wire format for small messages, but not great as a data storage format for large volumes of data.

4). Is this basically reflection? If I‚Äôll be able to do typeof(x) == MyType then I‚Äôm all for it.

Although it could be used for this, we really don't want to go there: reflection lets you break all sorts of abstraction properties and is a bad idea in general (even though it can be convenient). Really, it's main application is to enable the graph-copy based stabilization/destabilization algorithm to accommodate (in-memory) data representation changes when necessary. But it also helps data recovery and debugging tools by letting them look at the representation of a value to determine its type rather than consulting out-of-band type information (which we may not even have).

> 7. - Why not IC based debugging :grimacing: (other than it is harder). This is mostly targeted at base library devs right? The second you start doing async you‚Äôd lose the ability to debug? 

It's just because it's easier than full IC debugging, tbh. Don't let the best be the enemy of the good and all that.

> 11. Is this just like type MyType = ‚Äúmo:myclass/lib/MyType‚Äù? What would this look like?
```
import { type List; pop } = "mo:base/List";
```
i.e. allow destructuring/pattern-matching imports to bind type components as well as values.

> 15 - What makes something ‚Äòunreachable‚Äô? My use of memory in the past has been write and forget and only read when the program looks it up. 

It's the job of the GC to recover memory that is no longer referenced (reachable) from the live data of your program. The GC does this for ordinary Motoko values but not the special region objects. Currently, if you drop a reference to a region object the  stable-memory dedicated to that the region will never be reclaimed nor reused but could (and really should) be in future.

-------------------------

dfx-json | 2024-01-22 20:48:21 UTC | #76

Reminder to add your votes to the surveys. Voting ends tomorrow (1/23) EOD. 

[SDK 2024 Roadmap Community Survey ](https://ynfsok7ybmn.typeform.com/to/O3J8OIeJ) 
[Motoko 2024 Roadmap Community Survey ](https://ynfsok7ybmn.typeform.com/to/Oogyp649)

Thanks!

-------------------------

ckMood | 2024-01-26 19:01:25 UTC | #77

Known Neurons functionality in SNS

-------------------------

atomikm | 2024-01-28 14:41:39 UTC | #78

I love that you wrote all these out Jordan, and I believe they touched on many of the issues/roadblocks that developers on ICP experience.

I'm going to focus on a feature you mentioned that has been a massive blocker for us, and is a major limitation for any serious dapp on ICP.

I'm referring to **Full Inter-Canister Query Calls**.

Or another way to phrase it would be "Being able to do a Composite Query during an Update Call"

To build a scalable database on ICP, there is a big limitation in that inter-canister query calls take as long as update calls. Of course, this has improved with composite queries, but they only work if the originating call is a query call. If you're trying to query another canister during an update call, then the query call is treated like an update call, and adds 2-3 seconds.

In order to build massively scalable databases on ICP, you need to scale horizontally by spreading data in thousands of canisters. However, the blocker I mentioned above leads to it taking 4-6 seconds to make modifications to data in databases. An example flow is a user calls a dapp canister, which queries a database canister. Then the dapp canister does modifications to the data, then returns the response back to the user. This takes 4-6 seconds minimum because it's the equivalent of two update calls. If the dapp canister could make a composite query to the database canister during the update call, and the composite query takes 100-200ms, this would be a huge milestone. It would allow for complex and scalable databases to be built without the dapp being super slow.

It's a major blocker for us and any serious dapp on ICP. I hope it gets prioritized. We want to show how fast ICP can be!

Also, another feature we would love is being able to download canister state as a backup file and restore it to the canister in case data becomes corrupted during an upgrade. Would make upgrades way less stressful.

-------------------------

free | 2024-01-29 09:54:02 UTC | #79

[quote="atomikm, post:78, topic:25726"]
An example flow is a user calls a dapp canister, which queries a database canister. Then the dapp canister does modifications to the data, then returns the response back to the user. This takes 4-6 seconds minimum because it‚Äôs the equivalent of two update calls.
[/quote]

That is not exactly accurate. A canister-to-canister call can be "instant" (i.e. it may complete in the same round) if the callee is on the same subnet; or it will take 5+ seconds if the callee is on a different subnet. Of course it all depends on subnet load (no canister is guaranteed to get scheduled every single round unless it pays for 100 CPU allocation; and there isn't all that much CPU to allocate).

In your particular case, I'm not sure whether the 4-6 seconds you're observing are simply ingress latency plus one second here and there due to subnet load, preventing everything from being scheduled in one round (and your canisters are both on the same subnet); or it's because you're actually making cross-subnet calls and that's just how long a cross-subnet call takes.

[quote="atomikm, post:78, topic:25726"]
If the dapp canister could make a composite query to the database canister during the update call, and the composite query takes 100-200ms, this would be a huge milestone. It would allow for complex and scalable databases to be built without the dapp being super slow.
[/quote]

Again, that is not exactly accurate. On the same subnet, it is likely more (or just as) efficient to make a replicated query call as it would be for every replica to independently execute a non-replicated query. And cross-subnet, it would still not be advisable to implement it the way you describe it, because would basically block replicated execution (and stall the caller's subnet) for however long it takes to execute the query.

But it is an interesting idea for reducing cross-subnet latency nonetheless. Currently, as said above, a XNet call has a latency of 5-6 seconds (essentially 2x ingress latency, because first the request then the response have to be included into into a block, block needs to be finalized; message executed; resulting state certified). It would be technically possible to introduce a "read-only XNet call" (or "XNet query") that would work more or less like an HTTP outcall, except as opposed to requiring every replica on the caller subnet making the call and then achieving consensus, it could rely on a single call and either certified variables or a certified query (where f+1 replicas are queried and each of them certifies the response). Something like this may theoretically cut latency in half.

It's not something that is likely to get picked up any time soon, but it's definitely worth keeping in mind. Thanks a lot for the suggestion.

-------------------------

peterparker | 2024-01-29 10:07:29 UTC | #80

Given that it has not yet been listed, a drastic reduction in the size of agent-js and the removal of all its NodeJS dependencies for the browser.

This would be beneficial and impactful for anyone building frontend dApps on the IC.

-------------------------


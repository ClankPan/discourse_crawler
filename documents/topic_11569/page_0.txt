ildefons | 2022-03-18 11:45:17 UTC | #1

I would like to implement a machine learning package for Motoko. This would be handy when creating canisters interacting with other canisters (e.g. trading bot) or quickly preprocessing data retrieved by oracles by means of future http requests.

Most machine learning methods uses linear algebra methods for instance to multiply, decompose or invert matrixes. Usually linear algebra functions implemented in high level languages like Python call highly optimized well-known packages like LAPACK which offers high-quality and very well tested subroutines for linear algebra. 

Reimplementing a linear algebra library in Motoko is out of question due to implementation and maintenance complexity.

In cases like the one described where it is not feasible to implement a functionality in Motoko, does it exist a way to create a Motoko interface able to call an existing library?

-------------------------

paulyoung | 2022-03-18 15:23:21 UTC | #2

I don‚Äôt believe so but it looks like there has been some discussion about this.

https://github.com/dfinity/motoko/issues/2303#issuecomment-772445477

https://github.com/dfinity/motoko/issues/1905

@claudio might be able to say more.

A way to achieve something similar today would be to compile an existing package to Wasm and expose it as a canister.

Here‚Äôs an example of doing that in C: https://github.com/dfinity/examples/blob/6f9478f1976d76d93a35ab141437648f715b44d8/c/qr

What missing there is a `.did` file that would allow other canisters to know how to call into it. See https://sdk.dfinity.org/docs/candid-guide/candid-concepts.html

-------------------------

ildefons | 2022-03-19 09:58:56 UTC | #3

@paulyoung, Thank you very much for the reply. I think that to expose a full LAPACK library as a canister is not a good approach in my case because the main motivation of creating a linear algebra in Motoko is precisely to simplify the development of machine learning libraries in Motoko, so having to run an additional canister just to use a Motoko library seems against the main purpose to simplify things. 

I really think that to make Motoko a mainstream language to implement sophisticated contracts, it will be necessary a simple way to interface external libraries compiled in WASM.

By the time being, I have no more option that moving my project to Rust and using the many ML/AI libraries available in Rust.

@paulyoung @claudio, Can I use any Rust library if I develop my canister in Rust or are there any restrictions? 
I'm asking because @skilesare says that:
[quote="skilesare, post:2, topic:11503"]
Rust has a bunch of existing libraries that can be leveraged as long as you are doing only small bits of work in your contract.
[/quote]
I don't understand what is exactly this limitation. Could you explain to what extend I can reuse Rust libraries?

-------------------------

paulyoung | 2022-03-19 14:44:38 UTC | #4

[quote="ildefons, post:3, topic:11569"]
Can I use any Rust library if I develop my canister in Rust or are there any restrictions?
[/quote]

I think this comment sums it up pretty well: https://github.com/dfinity/cdk-rs/issues/123#issuecomment-1042424271

-------------------------

ildefons | 2022-03-19 14:59:56 UTC | #5

Why is that I can only do "small bits of work" in my contract when leveraging using existing libraries?

-------------------------

paulyoung | 2022-03-19 15:02:29 UTC | #6

In my experience you aren‚Äôt limited to ‚Äúsmall bits of work‚Äù.

The comment I linked to above by @AdamS says:

> Rust is a great language to develop on the IC, and many of our official canisters like certified-assets and cycles-wallet are written in Rust. The limitations are those of any other WebAssembly target; `std` is available, but most functions available in `std` but not in `alloc` other than threading primitives will panic/error/generally do nothing useful, such as `std::fs` functions. This should allow you to compile against most any crate, but any code path that actually *attempts* to, for example, read the file-system, will unconditionally error. Shouldn't be a problem for any library crates that don't interact with I/O at all.

-------------------------

paulyoung | 2022-03-19 15:07:06 UTC | #7

[quote="paulyoung, post:6, topic:11569"]
In my experience you aren‚Äôt limited to ‚Äúsmall bits of work‚Äù.
[/quote]

To clarify, there are currently some limitations such as the amount of work that can be done in a single block but these apply to the IC in general and aren‚Äôt specific to using Rust.

-------------------------

ildefons | 2022-03-19 15:33:51 UTC | #8

I am sorry this is really confusing for a beginner like me. Is this paragraph saying that I can basically use any Rust library as long as this library is not attempting to use the file system? is there any other constraint?

-------------------------

ildefons | 2022-03-19 15:35:11 UTC | #9

Where can I find more information about the "limitation of work that a canister can do in a single block"?

-------------------------

paulyoung | 2022-03-19 15:43:19 UTC | #10

This has some good information: https://forum.dfinity.org/t/deterministic-time-slicing/10635

-------------------------

ildefons | 2022-03-19 15:53:29 UTC | #11

Looks like this is one more reason why I need to way to call a library function instead of a canister method. It confirms the need a "simple way to interface external libraries compiled in WASM" instead of calling a canister.

Concerning my previous question about @AdamS comment, is he saying that "I can basically use any Rust library as long as this library is not attempting to use the file system?" is there any other constraint?

-------------------------

paulyoung | 2022-03-19 15:57:18 UTC | #12

[quote="ildefons, post:8, topic:11569"]
Is this paragraph saying that I can basically use any Rust library as long as this library is not attempting to use the file system?
[/quote]

The file system is one example. I don‚Äôt know if there‚Äôs a comprehensive list of what does/doesn‚Äôt work but it seems there may be an opportunity to create a resource that does so.

[quote="ildefons, post:8, topic:11569"]
is there any other constraint?
[/quote]

Below is another limitation, at least for now. I thought this might interest you as well.

https://forum.dfinity.org/t/wasm-module-defined-globals-which-exceeds-the-maximum-number-allowed-200/10834

-------------------------

ildefons | 2022-03-19 16:04:12 UTC | #13

[quote="paulyoung, post:12, topic:11569"]
it seems there may be an opportunity to create a resource that does so
[/quote]

I ¬¥m sorry, I don¬¥t understand what your are referring to when you write "resource", "does so" ?

-------------------------

paulyoung | 2022-03-19 16:08:15 UTC | #14

I meant some documentation that people like you and I could refer to when we‚Äôre wondering what we can and can‚Äôt use üôÇ

Some sort of static analysis tool that informs people of unsupported API usage would be great as well.

-------------------------

paulyoung | 2022-03-19 16:23:06 UTC | #15

[quote="ildefons, post:8, topic:11569"]
is there any other constraint?
[/quote]

There is also a limitation with individual message size being capped at 2MB.

This means that it‚Äôs possible to create a Wasm file that is too large to be deployed using traditional methods.

I think @skilesare has a workaround for that scenario.

-------------------------

skilesare | 2022-03-19 16:57:31 UTC | #16

You are still constrained by the inter canister message size.(I think 3MB), but using a canister you can apprend a couple chunks and get up to that limit. The ledger canister is just over 2MB so you have to use this method.

-------------------------

skilesare | 2022-03-19 19:05:56 UTC | #17

[quote="ildefons, post:1, topic:11569"]
Reimplementing a linear algebra library in Motoko is out of question due to implementation and maintenance complexity.
[/quote]

If 10 years in the future, motoko is a dominant programming paradigm in the blockchain space, do you still feel this way?

I‚Äôd argue that it is imperative for these libraries to exist in an async-bounded work cycle framework. Even if time slicing solves long running processes, I don‚Äôt think it solves blocking and we will be right back at square one where we need chunkable computation for scalability.(I‚Äôd be thrilled to be wrong here and hopefully timeslicing doesn‚Äôt block).

We have the funds and are growing the community to create these libraries. If you write up a spec for what you need and and provide sample libraries that can be easily portes to motoko, then we can write up an ICDevs bounty to try to get the work done.

Ultimately we likely need a few Manhattan project(without the mass destruction) style projects to brute force some motoko libraries. RegEx, Math Libraries, Templating libraries, workflow libraries, media libraries all come to mind.

-------------------------

ildefons | 2022-03-20 11:45:03 UTC | #18

[quote="skilesare, post:17, topic:11569"]
I‚Äôd argue that it is imperative for these libraries to exist in an async-bounded work cycle framework. Even if time slicing solves long running processes, I don‚Äôt think it solves blocking and we will be right back at square one where we need chunkable computation for scalability.(I‚Äôd be thrilled to be wrong here and hopefully timeslicing doesn‚Äôt block).
[/quote]

I think you are right. Actually Javascript seems to have implemented native linear algebra libraries. So, they probably came down to your same conclusion. For instance ["lalolib.js"](https://mlweb.loria.fr/lalolib-module.min.js) or ["numericjs"](https://github.com/sloisel/numeric/blob/master/src/svd.js) shows they have implemented singular value decomposition solvers and other solvers natively in JS. Maybe JS libraries could be taken as reference.

I think that a possible implementation strategy could be based on gradually developing 3 packages: 1) Core linear algebra and math tools, 2) machine learning library implementing a set of simple methods and 3) few simple canister examples leveraging 2. Depending of the machine learning library (2) that we decide to implement we would prioritize few core functionalities (1). So it is important to pick a useful yet simple ML method to start with package (2). A good candidate for package (2) are filtering methods like recursive least squares, multi arm bandits and Kalman filters. Filtering methods are interesting because they do not require training, therefore they do not require offline training data because these methods are adaptive. This functionality could be handy for the many "always on" forms of bots, oracles and other data processing engines.

-------------------------

ildefons | 2022-03-21 11:55:19 UTC | #19

[quote="skilesare, post:17, topic:11569"]
it is imperative for these libraries to exist in an async-bounded work cycle framework
[/quote]

@skilesare I would like to investigate further the complexities of developing such libraries. I am not familiar with the implications of developing such library in a "async-bounded work cycle framework". Could you indicate me how to learn more about this specific difficulty when developing a Motoko library?

-------------------------

skilesare | 2022-03-21 15:49:58 UTC | #20

We could have a lengthy discussion at some point, but the highlights are that you only have so many instructions that you can use. An error occurs once you run out.  So if you are doing a long running process(like updating an index on a collection), you may have to 'chunk' the process and step through the  data set over a number of consensus rounds.  Time slicing may fix this, but then I think the canister will be blocked until it finishes.

So ideally, you want to find some number of operations that take up less than half the "block" and execute your long-running calculation over a number of blocks.  In the index example, If you have 10,000 blog entries and processing 2,500 entries takes about 1/4 the block then you'd call the process 4 times.  Unfortunately, motoko can't see the current balance on remaining cycles or this would be much easier. I've had to just use trial and error in the past to find a good value.

-------------------------

ildefons | 2022-03-22 12:29:25 UTC | #21

@skilesare  @paulyoung. It seems that a library responsible to execute a large computation should divide this computation in chunks. Ok, I get the idea. So, probably Dfinity has already thought about this and they may have a "best practice" implementation pattern. I would imagine, such implementation pattern should be actually implemented in some core package provided by Dfinity due to the close connection with the details of the protocol specification. Does this package or implementation pattern exist? if it does not exist, then should we propose and implement this core package first?

-------------------------

cryptoschindler | 2022-03-22 12:36:39 UTC | #22

[quote="paulyoung, post:2, topic:11569"]
A way to achieve something similar today would be to compile an existing package to Wasm and expose it as a canister.
[/quote]

Can you also expose it as a `module` instead of of an `actor` and just reference it locally to include in your actor build?

-------------------------

ildefons | 2022-03-22 12:41:25 UTC | #23

When you write module, do you mean a motoko package?

-------------------------

cryptoschindler | 2022-03-22 12:42:51 UTC | #24

Yes exactly, that's what I mean.

-------------------------

ildefons | 2022-03-22 12:46:47 UTC | #25

This is also the suggestion by @skilesare. It seems that this is the right way. However, now the discussion moved to the problem of how to implement a motoko package where methods require a lot of computation and need to be divided in chunks to prevent errors at the end of a consensus round. I suggested/asked about the need of a standardized implementation pattern for modules doing large computations. this was the last issue along that line...

-------------------------

skilesare | 2022-03-22 13:52:03 UTC | #26

I have written https://github.com/skilesare/pipelinify.mo to do this. It allows for sequential or parallel computation. There are a few tests, but they are lacking and the documentation is even more sparse. I‚Äôm happy to answer questions about it and would love pull requests.  It also allows for streaming workloads to other canisters and pushing/pulling data back and forth.

-------------------------

ildefons | 2022-03-23 10:12:07 UTC | #27

@skilesare, thank you for sharing your project. As it is now, it would be a very significant effort to reverse engineer your code to figure out how it works (motivation of design decisions and their implementation), how to use it and whether it is at all relevant to the case of implementing a linear algebra library. 

In my opinion, the following documentation would help: 1) the problem that this library is trying to solve, 2) the design decisions that you took to address this problem, 3) functions should be commented to connect code with the design decisions, 4) finally, there should be a description of how to implement a library that use your helper library.

@paulyoung, probably the problem of executing a motoko function beyond the consensus round period is a problem that you have already addressed in some forum post and/or internally in some of your daily development tasks. Could you please advice us on how to proceed?

-------------------------

Harsh | 2022-03-23 10:30:51 UTC | #28

My team will try create couple of ML and advanced algebra modules for Motoko from their python counterparts later this year. But for the present, my question is: if JS works well in combination with Motoko and JS does have some libraries like tensorflow that can be used, wouldn't such a combination be helpful for now?

-------------------------

ildefons | 2022-03-23 10:48:02 UTC | #29

@Harsh That is great. What are for you the "ML and algebra" methods with most priority and why? It would be also interesting to know what are your plans to solve the problem we discussing in this post: how to deal with functions with longer execution time than the consensus period?
 
Concerning using JS, I guess it depends of your application: if it is fine for your application to execute javascript in the browser, then do it. A different case is to develop a backend service always processing data (e.g. oracles, bots, etc). In the second case, rust and motoko are, by the time being, the only supported options (I heard typescript is soon coming but not yet fully supported)

-------------------------

skilesare | 2022-03-23 11:34:19 UTC | #30

[quote="ildefons, post:27, topic:11569"]
In my opinion, the following documentation would help: 1) the problem that this library is trying to solve, 2) the design decisions that you took to address this problem, 3) functions should be commented to connect code with the design decisions, 4) finally, there should be a description of how to implement a library that use your helper library.
[/quote]

Yes, it desperately needs some documentation. It is on my list of todos. 

In the mean time:

The simplest implementation is in the tests on https://github.com/skilesare/pipelinify.mo/blob/a34056ba1109060a92d67802027f8aaa9c67aae3/tests/_pipelinifyTest-Processor.mo#L149

The consumer test file also shows how to push and pull data between canisters as well.

-------------------------

ildefons | 2022-03-23 12:29:18 UTC | #31

[quote="skilesare, post:30, topic:11569"]
The simplest implementation is in the tests on [pipelinify.mo/_pipelinifyTest-Processor.mo at a34056ba1109060a92d67802027f8aaa9c67aae3 ¬∑ skilesare/pipelinify.mo ¬∑ GitHub](https://github.com/skilesare/pipelinify.mo/blob/a34056ba1109060a92d67802027f8aaa9c67aae3/tests/_pipelinifyTest-Processor.mo#L149)

The consumer test file also shows how to push and pull data between canisters as well
[/quote]

Thank you. I will study it.

@skilesare, something that I did not understand until now is that it looks like you are assuming that the motoko module (i.e my linear algebra library) is supposed to be an independent canister and all calls to the new library will be canister calls. Is this correct?

-------------------------

skilesare | 2022-03-23 13:01:17 UTC | #32

You could build it that way, but the pipelinify module supports local serialized and parallel processing.

When you call .process you pass in a process config and you have a number of options:


```
public type DataConfig  = {
        #dataIncluded : {
            data: [AddressedChunk]; //data if small enough to fit in the message
        };
        #local : Nat;

        #pull : {
            sourceActor: ?DataSource;
            sourceIdentifier: ?Hash.Hash;
            mode : { #pull; #pullQuery;};
            totalChunks: ?Nat32;
            data: ?[AddressedChunk];
        };
        #push;
        #internal;
    };
```
#dataIncluded means that the data is in the request
#local(id) means that you've stored the data somewhere in your canister and the system will call the function you configure for getLocalWorkspace on the initialization interface to get a handle on the data.  You would only use push and pull if you were calling the library from another canister.

-------------------------

paulyoung | 2022-03-23 20:03:35 UTC | #33

[quote="ildefons, post:27, topic:11569"]
@paulyoung, probably the problem of executing a motoko function beyond the consensus round period is a problem that you have already addressed in some forum post and/or internally in some of your daily development tasks.
[/quote]

I‚Äôm afraid not. At least not yet.

I am interested in solutions that abstract this problem away from us as developers though.

-------------------------

ildefons | 2022-04-03 11:34:48 UTC | #34

@paulyoung @skilesare, today I learned about the system "hearbeat" function and I wondered whether this periodic system signal is related to the "consensus period". If this was the case, it would be possible to create a generic method to interrupt/save/recover the state of long computations. Does it make sense or I am confused?

-------------------------

skilesare | 2022-04-03 14:29:58 UTC | #35

Yes. I have on my todo list to add heartbeat to https://github.com/skilesare/pipelinify.mo. Heartbeat is expensive though, so a external crank turner will likely save you some money.

The library supports you just calling process(process_id) until you get a #done back.

-------------------------

ildefons | 2022-04-03 14:57:00 UTC | #36

[quote="skilesare, post:35, topic:11569"]
Heartbeat is expensive though
[/quote]
Does this mean that calling a "hearbeat" method consumes much more cycles that calling a normal canister method? 

[quote="skilesare, post:35, topic:11569"]
so a external crank turner will likely save you some money.
[/quote]

What is an "external crank turner"?

-------------------------

skilesare | 2022-04-03 15:08:04 UTC | #37

[quote="ildefons, post:36, topic:11569"]
Does this mean that calling a ‚Äúhearbeat‚Äù method consumes much more cycles that calling a normal canister method?
[/quote]

It is a function called every second I think. So even if you just check a flag, you are using cycles.

[quote="ildefons, post:36, topic:11569"]
What is an ‚Äúexternal crank turner‚Äù?
[/quote]

Just an external process. It can be another canister, a web browser waiting for work to be done, an aws instance I charge if processing requests.

-------------------------

ildefons | 2022-04-06 14:49:59 UTC | #38

[quote="skilesare, post:37, topic:11569"]
It is a function called every second I think. So even if you just check a flag, you are using cycles.
[/quote]

@skilesare  Why the cost in cycles of an implementation based on "heartbeat" is much higher than another implementation based on an external process? aren't both just update calls?

-------------------------


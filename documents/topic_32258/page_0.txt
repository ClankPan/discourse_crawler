lastmjs | 2024-06-21 15:54:21 UTC | #1

AO is a general-purpose computing platform coming from the Arweave ecosystem. In my opinion it is the most promising and similar project to ICP in the Web3 ecosystem.

I would like to ensure that AO characterizes ICP correctly (I can reach out to the team during this draft process). I would also like to know if AO is a serious alternative to ICP, and to push ICP to improve where necessary.

These goals may also be broadly interesting and useful to DFINITY and the ICP community.

AO now has a whitepaper. Here's a link to a recent draft: https://arweave.net/7n6ySzBAkzD4KZoTviHtskVlbdab_yylEQuuy1BvHqc

I would like to invite all interested and especially knowledgeable engineers and researchers from DFINITY to comment on the characterization of ICP in the whitepaper.

I also invite critique into AO's security model, as a continuation of the discussion here: https://forum.dfinity.org/t/lets-solve-these-crucial-protocol-weaknesses/28329

Tagging some people I would love have look at the paper's ICP section and security model in general: @Manu @ulan @free @bjoern @PaulLiu @timo @victorshoup 

P.S. Would be very neat to get a paper or other analysis like [Proof of history: what is it good for?](https://www.shoup.net/papers/poh.pdf) but for AO.

-------------------------

PaulLiu | 2024-06-21 17:15:42 UTC | #2

I haven't taken a deep look, but searching in your quoted whitepaper draft the word "verification" turns up 2 counts, and "verify" only 1.

-------------------------

w3tester | 2024-06-22 00:21:36 UTC | #4

We have discussed ao with tons of professionals in this industry, the conclusion is so simple:

ao = Arweave Ordinal. 
ao processes = Ordinal indexers that can exchange messages

That‚Äôs it.

It replaced the Bitcoin network with Arweave for inscription storage and carry out off-chain computation. Sure it has "Unbounded resource" for computation because it has no consensus mechanism. Basically it has nothing to do with ‚Äúblockchain‚Äù.

-------------------------

evanmcfarland | 2024-06-22 15:13:41 UTC | #5

I'm interested in this as a developer using an ICP + ArWeave stack. Not as a protocol-level expert, but I'll add some observations based on experience.

The whitepaper introduces ICP as having inherently limited scalability because it requires consensus on *results*, not the *inputs*, of computations. Meanwhile every other major blockchain performs consensus on *results*, and ICP is kinda-sorta the most scalable. I think this language unfair until it specifies what compute/scalability limitations are being referenced.

Everything else seems a fair classification, albeit without mention of the tradeoff involved in having no fixed node incentives, a governance-heavy approach, or one size fits all security.

While we wait for AO, I think ICP folks should be more open to the idea of using other chains in their stack. The common rhetoric here that trips up newcomers is 'store everything on ICP'. Than after searching/building an orthogonally persisted database (@lastmjs you remember pseudograph), you find something like ArWeave that is GraphQL on unlimited data in a few lines of code. While we wait, using ICP this way removes most [protocol weaknesses](https://forum.dfinity.org/t/lets-solve-these-crucial-protocol-weaknesses/28329?u=evanmcfarland). For those who love the Actor Model, this will likely remain the perfect combo.

-------------------------

Jdcv97 | 2024-06-22 17:57:19 UTC | #6

Really interested in what Dfinity team members have to say, why AO can claim they are able to train LLM‚Äôs on chain? As I remember they went from off chain smart contracts in their docs to ‚Äútrain Ai on chain‚Äù very strange that.

-------------------------

PaulLiu | 2024-06-22 18:20:19 UTC | #7

[quote="Jdcv97, post:6, topic:32258"]
why AO can claim they are able to train LLM‚Äôs on chain?
[/quote]

No they cannot. I'm not yet aware of any LLM training process that is completely deterministic, which is a prerequisite to running it either "on chain", or "off chain but verifiable later" like in the case of AR. So unless they made significant breakthrough, or they are not LLM.

-------------------------

lastmjs | 2024-06-22 18:30:23 UTC | #8

I'm not sure they said training, if I remember correctly they're talking about inference. But the question is if AO's computational model can be considered on chain.

-------------------------

tate | 2024-06-22 18:44:51 UTC | #9

Hey there, this actually is possible to do on AO and was done live yesterday. Here‚Äôs the video: https://www.youtube.com/watch?v=e8uSxTXnlsw

Here‚Äôs a breakdown on that video as well published by some from our team (building on AO): https://www.communitylabs.com/blog/ao-in-ai-key-highlights?utm_source=Blog&utm_medium=dfinityforum&utm_campaign=AI+on+AO&utm_id=Community+Labs

Hope this is helpful. Interested in contributing to the discussion not to position AO as superior but to make sure both technologies have correct representations of the facts üôÇ 

Still a fan of ICP!

-------------------------

PaulLiu | 2024-06-22 18:54:58 UTC | #10

Just to share some random comments after having a cursory look at the whitepaper.

I think the two most significant pieces in this whitepaper is "AO-Sec Origin" and "SIV" (for which strangely I cannot find any definition, so I don't know what it stands for). Both of them would resort to more traditional consensus mechanisms. For example, here is a snippet: 

![image|596x500](upload://z6hP3RyLvjTh4qoiRnqma5IaXJ7.jpeg)

This is quite understandable, because without consensus you would never be able verify if  a challenge is sound, and subsequently determine whether a stake should be slashed or not. However, it is not explained in the paper how many nodes are required to run the consensus protocol for "AO-Sec Origin", what exactly these nodes have to do in order to verify a challenge, and how this consensus protocol can ensure security on its own.

For example, if we consider a challenge that claims a CU has misbehaved. Does a "AO-Sec Origin" node re-run the computation by itself in order to verify? Does the node delegate the "re-run" to randomly chosen other CUs? I think more explanation is needed here.

Another repeated theme in this paper is that everything, including security, is "customizable", as if it is a good thing. But I disagree. As anyone familiar with information flow security analysis would tell you, "High" security does not compose with "low" security to become "mid-level" security.

-------------------------

PaulLiu | 2024-06-22 18:58:29 UTC | #11

I'll also add that this whitepaper is definitely a step towards providing more substance behind buzz words, but I'd maintain my previous conclusion:

[quote="PaulLiu, post:27, topic:28329"]
I don‚Äôt think optimistic verification is secure in an async setting without introducing a sufficient challenge peroid (which is sound, but goes directly against the scalability claim).
[/quote]

-------------------------

PaulLiu | 2024-06-22 19:06:34 UTC | #12

[quote="tate, post:9, topic:32258"]
Hope this is helpful
[/quote]

Thanks for the links. They are helpful for people who want to know the latest updates, but they are also "not helpful" being a reply to my comment, because I don't think training was mentioned (at least not in the blog article, because I don't have time to watch full 2-hour video). 

So maybe the correct conclusion is "AO can run deterministic LLM inference computation using Wasm64, but cannot yet run LLM training".

-------------------------

skilesare | 2024-06-22 22:47:56 UTC | #13

I'll link some of my previous AO thoughts below:

https://taggr.link/#/post/677509
https://taggr.link/#/post/957824
https://taggr.link/#/post/957837

Note: I have not kept up with AO since mid March...not sure if anything has changed or not.

Note 2: Since mid march I've been a couple days of programming away from having an operational AO CU running on the IC.  I'm sorry.....I've been busy. :slight_smile: The goal after that was to make a SU.  A CU + SU on the IC is probably the most secure, straightforward, and well-architected AO configuration at the moment.(Unless things have changed since march)

Note 3: My general feeling is that AO does a better job at mandating data permanence, but that is doable on the IC.  There may be some things that are out side the IC performance-wise, but as Paul mentions, the faster you go the harder it is to prove what you've done and for others to confirm it.

-------------------------

w3tester | 2024-06-22 22:48:01 UTC | #14

This is exactly the point. Who runs the "AO-Sec Origin", who governs it, how it can determine the correctness of other processes? Re-execution? ZK? Where is the code for that function?

I bet after the AO team actually built the consensus mechanism using the AO-Sec Origin, they'd find themselves re-invented the wheel of Ethereum PoS, or (not likely) ICP.

-------------------------

w3tester | 2024-06-22 23:55:54 UTC | #15

I send one image to two ao processes with the same AI model. 

One tells me it is a cat. The other says it is a dog.

Which one should I believe?

Please don't ask me to run my own AI model to verify by myself. If I can do this, I wouldn't need ao in the first place.

-------------------------

Forreal | 2024-06-24 01:26:42 UTC | #16

Straight from the AO's Whitepaper using Gemini AI: 

AO's approach to consensus is quite unique and differs significantly from traditional blockchain models:

**Lazy Evaluation and Holographic State**

AO doesn't directly reach consensus on the state of computations (the outcome or results). Instead, it focuses on consensus on the input data (the messages) and their order. This is achieved through:

1. **Scheduler Units (SUs):** They assign a unique, incremental number (a slot) to each message received for a process. This ensures an agreed-upon order of messages.

2. **Arweave Persistence:** The assigned message and its slot number are then permanently stored on Arweave. This creates an immutable log of messages and their order, forming the basis for consensus.

This combination forms what AO calls a "holographic state." The actual state of a process (its current memory and data) isn't constantly calculated by all nodes. Instead, it's implied by the message log on Arweave. When needed, a Compute Unit (CU) can calculate the state by replaying the message log from the beginning.

**Decentralized Computation**

Unlike traditional blockchains where every node does the same computation, AO delegates computation to specialized Compute Units (CUs). These CUs compete to offer their services, and users or messenger units choose which CU to use based on factors like price and performance.

**Trustless Verification**

While CUs perform the computations, the results are verifiable because:

* **Deterministic Execution:** The execution environment (the virtual machine) is deterministic, meaning the same inputs will always produce the same outputs.
* **Message Log on Arweave:** The entire message history is available on Arweave, so anyone can verify the results by replaying the log.

**Benefits of AO's Consensus Mechanism**

* **Scalability:** By not requiring every node to compute every state, AO can scale to support a massive number of processes.
* **Efficiency:**  Computation is only done when needed, saving resources.
* **Trustlessness:** The results are verifiable by anyone due to the deterministic execution and the immutable message log.

**Key Differences from Other Blockchains**

* **Ethereum, Bitcoin, Solana, etc.:**  Rely on on-chain computation, where all nodes participate in every calculation. This limits scalability.
* **Akash:**  Provides a decentralized marketplace for computation but lacks the trustless guarantees of AO's verifiable results.





TAO and the Internet Computer Protocol (ICP) share a common inspiration: the Actor Model of computation. However, their approaches to consensus and computation differ significantly, leading to distinct advantages and trade-offs.

**Similarities**

* **Actor Model:** Both AO and ICP are built around the idea of "actors" (processes in AO) that communicate through messages. This provides a natural framework for concurrent and distributed computation.
* **Focus on Scalability:** Both aim to address the scalability limitations of traditional blockchains.
* **WebAssembly (WASM):** Both utilize WASM as a virtual machine for executing code, offering flexibility and performance.

**Differences**

| Feature                   | AO Protocol                                                                                                                                                                                                                                                                             | Internet Computer Protocol (ICP)                                                                                                                                                                                                                                                                                       |
| :------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Consensus Mechanism        | Lazy evaluation of state. Consensus on message logs stored on Arweave, not on the computed state.                                                                                                                                                                                        | Chain-key cryptography and Probabilistic Slot Consensus (PSC) for fast finality.                                                                                                                                                                                                                                 |
| Computation               | Delegated to Compute Units (CUs). Users choose CUs based on price and performance.                                                                                                                                                                                             | Performed by replicas within subnets.                                                                                                                                                                                                                                                                      |
| State Verification        | Through deterministic execution and the immutable message log on Arweave.                                                                                                                                                                                                            | Through consensus among replicas.                                                                                                                                                                                                                                                                      |
| Scaling Approach          | Horizontal scaling by adding more CUs. No inherent limit on the number of processes.                                                                                                                                                                                            | Vertical and horizontal scaling by adding more powerful nodes and creating more subnets. However, there are practical limits on the number of subnets due to the need for cross-subnet communication.                                                                                                       |
| Trust Model               | Trustless due to verifiable computation results.                                                                                                                                                                                                                                   | Requires trust in the correct implementation and operation of the protocol and the honesty of a majority of nodes.                                                                                                                                                                                              |
| Smart Contract Integration | Easy integration with existing Arweave smart contract platforms (Warp, Ever, etc.) through the unified message-passing layer.                                                                                                                                                       | Smart contracts are natively supported within the ICP ecosystem.                                                                                                                                                                                                                                             |
| Development Experience    | Familiar to developers experienced with message-passing and actor-based systems.                                                                                                                                                                                               | Requires learning ICP-specific concepts and tools.                                                                                                                                                                                                                                                        |
| Current Status            | Active development, testnet launched with basic features.                                                                                                                                                                                                                           | Mainnet live, but has faced challenges with scalability and adoption.                                                                                                                                                                                                                                  |

**Which is Better?**

There's no one-size-fits-all answer. The best choice depends on your specific use case and priorities:

* **AO:** If you prioritize trustlessness, verifiable computation, and the flexibility to integrate with existing Arweave smart contracts, AO might be a better fit.
* **ICP:** If you need high throughput and fast finality, and are comfortable with the trade-offs of a more complex system and a higher degree of trust, ICP might be a better choice.

-------------------------

cryptodriver | 2024-06-24 04:39:59 UTC | #17

Reading @lastmjs's tweets, I feel that @lastmjs is beginning to lose confidence in ICP, just like many other developers. Does @dfinity need to reflect on why so many developers have lost confidence in ICP and left the community?

By the way, I am one of the developers.

-------------------------

Jdcv97 | 2024-06-24 05:43:05 UTC | #18

AO‚Äôs approach doesn‚Äôt look like can solve cybersecurity issues to enterprise, data that power AI doesn‚Äôt seem like will be safe and private (encrypted) by default. AO in my point of view is something that can be easily implemented in to ICP as a base layer providing security BY DEFAULT.

@PaulLiu  can you correct me please, but ICP value proposition at this point in time according to dominic‚Äôs vision, it‚Äôs that AI systems will be unhackable, tamper proof and unstoppable, all data deployed in to ICP via canisters will get the same properties that just blockchain provides, does this properties will be enabled by default with AO‚Äôs approach? Or this value proposition is lost on AO network? Thanks

-------------------------

jokerburger | 2024-06-24 07:15:14 UTC | #19

What happens in AO when you replay all input data (the messages) and you get a different result? As of my current understanding AO does not have an answer to this fundamental question.

-------------------------

Sormarler | 2024-06-24 08:53:19 UTC | #20

Why are you losing confidence in ICP? Is it related to the tech stack or the price?

-------------------------

lastmjs | 2024-06-24 11:48:30 UTC | #21

You would not have achieved consensus, just compare the results right?

Maybe use more than two CUs. 2/3, 10/13 CUs etc depending on the level of security you want.

-------------------------

w3tester | 2024-06-24 13:24:03 UTC | #22

Right, sure you can use more CUs for one task. But how many? What is the security level and how is it calculated? What happens when CUs misbehave? Who is going to coordinate all these tasks? How does staking take place? Who governs staking and how is this process decentralized? Which token is used? How does this token relate to the security of my system?

I can hardly call the ao a trustless/decentralized system before all these questions are answered.

-------------------------

Mar | 2024-06-24 13:40:25 UTC | #23

> Right, sure you can use more CUs for one task. But how many? What is the security level and how is it calculated? What happens when CUs misbehave? Who is going to coordinate all these tasks? How does staking take place? Who governs staking and how is this process decentralized? Which token is used? How does this token relate to the security of my system?

Just curious, but aren't these questions relatively easy to solve? Like, just by using Proof of Authority or something similar, by each set of actors/subnets interested.

-------------------------

w3tester | 2024-06-24 14:09:10 UTC | #24

Show me the code in production?

-------------------------

Mar | 2024-06-24 15:00:33 UTC | #25

It's a new project, I don't think we should be this hard :slightly_smiling_face::

> Basically it has nothing to do with ‚Äúblockchain‚Äù

Specially taking into account that the ICP has its own set of "weird blockchain design choices", as a blockchain OG recently told me (not Vitalik, but close enough):

![Screenshot 2024-06-24 at 15.19.59|690x303](upload://483C3tkr64kQZTsPyRYnS9oUh8i.png)

In my opinion, the idea of providing maximum flexibility has its merits, and we should be looking at how to cooperate rather than attack them.

-------------------------

Jdcv97 | 2024-06-24 14:43:13 UTC | #26

Your og forgot his favorite blockchain can be shut down just by a single cloud provider that runs on a single jurisdiction. So his smart contracts will be gone way easier

As it already happened in solana recently, not a supposed but a real fact.

-------------------------

Zane | 2024-06-24 15:09:12 UTC | #27

I think the AWS issue is overblown and ICP might be more vulnerable in this aspect despite having 100% independent nodes. 
In a free market everyone goes for the option which offers the path of least resistance, in crypto's case that means running nodes on big tech cloud, but there is nothing forcing them to, nor are these protocols being developed with a set of assumptions relying on AWS to function properly.
If tomorrow ETH nodes were banned from GCP or AWS, there'd be a temporary outage at best, then nodes would come back online with improved decentralization for the network.

On the other hand if an international institution like the IMF were to decide anything DeFi related is illegal, we'd only have 2 options: delete the canisters or move them to a subnet with nodes run in non compliant countries, which could potentially be very few and severely impact the user experience and decentralization of those subnets.

-------------------------

Jdcv97 | 2024-06-24 15:29:33 UTC | #28

You are discussing the whole value proposition of ICP haha, this is something that‚Äôs why i‚Äôm betting here, nothing new. That‚Äôs the point be able to move things between jurisdictions and avoid censorship.

-------------------------

Ajki | 2024-06-24 20:15:49 UTC | #29

[quote="Zane, post:27, topic:32258, full:true"]
I think the AWS issue is overblown and ICP might be more vulnerable in this aspect despite having 100% independent nodes.
In a free market everyone goes for the option which offers the path of least resistance, in crypto‚Äôs case that means running nodes on big tech cloud, but there is nothing forcing them to, nor are these protocols being developed with a set of assumptions relying on AWS to function properly.
If tomorrow ETH nodes were banned from GCP or AWS, there‚Äôd be a temporary outage at best, then nodes would come back online with improved decentralization for the network.

On the other hand if an international institution like the IMF were to decide anything DeFi related is illegal, we‚Äôd only have 2 options: delete the canisters or move them to a subnet with nodes run in non compliant countries, which could potentially be very few and severely impact the user experience and decentralization of those subnets.
[/quote]

This is a bit naive thinking. AWS has central authority, meaning if the US tells them to shut down a specific service worldwide or face restrictions in the US, they would comply.

If tomorrow, cloud providers ban all crypto nodes, sharded blockchains will be screwed and encounter data loss since data is not replicated on all nodes. 

If governments want to ban crypto, they could easily do it by imposing a 10-year jail sentence for people running nodes, forcing ISPs to filter out the traffic, and thereby causing trust in crypto to plummet. It could only remain as a niche thing. This could happen if only the US and EU agree to ban crypto, leading to exchanges shutting down and prosecuting those who allow US/EU citizens to trade.

As for ICP, the NNS control is what makes it great. It's not a dark web. People often confuse a full-stack blockchain with existing token databases. Imagine running child trafficking services and other illegal content without the ability to prevent that; governments would hold all node providers accountable. We saw Bitcoin and Ethereum transactions being censored, and non-US citizens prosecuted.

The ability for ICP to enforce compliance through NNS gives developers and enterprises assurance that it has a global aim and would not be stopped.

-------------------------

PaulLiu | 2024-06-24 20:59:03 UTC | #30

[quote="lastmjs, post:21, topic:32258"]
Maybe use more than two CUs. 2/3, 10/13 CUs etc depending on the level of security you want.
[/quote]

I think you are misguided here. Number of replication is **NOT** the whole story.

Suppose 10/13 is a good threshold, and there are indeed 13 unique and independent CUs. Now 10 of them have computed output message B from input message A. Can you now trust message B and take your own actions based on B (e.g. buy or sell on another market)?

No, you cannot because it is unsafe. You don't know whether A was computed correctly in the first place. These 10 CUs are not responsible for verifying A's correctness either, and their stake won't be slashed even if A turns out to be wrong, because they computed from A to B correctly.

The only sensible decision in a opportunistic setting is to wait until message B **finalizes**, which usually would then imply A has also finalized. I'll just quote myself again:

[quote="PaulLiu, post:27, topic:28329"]
I don‚Äôt think optimistic verification is secure in an async setting without introducing a sufficient challenge peroid (which is sound, but goes directly against the scalability claim).
[/quote]

-------------------------

PaulLiu | 2024-06-24 21:25:48 UTC | #31

We can also compare this to optimistic ETH rollups with a synchronous messaging model, like [Arbitrum](https://docs.arbitrum.io/how-arbitrum-works/bold/gentle-introduction).

Arbitrum gives 7 day challenge window, and also each bonding party (both the state submitter to L2, and the challenger) need to put down 3600 ETH. Note that the state submitter is responsible for **ALL** state, not just a tiny part of it like in the case of AO.

AO's whitepaper does not mention concrete numbers, but I fail to see how any setting could realistically work. Too short a challenge window or too little at stake would be insecure. But you also can't ask for too much stake of each individual unit because no one is responsible for ALL state.

-------------------------

Mar | 2024-06-24 21:45:56 UTC | #32

[quote="PaulLiu, post:31, topic:32258"]
AO‚Äôs whitepaper does not mention concrete numbers, but I fail to see how any setting could realistically work. Too short a challenge window or too little at stake would be insecure. But you also can‚Äôt ask for too much stake of each individual unit because no one is responsible for ALL state.
[/quote]

Isn't the idea of this "chain" to be flexible? So each dapp can choose its level of security by adjusting parameters like stake, window, and set of units. Some dapps might prefer a minimum level of security and execute immediately, while others might require higher security with a longer window and a fixed set of units with a high stake. And I guess these levels of security will not get mixed, etc...

-------------------------

lastmjs | 2024-06-24 22:34:12 UTC | #33

Message A must have been the result of correct computation yes. On ICP the security of message A is backed by the replication factor of the nodes that computed the message and signed it (and you just follow everything back to the first message, each hop is checking the signatures from the subnet that supposedly executed and signed it). That's what I'm saying about replication factor on ICP, all of ICP's security is rooted in the size of the subnets involved in computing those messages.

Is this understanding incorrect?

-------------------------

PaulLiu | 2024-06-24 22:01:49 UTC | #34

[quote="Mar, post:32, topic:32258"]
Isn‚Äôt the idea of this ‚Äúchain‚Äù to be flexible? So each dapp can choose its level of security
[/quote]

If you read my last reply to @lastmjs , it was a concrete example where a dapp can't choose the security parameter of it's upstream's upstream. The whole security setting thing is flawed due to the lack of finality.

-------------------------

Mar | 2024-06-24 22:29:09 UTC | #35

[quote="PaulLiu, post:30, topic:32258"]
No, you cannot because it is unsafe. You don‚Äôt know whether A was computed correctly in the first place. These 10 CUs are not responsible for verifying A‚Äôs correctness either, and their stake won‚Äôt be slashed even if A turns out to be wrong, because they computed from A to B correctly.
[/quote]

Isn't it easy to verify that A was computed correctly? And inductively, everything else? For instance, if we assume that everything is computed/attested by the same 13 (staked) CUs (or any actors needed for the whole process), isn't finality something that should and can be built on top of the protocol they offer? I feel that you are taking the draft very literally, whereas they just gave a light overview of how things can work at the base, leaving the rest to be built on top.

-------------------------

Jdcv97 | 2024-06-24 22:38:00 UTC | #36

No one realistically will be building none of those things, the world always take the option that solves by default everything, and takes complexity out, if your product instead of removing complexity adds more it will fail. Why would enterprise should the hardest way and insecure one over the proven by pure cryptography and not just ‚Äú optimistic‚Äù one

-------------------------

PaulLiu | 2024-06-24 22:50:39 UTC | #37

[quote="Mar, post:35, topic:32258"]
Isn‚Äôt it easy to verify that A was computed correctly? And inductively, everything else?
[/quote]

No, it is actually very difficult, because in an async world, no one has global state. If you do, it is basically reduced to a single chain, already not as scalable.


[quote="Mar, post:35, topic:32258"]
if we assume that everything is computed/attested by the same 13 (staked) CUs
[/quote]

It is clearly not AO's vision to let everything be computed by the same set of CUs. You are making an assumption that this whitepaper does not make.

-------------------------

Mar | 2024-06-24 23:12:43 UTC | #38

[quote="PaulLiu, post:37, topic:32258"]
t is clearly not AO‚Äôs vision to let everything be computed by the same set of CUs. You are making an assumption that this whitepaper does not make.
[/quote]

I mean, not everything on AO, just everything from the interacting set of processes. I would guess it's possible to build something like the IC on top, and then much simpler systems. I see the draft paper as "we have decentralized permanent storage, so here is our vision to build smart contracts on top as flexible as possible", not as something super polished or final. Perhaps you have a better idea on how to do it given these constraints?

-------------------------

Jdcv97 | 2024-06-24 23:03:29 UTC | #39

You will found yourself building an entire blockchain, but its ok seems like you love over complicate your life.

-------------------------

w3tester | 2024-06-24 23:50:58 UTC | #40

It literally took 4 years for the Ethereum Foundation to design and develop the PoS version of Ethereum, from 2018 to 2022.

I wonder why everything seems so easy to solve at your side? Maybe you can share your code to make the ao really trustless and decentralized now?

-------------------------

Mar | 2024-06-25 00:13:55 UTC | #41

> I wonder why everything seems so easy to solve at your side? Maybe you can share your code to make the ao really trustless and decentralized now?

I'm not in AO and not planning to work on it. I think they can rely on Arweave when needed, since they have BFT consensus there. Or any other blockchain, I guess.

-------------------------

w3tester | 2024-06-25 00:38:55 UTC | #42

Here is from ChatGPT 4o. Love it so much :laughing:

### Why AO is Not Fully Decentralized, Trustless, and Lacks Finality

#### Centralization in Computation
In traditional decentralized blockchains, every node participates in the computation and validation process, ensuring that no single entity has control over the entire network. However, AO delegates computation to specialized Compute Units (CUs). While these CUs compete to offer their services, the reliance on a limited number of specialized units introduces potential centralization risks. If a significant portion of computation is handled by a few dominant CUs, the system could become vulnerable to central points of failure or influence.

#### Dependence on External Storage (Arweave)
AO relies on Arweave for storing the message log that forms the basis of its "holographic state." While Arweave is a decentralized storage solution, AO‚Äôs dependence on an external system means that the integrity and availability of AO‚Äôs state are contingent on Arweave‚Äôs reliability. This introduces a layer of dependency that contrasts with the self-contained nature of traditional blockchains, where all state data is maintained and validated within the network itself.

#### Limited Trustlessness in Computation
Traditional blockchains achieve trustlessness by ensuring that all nodes validate transactions and compute state changes independently. In AO, computation is outsourced to CUs, and although the results can be verified through deterministic execution and the immutable message log, the initial computation process is not inherently trustless. Users must trust that the chosen CU performs the computation correctly unless they verify the results themselves, which may not always be feasible.

#### Potential for Centralized Control in Scheduling
AO‚Äôs Scheduler Units (SUs) assign a unique, incremental number to each message, determining their order. The centralized assignment of slots introduces a potential risk of manipulation or bias in message ordering. If the SUs are controlled by a few entities, they could influence the sequence of message processing, affecting the fairness and neutrality of the system.

#### Verifiability Challenges
While AO provides mechanisms for verifiability through deterministic execution and the availability of the message log on Arweave, the process requires additional steps compared to traditional blockchains. Users or other nodes must actively replay the message log to verify computations, which adds complexity and potential barriers to trustless verification. This reliance on additional verification steps could deter users from fully trusting the system without conducting their own checks.

#### Lack of Finality
A crucial feature of many blockchain systems is the concept of finality, where once a transaction is confirmed, it is permanently added to the blockchain and cannot be altered or reversed. AO lacks this feature because its state is implied by the message log on Arweave and can be recalculated at any time by replaying the log. This means there is no absolute guarantee that a computed state is final and unchangeable, which undermines the confidence that users and applications can have in the immutability of the system's state.

### Conclusion
While AO introduces innovative mechanisms for achieving consensus and scalability, it diverges from the core principles of decentralization, trustlessness, and finality found in traditional blockchains. The delegation of computation to specialized units, dependence on external storage, the need for active verification, and the absence of finality introduce elements that compromise its decentralized and trustless nature. These factors make AO a unique system with different design principles, but not a fully decentralized or trustless blockchain.

-------------------------

cryptodriver | 2024-06-25 00:52:51 UTC | #43

[quote="w3tester, post:42, topic:32258"]
Why AO is Not Fully Decentralized, Trustless, and Lacks Finality
[/quote]

If you ask chat gpt 4o like this: Why AO is Fully Decentralized, Trustless, and Finality?
You will get exactly the opposite answer.

-------------------------

Luffy | 2024-06-25 01:15:00 UTC | #44

https://ao.arweave.dev/#/mint/ethereum/

YEARLY AO FOR 1 STETH

~ 21.5787 AO

TOTAL BRIDGED STETH

97,531.2927 STETH


and

https://dashboard.internetcomputer.org/ethereum


ckETH Total Supply
Info button
561.9955
ckETH


Chain Fusion work is truly an embarrassing joke! Do you understand what value crypto assets need? Do you understand where the disappointment of ICP holders lies?

-------------------------

w3tester | 2024-06-25 01:18:58 UTC | #45

I don't need to. It is written already. It is called the AO whitepaper.

-------------------------

Kick1776 | 2024-06-25 01:24:54 UTC | #46

But these people are bridging assets to farm your AO tokens, right? Pretty sure a lot of these folks plan to dump once they get their allocation.

-------------------------

Luffy | 2024-06-25 01:41:29 UTC | #47

This is traffic, this is asset liquidity, and this is also explosive user growth. Since ETH started ICO, the blockchain world has grown this way. What's wrong with that?

-------------------------

blush | 2024-06-25 14:44:10 UTC | #48

Cheer up friends, most projects have stopped updating the code, such as Solana, they have not updated the code for two months, while our community has been updating, we are growing into teenagers, while most projects are still babies, including AO

-------------------------

Agnostic | 2024-06-26 01:15:32 UTC | #49

Has anyone here actually used or built anything on Arweave to verify that everything in the whitepaper is real and valid? (as opposed to just being promises made on minimally viable projects)

-------------------------

Jdcv97 | 2024-06-26 01:37:55 UTC | #50

The project is not even on production yet.

-------------------------

w3tester | 2024-06-27 13:57:47 UTC | #51

I got a question. Why nobody in the Ethereum and Solana community talk about AO?

-------------------------

Jdcv97 | 2024-06-27 14:28:40 UTC | #52

Because no one working in there will promote another project, just here the ones that get paid million usd for grants are feeding their family woth out money, and talking üí© about us. It‚Äôs really painful to see how dfinity spend our money in grants gave to people like lastmjs, the guy promotes another projects that are inferior or just meets his own ideals, while demerit ICP the one that feeds him. 1 million to this person it‚Äôs s painful. I would vote to remove his grant immediately

-------------------------

Mar | 2024-06-27 15:36:00 UTC | #53

To be fair, even Dominic was tweeting about it. In my opinion, it's super overblown for no reason. Maybe it's because the IC is still trying to find its niche, particularly with AI, and then AO came along with the same idea. I'm not sure. 

(I was just interested in the paper, it has some nice ideas)

-------------------------

Ajki | 2024-06-27 17:06:49 UTC | #54

[quote="w3tester, post:51, topic:32258, full:true"]
I got a question. Why nobody in the Ethereum and Solana community talk about AO?
[/quote]

Because both of them are token databases and don't have anything to do with verifiable general computing, check how much they talk about another token database, Algorand, when it aired [When blockchains meet the real world, only one delivers. (youtube.com)](https://www.youtube.com/watch?v=xyhX9bjf-GE)

The Solana community went wild when SUI demonstrated higher (real) TPS. Everyone, including the foundation and founder, was discussing it and making excuses about what should and should not be counted.

The crypto space is very tribal, especially when some unfounded claims are made.

-------------------------

Tbd | 2024-06-27 18:19:06 UTC | #55

lastmjs has done more for ICP than you ever will do

-------------------------

diegop | 2024-06-27 18:30:24 UTC | #56

**Moderator note:**

Folks,

Lets please refrain from commenting on an individual (in this case Lastmjs). This is not the decorum we want on this forum.

Thank you

-------------------------

Agnostic | 2024-06-30 04:09:45 UTC | #58

That sounds about right because I actually went through Arweave's [ecoystem](https://list.weavescan.com/) of projects and I haven't come across anything Ai nor AO related.  Surprisingly, one dapp that's listed on ICP is also listed on Arweave, i.e. DSocial (a decentralized Youtube) - and it also doesn't work on both sites.

I renew my call for anyone to demonstrate the capabilities of Arweave, esp. its AI fully on chain capabilities, beyond just referring to a White paper.  Do what Dominic did when he first demonstrated AI running on the blockchain.  Also, post the link here so I can go look at and try the dapp and Ai myself.  If that can't be done then it sounds like the typical hype and promises of crypto projects.

-------------------------

JaMarco | 2024-07-02 09:37:39 UTC | #59

I think a bigger threat to obsolete ICP is MegaETH. Claims to bring Web2 performance (real-time speed and general computation) to Ethereum using an EigenDA L2. https://megaeth.systems/research

-------------------------

diegop | 2024-07-04 05:48:33 UTC | #60

I think folks here may find this interesting : 

https://forum.dfinity.org/t/what-makes-ai-on-blockchain-hard-request-for-feedback-on-post/32686?u=diegop

-------------------------

bjoern | 2024-07-08 12:39:49 UTC | #61

Hey @lastmjs! Considering concrete points from the white paper where IMO it does not represent ICP fairly. To be honest, I think almost every sentence in the white paper that relates to ICP is wrong. Here are a few:

> ICP employs a single Byzantine Fault Tolerant (BFT) mechanism across its ‚Äôsubnets‚Äô, a design choice that mandates consensus on the results of computations.

Technically, ICP achieves consensus directly on the inputs (by inclusion in and consensus over a block) and indirectly on outputs (through deterministic computation and certification). I guess that's reasonably close, but I still find their description hard to understand.

> This necessitates that every node within a subnet execute every step of each computation, inherently limiting the amount of computation that can be feasibly performed due to scalability constraints.

This seems completely confused. Computation _on a single subnet_ is indeed bounded by the capacity of the nodes running the subnet. But the scalability approach of ICP is _horizontal_ by adding more subnets, and the protocol scales extremely well in terms of subnets thanks to chain-key cryptography.

> Furthermore, ICP adopts a monolithic protocol structure, enforcing uniform consensus and execution parameters across all resident containers.

This is also not true, some execution parameters do differ between subnets. And consensus parameters are also different for subnets of different sizes.

Consequently, also the "contrasting" statements about AO that follow up are misleading.

The one aspect that I think _is_ represented fairly is that ICP relies more on in-protocol governance. The statement

> This centralized control is akin to a public-company operated by its shareholders, potentially leading to discriminatory practices against certain protocol uses.

however, is again misleading as to (a) the word _centralized_ ‚Äì the NNS is of course a singleton component, but it does not encode _centralized_ control according to the usual web3 lingo, and (b) it does completely disregard that control in less governance-focused platforms is usually also quite centralized around small groups of people that contribute to the same code that everyone runs. (So it only discusses the point for one approach, not for both.) Similar regarding the use of the term _KYC_ which indicates centralization while actually it's just a vote of the DAO.

-------------------------

diegop | 2024-07-08 15:10:22 UTC | #62

small nit:

as a former PhD, I am suspicious of obtuse writing vs simple, easy to verify, easy-to-invalidate writing.

I found the AO paper to be too lofty or academic for my tastes, but didnt boil down the key things i was looking for in AI x Blockchain.

This was one (of many) of the inspiration for writing this: https://forum.dfinity.org/t/what-makes-ai-on-blockchain-hard-request-for-feedback-on-post/32686

-------------------------

diegop | 2024-07-08 15:12:39 UTC | #63

[quote="diegop, post:62, topic:32258"]
I found the AO paper to be too lofty or academic for my tastes, but didnt boil down the key things i was looking for in AI x Blockchain.
[/quote]

@lastmjs for example... i found the paper to have all this talk about centralization, consensus, etc...

but when it came to the basics: compute, memory, determinism, ecostsystem, i found it lacking. I dont think this is an AO problem. I think this a median example of the writing i dislike in Web3 papers or academia as a whole :)

-------------------------

Mar | 2024-07-08 17:07:00 UTC | #64

I think their main advantage, which is also true for MegaETH and modular approaches, is their flexibility in using different kinds of nodes. From super big sequencers in datacenters to light nodes in phones. 

Besides being able to run AI, another notable feature is their capacity for very low latencies‚Äîin the case of MegaETH, as low as one millisecond.

I wonder if it's on the roadmap or even possible to provide such services using the IC. For some applications 2 seconds (and more) of latency feels like an eternity. @diegop

-------------------------

diegop | 2024-07-08 18:07:59 UTC | #65

[quote="Mar, post:64, topic:32258"]
Besides being able to run AI, another notable feature is their capacity for very low latencies‚Äîin the case of MegaETH, as low as one millisecond.
[/quote]

Real time is usually 100 milliseconds. 

A good latency in centralized web services is 20-50.

1 millisecond (in AI of all cases) is enough for me to say:

1. I‚Äôm suspicious 
2. Posible if I dive deeper it will make sense, but I‚Äôm tapping out here at diving deeper

-------------------------

Mar | 2024-07-08 18:22:24 UTC | #66

Yeah, agreed. Maybe it's just pre-confirmations. My point is that it would be nice for some subset of devs to have much lower latency.

In general, providing a more flexible environment, apart from the current IC implementation, could be decisive in attracting more devs. I still remember the times when we had talks of Badlands but ended up with arguably the opposite (Utopia).

Flexibility in terms of latency, governance (zero governance to NNS), computation (AI), async to sync, etc. The perception from devs outside of the ecosystem is that we're very rigid and all controlled through the NNS, plus the typical suspicion that it's centralized, given the genesis chart.

-------------------------

diegop | 2024-07-08 18:26:03 UTC | #67

[quote="Mar, post:64, topic:32258"]
For some applications 2 seconds (and more) of latency feels like an eternity. @diegop
[/quote]

The two seconds is only for update calls.

A lot of the web has similar for writing to DBs. If you like a comment in Instagram, the instagram app will show you liked it ‚Äúimmediately‚Äù but actually the DB recording it may take 2-3 seconds to record globally.

App developers in 2024 are really good at mixing frontend, high latency, low latency calls. I suspect IC devs will find similar patterns

Query calls are 200 milliseconds and I suspect we are not using them enough in IC ecosystem.

-------------------------

Mar | 2024-07-08 19:15:51 UTC | #68

[quote="diegop, post:67, topic:32258"]
A lot of the web has similar for writing to DBs. If you like a comment in Instagram, the instagram app will show you liked it ‚Äúimmediately‚Äù but actually the DB recording it may take 2-3 seconds to record globally.
[/quote]

Also, I don't know how much potential there is on social networks. Perhaps blockchains are mostly meant for DeFi. In that case, lower latency is important.

In general, whenever a customer (a.k.a. a developer) comes with a suggestion, we should probably listen to them instead of trying repeatedly to instill the idea that the IC is perfect as it is. Many successful companies have a customer-obsession mindset, even our evil competition, AWS.

-------------------------

diegop | 2024-07-08 19:18:30 UTC | #69

[quote="Mar, post:68, topic:32258"]
In general, whenever a customer (a.k.a. a developer) comes with a suggestion, we should probably listen to them instead of trying repeatedly to instill the idea that the IC is perfect as it is. Many successful companies have a customer-obsession mindset, even our evil competition, AWS.
[/quote]

I agree with your sentiment. I am sorry I came off that way. You are right.

My intent was not to say that the IC is perfect.

My intent was more to say:

*I personally believe Latency is a red herring for update/query calls... I personally believe there are half a dozen more vital blockers*

I should have been more clear.

-------------------------

Jdcv97 | 2024-08-17 06:42:03 UTC | #70

https://x.com/communitylabs/status/1823760521637577128?s=46

They came with this thing, thoughs ? @PaulLiu

-------------------------

Jdcv97 | 2024-08-18 04:36:03 UTC | #71

I would assume this is completely garbage, simply a joke..

-------------------------


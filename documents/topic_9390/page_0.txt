diegop | 2021-12-07 03:33:48 UTC | #1

## 1. Summary

This is a motion proposal for the long-term R&D of the DFINITY Foundation, as part of the follow-up to this post: [Motion Proposals on Long Term R&D Plans](https://forum.dfinity.org/t/motion-proposals-on-long-term-r-d-plans/9261) (Please read this post for context).

### This project's objective
Currently, the Internet Computer has two types of subnet blockchains: system (with high replication) and application (with medium replication). This project is to add support for a third subnet type to support dapps with high storage requirements.

## 2. Discussion lead

Akhi Singhania

## 3. How this R&D proposal is different from previous types

Previous motion proposals have revolved around specific features and tended to have clear, finite goals that are delivered and completed. They tended to be measured in days, weeks, or months.

These motion proposals are different and are defining the long-term plan that the foundation will use, e.g., for hiring and organizational build-out. They have the following traits and patterns:

1. Their scope is years, not weeks or months as in previous NNS motions
2. They have a broad direction but are active areas of R&D so they do not have an obvious line of execution.
3. They involve deep research in cryptography, networking, distributed systems, language, virtual machines, operating systems.
4. They are meant to match the strengths of where the DFINITY foundation’s expertise is best suited.
5. Work on these proposals will not start immediately.
6. There will be many follow-up discussions and proposals on each topic when work is underway and smaller milestones and tasks get defined.

An example may be the R&D for “Scalability” where there will be a team investigating and improving the scalability of the IC at various stages. Different bottlenecks will surface and different goals will be met.

## 3. How this R&D proposal is similar to what we have seen

We want to double down on the behaviors we think have worked well. These include:

1. Publicly identifying owners of subject areas to engage and discuss their thinking with the community
2. Providing periodic updates to the community as things evolve, milestones reached, proposals are needed, etc...
3. Presenting more and more R&D thinking early and openly.

This has worked well for the last 6 months so we want to repeat this pattern.

## 4. Next Steps

[ ] Developer forum intro posted
[ ] 1-pager from the discussion lead posted
[ ] NNS Motion proposal submitted

## 5. What we are asking the community

* Ask questions
* Read 1-pager 
* Give feedback
* Vote on the motion proposal

Frankly, we do not expect many nitty-gritty details because these are meant to address projects that go on for long time horizons.

The DFINITY foundation’s only goal is to improve the adoption of the IC so we want to sanity-check the projects we see necessary for growing the IC by having you (the ICP community) tell us what you all think of these active R&D threads we have.

## 6. What this means for the existing Roadmap or Projects

In terms of the current roadmap and proposals executed, those are still being worked on and have priority. 

An intellectually honest way to look at this long-term R&D project is to see them as the upstream or “primordial soup” from which more baked projects emerge from. With this lens, these proposals are akin to asking, “what kind of specialties or strengths do we want to make sure DFINITY foundation has built up?”

Most (if not all) projects that the DFINITY foundation has executed or is executing are borne from long-running R&D threads. Even when community feedback tells the foundation, “we need X” or “Y does not work”, it is typically the team with the most relevant R&D area that picks up the short-term feature or project.

-------------------------

diegop | 2021-12-07 04:46:26 UTC | #2

**Please note:**

Some folks gave asked if they should vote to “reject” any of the Long Term R&D projects as a way to signal prioritization. The answer is simple: “No, please, ACCEPT” :wink:

These long-term R&D projects are the DFINITY’s foundation’s thesis at R&D threads it should have across years (3 years is the number we sometimes use internally). We are asking the community to ACCEPT (pending 1-pager and more community feedback of course). Prioritization can come at a separate step.

-------------------------

akhilesh.singhania | 2021-12-07 07:43:36 UTC | #3

Hi all, I am Akhi Singhania.  I will be the discussion lead for this proposal.  I am the senior engineering manager for the Execution team.  My background is in operating systems and distributed systems.  Before working on the Internet Computer, I worked on [OpenOnload](https://github.com/Xilinx-CNS/onload) and [Barrelfish](http://www.barrelfish.org/).

-------------------------

akhilesh.singhania | 2021-12-07 07:47:34 UTC | #4

# Summary

This project aims to improve the support for dapps with high storage requirements on the Internet Computer.

# Background

Currently the Internet Computer has two types of subnet blockchains: system (with high replication) and application (with medium replication).

System subnets with high replication factor are necessary for platform crucial services like the NNS. They are costly to operate (lots of nodes are needed); slower to update (the finalisation rate is slower to accommodate the additional nodes); but offer very high security. Application subnets have medium replication so they are cheaper; faster to update; but have slightly lower security.

# Objective

As the Internet Computer evolves, it is possible to imagine other types of subnets that operate at different points on the design spectrum and have different trade offs between security vs. speed and cost.

This motion proposes that the DFINITY organisation invest engineering resources into researching and developing additional types of subnets. More concretely the motion proposes to explore the concept of storage subnets. The core feature of this subnet type will be:

* It uses node machines with higher storage capacity and
* It operates with fewer nodes (smaller replication factor) than other subnet types.

In order to realise this new subnet type, research into the following topics will be needed:

* Intra-subnet protocol improvements: to ensure that a subnet with a large state is operational.
* Inter-subnet protocol improvements: to ensure that a less secure subnet cannot impact the security and functionality of other subnets.
* Data integrity improvements: to ensure that data integrity is maintained with lower replication factor.

# Why this is important

At 5 USD / GiB / year, the Internet Computer today already has very competitive fees for storage. This feature will allow the IC to offer storage to dapps at even lower costs (albeit with potentially different semantics and guarantees). Lower storage costs will enable a new class of dapps on the IC that today are prohibitively expensive to run on the IC and help improve resilience of existing dapps by allowing them to store backups of their data.

Due to the lower replication factor, fewer nodes will be needed to provide the same amount of storage capacity on the IC. This means that for the same number of nodes, the IC will be offering a bigger storage capacity.

# Topics under this project

## Intra-subnet protocol improvements

The new storage subnets will have larger states. So additional improvements to the protocol and implementation will be needed to ensure that the large states are properly handled. One obvious component that will have to be improved is state synchronization. This component is responsible for allowing new nodes or slow nodes to catch up with the latest state. Improvements will be needed to ensure that nodes can still catch up even with larger states.

## Inter-subnet protocol improvements

Due to the lower replication factor, the new subnet type might be easier to corrupt or to stall. Protocol improvements will be needed to ensure subnet isolation so that faults in one subnet cannot spread to other subnets.

## Data integrity improvements

A subnet with a lower replication factor can tolerate fewer corrupted nodes. Protocol improvements will be needed to ensure that as long as at least one honest node is available, data integrity will be guaranteed.

# Discussions leads

@akhilesh.singhania , @bogdanwarinschi , @derlerd-dfinity1 

# Why the DFINITY Foundation should make this a long-running R&D project

This project will enable an important class of dapps on the IC. Additionally, a number of protocol and implementation improvements required to achieve the goals of this project will also be applicable to other parts of the IC and improve the IC in general.

# Skills and Expertise necessary to accomplish this (maybe teams?)

Due to the complexity of the initiative, a broad selection of skills as outlined next:

* System design

* System level software engineering

* Algorithms, complexity

* Probability theory

* Cryptography

* Deep understanding of Internet Computer consensus

* API design

At least the following teams are likely required:

* Research

* Networking

* Consensus

* Message Routing

* Execution

* Security

# Open Research questions

There can be multiple other mechanisms to achieve the desired goals of this project.

Another idea is to use erasure codes to split the data on multiple nodes. With this latter approach you could have a subnet with many nodes and high resilience, but where the total storage overhead is small (<2x). Communication is higher during storage and retrieval though (<2x) and the nodes that store data must compute the codewords. Also, search is not as easy, so it depends on whether data will be fully at rest. Also, if the nodes running the storage network change, you have to run an expensive recoding.

# Examples where community can integrate into project

As already mentioned before, in the initial phase of this motion input regarding refining the scope and priorities of this project from the community is highly appreciated. In addition many technical discussions with the community are anticipated as the motion and research and development of potential technical solutions to address the goals of this proposal move forward.

# What we are asking the community

* Review comments, ask questions, give feedback

* Vote accept or reject on NNS Motion

-------------------------

jzxchiang | 2021-12-08 05:22:28 UTC | #5

Thanks for the overview. Excited to see how this develops.

Two questions:

> * It operates with fewer nodes (smaller replication factor) than other subnet types.

With fewer nodes, a subnet may struggle to serve queries with high throughput and low latency. Storage subnets will conceivably store large assets like >1 GB video files. Serving 1 GB may require up to 500 queries (500 queries * 2 MB per query request = 1GB). It's already at least 3x [slower](https://forum.dfinity.org/t/simplest-example-of-http-streaming-chunks-in-motoko/9116/9?u=jzxchiang) serving images from IC versus conventional CDNs. I worry that reducing the # of nodes may make this worse.

> At 5 USD / GiB / year, the Internet Computer today already has very competitive fees for storage. This feature will allow the IC to offer storage to dapps at even lower costs (albeit with potentially different semantics and guarantees).

This is a great opportunity to understand how "prices" in IC are set. This is something that's been bugging me for a while. Right now, storages costs ~5 USD / GB / year on the IC. How were the cycle costs determined? Couldn't we all vote to lower that to, say, 2 USD if we wanted? What economic considerations are important when setting "prices"? A higher price means more cycles (and ICP) will be burned. What is the right deflation rate to target for a healthy ecosystem? Is it OK to accept more inflation in the short term (e.g. lower storage costs) in order to attract developers? I have so many questions.

In a cloud like AWS, the price is set based on ordinary business metrics like SKU unit economics, margin, revenue, etc... How should prices be set on the IC?

-------------------------

jzxchiang | 2021-12-08 05:24:20 UTC | #6

Also, with respect to serving asset files, I think the design of a storage subnet should be informed by the (future) design of IC boundary nodes. If a storage subnet is an IC data center, then the boundary nodes are the IC's CDN. They are [related](https://forum.dfinity.org/t/long-term-r-d-boundary-nodes-proposal/9401/9).

-------------------------

akhilesh.singhania | 2021-12-08 10:08:50 UTC | #7

[quote="jzxchiang, post:5, topic:9390"]
With fewer nodes, a subnet may struggle to serve queries with high throughput and low latency.
[/quote]

This is a good point.  An idea that has been discussed is to have subnets where not all nodes participate in consensus and only serve queries.  Such subnets would be ideally positioned to serve query heavy workloads.  

There are applications that benefit from large storage but do not necessarily need a lot of query capacity (e.g. backups).  However, if the primary usecase is of serving queries, then such subnets may indeed not be ideal.

[quote="jzxchiang, post:5, topic:9390"]
This is a great opportunity to understand how “prices” in IC are set. This is something that’s been bugging me for a while. Right now, storages costs ~5 USD / GB / year on the IC. How were the cycle costs determined? Couldn’t we all vote to lower that to, say, 2 USD if we wanted? What economic considerations are important when setting “prices”?
[/quote]

From my perspective, the current prices are sort of a finger in the air estimate of what they should be.  What prices to charge for something as you can imagine is a very complicated subject indeed.  The ideal price should be where the supply and demand curves meet.  The community could of course make a proposal to set the price to 2 USD or even 200 USD.  But if that is not where the curves interact, we will either have too much supply (not enough usage) or too much demand (not even free capacity left).

I don't know what the best way to set fees on the IC could be.  I just have some intuition from my basic understanding of economics.  I would love to hear from others on this subject.  It is probably wise to fork off a thread for this topic though.

[quote="jzxchiang, post:6, topic:9390, full:true"]
Also, with respect to serving asset files, I think the design of a storage subnet should be informed by the (future) design of IC boundary nodes. If a storage subnet is an IC data center, then the boundary nodes are the IC’s CDN. They are [related ](https://forum.dfinity.org/t/long-term-r-d-boundary-nodes-proposal/9401/9).
[/quote]

Yes, another very valid and fair point.  The two functionalities are deeply connected and one should not be evolved without informing the other.

-------------------------

jzxchiang | 2021-12-09 05:32:39 UTC | #8

> This is a good point. An idea that has been discussed is to have subnets where not all nodes participate in consensus and only serve queries. Such subnets would be ideally positioned to serve query heavy workloads.

Yeah, I was thinking of something [similar](https://forum.dfinity.org/t/long-term-r-d-scalability-proposal/9387/5?u=jzxchiang), but even more generally. What if anyone could host a query node?

Kinda like anyone can run an Ethereum node but not necessarily participate in mining / validating new blocks. But it's even easier in IC because you don't need to download the entire 400 GB blockchain like you do in ETH; you just need to download a catch-up package from the subnet you're running the query node for.

> There are applications that benefit from large storage but do not necessarily need a lot of query capacity (e.g. backups). However, if the primary usecase is of serving queries, then such subnets may indeed not be ideal.

Exactly. S3 and GCS have different storage classes for different cost + latency requirements.

> What prices to charge for something as you can imagine is a very complicated subject indeed. The ideal price should be where the supply and demand curves meet.

This is something I've been thinking about. Why is the price for 1 GB / year storage ~$5 on the IC but ~$840,000,000 on Solana? Is it really because the curves for the supply for storage and the demand for storage intersect at a point much lower on the IC than on SOL? The economics are hard to wrap my head around, since there's not a conventional supply curve here. Node providers supply storage but also supply compute, and are compensated with monthly rewards based on SLA instead of on a per-unit basis. I'd be curious about the decision [rationale](https://github.com/dfinity/ic/blob/8fdbd8f514743fb38c3d8d56112a4e49a76c701e/rs/config/src/subnet_config.rs#L225) of the current cycle costs.

-------------------------

akhilesh.singhania | 2021-12-10 13:17:27 UTC | #11

[quote="jzxchiang, post:8, topic:9390"]
Yeah, I was thinking of something [similar](https://forum.dfinity.org/t/long-term-r-d-scalability-proposal/9387/5), but even more generally. What if anyone could host a query node?

Kinda like anyone can run an Ethereum node but not necessarily participate in mining / validating new blocks. But it’s even easier in IC because you don’t need to download the entire 400 GB blockchain like you do in ETH; you just need to download a catch-up package from the subnet you’re running the query node for.
[/quote]

In theory this should work.  I suppose we would start off with the simpler version of this where the nodes are similarly capable and managed in a similar style as all other nodes.  Once the engineering is worked out from that, then extend...

[quote="jzxchiang, post:8, topic:9390"]
This is something I’ve been thinking about. Why is the price for 1 GB / year storage ~$5 on the IC but ~$840,000,000 on Solana? Is it really because the curves for the supply for storage and the demand for storage intersect at a point much lower on the IC than on SOL? The economics are hard to wrap my head around, since there’s not a conventional supply curve here. Node providers supply storage but also supply compute, and are compensated with monthly rewards based on SLA instead of on a per-unit basis. I’d be curious about the decision [rationale ](https://github.com/dfinity/ic/blob/8fdbd8f514743fb38c3d8d56112a4e49a76c701e/rs/config/src/subnet_config.rs#L225) of the current cycle costs.
[/quote]

I think we roughly calculated it as following.

- eventually the IC protocol and implementation will be sufficiently improved that a subnet with 3TiB of disks will be offer around 1TiB of storage to canisters.
- A disk has a lifetime of 4 yrs.
- $5 / GiB / year => $20 / GiB / 4 yrs => $20'000 / TiB / 4 yrs.
- For a 7 node subnet, that is a little less that $3k per node and for a 13 node subnet, that is around $1500 per node. 

As more experience is gathered from operating the IC, the above assumptions will have to be revised.

-------------------------

diegop | 2021-12-20 19:33:55 UTC | #12

Proposal is live: https://dashboard.internetcomputer.org/proposal/35649

-------------------------

C-B-Elite | 2022-03-10 07:00:30 UTC | #13

What will be happend when the storage subnet on live? If we have storage much files, such as NFT metadata  in canisters on the application subnet, how can we move the data to the storage subnet?

-------------------------

jzxchiang | 2022-04-19 01:23:02 UTC | #14

Are there any updates on this?

-------------------------

Hashimoto | 2022-04-19 09:31:42 UTC | #15

Just chipping in to suggest that legal, privacy and censorship issues should be a key part of the design consideration, and noting that:

1. Even defining the objectives and potential design space will require some debate and learning from prior art.
2. There is interdependency with other research programs and ongoing debates such as DNS as censor or boundary nodes as censor, or the role of the NNS.

-------------------------

jzxchiang | 2022-07-08 20:45:47 UTC | #16

Are there any updates on this? I'd like to store videos and images on-chain, but the $5 / GB / year will need to be brought down (by 2-3 orders of magnitude) to make it economical to do so.

-------------------------

Sormarler | 2022-09-10 03:45:54 UTC | #17

If the internet computer is the truly match the internet and four people to be able to build any application on it, we all likely going to need a storage subnets that can compete on price and performance with the likes of  AWS and other decentralized storage networks. $5 per gig while it is cheap for a blockchain, but it is still prohibitively expensive for running data intensive applications. I wonder if there is any progress at all to make this happen on the internet computer.

-------------------------

Zane | 2022-09-10 04:38:55 UTC | #18

Competing with AWS is impossible unless Amazon earns an incredibly high margin on data storage, the inherent overhead of a decentralized system will always make it more expensive than a centralized one and if we want deflation the cycle cost per instruction can't be arbitrarily lowered, instead I think we should aim to compete with similar systems focusing on decentralized storage only: Filecoin, Arweave, Storj to name a few. That's a much more realistic goal

-------------------------

JaMarco | 2022-09-10 05:06:23 UTC | #19

[quote="Zane, post:18, topic:9390"]
I think we should aim to compete with similar systems focusing on decentralized storage only: Filecoin, Arweave, Storj
[/quote]

Whats your definition of "compete"?

-------------------------

Zane | 2022-09-10 05:16:24 UTC | #20

Pricing mainly, on Arweave 1GB costs 8$ for 200 years worth of *immutable* storage, that's orders of magnitude cheaper than IC. If you add the cost to upload the data to the IC, which according to this tweet, is around 7$ per GB, any app with non trivial memory usage is not economically viable on the IC. 

https://twitter.com/BobBodily/status/1568346734287540224?t=m2RTODheSXJOHXJnEBQy5A&s=19

-------------------------

Denis | 2022-09-16 19:18:41 UTC | #21

@akhilesh.singhania any update on storage subnets?

-------------------------

berestovskyy | 2022-09-29 17:09:15 UTC | #22

Hey guys,
Sorry for not updating you for such a long time.

While this is a long term vision, there some concrete steps in this direction done or in progress (see the last [Global R&D](https://youtu.be/Q9FJtye_-6E?t=849)):

1. **Stable Structures** -- allows to store data directly on the stable memory, [repo](https://github.com/dfinity/stable-structures).
2. **High-repl. Subnets** -- allows to choose a subnet type with a higher replication factor or more storage space.
3. **Replica HW 2.0** -- a step toward having subnets with more storage.
4. **Big Data** -- Scalability and Performance group is working on allowing canisters to access much more data. It's open, you can find more info and join [on our wiki](https://wiki.internetcomputer.org/wiki/Scalability_%26_Performance).
5. **32GB Stable Memory** -- allows canisters to have up to 32GB of stable memory.

Sorry, it's just from the top of my head, and we don't have any price targets yet... But we definitely work on storage.

-------------------------

jzxchiang | 2022-10-18 06:22:56 UTC | #23

This was an interesting part of Dominic's recent blog [post](https://medium.com/dfinity/lets-grow-the-internet-computer-network-why-and-how-and-general-updates-1c8d0770a299):

> Subnets can also have less replication. For example, we hope to eventually add a “Storage” subnet type, which replicates data processing and storage across only four nodes. This will enable Storage smart contracts to leverage persistent memory pages very inexpensively, making it more economical to store a user photo and video libraries in smart contracts, or their newsfeed say, with the tradeoff being that contracts are hosted with much weaker security and liveness guarantees.

> **Pro Tip for developers:** Due to the much weaker security and liveness guarantees that Storage subnets provide to hosted smart contracts, smart contracts tagged “Storage” will not be able to call into other smart contracts. However, this will not stop them playing the role of perfect data buckets.

-------------------------

JaMarco | 2022-10-18 09:08:42 UTC | #24

I'm not sure what the advantage would be to save data on storage subnets as opposed to just saving data on IPFS/Filecoin.

-------------------------

jb747 | 2022-10-26 23:12:25 UTC | #25

A specialized subnet might be capable of transferring data into a requesting canister more simply and quickly than an external storage service accessed via an HTTPS API.

-------------------------

Sormarler | 2022-12-06 02:41:20 UTC | #26

Today open chat just announced that they have almost reached their limit in the current subnets. They only have 60,000 people and they are already topping out the subnet. What is the plan to scale beyond cross subnet canisters. I fear that without storage subnets, just a few million people using socials will take the bulk of compute and storage across all subnets of the IC. What is the plan to deal with a huge spike in users overnight?

-------------------------

hpeebles | 2022-12-06 22:50:49 UTC | #27

Hey! I am one of the OpenChat devs.

The current bottleneck we're hitting is due to the number of canisters on the subnet, not the storage.
Dfinity have plans to allow subnets to handle far more canisters than currently possible but this work hasn't been done yet, hence why we need to start scaling onto a 2nd subnet.

The OpenChat subnet is currently using ~300GB of storage, but the vast majority of that is from having to store all of the canister wasms, each canister is around 3-4MB, and we have 70k canisters, so those canister wasms are probably around 250GB. But we only actually have ~10 different wasms, since each user canister runs the same wasm and each chat group also runs the same wasm.

Dfinity have plans to deduplicate the wasms, this will reduce our storage usage to around 50GB.

So although we are currently hitting the limit of our subnet, this is a temporary limit, and in the future it is likely we'll have 100's of thousands or even millions of canisters on a single subnet.

:chart_with_upwards_trend:

-------------------------

icme | 2022-12-07 01:05:45 UTC | #28

[quote="hpeebles, post:27, topic:9390"]
Dfinity have plans to deduplicate the wasms, this will reduce our storage usage to around 50GB.
[/quote]

This feature would be great! @diegop any idea on who’s leading it and what the ETA might be? 

Several projects are really pushing scalability limits live on the IC right now, it’s a very exciting time to be an IC developer or investor. A reminder to everyone reading this that growth problems are a good sign as long as you have solutions coming down the pipeline!

-------------------------

diegop | 2022-12-07 02:43:52 UTC | #29

[quote="icme, post:28, topic:9390"]
@diegop any idea on who’s leading it and what the ETA might be?
[/quote]

No, but I’ll ask the team.

-------------------------

cymqqqq | 2023-01-17 07:03:17 UTC | #30

any update on storage subnets?

-------------------------

diegop | 2023-01-18 21:36:12 UTC | #31

Thanks for asking @cymqqqq . I did ask few weeks ago, but did not get an answer as folks are all heads down on SNS or BTC work, let me ping some other folks.

-------------------------

bjoern | 2023-01-18 22:34:14 UTC | #32

The current thinking is moving away from the notion of an explicit storage subnet and toward providing a more scalable type of blob storage (i.e. that would have somewhat weaker access guarantees but be much easier to scale than canister state) on each subnet. The main reasons for this change are that the access is faster if we keep the storage closer to the canister, and that the storage inherits the same decentralized structure from the subnet that hosts the canister. Dom pointed toward these discussions in [a recent tweet](https://twitter.com/dominic_w/status/1615073385108709376?s=20&t=5uslXmaRTPDwolfnEvy9DQ). We hope to provide more updates soon.

-------------------------

skilesare | 2023-01-18 22:49:59 UTC | #33

Hmmmm.....There are a whole host of applications around context-mutable data that still need access to data in a mutable state.  If I'm reading this right, the considered solution is immutable storage(write once, never delete) that could be really cheap. Is that a correct understanding?

If this is the case then our use case would produce a ton of writes and leftover copies of things.

-------------------------

Tbd | 2023-01-18 23:01:57 UTC | #34

[quote="JaMarco, post:24, topic:9390, full:true"]
I’m not sure what the advantage would be to save data on storage subnets as opposed to just saving data on IPFS/Filecoin.
[/quote]

+1 to this. Should just focus on better interop with those instead.

-------------------------

bjoern | 2023-01-31 09:03:33 UTC | #35

The data could be deleted. It could also be read by the canister, but the read operation would be relatively slow (reading would need to go through consensus, as the way the data would be stored does not guarantee that it's available to all nodes).

That last part would also be the case if data were stored on IPFS or so.

-------------------------

skilesare | 2023-01-31 13:01:36 UTC | #36

if someone has time and information, it would be cool to see a little back of the envelope math of what an HTTP out call to an IPFS gateway to retrieve a file would cost per byte. Do you really need consensus for these since the IPFS hash has the verifiability built into it? You could give it to the application to decide to trust a hash or not.

-------------------------

free | 2023-01-31 15:14:50 UTC | #37

The reason why an IPFS read would need to go through consensus is not so much in order to ensure consensus (i.e. that a majority of replicas read the same content), but because that's how inputs make it into a subnet, whether it's ingress messages, canister messages or HTTP responses: they get included into a block. And said block needs to go through consensus in order for a majority of replicas to agree that it is indeed a valid block.

We have been idly considering the possibility of not putting all payloads into blocks, but only their hashes. That still requires the actual payload to be present on a majority of replicas in order for them to be able to decide whether the block is valid or not. And eventually every single payload would need to make it onto each replica regardless, in order for the replica to be able to make any progress at all.

-------------------------

skilesare | 2023-01-31 17:22:35 UTC | #38

[quote="free, post:37, topic:9390"]
We have been idly considering the possibility of not putting all payloads into blocks, but only their hashes.
[/quote]

Ahhh...This is interesting.

Just a couple of comments for more context of what I was thinking:

1. Because of the way IPFS works, asking to retrieve an already consensus-agreed-upon hash could be handled by a 4-node subnet at a smaller price than a 34-node fiduciary subnet.

2. I've made this same argument as to why 4 node subnets are ok for storage if you took the hash of the file previously on a larger subnet....you can trust the transfer of the data back to your bigger subnet for processing.

I'm more curious about doing a cost analysis of storing on a 4-node subnet per GB so all data is always on vs retrieving via http_outcalls to get data as needed and what the inflection point might be.

Another interesting comparison:

If I want to mutate a file via deterministic canister is it cheaper to 

1. Ship the file from a 4 node subnet to a 13 node subnet, do the manipulation, store the hash and ship the mutated file back for storage.

or

2. Ship the file from a 4 node subnet to a 13 node subnet to do the manipulation, store the hash and only return the hash. Have a dapp run the same code off-chain and push the file to the 4 node subnet for storage(can be checked later by the 13 node via the hash).

-------------------------

free | 2023-02-01 17:43:41 UTC | #39

I wanted to reply to this since yesterday, but I didn't have a good answer. And unfortunately I still don't. This is clearly something I have not spent much time thinking about.

The issue I see with using either IPFS or a low-replication subnet for storage; and a high-replication subnet for backend logic is that you have to ship data back and forth between the two. And you run into whatever bandwidth limitation the subnet has (currently 4 MB/s, although one can imagine 10x that; but likely not 100x).

There are some use cases that would be at least somewhat practical (e.g. append-only storage; or a video platform where content is not mutated a lot and the content hash may even come directly from the FE, without requiring "upload" of the video through the BE; etc.). But I cannot think of an efficient solution for something like a general purpose database, where arbitrary, small chunks of data get updated all the time.

One could e.g. chunk the data and maintain hashes for each chunk. But if the chunks are large, you need to transfer a lot of data back and forth between BE subnet and storage subnet. And if the chunks are small, then your hashes will likely not be a lot smaller than the underlying data. And regardless of chunk size, you still run into the subnet's bandwidth limits.

I'll keep thinking about this, it's an interesting problem. Thanks for bringing it up.

-------------------------

free | 2023-02-01 19:12:01 UTC | #40

One half-baked idea, just so I don't forget it. Not sure how useful this would be, but here goes.

Assume an arbitrarily large database. Break it down into chunks of _N_ MB. For each chunk:
* Break it down into segments of _M_ KB.
* Hash every segment.
* Produce a Merkle tree out of segment hashes. Its root hash is the chunk hash.
* Store the chunks (with Merkle trees) on a low-replication subnet.
* Store the chunk hashes on a high-replication subnet.

Then, when the high-replication subnet wants to read some data, the low-replication subnet replies with:
* the requested data segments;
* a witness consisting of the pruned Merkle tree branches needed to recompute the chunk root hash (every hash immediately to the left and to the right of the subtree consisting of the requested segments).

The high-replication subnet can use the above to verify that the data has not been tampered with.

every time the high-replication subnet wants to mutate the contents of the database, have the high-replication subnet send a mutation request to the low-replication storage subnet. The storage subnet applies the mutation and replies with:
* the same witness as above, plus the hashes of the affected segments before the mutation was applied;
* the contents of the first and last affected segments before the mutation was applied;
* the new chunk root hash (only as a sanity check).

Using the above, the high-replication subnet can verify that:
* the data before applying the mutation had not been tampered with (from validating the witness)
* the "before" contents of the first and last segment match their "before" hashes;
* only the requested parts of the first and last segments have been mutated;
* the new chunk hash has been correctly aggregated from: the computed hashes of the first and last segment; the precomputed hashes of all other mutated segments; and the witness.

Once it has verified that the mutation has been applied correctly, the high replication subnet can replace the old chunk hash with the new one.

There are still some rough edges (e.g. what if the high replication subnet panics and fails to update the chunk hash after the chunk has been mutated) and unanswered questions (e.g. how would you prove the correctness of something as simple as a count query), but the above should give you arbitrarily mutable storage with very little overhead (where you can trade up to 2x storage for lower network overhead; or the other way around). Oh, and obviously, some issues regarding concurrency. The protocol guarantees in-order delivery of requests, but not of responses (although if the low-replication subnet does not do any downstream calls, you can pretty much have in-order responses too; just not 100% guaranteed).

-------------------------

skilesare | 2023-02-01 19:51:39 UTC | #41

Super interesting pattern.  

Is the mutation verified programmatically somehow?  Maybe a simple example would help.

-------------------------

free | 2023-02-02 07:28:20 UTC | #42

I don't have any example at hand, but yes, the whole point is for both reads and mutations to be reliably verified by the high-replication subnet, with the low-replication subnet serving merely as replicated storage.

For more context about Merkle trees and how they can be used to verify whether some piece of data is authentic (which the above uses both when reading and mutating data), check out this [very straightforward description](https://www.bitpanda.com/academy/en/lessons/everything-you-need-to-know-about-merkle-trees/) (do note that their last picture is wrong, though: those leaves are not supposed to be messages, but hashes; that witness would prove that `m6.5` has not been tampered with, not `m6`; and you'd need the hash for `m7` instead of the one for the node above `m7` to do the verification; so, so close to a clean explanation). (o:

-------------------------

Zane | 2023-02-03 16:25:19 UTC | #43

Think it might be worth taking a look at how other projects are trying to tackle the same issue: 
https://github.com/bnb-chain/greenfield-whitepaper/

-------------------------

Ajki | 2023-12-23 11:51:57 UTC | #44

Any updates, regarding storage subnets.

-------------------------

Sormarler | 2023-12-24 10:25:11 UTC | #45

This will be super important when the internet computers start to having really storage hungry applications.

-------------------------

augchan42 | 2024-01-02 13:25:37 UTC | #46

I have a question about the asset storage for front end canisters.  Is this persisted to disk or does it stay in RAM?

-------------------------

domwoe | 2024-01-03 15:31:46 UTC | #47

All canister memory is persisted to disk and this is automatically managed by the platform. You can read more about the concept, called Orthogonal Persistence, here: https://mmapped.blog/posts/06-ic-orthogonal-persistence

-------------------------


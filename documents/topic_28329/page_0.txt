lastmjs | 2024-03-11 12:24:09 UTC | #1

Some social context: https://x.com/lastmjs/status/1766471613594083348

ICP has a number of crucial weaknesses that I believe work together to help inhibit it from achieving the vision of an unbounded scalable virtual machine, blockchain singularity, infinite scalability, or any other form of saying that ICP will be a limitless compute platform.

The premise of prioritizing to completely remove these weaknesses stems from that vision. If you don't believe in that vision, believe it's impossible, or believe it's unwise to seek it, that's a different concern or topic. I also believe you then go against the vision of ICP that has been sold for years.

These are the crucial weaknesses. We should resolve them to stop inhibiting achievement of the vision. I have put them somewhat in order of my perceived priority or importance:

1. Instruction limits
2. Memory limits
3. High latencies
4. Message size limits
5. Storage limits
6. High costs
7. Rigid network architecture (subnets static, canister unable to choose replication/security with flexibility, can't move between replication factors, homogenous hardware required)
8. Centralizing DAO governance (one entity able to gain write access to the provisioned protocol, lack of checks and balances)

From my own point of view and desires, I ask for DFINITY to focus and prioritize with relentless effort to completely resolve each of these issues to the satisfaction of developers and community members.

Wisdom is of course required to weigh these concerns with the many other concerns. But I urge you to consider the possibility of great harm being done to ICP's growth and success by continuing to prioritize other matters over these crucial use-case-inhibiting weaknesses of the protocol.

-------------------------

ChauDoan21165 | 2024-03-11 12:28:43 UTC | #2

Thank you! ICP need this for being more powerful in the future!

-------------------------

cryptodriver | 2024-03-11 12:55:59 UTC | #3

We have not too much time to waste. More and more players are coming to fight against ICP. 

I personally totally agree with you, and hope dfinity team to solve these problems as soon as possible.


ICP is the best, if it could clear these problems.

-------------------------

evanmcfarland | 2024-03-11 13:12:25 UTC | #4

Thanks for being the voice of this Jordan. It feels this summary of requests is a broken record of community-requested priorities.

My personal project could greatly benefitted from higher instruction, memory, and storage limits. Having lost hope in timely progress on this, I've moved these operations off-chain, and wish I made that decision months ago. I don't plan on migrating off the IC, but since my dapp is now an 'off-chain hybrid', it forces me to wonder why I'm building here.

-------------------------

ktimam | 2024-03-11 13:43:29 UTC | #5

Hope those issues gets prioritized as well.

-------------------------

LightningLad91 | 2024-03-11 14:00:28 UTC | #6

I appreciate you taking the time to express your thoughts both on Twitter and here in the forum. I do have a few questions.

[quote="lastmjs, post:1, topic:28329"]
If you don’t believe in that vision, believe it’s impossible, or believe it’s unwise to seek it, that’s a different concern or topic. I also believe you then go against the vision of ICP that has been sold for years.
[/quote]

As someone who works in computer science professionally, regardless of the DFINITY marketing material, do you believe it is actually possible to build a world computer that provides "unbounded" processing and "infinite scalability"? 

I have other questions/feedback but I was hoping you might respond to this question first.

-------------------------

hehe | 2024-03-11 14:08:44 UTC | #7

My concern is: will there be an official person involved in the discussion

-------------------------

lastmjs | 2024-03-11 14:14:35 UTC | #8

I hope so. My original hopes for ICP were a protocol like TCP/IP. Would you consider TCP/IP infinitely scalable? I would.

For example, instead of subnets being exposed to users and storage being limited to a single subnet, I envision a virtual memory system, perhaps on top of an underlying subnet system, that abstracts the underlying storage access mechanisms. Operating systems do this when RAM hardware is reaching capacity, allowing the hard drive to be used as a location for RAM, all of this as I understand it, transparent to the processes. They don't need to program themselves with the understanding of a virtual memory system.

Is there any reason why a virtual memory system could not scale infinitely, at least to the needs of the current population of Earth?

-------------------------

LightningLad91 | 2024-03-11 14:27:12 UTC | #9

Thanks for the response. I believe TCP/IP as a protocol is infinitely scalable, sure. Are we just talking about scaling the logical components of ICP? If that's the case then I think your argument could be presented differently.

[quote="lastmjs, post:8, topic:28329"]
Operating systems do this when RAM hardware is reaching capacity, allowing the hard drive to be used as a location for RAM, all of this as I understand it, transparent to the processes.
[/quote]

But even in this case the amount of swap space is bounded by the configuration of the system, or at the very least, the storage capacity of your drive.

As an engineer, I just have a hard time wrapping my head around unbounded things. When we have unbounded requirements it leads to a lot of risk, as well as potentially wasted effort and resources.

[quote="lastmjs, post:8, topic:28329"]
at least to the needs of the current population of Earth?
[/quote]

It may seem silly but even setting this expectation seems more reasonable to me. One of my other questions was going to be to ask if you were willing to set some measurable expectations for the following bullets, even if they seem crazy I think it would make for a more productive conversation with the DFINITY engineers.

[quote="lastmjs, post:1, topic:28329"]
* Instruction limits
* Memory limits
* High latencies
* Message size limits
* Storage limits
* High costs
[/quote]

-------------------------

lastmjs | 2024-03-11 14:31:12 UTC | #10

[quote="LightningLad91, post:9, topic:28329"]
But even in this case the amount of swap space is bounded by the configuration of the system, or at the very least, the storage capacity of your drive.
[/quote]

I'm saying that the virtual memory system would use subnets or any other abstraction or division necessary under-the-hood to present the developer with a single contiguous address space.

-------------------------

LightningLad91 | 2024-03-11 14:36:57 UTC | #11

[quote="lastmjs, post:10, topic:28329"]
I’m saying that the virtual memory system would use subnets or any other abstraction or division necessary under-the-hood to present the developer with a single contiguous address space.
[/quote]

I understand the ask. I’m just not clear on the expected outcome. Am I correct in my understanding that you want this change so that you don’t have to worry about hitting any storage limits? If so, how does creating a virtual memory system spanning multiple subnets prevent that? There aren’t an infinite number of subnets so eventually the protocol will hit a limit there too.

-------------------------

lastmjs | 2024-03-11 14:37:54 UTC | #12

[quote="LightningLad91, post:9, topic:28329"]
It may seem silly but even setting this expectation seems more reasonable to me. One of my other questions was going to be to ask if you were willing to set some measurable expectations for the following bullets, even if they seem crazy I think it would make for a more productive conversation with the DFINITY engineers.
[/quote]

Instruction limits: there should be no limit as long as it is paid for. Hours of computation should be possible, days even, weeks. GitHub Actions for example times out after a few days I think.

Memory limits: probably 100s of GiBs, maybe less

High latencies: the same as Web2, I don't know under one second for most requests? As fast as the network please

Message size limits: At least abstract chunking entirely away from the clients and increase the throughput so that it isn't noticeable. I should be able to upload data at the speed of the network and other processes required, the actual limit probably doesn't matter if throughput and chunking is never seen by a dev or library author

Storage limits: unbounded as long as you pay, like I assume Filecoin and Arweave give you. Make a virtual memory system for this

High costs: as cheap as the replication? As cheap as possible, barely any margin over the actual resource costs...I don't know, maybe BFT can be obtained in other ways besides replication

I want this to feel like a Web2 app but with extra-high levels of security. That's really what we're after. And security in these senses: confidentiality, integrity, availability, verifiability

-------------------------

lastmjs | 2024-03-11 14:43:49 UTC | #13

Maybe not necessary if adding storage space within a subnet is simple enough.

I want to get rid of the subnet abstraction though, canisters should just exist on the network, have memory and storage, choose level of security, and communicate with other canisters or the Internet, super secure, very fast.

-------------------------

LightningLad91 | 2024-03-11 14:51:22 UTC | #14

I think i'm starting to understand.

Let say that ICP develops into a system that appears, from the developers perspective, to be infinitely scalable. A dev can run a process as long as they like, store as much as they want, and all that. Now let's say in reality there is an army of people at DFINITY or some other org actively managing the network in the background; actively adding and removing nodes in realtime to meet the needs of the network so that this appearance of infinite scalability is maintained. In that scenario, would your expectations be met?

Edit: I should've added that there would obviously be a (managed) risk that the network could run out of resources in the event of some catastrophe or organziational failure. But 99.999% of the time you as a dev wouldn't have to worry about that.

-------------------------

lastmjs | 2024-03-11 14:52:21 UTC | #15

Sure...from the dev side that's what I want and I feel like that's what was promised.

How that actually works under the hood, I would hope it would be decentralized, transparent, relatively permissionless, and automated. Not one or two orgs manually adding and removing resources.

-------------------------

lastmjs | 2024-03-11 14:56:27 UTC | #16

ICP is pretty good at some kinds of horizontal scaling right now, but vertical scaling of even a single app is very bad. You can't get many single apps that work just fine on Web2 to work on ICP because of all of these vertical/single app limits.

So we can have a lot of subnets right now filled with crippled applications, and we can keep scaling that out pretty far it seems.

We need to get rid of the limitations on single applications so that we can actually build real-world solutions.

-------------------------

LightningLad91 | 2024-03-11 14:58:26 UTC | #17

I think this is a reasonable expectation.

[quote="lastmjs, post:15, topic:28329"]
How that actually works under the hood, I would hope it would be decentralized, transparent, relatively permissionless, and automated. Not one or two orgs manually adding and removing resources.
[/quote]

I do wonder though, if you and I were to continue workshopping this, how soon we'd come up with something similar to what is being done today with ICP.  Like yourself, I have concerns about the network. But from an architecture standpoint I think DFINITY has developed something that can, theoretically, support the sort of decentralized administration you desire. For me, the biggest risk is the decentralization of the governance.

[quote="lastmjs, post:16, topic:28329"]
We need to get rid of the limitations on single applications so that we can actually build real-world solutions.
[/quote]

I do agree.

-------------------------

CoolPineapple | 2024-03-11 15:38:08 UTC | #18

> 1. Instruction limits

My understanding is that this is already in production with [Deterministic Time Slicing](/t/deterministic-time-slicing/10635) does this not already cover this issue? 

Do they just need to increase/remove the limit or is something else required?

> 2. Memory limits

Do you mean WASM memory and ease of sharing across multiple canisters? 

> 3. High latencies

Queries can be cached but for updates. I really can't see how this can be solved given the need for BFT. The consensus latency is about as low as it can go baring some novel cryptography or completely rearchitecting as rollups. And from my POV subnet replication factors are about as low as acceptable anyway.

What it sounds like you are suggesting though is that there is need for more flexibility to choose very low replication factors for low risk Dapps and I recall a game dev saying something similar. But at some point that just becomes a single server without any replication and correctness guarantees. 

One left field idea might be to allow pass though P2P communication so that applications can just work with low latency by exchanging operational transformation/ crdts and only update the consensus state to save snapshots or where trust is important.

Thus for example a game would proceed with players sharing signed messages, updating their game state locally and bypassing the IC consensus nodes most of the time. With the IC saving a snapshot at random intervals. In most cases play would happen with very low latency but in case of dispute you would run a replay of say the last 30 seconds of signed messages since the last snapshot and let the canister decide the state.

Variant would have pass though nodes just notarise the messages as seen without updating state.

> 4. Message size limits

I think (from your twitter thread) you are specifically referring to message payload size here with reference to file uploads. Chunking is already implemented for canister WASM uploads so making that for general file uploads and providing grants for tooling around that would seem to fix a lot of the issues except it still would be slow.

* Perhaps there is a way to upload and download in parallel using multiple boundary nodes or perhaps specialised large file server nodes.
* I worry about DoS attacks if the size is increased unless some metering is applied.
*  Perhaps there needs to be a separate pure storage system.

> 5. Storage limits

Think something could be done about making file storage a transparent service across multiple subnets but again this seems to speak to the need for specialised file storage. I would not however that Filecoin and Arweave are both subsidising storage with issuance.  So I'm not really convinced their model is sustainable. 

Perhaps the play here is not for the IC itself to provide large scale storage but to deeply integrate with existing file storage networks like Filecoin,  Arweave and Ethswarm.

BTW Might be an interesting play for @dfinity to team up with [Ethswarm](https://www.ethswarm.org
) as they are almost completely overlooked and underused so would should in theory welcome both funds and  collaboration. Though perhaps they are politically too cyberpunk and Ethereum orientated to accept a deal.

> 6. High costs

Elephants in the room here are:

* Most networks subsidise via issuance. ICP doesn't but it has unnecessarily high NNS rewards. 
* Costs have to be multiples due to replication.
* Subnets are not actually net burners of ICP so if anything devs are being undercharged given node rewards. (There are potential pricing models which square this circle but they mean more uncertainty about costs)
* Dev pays model means costs fall on devs and also that we don't benefit from MEV burn.

> 7. Rigid network architecture (subnets static, canister unable to choose replication/security with flexibility, can’t move between replication factors, homogenous hardware required)

This is true but nothing stops more flexible systems being built on top of the IC. I think there is potential for incentivised service workers and storage services to be built on top. That this isn't happening speaks to a cultural problem that the IC is positioned as a one stop full stack and this discourages infrastructure investment by parties which are not Dfinity. 

> 8. Centralizing DAO governance (one entity able to gain write access to the provisioned protocol, lack of checks and balances)

This is huge and fundamental and solving it would require not just technical breakthroughs but a change in philosophical direction. It would also mean confronting the moral issues around building an actually uncensorable network.

-------------------------

jeshli | 2024-03-11 16:22:49 UTC | #19

[quote="CoolPineapple, post:18, topic:28329"]
My understanding is that this is already in production with [Deterministic Time Slicing](/t/deterministic-time-slicing/10635) does this not already cover this issue?

Do they just need to increase/remove the limit or is something else required?
[/quote]

Here is some additional context on instruction limits that may help clarify things.

Reviewing the DTS thread shows that:
1. DTS will have a maximum increase of another 2.5x to the current Update instruction limit (for a total of 50 billion instructions) [at that point DTS will be at its current limit of 500 rounds](https://forum.dfinity.org/t/deterministic-time-slicing/10635/83?u=jeshli) and more fundamental changes to the protocol would be needed.   
2. DTS is not required for queries, however:
    * Queries hold the entire subnet state in memory until the query is complete ["only retaining the state of a single canister as opposed to the whole subnet’s is not something that’s supported yet. I believe it is technically possible, but it would likely take time and effort to design and implement."](https://forum.dfinity.org/t/deterministic-time-slicing/10635/93?u=jeshli) 
    * Only a few concurrent queries are allowed "the average web server that can handle hundreds of concurrent requests, we impose a hard limit (4? 10?) on the number of concurrent queries"

In another thread, we tried to address another aspect of the issue which is that queries are currently free. This leads to DDOS vulnerability and network cost asymmetry and lack of sustainability. [The DeAI community has suggested enabling a fee option to queries in order to address those short comings.](https://forum.dfinity.org/t/community-consideration-explore-query-charging/19247/32?u=jeshli)

-------------------------

marcpp | 2024-03-11 16:49:47 UTC | #20

Great thread! 

[quote="lastmjs, post:16, topic:28329"]
You can’t get many single apps that work just fine on Web2 to work on ICP
[/quote]
Unless I've misunderstood the IC's vision, this should be the main focus. Otherwise, what's the point?

I really hope we can get some **answers from Dfinity** on how they plan to tackle those [limitations](https://forum.dfinity.org/t/lets-solve-these-crucial-protocol-weaknesses/28329/12?u=marcpp). Even if it's long term. @lastmjs says he's in contact with them on a regular basis, so I'm confident they're aware of those issues, but it'd be great to let the community know what's being said. The fact that @lastmjs has to [come out publicly](https://twitter.com/lastmjs/status/1766471613594083348) suggests he might not be as listened as he'd hope. Which is fine if Dfinity have their own convictions and prioirities. But having some transparency about all this would be awesome.

Again, this is the only thing that matters to me (and many in the community I'm sure):
[quote="lastmjs, post:16, topic:28329"]
You can’t get many single apps that work just fine on Web2 to work on ICP
[/quote]

-------------------------

PaulLiu | 2024-03-11 17:40:43 UTC | #21

Hi @lastmjs , thanks for summarizing the list of weaknesses of ICP from your twitter post on this forum. I don't think Twitter is a good venue for in-depth discussion, so I'm glad you moved them here.

While others may be able to make suggestions to address these weaknesses, I want to digress a bit and focus on the background of your twitter post, namely, whether AO is a sound protocol that allows for infinitely scalable (and secure) computations without the trade-offs made in ICP.

But first, I'll take a detour in a completely different direction, and discuss how exactly we "Don't trust, Verify". Please bear with me, and you will understand why I want to do this before explaining what AO is about.

IMHO, blockchain is all about verification. So "how to verify" is the no.1 crucial thing when it comes to understanding a blockchain protocol. "How to verify" certainly has evolved over the years:

1. **Run a full node** to sync all block history since genesis, and for each block, verify inputs in it, perform required computation, and verify outputs. Note that a full node is also required to participate in blockchain consensus, where it is expected to perform both verification and computation (in addition to agreeing on the ordering of inputs).
2. But running a full node is very demanding, and ordinary users do not have resources to run them. Instead, when a user only wants to verify, they can **run a light client** to sync all block headers since genesis (or a recent and publicly known checkpoint), and for any received data that requires verification (which can be a full block or part of a block with merkle proof), check whether the merkle hash matches known block headers. Bitcoin SPV client would also compute utxos for the user, but Ethereum light client only verifies data without running actual smart contract computations. So a light client is assuming that a verified block has the consensus of the majority of full nodes in a blockchain, and the result of computation is correct.
3. ICP goes one step further by **reducing the implementation of a light client down to verifying a BLS signature**. If the signature checks out, it is assumed that the result has the consensus of all full nodes in a blockchain (namely, one IC subnet), and the result of computation is correct.
4. Layer 2 (L2) roll-ups took a different direction when it comes to verification, because it can seek the help from a smart-contract enabled layer 1 (L1). Instead of running a consensus protocol and replicated computations, L2s usually run a centralized server to process user transactions. The results (after running through many blocks on the central server) are "rolled-up" into a short evidence and put on L1 for verification. 
    * For zk-rollups, the verification is done by **a smart contract on L1 checking zero-knowledge proof** against the evidence. 
    * For optimistic roll-ups, the verification is only required when a challenger submits a challenge to the L1 smart contract, and the **L1 smart contract will re-compute everything and verify** if the evidence from L2 was correct. It is assumed that the L2 node had already staked tokens in the L1 contract, and would be punished if the verification fails. So there is incentive not to be malicious. Lack of challenge for a certain (and usually long) period of time is silently taken as a positive signal of "being verified". 
5.  Besides roll-ups, there are other layer 2 protocols (Ordinals, Ethscription, etc.) that avoid running consensus. They usually run off-chain computation with inputs taken from block data from an L1. More often than not, such inputs are not verified before they are admitted into a L1 block, because the L1 lacks capability to perform required verification. So it is up to the L2's off-chain computation to decide some inputs are legit and others are not, and only compute results based on "correct" inputs. These protocols **still offer verifiability by asking users to run a full node + indexer**. Due to version differences and bugs, different people running their own choice of indexers may arrive at different state even when given the same set of inputs. So it sometimes requires extra work and **social consensus** to resolve conflicts.
6. Yet still, there are other protocols running off-chain computation and do not require running a full node. They are usually point-to-point protocols where it is sufficient (**with the help of a L1 light client**) to verify a transaction with only data presented by parties involved in a transaction. Examples are payment channels (lightning protocol), RGB protocol, and so on. **They do still specify their own methods of verification**, and offer analysis on why the protocol is secure.
7. Last but not least, when it comes to cross-chain communication, verifiability also plays a crucial role. Usually this is in the form of a "bridge" (where the only communication is token custody), with smart contracts on both chains, and each securing assets on respective chains. They would need to verify if a transfer request from the other chain is "authentic". This is usually done by **running either full nodes or light clients**, and often a 3rd chain is introduced in-between because consensus is needed to reduce the work required for smart contracts (which are often less capable when compared to off-chain computation). There are many examples, polkadot, cosmos, and even ICP fits in here, except that ICP greatly reduces the complexity of verifying inter-subnet communication down to verifying signatures.

Now let's look at AO, which is still a project in its early stage with a not-so-comprehensive spec, and much still in flux. I had the opportunity to chat with one of AO's founders in a WeChat group. After some heated debates, here are my takes. Please take this with a big grain of salt because so much hasn't been specified at all, and they are all subject to change.

* AO allows any deterministic computation to be taking place off-chain in the form of "a process", where the chain is Arweave (AR) with only decentralized storage but no on-chain smart-contract capability. So AR cannot offer computation verification like some other L1s. All inputs to a process must first be recorded on AR, so there is a permanent record of all historic inputs.
 * One or more CUs (computing units) work together to perform the computation required of a process, taking inputs to outputs, where outputs are put on AR as well. They do not run a consensus protocol (or at least they are not required to run consensus), so their computation results may not be "trust-worthy". Yet still, such results or outputs are recorded on chain, and can be verified if anyone chooses to do so (we'll see about the "how" a bit later).
* However, things become tricky here because when a process A receives an input from another process B, even though the input is recorded on chain, it is not immediately clear that the input from B can be "trusted" by CUs computing for process A. The unofficial answer I get from AO team was that CUs computing for process A do not verify any input except that checking if they are already recorded on AR.
* This may lead to a situation where CUs for A records "wrong" output on chain from running process A, either because of bug, or them being malicious. But this can be remedied by a optimistic verification mechanism via staking and slashing.
* It is assumed that a special group of CUs run a process that manages staking & slashing, and they would respond to challenge requests from anyone, and they will check if the recorded outputs of a process is really computed from its inputs. Needless to say, they would run through all input histories of a process in order to verify, because no intermediate state was saved anywhere.
* Now the remaining question is who would challenge. It is assumed that the project team running CUs for process A would have an interest in at least running one CU for process B as well, because A's correctness depends on B's output. Also because AO is an open-membership protocol, anyone is free to run any CU. According to unofficial discussion, A's stake would also be slashed if A ever accepts a "wrong" input from B without verification. So there is even greater incentive for A's team to help with verifying B. So if we expand this logic, teams would cross-verify each other if their project has dependencies.

If I'm allowed to make an analogy, AO is basically a distributed network of off-chain indexers, each responsible for themselves (by computing for their own process, and also by offering to run CUs for processes that may give them inputs). All events (inputs & outputs) are permanently recorded on a storage chain AR. AO's security relies on optimistic challenging + staking + slashing, which is managed by a group of CUs instead of a smart-contract enabled Layer 1.

So, is AO's computation verifiable? Since everything is recorded, and computation is assumed to be deterministic, then yes it is. 

How much of an effort will it take to fully verify the computation of a single transaction? I think it is equivalent to running a full node that syncs all histories of all processes. First of all, every CU must stake, so to verify their respective membership, you need full state of the special staking manager process, and I'll assume this will be the main token ledger of AO. Then almost all processes will take input from or give output to the main ledger, so they all becomes dependencies of each other. Therefore **a full verification requires computing for all dependencies, which will eventually involve the entire global state of AO**. Given that AO's goal is to "absurdly scale", **this kind of full verification would be impossible to achieve**.

Now that running full node verification is out of question, can we run a **light client equivalent** for verification purpose? This would be the verification of the recorded outputs of a single process against its recorded inputs, **assuming all recorded cross-communication between processes are correct**.

But this is a very big assumption to make, so big that I'm not even sure it is secure any more. Just compare this to cross-chain communications as noted in the above point 7 when I discussed verification. It is immediately obvious that AO's design took a radical approach when it comes to verifying the equivalent of "cross-chain messages". AO's processes are not even chains, since there are no consensus. When protocols like polkadot and cosmos took extra care in designing a secure cross-chain message exchange mechanism, AO leaves it to optimistic challenge & slashing. When optimistic Layer 2s like Arbitrum are extra cautious to insist a 7-day withdrawal delay in order to limit the potential damage of "wrong outputs", AO wants every inter-process message to exchange immediately since they can be "verified later".

It is also unclear whether the CUs in this stake managing process would run a consensus protocol. If not, their own computation would require challenging as well, which falls flat due to the recursion. AO is a young protocol making bold claims, and I hope they can pay more attention to verification and its practicality, because they directly affect security.

My conclusion so far is that ICP chose to make some trade-offs in order to be scalable, AO chose to make a different set of trade-offs in order to be scalable. Both are yet to be entirely proven to be practical, but at least we have some assurance that when an IC canister receives a message from another canister, it is "secure" within the safety parameter of a consensus protocol (of a subnet). With AO, it is "optimistic", remember?

PS: it is also unclear how a "roll-back" would work when mismatch is discovered and various stakes got slashed. The AO team roughly mentioned something like multi-versions or branches could co-exist, but I'm not sure when and how a re-computation is triggered, because they would necessarily follow the dependency order. It is almost like branching off of an old check point, but you don't actually know when or where since the team insisted that "AO has no global state".

-------------------------

bob11 | 2024-03-11 17:41:06 UTC | #22

This response is absolutely fantastic. Paul you are a legend. 

Do we have docs anywhere comparing the Internet Computer Protocol with other computing paradigms in crypto right now?

It would be extremely helpful to take the various categories of blockchains identified here and put them into a nice comparison table somewhere with detail comparing verification/consensus mechanisms across chains.

-------------------------

lastmjs | 2024-03-11 17:42:40 UTC | #23

Thank you for your response which I will be studying more in-depth later.

In a world of ZK and FH VMs, doesn't this call into question ICP's focus on replicated computation for verifiability?

Would not AO be setup very nicely for this future?

-------------------------

PaulLiu | 2024-03-11 17:52:08 UTC | #24

[quote="lastmjs, post:23, topic:28329"]
In a world of ZK and FH VMs, doesn’t this call into question ICP’s focus on replicated computation for verifiability?
[/quote]

Yes, it would. But I don't think it completely diminishes the value of replicated computation, which is still the most straight-forward and perhaps more cost-effective(?!). And as explained below, ZK verification would require consensus too.

[quote]
Would not AO be setup very nicely for this future?
[/quote]

Unfortunately no. ZK does not give AO an immediately boost because its verification would necessarily remain optimistic due to its async nature. If you think process A can verify inputs from B by ZK, yes, but that also depends on B's own input and its dependencies. I can't possibly imagine A verifying entire dependency closure of B (with their entire historic inputs) through ZK. You have to assume some "verified" checkpoints exist somewhere. How do you arrive at these "verified" checkpoints? Through consensus. Ditching consensus is unwise (For example, you almost absolutely need it for the stake manager).

-------------------------

lastmjs | 2024-03-11 18:00:12 UTC | #25

It seems like AO is flexible enough to build consensus into it in a much more modular fashion...this is one of my main thoughts/wonderings, is that AO might be building a more flexible protocol from the beginning, whereas ICP has chosen a much more rigid design.

From your point of view though, I wonder if you think they would have to essentially come up with the consensus design of ICP then?

Is chainkey really that beneficial here? Verifying multiple signatures is another way to go about it, would it be that bad to deploy your process to multiple CUs, ask for their public keys, and verify the results? Of course you brought up the inter-process verification...

Do we really need this pBFT-style ICC for verifiable compute? Might not staking with simpler verification be good enough in the end?

Especially if it allows a much more expressive computational environment from the very beginning?

-------------------------

lastmjs | 2024-03-11 18:04:43 UTC | #26

[quote="PaulLiu, post:24, topic:28329"]
ZK verification would require consensus too
[/quote]

Yes but can't Arweave provide that just fine? At least for client -> server, request/response, assuming no inter-process communication? And I wonder how hard the inter-process communication consensus would be in this case, perhaps it's just on Arweave again.

Am I misunderstanding the role of Arweave in consensus here on AO? There is consensus on inputs to processes stored on Arweave correct?

-------------------------

PaulLiu | 2024-03-11 18:17:23 UTC | #27

[quote="lastmjs, post:26, topic:28329"]
Yes but can’t Arweave provide that just fine?
[/quote]

Are you saying AR would be the chain that runs ZK verification? Yes, it would work, with AR being the bottleneck. This is essentially taking the same roll-up approach taken by the Ethereum community, how is AO then different than multiplying ZK roll-ups by 10-thousand times on Ethereum?

Yet still, inter-L2 communication is very crucial. It has to be the L1 that offers verification, IMHO, because L1 is the synchronization point.

If I may be even more blunt, I don't think optimistic verification is secure in an async setting without introducing a sufficient challenge peroid (which is sound, but goes directly against the scalability claim). By async setting, I mean either the actor programming model offered by ICP or AO, or the inter-L2 communication between ETH roll-ups.

ZK verification in an async setting would still either require a single L1 at the base layer, or relying on the replicated computation (because ZK verification is still computation) of each chains/subnet/shards running consensus protocol.

-------------------------

gip | 2024-03-11 19:26:04 UTC | #28

Thank you for starting that thread lastmjs!

[quote="lastmjs, post:16, topic:28329"]
You can’t get many single apps that work just fine on Web2 to work on ICP because of all of these vertical/single app limits.
[/quote]

My assumption was always that because consensus is very expensive, to make economic sense the stateful part of an app should run on the IC while everything that is stateless should probably not. So my initial take was Web3 would imply a novel architecture regarding how we build apps.

In particular, serving or processing large files on the IC doesn't seem to make economic sense. I'm wondering if that is what you are talking about when speak of vertical/single app limits? Any specific example of limits you can share to help me understand your point better?

Thanks!

-------------------------

NS01 | 2024-03-11 20:14:21 UTC | #29

Its awesome that the ICP community can have discussions like this. 

Blockchain tech has come a long way in the past couple of years - other blockchains (not going to throw mud here) are patting themselves on the back for implementing 1990's levels of compute... Yet we are here asking if hundreds of GB of storage, http outcalls, timers, chainkey integrations and vetkeys are enough. 

It still blows my mind that we have several full-blown apps running fully on chain. 

That said, its healthy to reflect on what we can do better to make it easier for the next generation of developers. For me, when building 221Bravo.App the one issue we hit quite often is the instruction limit. The app is quite data intensive - indexing tens of thousands of transactions every day. 

As I've said before, I dont think every business process needs replicated X number of times. There are plenty of tasks (non-mission critical) that I would happily run on a single trusted server. For example running a force directed map on transaction data. If a node misbehaves it's not a massive deal. 

It would be great to choose how many times your smart contract is replicated. Got a ledger canister - max out the replication... got a canister monitoring cycles ussage.. stick it on a low rep subnet. 

Looking back at the ICP developments over the last 24 months, I'm confident we will overcome any bumps and the developer experience will continue to get better 😀

-------------------------

lastmjs | 2024-03-11 20:13:04 UTC | #30

[quote="gip, post:28, topic:28329"]
My assumption was always that because consensus is very expensive, to make economic sense the stateful part of an app should run on the IC while everything that is stateless should probably not. So my initial take was Web3 would imply a novel architecture regarding how we build apps.
[/quote]

This may be a practical reality currently, perhaps always, but it is not the vision put forth over years from DFINITY. I would like to pursue that vision if it is at all possible.

-------------------------

lastmjs | 2024-03-11 20:16:05 UTC | #31

[quote="gip, post:28, topic:28329"]
Any specific example of limits you can share to help me understand your point better?
[/quote]

These limits get hit often in a variety of circumstances and preclude many many things from being built...there are so many things.

-------------------------

Zane | 2024-03-11 22:58:45 UTC | #32

wrt instruction limits this is my mental model, please correct me if I'm wrong:

At the moment, the entire subnet's state, including the state of all canisters running on it, is certified and committed in each block. The rationale behind this design was to reduce overhead: batching state certification and notarization of a large group of canister is more efficient than doing it on a per canister basis, potentially numbering in the tens of thousands. 

In this context the instruction limit serves mainly two purposes: 
1) Achieving steady block times; without it the finalization rate would be as fast as the slowest running canister.
2) Ensuring subnet can be checkpointed at regular intervals.

This architecture makes sense, as most canisters won't be bottlenecked by execution, but in some cases we'd rather have subnets with fewer, but less restricted, canisters.  


DTS was implemented to mitigate the limitation, allowing message execution to span across multiple rounds, but it doesn't completely address the issue and comes with its own drawbacks.
Let's take a 100B instructions message as example, a modern CPU is capable of processing such a workload very quickly, but with DTS it would take almost a minute, which is terrible for the end user. 
This is cause each round can still only process a finite amount of WASM instructions for the sake of block rate and there are hundreds of milliseconds between each of them, during which no progress is made.
The number of rounds a single message can be spread over also can't exceed the checkpointing interval.

What if a new subnet type were introduced where, instead of having constrained execution rounds, each canister can run as long as it needs to (maybe with some loose safeguards to prevent infinite loops)? 
In order to make this happen the "subnet" shouldn't attempt to certify its entire state at a fixed interval but instead:
- Do the usual gossiping and ordering of messages
- Induct messages into canister queues
- Exhaust the canister queue at its latest certified height + 1
- Sign the canister state
- Gossip finalization shares on a per canister basis
- Certify canister state at latest height with enough shares

With this approach:
- Each canister has its own finality determined by the usual BFT latency + the time it takes to complete execution. It isn't bounded by other canisters, nor penalizes them.
- UX is improved: long spanning messages are executed as fast as the hw can process them, so response times to end users improves drastically.
- Long spanning messages only prevent checkpointing of individual canisters instead of the entire subnet, while still not ideal, the amount of instructions a message must execute to make this happen would be order of magnitudes higher and it is still less disruptive.

A per canister certification model would also make it easier to load balance the network by moving single canisters around, which in some cases is preferable to subnet splitting and possibly even open up the possibility for adjustable replication factor in the future.

-------------------------

lastmjs | 2024-03-11 21:42:54 UTC | #33

[quote="PaulLiu, post:21, topic:28329"]
However, things become tricky here because when a process A receives an input from another process B, even though the input is recorded on chain, it is not immediately clear that the input from B can be “trusted” by CUs computing for process A. The unofficial answer I get from AO team was that CUs computing for process A do not verify any input except that checking if they are already recorded on AR.
[/quote]

In one of my discussions if I remember correctly, the idea was thrown around that a CU could wait for multiple CUs to post a message before accepting it. Even if the team did not say that, could this be a way of performing the verification?

My discussion seemed to paint AO in a very flexible light, where a threshold of correct outputs could be waited on before trusting. Chainkey might help with the verification latency and complexity, but this could be done with some registry of public keys of just asking for the public key and having the right to slash, could it not?

-------------------------

free | 2024-03-11 22:23:30 UTC | #34

[I will be trying my best here to stay focused and dispassionate, so please excuse any accidental slip-up. I'm a software engineer and do not have any PR training. Or inclination.]

There are literally very simple, straightforward solutions to most of the points raised here.

E.g. you can have a single-replica subnet (or 4 replicas in the same data-center, if you want); it is literally one NNS proposal away. With some tweaks to Consensus timing, It should give you amazing latency You will just have to cross your fingers and hope that no one cares enough to hack into your one replica; and that the data center doesn't go up in smoke.

Similarly, you could set arbitrarily high instruction limits. Or only checkpoint once a day; then you could have DTS executions spanning hours. Just hope it's fewer than 4 concurrent DTS executions at once; and that enough replicas make it to the end of the day, so you won't have to wait for an extra day or two to finally get that checkpoint.

Or make an NNS motion proposal to reduce fees 10x. Again, trivial.

The point I'm trying to make in my stunted, patronizing way (and you have my sincere apologies for that) is that virtually all of the limits currently in place are the result of some compromise: fees vs tokenomics; instruction limits vs liveness; latency vs availability / tamper resistance; and so on.

There are also cases where the limitations are due to lack of resources and/or prioritization. E.g. we have some pretty clever ideas for cheap, scalable storage, side-channel computation and huge payload limits, all-in-one; but before piling on more weight, we need a more scalable persistence layer; and messaging model; and more efficient certification; and lower DSM overhead.

In some cases, we may not prioritize the right things. And in many cases we may not have the right solution at all (I know I don't). So we very much appreciate constructive feedback.

I just don't find that more everything with lower latency at lower cost all at once is realistic, even with infinite engineering resources behind it. You must make trade-offs and some of them are not as obvious as the ones I listed above. One tiny example: it would be trivial to set up a small replication or geographically concentrated subnet. But how much can other subnets trust it? (E,g, to not mint cycles out of thin air?) How much can users trust it? How does a user even know whether they're interacting with a canister running on a 40-replica subnet vs. on a 1-replica subnet? If they somehow can tell they're interacting with a DEX running on a 40x subnet, how do they know its backend isn't running on a single-replica subnet? And whatever solution you come up with to address all of that, will it be worth the huge added complexity to the protocol?

I've seen some pretty clever solutions to specific issues proposed in this thread. Many of which I'm not ashamed to admit I would have never thought of myself. They usually miss some aspects that would make them difficult or impossible to implement as suggested, but much of that is because it's really hard to communicate the full picture across this medium (and I know I'm definitely not putting in nearly as much effort in this direction as others) so as a result those proposing them are not as neck-deep in the protocol and its implementation as I am. I only know many of these constraints/imitations myself because I came up with similar ideas, brought then up and someone kindly pointed out to me what the issue was.

So I'm afraid I don't have a good answer to many of the points made here. I definitely don't want to claim any authority or higher standing than anyone contributing to this thread, But I do know that for the most part, there are no simple solutions. Whenever you make something look simple, you have to pay for it elsewhere. And it's often not obvious until long after.

I'm happy to talk specific ideas or solutions. And likely so are others. But I don't think this thread is the right place, they would just drown in the flood of messages. So if you do have a specific idea that you think is worth discussing; and don't mind me shooting it down and picking through the rubble, please start a new thread and ping me. We'll see where it goes.

-------------------------

lastmjs | 2024-03-11 22:51:02 UTC | #35

A lot of the purpose of me doing all of this is to gather enough support across enough people across DFINITY and outside of it, to get these major issues prioritized.

I hope the decision-makers will take all of this feedback and prioritize finding revolutionary solutions to these problems, as I know they are non-trivial, and some may be impossible with current consensus technologies, without more major trade-offs.

-------------------------

chenyan | 2024-03-11 23:19:38 UTC | #36

Just one clarification about instruction limits. It's the limit of a single message. It doesn't limit how many instructions a task/endpoint can perform: you can chunk up the computation into several async calls, and the computation can span as many rounds as possible without hitting the per message instruction limit. Of course, we need better language/runtime support to make this idea more end user friendly, but I don't think instruction limit fundamentally limits how much computation we can perform on the IC.

-------------------------

skilesare | 2024-03-13 11:33:42 UTC | #37

This is a bit stale after Paul's amazing post, but I'll post it for the record:

This is a response to @lastmjs ’s thoughtful post on DFINITY ’s Internet Computer and the comparison with #ao. (https://x.com/lastmjs/status/1766471613594083348?s=20)

tldr: The IC is awesome, DFINITY has built something amazing, it interops with ao, lets go build.

👇 (see below)



I’ve also spent the last week or so investigating ao to the extent that I wrote what is probably the first ANS-104 compliant data item signed with a trustless t-ecdsa key and broadcast from the IC. This is a precursor to being able to run the mu, su, and cu components of ao on the IC. (https://x.com/afat/status/1765820285700247707?s=20)

I’ve spent the last 3 years building on the IC for myself, Origyn(we build a super NFT for robust, permissionable, data-rich certificates of authenticity) and shepherding a number of devs through development on the IC through ICDevs.org.  The 3 years before that I worked alongside and sometimes with DFINITY in anticipation of their launch with a focus on how the IC could be used to enable web3 for the enterprise.  Now with @Pan_Industrial we’re making that a reality.

I’ve had the pleasure of watching @lastmjs do some amazing things on the IC including bringing TypeScript to the IC. In 2019, when I found out that javascript, the language of the Internet, despite all its flaws, was not going to be an initial option to build smart contracts on the IC I was a bit disheartened and felt a huge opportunity was being left on the table for initial adoption. Jordan has almost singlehandedly closed that gap.  We do differ a bit on what we think the IC will ultimately be best for which you can read about more in this thread if that has interest to you. https://forum.dfinity.org/t/i-just-hit-the-instruction-limit/27700/9?u=skilesare The tldr is that Jordan and I are hacking away at different approaches to the IC both of which I think are necessary for the IC to have a maximum surface area for success.  This thread will push my agenda a bit unapologetically as I think the best way for people in the ecosystem to grow and find new ideas is to continually discuss and reevaluate our assumptions.

To the ao engineers that will read this and cuss me for my naive understanding, please correct where I've made poor assumptions or have a wrong understanding. I know what a feat it is to actually ship and you all should be incredibly proud of what you e accomplished up to this point.(Same for my friends at DFINITY where I'm still learning and not much of an expert on the actual replica.)

The first consideration to mention is that, at this point, ao is a protocol with a single reference implementation that has limited security guarantees. The IC is a functional system that has been securing $X B worth of value for almost 3 years. Currently, ao is aspirationaly sophisticated, but functionally inferior in almost every way. Not unexpected as it launched a week and a half ago. Set proper expectations if you want to evaluate the two. It will be enlightening to check back in three years and see where each is.

What is the best we can hope for if we are trying to get computers across the globe to reach consensus about calculations across previously agreed upon state? Likely it is available state(s1) + transform(t) + zero knowledge proof of correctness(zk) = state (s2). I am unfamiliar with any solution outside of this that could deliver distributed computation faster and with more finality. The crux of a debate around ao vs IC is that this optimal solution is inside the bounds of the declared ao protocol. It does not exist yet, and it is likely that if it did the zkWASM prover would force latency to a rate far above what a parallel ao implementation was that made the same trade off of the IC. That trade off is that, according to the proof of the IC, see https://medium.com/dfinity/achieving-consensus-on-the-internet-computer-ee9fbfbafcbc#d7a6, we can assume correctness give 2/3 honest nodes.  There are likely more optimal trade offs than the IC makes that can be found, but the selected trade off and others combinations all can exists under the ao protocol definition. Therefore it just really isn't appropriate to compare all possible ao implementations to the one specific implementation(the IC's selection on this graph).

![IMG_0487|690x458](upload://8Q2oxAjPCb8JAROkunjosLV7Oj4.jpeg)


There are other graphs with different axis that are just as important, but I think this frames the debate the best) I'll propose a theory latter as to why I think the IC and Evm on IC might be able to shift right out of the ao space, but for now let's assume that all these networks sit inside the possible ao protocol network space.

Now that we have a frame I'll get back to Jordan's comments.

My concern with the approach Jordan has taken is that his goal is an "unbounded scalable virtual machine." I believe that baring a quantum revolution, I do not think this is achievable without making a concession somewhere along the continuum of latency, storage, liveness, or security.  Trying to shove either of these systems into that standard will result in disappointment.

What the internet computer has achieved is an "unbounded and scalable strata for actor-based computation." Ironically, this is also what ao seems to be claiming to be with the focus on the actor-based model of computation. Classic web2 does not fit into that actor paradigm. It has evolved into a microservices architecture where each service has unrestricted fast access to unbounded data stores. We just won't get this on the IC or ao. Your actors will have to be selective about what data they compute over. You scale by replicating these actors across 'subnets' where each actor operates independently. This takes a fundamentally different data storage and query architecture than classic web2.  It isn’t more efficient (and by definition likely can’t be) but it is the pattern the world uses to create anti-fragile, sovereign entities that burst into the diverse universe we have around us. The trade-off from moving from the fast, micro-service architecture backed by centralized monolithic data structures is a fundamental shift in ownership, the movement of value to the edges of the network, and disruption of centralizing entities that too often take advantage of their power to extract excessive value.  Actors are slower from a latency perspective, but better from a parallelization perspective. An EVM has nice atomic properties, but it is a monolith and the person holding the keys to scheduling the transactions gets the same centralized kind of power(MEV extraction) that we’re pushing back against in web2.  

The entire current L2 diaspora is much less about decentralization than it is about value extractors trying to convince you that you should let them order your transactions, extract to the MEV, and fund their investor's kid’s trust fund.  Actor networks do their own ordering, run their own markets, and keep their value at the edge of the network.

![actors](https://global.discourse-cdn.com/business4/uploads/dfn/original/3X/2/2/22906f3edaf6c540a972b57bf427525186c8bef5.jpeg)


The belabored point here that I bring up often when Jordan pushes on the tech to try to deploy web2 tech to the IC is that, first I’m rooting for him because I too want many of those conveniences, but second, that the ability to do those web2 things should be viewed as a gateway drug and not an endgame.  Because of the speed of light, the cost to produce computational proofs, and developer’s ability to always push a tech just a bit further than it was designed to support, no platform will ever out-compete web2 at web2. You just can’t get to consensus and a trustless state as fast as they can get proprietary state.  As long as we try to make the IC about replacing existing things we don’t like with something on the IC with THE SAME ARCHITECTURE, we’re doomed to fail. The future for ao or the IC is all blue oceans and if we manage to replace some old web2 stuff with something they will be alien to how we see those services today.  Twitter on the IC just isn’t going to be better than twitter at twittering. Ever. And graphQL on ao will never be as fast, performant, or cheap as graphql running on web2 infrastructure.

I’ll now go through the deficiencies of the IC he mentioned and discuss how many of those are features and not bugs for the long-term viability of not just the IC, but ao, and any system ultimately trying to bring web3 values to a broad audience. And that that is ok.

1. Instruction limit of a few seconds

This is an actor model issue and I don’t see how ao would handle this any differently than the IC. Because your function is s1 + t + (c | zk) = s2 your actors are generally single-threaded ( c being consensus).  Maybe there is a multithreaded actor model out there, but if not, even with a single node where zk provides the correctness you have to process the messages in order so you can’t get to s4 without going through s1, s2, and s3 somewhere in the network. If a machine needs s5 it has to wait for someone to deliver the proof of s1, s2, and s3.  If s2 takes 5 minutes, your actor isn’t doing anything else for 5 minutes.  If you try to do something in s5 that s2 changed out from underneath you, your s5 will trap and your state won’t change(ie, at the end of s2 you send tokens so they aren’t there anymore when your s5 transaction gets there).  

How do you counteract this? The same way databases do this kind of thing.  You lock what you expect to have rights to change and process over many rounds.  You can do this today with tools like ICRC-48 https://github.com/PanIndustrial-Org/icrc48.mo/blob/main/standard.md that split tasks across rounds so that other processes can be run(as long as they don’t run into your locks).  ao doesn’t get the benefit of the doubt here that they’ll just be able to pull something out that makes them magically be able to parallelize many transactions. The spec specifies the transactions must be processed in the order assigned by the su. In fact, I think a cu that was trying to do this would have to issue itself messages routed through the mu/su to split this work into chunks. If these messages have to settle to arweave before they can be properly sequenced and consumed by the cu then it is likely fundamentally impossible for ao to outperform the IC without resorting to significantly superior hardware.  Thus, with the su built into the IC via crypto math and the insistence on high machine specs, I predict that many IC applications exist outside the possible ai network space due to the internet latency of message passing. If the cu and the su are the same process and the cu looks ahead to see if it can continue uninterrupted, then maybe….but then you have a single node cu/su and I’m not sure how you give that any kind of security and trust guarantees(maybe zk?).

Unless the ao guys weigh in differently here, I don’t think it is as simple as “CUs can run whatever computations they are capable of running. If a process specifies that it needs a certain amount of computation, only CUs willing to perform that should pick up that process.” The CUs are still bound by the ordering of the su and must finish message 4 before moving to 5. Your scalable global computer is blocked on a thread until it finishes and can’t serve other requests.  This is going to be new software built from the ground up whether you are using ao or the IC. Unfortunately, no free lunch here when trying to create a new Internet with web3 properties.


2. Message limit of 2/3 MiB
3. High latencies

These two issues are a speed of light issue when you want nodes across the globe to agree on consensus.  Even with zk you’ll need to ship the proof and the state diff many miles which leads to latency.  Maybe a pure zk solution where you only need one node to agree could get around this? But if you want your data as part of the proof, it takes time to process and distribute.  

There are cryptographic schemes(file hash) that let you skip some of this and none of them are precluded from the IC.  You can just as easily ship the IC an IPFS/arweve hash and then serve that file from a gateway to avoid uploading the whole thing. The key here is that if you do that, you can’t compute over the content.  Ao will suffer from the same thing. Unless you give it a file hash in your message, the cu doesn’t have access to your file to process over it. According to the ao spec, if you do give it a file hash, it has to load in the file before it can process the message.  I can’t imagine this is quick unless the cu keeps all possible files cached.  When you upload a file to the IC you’re putting every byte through consensus. This is unnecessary for most cases.  I love having the bytes in my canister because it opens things up for compostable third-party services down the road, but we aren’t quite there yet.

Most query latency on the IC is a function of certifying that the data coming out of the query was agreed upon by the smart contract at some point.  This system is still evolving, but as far as I can tell, the ao paper makes no suggestion about how the cu is going to certify a response to a requestor.  Each cu is going to have to roll its own way to tell a client that it isn’t lying. There will either be a signature of some kind, a slashing mechanism(which theoretically requires significant latency, on the order of days in the optimism world) before you can rely on the result, or a zk proof of calculation output by the cu which will add significant processing time.  

The IC does need better patterns for serving data and information that doesn’t need this certification and agreement.  But that is more of a UX and architecture issue than a failing of the IC.  You’re getting a guarantee that the contract ran correctly and that all nodes agree that the query you just got back in <400ms is valid.  If you don’t need that, route around it, but I’m not sure, if you do need that, how you get it with less latency.  More processing power will drive it down a bit, but eventually, you run into the speed of light.

As an aside, the architectural solution for uploading large files is to upload each chunk in parallel to different subnets.  This helps with serving the chunks as well if you use a client-side aggregator.  The solution is UX + architecture but in a new, ground-up solution.

4. High costs

Arweave’s price for data uploads is significantly higher than the IC(ardrive quotes $3-8/GB, but I think I saw a tweet mentioning $30 the other day).  You theoretically get 200 years for that and items under 100kB are free(most ao messages).  Thankfully storage tends to follow a Moore’s law curve and this will decline over time.  I know storage subnets and static storage are also being considered for the IC which may help bring the cost down.  I guess it depends on your perspective with costs as $1GB to upload and $5/GB/year is so comically less than any other web3 platform out there that has compute over content that I’ve always considered it absurdly low cost.  You probably don’t want to try to build the next youtube, but it is pretty cheap to host a few videos for a business.

5. Rigid network architecture

In 2019 I saw and had discussions with DFINITY that had plans for dial-up, dial-down subnets. With the movement on the Swiss-only subnet and discussions around AI on the IC I think there is only a matter of time before we see much more flexibility here. In the meantime, the 2 choices are likely an ergonomic and UX issue while the network is growing. I don’t think there is actually anything keeping you from compiling a 4-node subnet via the NNS if you can get the votes.  With UTOPIA and the ‘bad lands’ discussions a couple of years ago, there is obviously flexibility available, but I wholeheartedly agree that a clearer path illuminated on how to get from there to there would be great, but I also recognize that is very hard to do when these markets change as much as they do.

I will note that while “It's very permission-less and flexible, there is no need for a central authority like the NNS DAO,” Begs the question that if a DAO is not providing assurances that the network can meet the demands of users, then who is?  The largest complaint in web3 has been useability due to wildly volatile gas/transaction fees. Heterogenous is great as long as the interface to the service consumer is reliable, consistent, and performs as expected. ao is going to run headfirst into this problem with every solution deployed and the IC has the answer of reverse gas already deployed.

Going back to our diagram, there are a number of architectures that ao could be built on and the IC is in that blue shaded area as one that would work inside the ao universe.  In fact, I’m not betting on one emerging soon that works technically better than the IC for ao.  That doesn’t mean that ao won’t become the standard because, as we’ve all seen, this industry is insanely memetic and arweave and ao seem to have pretty good market traction and are viewed in a pretty positive light. Basically, if ao does become the dominant world computer protocol, the IC will likely be the best way to deploy on that protocol because all the batteries to reach trustless execution of a mu, su, and cu are included.

6. Centralizing DAO governance

Jordan’s concerns about the NNS are valid at the present. I’ve thought a lot about how things are set up and I’m firmly in the ‘I trust DFINITY for now camp,’ but I see the need for eventual decentralization and understand that this currently is driving projects away from the platform.  

Fortunately, this is a political issue and not a technical issue and one can currently draw a line from today to a universe where DFINITY does not have majority voting power on anything.  I wish that pathway was better illuminated today, but I also recognize that the community is NOT ready to take on all the things that go on in the NNS.  We should start getting ready now though. I think it will take at least one, possibly two other organizations as well funded as DFINITY to step up and become experts in the network topology, replica development(to the point of probably having replicas in other languages to diversify away code bugs), and have enough operating capital to have full-time employees focused on these things.  We seem a way from these entities emerging. Enough tvl and enough value delivery and they will emerge. This leads me out of the IC's deficiencies and into its advantages.

One of my biggest disappointments and frustrations over the last three years is how much of this debate has ended up being memetic. Of course I should have known this, but it still surprised me. Attention economics end up being as important as tokenomics. For whatever reasons and with hindsight we can see that the memes the IC launched with didn't hit the market. It probably isn't helpful to look backwards too much. 

We are extraordinarily fortunate that DFINITY was funded to the extent it was because despite memetic whiffs(which are damn hard to get right) on the "let's replace aws" narrative and the "nodes on the corporate cloud are dangerous " which no one seemed to care about despite it being a serious issue, they have shipped and shipped and shipped. Http_outcalls, t-ecdsa, improved key sharing, and on and on. 

We find ourselves at a point where the Internet Computer has an immense amount of superior tech ready to deployed to a web3 world. One only needs to spend a few minutes wandering around the floor of EthDenver to realize how many entire enterprises and L2s have been launched to attempt to solve one of the 50 problems that the IC has already solved to a threshold of sufficient security and comparatively unreal performance. If we are being memetic, why aren't we leaning into these memes? The latest meme seems to be AI. One day the IC may provide the most secure and trustworthy AI solution one day and everyone is excited about it, but in the next 5 years doubt anyone is going to out AI openAI, google, Amazon, Tesla, and Apple. We have a long way to go for public proof on that meme.

Right now we have built the best btc bridge brige with sufficient security. We have most of the best ETH L2 in place with sufficient security. We can build the best ao mu, su, cu pipeline with sufficient security despite testnet. Let's do that and launch those memes. Seven-day optimistic withdrawal? Here is a 1-minute solution. $100 gas for a zk roll-up? Here is a reverse gas model that costs a couple of cents. You have a data availability problem? Here is a compute + data solution that solves your problem with self-funding of eternal data storage.  Need a crypto secure scheduler? Ours just works up to 500tx/second per subnet.

Yes, sufficient security isn't sufficient in the long run and we need better decentralization. We need an illuminated pathway to get there(the market seems to be fairly forgiving with third as many of the L2 operate on laughable multisig scheme). It is likely time to say "look...due to VC, funding, and market pressure we had to ship before the vision was complete...we aren't finished yet ... here is the pathway and as soon as we're finished with the tech we'll activate it but we are going to build this tech and if you need beyond sufficient decentralization before that, come and take it(an invitation, not a threat).. If "they" can't say this for some regulatory or securities reason then we need to scream it from the rooftops for them.  At some point the rubber will meet the road and the it will either happen gracefully, or it won't. Yes, for now there will be a segment that will demand pure permissionless from the jump and this is going to be a non-starter for them. They have other avenues.

What if when the rubber meets the road and we need to move beyond sufficient security and the foundation doesn't go where you want to go? Say in 2030 the new King of Switzerland and Lesser Europe is holding a literal gun to Dom's head and demanding the figurative keys to the IC be handed over to a {insert your second least favorite form of government} government. (Exaggerated scenario because DFINITY had shown a remarkable amount of good faith to this point even if they've had to navigate some regulatory, political, and memetic hoops with a bit less grace than would have been preferred) What do we do? How many people is this scenario keeping from leveraging the insane tech the IC offers today?  

The answer likely lies in architecture and proactive game theory planning. External t-ecdsa based UTOPIAs enabling social recovery and forkability? Contracts that regularly checkpoint and publicly stash state in forkable schemes? Co-execution between ao and the IC? All kinds of options are in the table, but I hate to disappoint the community...this is 100% on us. DFINTY is finishing the base layer. In the meantime, we're underfunded, unorganized, in over our heads, and completely reliant on ourselves to figure it out. Easy-peasy. LFG.

I'm going to keep encouraging Jordan to push on the IC for as much performance as we can squeeze out of physics. I'm going to keep focusing on actor-based infrastructure to drive a web3+ world that catapults humanity forward. We all should look to better understand the decisions and priorities DFINITY is pushing as they've done a damn good job on the platform so far. We all will only move beyond the web2 world together if we marshal 10x value platforms for the users. If ao can help, let's use it. No one is better positioned to accelerate what they are trying to accomplish because we already have 70% of it, and it's working. In prod. 🚀🚀🚀

#TICADT - The Internet Computer Already Does That

Edit: fixed an image

-------------------------

zensh | 2024-03-11 23:57:34 UTC | #38

IC are used to process decentralized trustless (verifiable) state data, and as @PaulLiu points out, the verification on decentralized node limits computing efficiency to the greatest extent possible.

What @lastmjs is actually proposing is non-verifiable, unlimited cloud computing resource, which is not the goal of IC.

But I believe it can be implemented based on IC, it will be a IC's L2 solution -- IC governs this unlimited growing L2 cloud computing network, which hosts applications that do not require decentralized verification.

-------------------------

NS01 | 2024-03-12 00:29:44 UTC | #39

> One tiny example: it would be trivial to set up a small replication or geographically concentrated subnet. But how much can other subnets trust it? (E,g, to not mint cycles out of thin air?) How much can users trust it? How does a user even know whether they’re interacting with a canister running on a 40-replica subnet vs. on a 1-replica subnet? If they somehow can tell they’re interacting with a DEX running on a 40x subnet, how do they know its backend isn’t running on a single-replica subnet? And whatever solution you come up with to address all of that, will it be worth the huge added complexity to the protocol?

I completely get this. The knock on risks to other subnets/ core ICP processes is certainly something to consider. 

I don't however buy into the 'user' argument. Given the flexibility of ICP a 'bad' dev can do plenty of wrong things on even the most replicated subnet. For example, the frontend might just do a fetch request to a web2 server which could be doing anything really. The DEX backend might have methods that aren't on the DID file allowing admins to do 'secret' stuff. The devs might just decide to push an upgrade which rugs the whole app before anyone knows what's hit them. None of these issues are linked to the number of nodes on the subnet. Bad devs will be bad regardless. 

Knowing what code a canister is running is really relevant here and is something I've mentioned before as being on my wishlist. I'd love to go onto the ICP dashboard and have canister code shown like the DID file is. I appreciate this is not a 2 minute job :slight_smile:

-------------------------

jeshli | 2024-03-12 01:10:36 UTC | #40

I'm particularly intrigued by your perspective on navigating instruction limits for complex computations, such as AI model inferences. Your clarification that the instruction limit applies per message and not to the entirety of a task's computation opens a doorway to potentially more efficient AI model execution on the IC, despite existing constraints.

Considering the specific challenge of AI inference, which often requires significant computational resources—for example, executing a single transformer layer for a modest AI model—how do you envision effectively utilizing the IC's architecture to support more complex AI applications? Given the constraints you've outlined and the need for dynamic data partitioning to manage instruction limits effectively, could you elaborate on strategies for minimizing added latency while ensuring the computation remains feasible and efficient? Specifically, how might we approach the design of such systems to leverage async calls and chunked computation in a way that aligns with the IC's unique infrastructure, and what developments in language/runtime support do you foresee as necessary to make these solutions more accessible to end users?

Furthermore, how do these strategies reconcile with the need to maintain performance and reliability, especially when considering the additional layers of complexity introduced by managing state across potentially fragmented computation tasks?

-------------------------

Jonathan | 2024-03-12 01:25:00 UTC | #41

[quote="lastmjs, post:35, topic:28329"]
I hope the decision-makers will take all of this feedback and prioritize finding revolutionary solutions to these problems, as I know they are non-trivial, and some may be impossible with current consensus technologies, without more major trade-offs.
[/quote]
I appreciate this discussion, as it brings transparency and fosters trust among users and investors.

Having followed his dilemma, however, I think @lastmjs brings up a valid but uncomfortable point: that what the IC publicly promises sometimes differs from what it can physically deliver. I would hate to see the team's amazing efforts undermined by a marketing campaign that sets up it's own straw men.

-------------------------

PaulLiu | 2024-03-12 01:37:25 UTC | #42

[quote="lastmjs, post:33, topic:28329"]
In one of my discussions if I remember correctly, the idea was thrown around that a CU could wait for multiple CUs to post a message before accepting it. Even if the team did not say that, could this be a way of performing the verification?
[/quote]

Yes, many CUs can collectively run one process. But the primary model of AO is that a user can request N>=1 CUs from a market to run a process (and the user will pay for it). This replication factor N has to be set (and agreed upon) so that any downstream receivers of a process will know not to wait on more than N messages. Therefore, in the situation when A receives message from B, A cannot retrospectively ask for more CUs to re-compute for process B (I was explicitly told this answer, as it would violate the importation assumption of AO: CUs should take inputs from AR as is). Also due to dependencies, it is unclear how much security A would get by insisting on its upstream B to have 100 CUs, while B's upstream only has one or 2 CUs.

When you "compose" security (for the lack of a better word), you don't get the sum or the maximum, you get the minimum.

PS: another goal of IC to is run autonomous internet services. I'm sure that you are aware that most other blockchains would expect the team behind of a project to run their own service. Off-chain computation protocols like Ordinal would fully expect this if a team wants the maximum security. AO is no different in this regard. So you can't really expect autonomous services on AO, because the protocol does not require (and cannot force that) a process always has at least one CU assigned. Your smart contract may get abandoned if you don't at least put in one CU yourself. You see, being flexible has its cons too.

-------------------------

lastmjs | 2024-03-12 01:43:20 UTC | #43

Not all algorithms or libraries can be easily chunked like this. If you pip or npm install a package and it doesn't provide for chunking, imagine being that developer.

We can of course chunk things and use the timers features to even do it automatically in the background, but it's a lot of work and for some devs and libraries they will just hit a practical dead end for their skillset.

Unless you're saying that somehow the IC could pause a computation and initiate another update call in a timer automatically or something?

Could this be the case? Could the host replica just decide to interrupt a canister method during execution? I imagine this might have undefined behavior around global state as other messages come passing through possibly updating the state.

-------------------------

free | 2024-03-12 07:43:12 UTC | #44

As a bit of food for thought, here's a brief overview of an idea we (in and around the Message Routing team) have been throwing around to significantly increase (data and computation) throughput on the IC. It is just an idea, with a couple of big question marks and probably a bunch of pitfalls we aren't even aware of quite yet. And if it does turn out to be feasible, it will require huge effort to implement.

Finally, we're not claiming it is entirely our idea and that no one else has had more or less the same thoughts. These kinds of things grow organically and directly or indirectly influence each other.

The basic idea is nothing revolutionary and it has even been brought up a few times in this thread: don't put the full payload into blocks, only its hash; and use some side channel for the data itself. That side-channel could be IPFS running within / next to the replica; the replica's own P2P layer; some computation running alongside the replica (e.g. training an AI model on a GPU); and so on and so forth. Once "enough" replicas have the piece of data, you can just include its hash / content ID in the block, the block is validated by said majority of replicas (essentially agreeing that they have the actual data) and off you go.

You could use this to upload huge chunks of data onto a subnet; transfer large chunks of data across XNet streams; run arbitrarily heavy and long (but deterministic) computations alongside the subnet; and probably a lot more that we haven't even considered.

The obvious issue here is that combining many such hashes into a block (or blockchain) could make it so that not enough replicas have all of them. E.g. imagine a 13 replica subnet; and a block containing 13 hashes for 13 pieces of data; each replica has 12 pieces of data and each replica is missing a different one. So going about this naively (and e.g. including all 13 hashes in the block) you'll end up stalling the subnet until at least 9 of the replicas have collected all the data needed to proceed. This may easily be minutes of latency before the block can even start execution. Even being exceedingly cautious and saying "at least 11 of the 13 replicas must have all data" can lead to the other 2 replicas constantly state syncing, never able to catch up. And what if 3 replicas are actually down? I'm sure there's a way forward (again, implying some trade-off or other -- liveness, latency, safety), I just haven't found it. The best I have so far is to use this as an optimization: if "enough" replicas have all the data, they propose and validate a block containing just hashes; if not, they continue including the actual data into blocks and advance with much reduced throughput (as now).

As said before, if you have ideas on how to make this work; or completely different ideas of your own  that you want to talk about; please start a separate thread. I'll be happy to chat. Just keep in mind that there's a long way from idea to working implementation; and that there's always -- always -- a trade-off and a price to pay: sometimes it's worth it, more often than not it's not.

-------------------------

lastmjs | 2024-03-12 09:10:18 UTC | #45

This is the kind of radical idea I've been hoping for. The benefits would be enormous, solving for the instruction and memory limit it seems.

I would love to participate in a discussion about this in another thread. Would you like to make it @free? I am also happy to.

-------------------------

Jdcv97 | 2024-03-12 09:48:32 UTC | #46

Hi, my first time doing part of this forum, I always read, but this time I feel that I have to comment a few things.


First off, I want to make it clear that I don't have an advanced technical background; I'm more of an investor and entrepreneur aiming to create some startups, leveraging unique business models made possible by the promised technology of Blockchain on the IC and current infrastructure. I'm someone who's passionate about reading and staying informed on cryptography, and I try to study all the technical aspects of the Internet Computer (IC) to at least have a basic but notable understanding.

With that said, I apologize in advance if what I'm about to say doesn't make sense, and I hope you correct me by explaining in more detail.

As I understand it, you propose to manage data on the IC more efficiently by, instead of including the data (payload) inside a block (making it on-chain) - and as I understand, the limit is 3 MB per block -, now processing it off-chain and storing it on IPFS, where only the hashes would be included in the blocks as such.

If I've understood correctly, this would fundamentally affect the added value of the IC, as where does the ownership of your data stand? Wouldn't this make IC the same as Flux, Akash, and all those other projects that lack on-chain computing or storage capabilities? I've also researched these projects before betting on the IC, and my perception is that they do the same for data processing, using hashes and storing data off-chain. Wouldn't we be doing the same as those projects we criticize, where they store their NFTs on IPFS linked by a hash?

If this is the idea or solution for this current limitation, I want to express my discontent, as this would go against the spirit and vision of the ICP and what all of us, both investors and entrepreneurs, (maybe developers?) aim to achieve: a vision where all web 2.0 software has to be rewritten and adapted to the IC, where all data must be processed on-chain. This is what we are selling to the public. Therefore, I believe that from the community and investors' perspective, we would not support such an idea. 

Although I understand it may require a lot of resources and R&D to find a definitive solution, I think the right path is to continue revolutionizing the industry, not just innovating. We should always be at the forefront with cutting-edge technology.

I don't think rushing to take the easier paths, as the competition has, will turn us into the crypto cloud we all dream of. You mention it could be an optimization, but I'm not sure it's healthy to take the quick and “easy” path, even when the solution fail to meet the promised expectations of a completely on-chain world.

-------------------------

patnorris | 2024-03-12 11:38:38 UTC | #47

Thank you for this great thread!

For instruction limits, the query charging proposal as linked to by @jeshli (https://forum.dfinity.org/t/community-consideration-explore-query-charging/19247/31) seems like an interesting next step to explore from my perspective.

For memory limits, I'm hoping that Wasm64 will be effective. I think it'd be great to understand the exact effects it'll have in more detail though.

Exploring dedicated "High performance computing" (likely also with GPUs, e.g. for DeAI applications) and "storage" subnets seems like a good idea and would enhance the IC's toolkit significantly.

While subnets are a great architecture choice for a scalable, decentralized cloud like the IC, I like the idea of abstracting these away in the dev experience such that the "dfx deploy" demand becomes "smarter" (and allocates resources as best fit) and the canister orchestration is adapted automatically based on usage/workloads (to balance canister demands with subnet supplies). The dev would then only specify parameters as deployment requirements and preferences (or stick to the default smart handling by dfx deploy and the network).

-------------------------

patnorris | 2024-03-12 11:42:52 UTC | #48

This is certainly a highlight in this great thread, thank you for it!

And I think your post would make for two great articles (“How to verify” and how AO approaches this), plus probably a third one about how the IC implements this :)

-------------------------

integral_wizard | 2024-03-12 12:38:28 UTC | #49

This radical idea, as far as I understand, would take away the one critical differentator that ICP has against everyone else. All on-chain for ICP is basically the same as 21M for Bitcoin. Offloading computation to 3rd parties will take away our fundamental lead that nobody else is even trying to solve. Id rather move slow and stick to the fundamentals. There should be no intermediary in the protocol stack.

-------------------------

free | 2024-03-12 12:48:39 UTC | #50

[quote="Jdcv97, post:46, topic:28329"]
If I’ve understood correctly, this would fundamentally affect the added value of the IC, as where does the ownership of your data stand? Wouldn’t this make IC the same as Flux, Akash, and all those other projects that lack on-chain computing or storage capabilities?
[/quote]

The data that made it onto the replicas via these side-channels would still be technically part of the block. A block with only a hash and no actual data would be more or less useless. So for the purposes of gossiping the block around and achieving consensus, the block would still have a 4 MB limit. But for the upper layers (or if you wanted to back up and preserve the full blockchain) you would have to include these additional pieces of content.

The reason why there's a relatively minuscule limit on block size is that the block must be gossiped to all (well, most) replicas on the subnet in order to achieve consensus. And eventually to all of them in order to be executed. That means reliably sending the full block across the Atlantic and Pacific in well under one second. But if there was some way to know that all (or most) replicas already have some piece of content, all they would have to agree on is its "content ID" (i.e. hash). So there would be less data to gossip in this tiny time window. And the actual payload could have taken arbitrarily long to be uploaded to or generated by every replica independently, without holding back subnet progress.

So I fully agree with your concern and this would definitely not change anything in terms of safety / tamper resistance / trust.

-------------------------

free | 2024-03-12 12:59:06 UTC | #51

[quote="lastmjs, post:45, topic:28329"]
This is the kind of radical idea I’ve been hoping for. The benefits would be enormous, solving for the instruction and memory limit it seems.
[/quote]

Maybe, to some extent. But keep in mind that computation would still need to be deterministic. So it would still likely imply Wasm code compiled against the IC's system API, rather than arbitrary code. Or you could easily run the risk of running some computation for hours on end across all replicas on a subnet only to find out that they disagree (which I understand is a common issue with e.g. HTTP outcalls).

So IMHO this is definitely not a silver bullet.

[quote="lastmjs, post:45, topic:28329"]
I would love to participate in a discussion about this in another thread. Would you like to make it @free? I am also happy to.
[/quote]

Furthermore, this is a half-baked idea that we've been poking at every now and then. As said, I for one have no clue how one would decide what to include into a block, so you don't end up with `2f+1` replicas making progress and `f` replicas constantly state syncing; only to then stall the entire subnet as soon as one of the `2f+1` replicas has any kind of issue.

So until we figure that one out, ensuring that it degrades gracefully (i.e. throughput is reduced progressively depending on the number of replicas at consensus height rather than everything working fine up to a point and then stalling for half an hour), it's only an idea.

And once we've got everything figured out, we'd need to put a number of things in order (as said, persistence layer, messaging, overhead) and then spend probably up to a year putting together the pieces of the puzzle.

But sure, feel free to kick off the discussion.

-------------------------

lastmjs | 2024-03-12 13:20:44 UTC | #52

I'm not sure it's really "third parties", though I suppose that could be the case.

The replicas will, if honest, obtain the data and hash its contents, and place those hashes into the blocks for consensus. The replicas will store that data if they want or discard it, they'll always keep the state around hopefully as well...

The IC already throws away a lot of data relative to Bitcoin and Ethereum, and blocks aren't even kept around forever is my understanding. So I don't know if this is that much of a departure.

Also keep in mind, if you assume Ethereum as a good example of the ethos of decentralized blockchain networks (I do), it seems well integrated into their roadmap to begin throwing away large amounts of data after consensus. EIP-4844 in fact, tomorrow, will go live and begin to do this.

State expiry in the future will get rid of even more data. This is called "the purge" in the roadmap. This puts Ethereum much more in line with the design decisions ICP has already made.

So I'm not sure it's correct to think that this change significantly makes things not "on-chain". ICP already isn't "on-chain" in many ways that other blockchains are. It's more "on-node" or "on-replica", and only the most recent agreed-upon info.

Someone help me out if I mischaracterized the technicals of ICP here, but I believe I am materially correct.

-------------------------

lastmjs | 2024-03-12 13:22:33 UTC | #53

[quote="free, post:50, topic:28329"]
But if there was some way to know that all (or most) replicas already have some piece of content, all they would have to agree on is its “content ID” (i.e. hash). So there would be less data to gossip in this tiny time window. And the actual payload could have taken arbitrarily long to be uploaded to or generated by every replica independently, without holding back subnet progress.
[/quote]

I wonder if data availability sampling is the solution here, like Ethereum proposes in their full dank sharding, and like I believe EigenDA and Celestia use to provide data availability to blockchains.

I will start the thread and post back here.

-------------------------

lastmjs | 2024-03-12 13:51:36 UTC | #54

I have started a new thread to discuss Hashed Block Payloads: https://forum.dfinity.org/t/hashed-block-payloads/28365

-------------------------

dieter.sommer | 2024-03-12 14:42:13 UTC | #55

[quote="lastmjs, post:52, topic:28329"]
ICP already isn’t “on-chain” in many ways that other blockchains are. It’s more “on-node” or “on-replica”, and only the most recent agreed-upon info.
[/quote]

I need to disagree here. ICP is the only blockchain that offers an end-to-end on-chain smart contract experience.
* The UI is downloaded from the smart contract by the browser, instead of from a cloud service in *every* other blockchain.
* Read interactions are done from the blockchain. Via certification you can have secure yet highly-efficient reads. Certified queries will provide efficient certified reads for *any* use case. *Every* other blockchain uses public cloud or other proprietary services like RPC nodes like Infura for reading data from the chain.
* With HTTP outcalls, smart contracts can interact with Web2 without involving any other party. *All* other chains require oracles to connect to Web2.
* ICP integrates with the Bitcoin network without any intermediary and uses t-ECDSA for trustless signing of transactions. *Almost every* other chain (ThorChain is one of very few notable exceptions) requires bridges to integrate with other networks.

ICP does discard history. This is at the core of the design of ICP because it intends to replace public cloud, meaning it needs much more throughput than other chains. Just to give you an intuition why it is infeasible to keep around the complete history, even just the ingress messages: Considering a subnet works at its maximum capacity with a 4MB block per second. This would give just a block history of around 126 TB. Per subnet. Per year.

To summarize, I think it's really not fair saying that ICP is not "on-chain". It just does not keep around all the (often useless) history. Canisters can implement their "own blockchain", like ledgers do, in order to keep around history that's relevant. So I'd claim that ICP is an architecture that allows for an excellent tradeoff between allowing smart contracts to keep things around, while discarding mostly useless history. In terms of doing things on chain, it is lightyears ahead of any other chain out there.

-------------------------

lastmjs | 2024-03-12 15:24:43 UTC | #56

I suppose a definition of on-chain might help, as I love many of your points, but I feel I might be referring to properties that other communities would consider necessary to even be a blockchain.

For example on Bitcoin block data can be retrieved always and forever from full nodes (is my understanding), and this is currently the case on Ethereum as well (about to change tomorrow). Anything on-chain on Bitcoin is immutably written to that blockchain forever.

ICP works nothing like this and there is confusion around that, and indeed I think it is a major trade-off that ICP has taken, because individuals cannot independently verify anything (maybe anything is strong, you can verify consensus but you cannot detect collusion or incorrect state changes without observing their effects in a more difficult way than other blockchains provide) about the ICP blockchain.

You cannot download blocks and execute them and (similar to Ethereum) recreate states from the beginning. You have to trust that the nodes did not collude. You don't need to trust that on Bitcoin or Ethereum, you can independently verify the entire history up to and including a transaction you're about to participate in.

I feel saying ICP is completely on-chain makes it seem like it has all of the properties of the other blockchains and more, which it doesn't.

It has chosen its set of trade-offs.

Then again, Ethereum is heading in many ways towards a similar set of trade-offs...or maybe some wouldn't consider them trade-offs?

I may be mischaracterizing, happy to be wrong here...help me understand why it's not a trade-off?

-------------------------

lastmjs | 2024-03-12 15:13:45 UTC | #57

Also on-chain sounds like it has similar security to other blockchains like Bitcoin or Ethereum, and I am yet to be convinced that ICP has anywhere near the resilience of the other blockchains.

Is a 13 node blockchain really a blockchain? I mean the underlying data structures would technically say yes if there is a chain of blocks used, but I wonder if most people in the crypto space think of something much more decentralized, verifiable, and robust than ICP when they think on-chain.

And if the claim is that ICP is as secure as Ethereum because of "deterministic decentralization", I want to see real, hard, formal research done to convince myself and others, so far it's just a lot of opinions or statements that this is true or probably true without much to back up those opinions.

Why is 13 okay? Why not 5? Why not 40? Why not 100?

Where is the line at which we find sufficient decentralization for a use case?

We need to research this, not just assume it's true...or at least, I wish someone would research this, especially considering all of ICP security is based around t < n / 3, which is great, but how big does n need to be? Surely security breaks down with a sufficiently low n.

-------------------------

skilesare | 2024-03-12 15:14:16 UTC | #58

[quote="lastmjs, post:43, topic:28329"]
Could this be the case? Could the host replica just decide to interrupt a canister method during execution? I imagine this might have undefined behavior around global state as other messages come passing through possibly updating the state.
[/quote]

This would be an interesting avenue to pursue.  If the replica were smart enough to say, "look, you get 1_000_000 instructions this round and then we're going to freeze your memory and give it back to you next round to continue" then maybe non-ground-up libraries become viable long-term.  If there are 50_000_000 instructions available per round then this gets you 50 concurrent processes(I made these numbers up).  

The big issue would be what memory you read in to date because if another process changes that then you'd need to trap. (This is the biggest thing that gets people on audits is they do an await and then don't revalidate their variables when they get the response).

-------------------------

Sormarler | 2024-03-12 15:18:54 UTC | #59

I don't think anyone care about everything being all on chain. In fact what I have seen people state is that it is on realistic and practically impossible as it just too inefficient to put all data on the blockchain.

-------------------------

skilesare | 2024-03-12 15:19:04 UTC | #60

It seems the big conundrum is between capacity vs latency. If you get more capacity you increase latency. If you decrease latency, you have to reduce capacity(as in the messaging stuff that @free has been proposing elsewhere to increase throughput on messaging).

It seems zk can fix some of this by shrinking proof time, but if transform 2 needs the output of state 1, you still have to get all that state to the prover, which seems to reintroduce latency(unless they are colocated?)

-------------------------

lastmjs | 2024-03-12 15:20:55 UTC | #61

With more formal research of what level of decentralization is necessary, and combined with the following (I know some are pipe dreams), I would feel much better, maybe even amazing about ICP's security relative to the major secure blockchains like Bitcoin and Ethereum:

- Node shuffling
- Secure enclaves
- Anonymous node providers with ZK identity verification
- Node staking/slashing
- Automatic node onboarding
- Sufficiently large subnets (need more research to know what that is)
- Node operators shouldn't know what subnet they're in, what canisters they're running, nor be able to see any of the canister data
- zkWasm or another way for clients to verify computations beyond blindly trusting the consensus amongst a small group of node operators

And I would perhaps feel more comfortable calling this a blockchain, and apps running on it "on-chain".

-------------------------

skilesare | 2024-03-12 15:29:10 UTC | #62

[quote="lastmjs, post:52, topic:28329"]
Also keep in mind, if you assume Ethereum as a good example of the ethos of decentralized blockchain networks (I do), it seems well integrated into their roadmap to begin throwing away large amounts of data after consensus. EIP-4844 in fact, tomorrow, will go live and begin to do this.

State expiry in the future will get rid of even more data. This is called “the purge” in the roadmap. This puts Ethereum much more in line with the design decisions ICP has already made.

So I’m not sure it’s correct to think that this change significantly makes things not “on-chain”. ICP already isn’t “on-chain” in many ways that other blockchains are. It’s more “on-node” or “on-replica”, and only the most recent agreed-upon info.
[/quote]

These make me a bit sad as one of my biggest hopes for decentralized blockchains is that we'll be able to do things in the future, that we don't know we want to do now, based on what happened in the past.  Once we start throwing away data we lose some of that optionality.

The good news is that IC canisters can recreate this by logging to ICRC3 logs.  We can find ways in the future to offload the archives from state with return with a witness scheme so that we get the best of both worlds.  Ethereum was going down this route with the "stateless" themes back in 2018, but it seemed to fall out of favor for L2 solutions.

Putting together these libraries and frameworks is a bit down my todo list, but is on there. :). 

tldr:  we can offload state if we have a way to bring it back with a witness. This creates a data availability problem, but some solutions for that are emerging.

-------------------------

Sormarler | 2024-03-12 15:29:18 UTC | #63

Why should the internet computer resemble a10-year-old blockchain like Bitcoin and Ethereum and not the newer blockchains like Sui, Aptos, and Solana which doesn't keep the entire history of the chain? Would you say those aren't blockchains as well?

-------------------------

skilesare | 2024-03-12 15:36:32 UTC | #64

[quote="dieter.sommer, post:55, topic:28329"]
This would give just a block history of around 126 TB. Per subnet. Per year.
[/quote]

Looks like cost per TB is about $10 and will be half as much in 18 months.  https://diskprices.com/

126 * $10 * 4x geographic replication - ~$5000.  That actually isn't that much considering what a subnet can do(especially how much we're paying subnets right now).

-------------------------

skilesare | 2024-03-12 15:42:50 UTC | #65

[quote="lastmjs, post:56, topic:28329"]
You cannot download blocks and execute them and (similar to Ethereum) recreate states from the beginning. You have to trust that the nodes did not collude. You don’t need to trust that on Bitcoin or Ethereum, you can independently verify the entire history up to and including a transaction you’re about to participate in.
[/quote]

Given @dieter.sommer 's comment about 128 TB per year of block state, perhaps it wouldn't be crazy to have some 'fully replayable' subnets?  You probably don't need to host asset canister there, but things like tokens or governance might be worth paying the extra cycles per year to store all the data?

-------------------------

free | 2024-03-14 09:58:12 UTC | #66

[quote="skilesare, post:64, topic:28329"]
126 * $10 * 4x geographic replication - ~$5000. That actually isn’t that much considering what a subnet can do(especially how much we’re paying subnets right now).
[/quote]

That's in the first year. Costs grow linearly (edit: was "quadratically") over time. So in 10 years you'd have to pay 10x (edit: was "50x") more per year. Storage costs may decrease over time, but quite possibly not at that rate.

This data would also have to be queriable, which doesn't come for free. Someone (likely multiple someones) may want to download a few subnets' data for the past couple of years. And if the argument is that very few (if any) parties would be interested in that, then what's the point of persisting and making available millions of dollars worth of data forever?

-------------------------

Zane | 2024-03-12 16:18:37 UTC | #67

[quote="free, post:34, topic:28329"]
There are literally very simple, straightforward solutions to most of the points raised here.

E.g. you can have a single-replica subnet (or 4 replicas in the same data-center, if you want); it is literally one NNS proposal away. With some tweaks to Consensus timing, It should give you amazing latency You will just have to cross your fingers and hope that no one cares enough to hack into your one replica; and that the data center doesn’t go up in smoke.

Similarly, you could set arbitrarily high instruction limits. Or only checkpoint once a day; then you could have DTS executions spanning hours. Just hope it’s fewer than 4 concurrent DTS executions at once; and that enough replicas make it to the end of the day, so you won’t have to wait for an extra day or two to finally get that checkpoint.

Or make an NNS motion proposal to reduce fees 10x. Again, trivial.
[/quote]

While this is technically true, what I, and I guess Jordan too, are trying to point out is that the protocol's design often overreaches and makes lots of these decisions for us, tweaking the tradeoffs comes with tons of friction and is sometimes even impossible due to the fact the protocol itself is being developed and optimized with the current topology as a the main frame of reference.

Say I want to run my dApp on 6 nodes, making an NNS proposal is trivial, but I have to hope it gets approved in the first place, then the subnet has to be formed. 
Eventually I find out the configuration doesn't work as expected, so I propose to create a 5 node subnet, but the NNS is concerned there isn't enough demand for it and the proposal is rejected, in the end I decide to compromise and use an existing 4 nodes subnet. 
Fast forward two years and my app has become a potential target by hosting a whisteblower's deadman switch on it, I decide to prioritize security over performance and want to move it to a 100 nodes subnet, unfortunately it turns out the protocol can't handle that, due to some component bottlenecking, which nobody knew about, cause it had never been tried before.

The current design disincentivizes experimentation as it leads to topology fragmentation, which reduces cost efficiency of subnets. If my 6 node subnet is approved and it doesn't get much traction there are only two options for the governance body: either get rid of it and screw me over or accept the inefficiency, both aren't ideal.

This is just for customizing replication factor, the number of possible permutations taking into account all the variants of execution/consensus related settings, makes it impossible to satisfy everyone's needs with the current architecture. 
Subnet rental is going to be the only option in those cases, but it'll require a significant investment many aren't capable or willing to undertake.

If the IC at a fundamental level provided "just" an incentive structure to reward network participants and a protocol to run serverless services with blockchain functionality layered on top, with no assumptions about how the network itself is structured, we'd be able to experiment much more freely and find the right sets of tradeoffs for our use case more quickly.

Subnet's architecture is too rigid and gets in the way of that, ideally the dev experience should be something like: "Run this canister on N nodes with high CPU, low storage, etc.. with this execution settings".

-------------------------

free | 2024-03-12 18:19:28 UTC | #68

AFAIK there are no structural requirements for subnets to have 13 replicas. You can look for end-to-end tests: they are running combinations of 1 node subnets, 4 node subnets and many others. IIRC there is some minor implementation detail that would prevent a 100-replica subnet from working, but it's definitely not an architecture / structural constraint.

As said (and again AFAIK), the only reasons why we don't have arbitrary subnet sizes are (1) no one really had a compelling argument for them and (2) a subnet with too low a replication factor might more easily be taken over and we are still missing a few checks and balances that would prevent a malicious subnet from minting cycles at will (and sending them to any canister); or flooding honest subnets with garbage. I know there were some efforts in this direction (specifically to support a "Swiss subnet"), but I have no idea what exactly they were planning to do or how far along they are.

-------------------------

diegop | 2024-03-15 15:53:06 UTC | #69

Hey everyone,

First of all, while I agree with some and disagree with things in this post, I wanted to comment two things:

1. ***I think the tenor of the conversation is what I like in the developer forum.*** Reasonable people can disagree, ask for clarification, push back, etc.. That is the nature of a good and healthy dialogue. I would argue that when i read *something I disagree with, but respect*, thats is the biggest *sign of how tolerant and respectful the environment is.* This after all, is a large computer science project, not a weird crypto cult :slight_smile: let's keep up the tone!

2. I (and others) have escalated this post to some folks at DFINITY who may have deeper insights. I expect more info to come. I and and others are actively reading and digesting what we see.

-------------------------

lastmjs | 2024-03-13 00:23:00 UTC | #70

Thanks @diegop that's all great to hear.

-------------------------

Jupes_M | 2024-03-13 03:53:30 UTC | #71

[quote="lastmjs, post:16, topic:28329"]
ICP is pretty good at some kinds of horizontal scaling right now, but vertical scaling of even a single app is very bad. You can’t get many single apps that work just fine on Web2 to work on ICP because of all of these vertical/single app limits.
[/quote]

Agreed. *However*: **Wordpress** is one of those apps which probably wouldn't suffer from these limits.
If there was one thing which would end the discussion about the future of ICP growth, I'd pick **Wordpress** integration. Many more people would look to the IC as a place to host their blog than will as a place to build the next Netflix. 

[quote="CoolPineapple, post:18, topic:28329"]
BTW Might be an interesting play for @dfinity to team up with [Ethswarm ](https://www.ethswarm.org) as they are almost completely overlooked and underused so would should in theory welcome both funds and collaboration. Though perhaps they are politically too cyberpunk and Ethereum orientated to accept a deal.
[/quote]

 Swarm's time is coming. Right now, no one really cares how their NFT data is stored; and the UX experience needs to come a few country miles. 

This and Fetch.ai are two projects which I think would totally change the IC.

-------------------------

gip | 2024-03-13 04:36:52 UTC | #72

I like the idea of focusing on the application first and identifying 3 to 5 possible "killer" dapps is the way to go (and then look at the building blocks / technology). Hopefully 1 or 2 will really work out.

[quote="Jupes_M, post:71, topic:28329"]
Agreed. *However*: **Wordpress** is one of those apps which probably wouldn’t suffer from these limits.
If there was one thing which would end the discussion about the future of ICP growth, I’d pick **Wordpress** integration. Many more people would look to the IC as a place to host their blog than will as a place to build the next Netflix.
[/quote]
Interesting idea. So there would be an open source way to build a sire and start a canister that will basically contain the site. An II and a payment would be required to create and run the canister if I understand correctly. Where would the assets be stored (large images or videos)?

-------------------------

lastmjs | 2024-03-13 04:59:32 UTC | #75

I have been talking with the founder of Arweave through DM, and I am going to post excerpts from our conversation with his permission.

Some of this conversation is in response to @PaulLiu's posts here.

These will just be excerpts, I may remove or shorten some message responses, correct typos, and the order/flow might not be exactly how they were in the DMs:

> Jordan: How are you going to secure these processes running on possibly untrusted CUs?

> Sam: I think this is a misperception. The CUs will be staked, so if they provide you with a false state attestation they can be slashed. This gives you a security guarantee proportionate to their stake -- if you would like more stake, you can just ask more CUs

> Jordan: Your claims of smart contract-level verifiable compute seem strange without explaining or figuring it out yet, I've been talking with your team in ETH Denver

> Sam: I think the core difference between the approach of ICP and ao is that ao has dissociated compute and consensus, while ICP bundles them

> Sam: Having them separated lets you do interesting things with them -- like let the compute be in other types of VM, run longer, require VM extensions, etc

> Sam: It also gives you a ton more flexibility on the consensus side, too: Choice of SU (giving ordering and DA guarantees) is left to the developer. You can run a trusted one (like the PoA testnet ao currently runs), or you can use a staked one (as we plan for the base mainnet release), but you could also use Bitcoin, Arweave, EigenDA, or Celestia without changing the core data protocol

> Sam: So to put it in the simplest sense: Your process is secured by the availability of its inputs, because verifiability of that (with any deterministic VM) gives you reproducibility of the state. You can then ask any CU -- or even just run it yourself -- to calculate your state.

> Sam: The staked CUs actually give you far higher guarantees on reading the state vs traditional blockchains (I think this holds for ICP, too?). Typically, a user reads the state of the network by sending a HTTP request to a gateway/indexer/RCP. In ao when you ask a CU (also via HTTP) you get a signed response from the node. If you later find that this state attestation was invalid (either by asking another CU, or running it yourself), then you can slash the CUs stake.

> Sam: You can also validate it yourself much faster, as execution is decoupled from consensus. Essentially each process is its own independently verifiable 'blockchain' -- so you can calculate its state without generating the state of any other process. I believe if you tried to do this in ICP you would have to re-validate the entire subnet?

> Jordan: I am referring to the idea that the network of CUs will be untrusted by default, as in they will be independent of the process owner, thus possibly Byzantine, and some kind of mechanism would need to be created on top to trust them. The staking is part of that mechanism it seems

> Jordan: Yes but how does slashing work? Who can slash? How do you prove that a computation was done incorrectly without zk? It seems you would need some kind of consensus mechanism, ideally in real-time so that a computational result can be trusted without a lot of latency

> Jordan: Sounds correct, now I wonder where the consensus on ao will come from, as it is necessary to provide security guarantees without zk...I think with zkWasm for example relying just on Arweave for consensus on inputs and outputs would be enough, correct?

> Jordan: Having VM optionality and long-running computations is a definite improvement over ICP currently, still confused on how/where the consensus will come from though

> Jordan: Consensus on inputs is crucial of course, but not sufficient (zkVM might change that story). I can't just ask one CU to process something because I can't trust that one CU, stake would help but I don't think that's sufficient for all use cases, some kind of consensus amongst multiple CUs sounds like what is needed

> Jordan: Also running it myself is not going to be feasible for building web-scale applications for example. I'm not sure what your ambitions with AO are, but on ICP we're building BFT web servers, databases, full-on web backends. For example we have Express.js running on ICP, you essentially deploy a BFT 13-40x replicated JS server. We have basic SQLite and hopefully soon Postgres compiled to Wasm running (PGLite). You can't run this stuff yourself to verify it

> Jordan: ICP doesn't have automated slashing like that, but nodes can be removed by the DAO, and subnets can provide signatures on all outputs (I believe they do actually for all state change requests, not for read-only requests by default, but they can do that to). The exact verifiability I don't remember, as in where exactly these signatures are verified

> Jordan: It's just completely impractical to expect a user/dev to verify a web-scale backend with potentially gigabytes of data, this doesn't scale of make sense for many use cases.

> Jordan: We're going for full-blown web-scale Ghz-level compute over gigabytes of data, you can't run this stuff on a client

> Jordan: Now again, having a zkVM at the core would change the story

> Jordan: Sadly I am still left unsatisfied, I don't see where the consensus on the processes is supposed to happen, well I guess it's supposed to happen outside of the system? But then someone needs to build this

> Jordan: As a dev I want to build full web backends on AO, I want http, Postgres, etc

> Jordan: I want to just run the process and have bounds under which it is provably secure, provably BFT

> Jordan: I don't see that here, I see some building blocks maybe

> Jordan: For example I want an algorithm/protocol here that says as long as 2/3 CUs come to the same output with the same inputs then I am guaranteed honesty or something like that

> Jordan: These are essentially the guarantees ICP, Ethereum, Bitcoin, etc give us, and these are all networks potentially full of Byzantines

> Jordan: Byzantines are processes that can fail for arbitrary reasons including dishonesty, which is exactly what a CU is even if staked

> Jordan: The stake just helps weed out Byzantines, but I think more than that is required

> Jordan: In the end: where is the 2/3 etc real-time BFT guarantee coming from?

> Sam: Ok, I think we are getting to the crux here. There are three layers:
- CUs: You can ask as many CUs as you want in order to gain as much certainty (backed by stake) as you desire. Because ordering+DA is separated from execution, you do not need an explicit consensus mechanism _at the CU level. For example, if you wanted to have the equivalent of 100% stake (on a PoS execution network) you could simply ask and pay every CU to do the computation. If they all come to the same result, you have your 'consensus'. This is flexible to reaching 2/3, 1/3, or just a USD token equivalent quantity of stake.
- Slashing: What if they don't agree? You can raise a vote on the staking process, calling others to calculate the real state and vote. This is a form of BFT consensus, but only executed when necessary. The core staking process itself will use Arweave's BFT consensus as the SU to ensure availability and ordering, without dependence on any specific node. The staking process will also allow subledgers that grant for faster votes on low-confirmation time BFT ledgers, or even simply staked SUs -- but participants can always default back to the Arweave network if problems occur on these subledgers.
- Finally, everything rolls up to availability on top of Arweave's consensus.

You are totally right that zkWASM will improve this. You could use any untrusted CU to grab your state.

> Jordan: So can I achieve this: spin up a process on 31 CUs, for every incoming message have the client/user check that at least 21/31 agree?

> Jordan: How will a user/client be able to verify that the computation was performed correctly without a lot of latency?

> Jordan: I'm imagining a client using HTTP, they'll want to perform an HTTP call to a server running in a process, and in the response they'll want to know somehow that 21/31 agreed

> Jordan: Is this possible with low latency?

> Jordan: And another question, do you foresee the kinds of use cases I've been describing as being plausible with AO? Web servers, databases, frontends, full on web scale backend applications?

> Jordan: * and by low latency I mean ideally under one second, but in the worst case a few seconds would maybe be acceptable, maybe

> Sam: Yep! Or any other configuration. You could just ask any number in parallel and aggregate the results (or the first x% to reply, etc).

> Sam: You could build an aggregator like this, or you could just have the client speak to many nodes in parallel. Both would work, although an aggregator doesn't exist right now

> Sam: These results you collate are a big step up on traditional RPC nodes, too, because they are staked against. If the CU lied you could take your result and have the node be slashed -- regardless of whether 'you' is a web browser, another MU, etc.

> Sam: Definitely decentralized databases and backends!

> Jordan: Awesome!

> Jordan: But what about latency?

> Jordan: I'm thinking there will be some significant latencies on the order of seconds at least??

> Sam: I think the claims of servicing HTTP requests 'directly' from ICP canisters are unfortunately relatively weak, because there is always a 'gateway' node that has to sit between the user's browser and network. The question is how the gateway will be incentivized (given it is transferring all of the bandwidth) and trusted (given lack of good browser options for validation). I think you could do exactly the same thing with ao (with staked results in the browser, too!), but I don't think it would be a high integrity claim we would be happy standing by to call it 'serving' HTTP requests from the processes. It can definitely _pre-process_ the results, though! Is there anything I am missing on the ICP side here?

> Sam: It will definitely depend on the way you write your process, but in the mode we expect to be the default (staked independent MUs, SUs, and CUs), it should be sub-1s latency. In the current setup we get roundtrip latency of ~500-800ms.

> Sam: If you want to move 1b USD in a process, though, the message recipient may want to wait a period of type with the message in the buffer (even if it is received with very high stake)

> Sam: Again, the approach is to allow flexibility and modularity, rather than a monolithic design where one is not needed

> Jordan: There is some nuance here. ICP has a system of boundary nodes that accept plain HTTP requests and convert them into API requests that are then sent (over HTTP still I believe) to the replicas, where they are then gossipped or otherwise communicated among themselves

> Jordan: So yes, there is essentially a proxy layer, the current plan is to allow anyone to run these proxies into the network

> Jordan: But you can also call the API nodes directly over HTTP...I'm not sure if you can call the replica nodes themselves directly. We are doing this to get around some authentication issues right now, where in the browser we override global fetch and intercept the dev's requests only if a certain HTTP header is present. We then use a client-side "agent" to perform the API calls, bypassing the translation of raw HTTP requests into the API call requests

> Jordan: Calling the claims weak might be warranted, but practically speaking the developer can write Express or other http servers in their canisters

> Jordan: There are of course limitations, but the developer experience is getting better. Here's an example of a very simple Express application that you can deploy to ICP: [[https://github.com/demergent-labs/azle/blob/main/examples/hello_world/src/backend/index.ts](https://t.co/ACgZRPo2yP)](https://github.com/demergent-labs/azle/blob/main/examples/hello_world/src/backend/index.ts%5D(https://t.co/ACgZRPo2yP))

> Jordan: There will always be infrastructure required to receive and translate HTTP requests, resolve DNS, and deal with networking that might be outside of the guarantees of the blockchain...perhaps?

> Jordan: But in the short-term only the HTTP Gateways themselves, the ones that convert raw HTTP requests into HTTP API requests, will be outside of the ICP network's incentivization mechanisms

> Jordan: And when I talk about serving the HTTP requests, I think I'm mostly interested in as a developer being able to write an HTTP server using normal web development libraries in my process, and just deploying that to the network and having it work

> Jordan: Obviously with good-enough security guarantees, but I believe ICP has pretty good guarantees on that and will be improving

> Jordan: If AO can provide a similar experience, that's what I'm most interested in knowing

> Jordan: It sounds like you're saying that it can

> Jordan: If latency, cost, scalability, and developer experience are good enough, then that's amazing

> Sam: Yep -- the 'pre-processing' (generating the HTML etc to serve) is definitely possible, and cool that it can be validated. _Serving_ web apps is an entirely different game though. In the Arweave ecosystem we have the

[@ar_io_network](https://twitter.com/ar_io_network)

which is building decentralized gateway infrastructure, but getting the incentives right is highly non-trivial.

> Sam: Yeah -- it is definitely an exciting idea. I don't see any reason it shouldn't work on ao, with some of the same caveats as ICP. Will probably take a little while for the compilation tooling to get there though

> Sam: This conversation has actually got me thinking much more about whether CUs could essentially be gateways themselves?

> Sam: You pay them for access, which solves the incentive problem, and their responses must be signed (we have a system called P3 for adding crypto auth in HTTP headers: [https://arweave.net/UoDCeYYmamvnc0mrElUxr5rMKUYRaujo9nmci206WjQ…](https://t.co/BPkEvtcT44)).

> Sam: Even if the CU thinks that the client it is talking to is a web browser that won't validate the signature in the headers (or re-validate the execution from other CUs), the risk of being slashed is so high that there is a very strong incentive not to lie about the results still

> Sam: So in theory you could 'serve' the site directly from the CU, with some strong guarantees. And of course, you could swap out the CU just like you can swap out an Arweave gateway (ex. [[http://sam.arweave.dev](http://sam.arweave.dev/)](https://t.co/1mtzKYHKQi), [[http://sam.g8way.io](http://sam.g8way.io/)](https://t.co/UlGaDfRa9p), [[http://sam.ar-io.dev](http://sam.ar-io.dev/)](https://t.co/JD4K9p6LQq), etc)

> Sam: Can't imagine how you could subsidize the CU-as-gateway, though.

> Jordan: My biggest concern with AO is still verifiability, and his takes validate my suspicions that AO may be lacking there

> Jordan: Being proven wrong would be very interesting of course

> Sam: ...If so desired, many CUs in ao can sign the same state to attest to its validation. This is essentially the same as providing the chain signatures that ICP has

> Sam: number of signatures from different staked CUs can give you far better verifiability than a BLS sig from many different unstaked nodes. Lack of stake means that these subnets are highly vulnerable to 'eclipse' style attacks. In ICP these can affect not only state attestations to users (which, I believe, are even relayed through unsigned and unstaked gateways?) but also the passage of messages between subnets.

> Sam: Somewhere in the message they also mention that no intermediate states are stored. This is again incorrect -- nodes in ao already store staked snapshots on Arweave that other nodes can validate and also resume execution from. Again, joining an ICP subnet from a BLS signature of state at a block height is far riskier, as nothing at all prevents an attacker from slowly eclipsing the subnet and signing any data they like with the trusted keys.

> Sam: A final point to note is that in general the entire ao architecture is flexible at its core. Processes are free to choose any requirements that they want in terms of security -- they could always trust a single set of keys (PoA), require a variable stake on the messages they receive, or even delay processing for riskier messages for a period of time (the delay the author mentions in rollups). You could even implement the precise security mechanisms of ICP if so desired. Instead of being prescriptive and enforcing one model on all users+devs, ao let's you choose what makes sense for each individual use case.

> Jordan: ust to check on something, CUs have flexible verifiability of messages between processes right? Process A -> Process B, Process B could require X signatures from specific CUs before accepting the message?

> Sam: I wouldn't call it flexible verification of messages at the CU level (they cryptographically attest to faithfully executing the code of the process), but yes, the processes can flexibly verify the messages as they like. Process B can require any number of signatures, optionally attached to any amount of stake, or require a ZK witness of correct execution if they prefer.

> Sam: Or even only accept messages from a certain set of other processes, or require a signature from a specific key

> Sam: Have been thinking that it might be interesting to demonstrate what an ICP-style security model implemented in ao would look like. It's actually far simpler than the PoS system that we expect most processes will employ

> Sam: I also think that a reasonable way to sum it up is inline with afat's diagram: [https://global.discourse-cdn.com/business4/uploads/dfn/original/3X/4/c/4cf1cb80b97d881fbd5d6b515bd767ea6bd463d6.jpeg](https://t.co/qXeLbOqh4s)

> Sam: I thought it was quite neat

> Sam: The exact placement of the dots is hard to follow (why is EVM on IC further to the right than EVM on ao, when his point is that IC is essentially 'EVM compatible' -- you could run EVM on ao+IC), but the idea to visually show that ao contains a flexible plane of different trade-offs is cool

> Sam: I think that afat is right that you could run a good 'permissioned decentralization' SU for ao on an IC subnet. This would be great! I remain to be convinced about the trust model for IC subnets, but this would be a cool option to give people if they want it.

> Sam: For CUs, however, IC would be very limited relative to 'normal' staked ao CUs. Having consensus at the state layer (rather than inputs) puts fundamental restrictions on what they can achieve (lower execution counts, no VM choice, VM extensions, etc)

> Sam: The subnet-consensus-on-execution approach even limits you from achieving greater trust on your execution outputs if you so desire: In ao, you could ask a full 'subnet's worth' of CUs about the state, or you could ask _every_ CU about the state -- or just a couple. Whatever your preference is

> Sam: So for that reason, I don't think IC CUs would be competitive.

> Sam: But for SUs, it could be very cool!

-------------------------

lastmjs | 2024-03-13 05:40:18 UTC | #76

@diegop please don't forget to escalate this latest post to those with deeper insights as well, thanks!

-------------------------

icarus | 2024-03-13 06:13:45 UTC | #77

Jordan that is a very informative dialogue you had with Sam and thanks for sharing it here. 
However I found it hard to follow the conversation as your questions and his replies seem to appear out-of-order.
Could you edit the post to restore the flow of question and response?
Cheers!

-------------------------

timo | 2024-03-13 07:51:13 UTC | #78

Since you guys dived into aocomputer already so much, I can probably ask my question here instead of having to look for an aocomputer forum. What is the criteria for the output of a process to be written to the AR layer?

I mean how many CUs, or what stake equivalent set of CUs, has to come to consensus that the data layer records the output of a computation, which could be a message to another process. Who chooses the CUs? They have to be chosen by the process owner?

-------------------------

PaulLiu | 2024-03-13 07:51:08 UTC | #79

Thanks for talking to Sam! Getting his opinions is very helpful to understand many aspects of AO. But I still hope he could clarify on how optimistic challenge would work in an async setting. Suppose the following messaging sequence between processes:

```
A -> B -> C -> D -> E
```

Everyone's input & output is recorded on the AR chain. Now suppose the output of A (which would include message A->B) is being challenged and eventually proved wrong, so CUs for A would have their stake slashed. But what happens to CUs for B/C/D/E? They merely took messages that was recorded on AR, and did their computation accordingly. Do they get slashed or not? Maybe E already launched a missile or something that can't be easily reversed. How is slashing CUs of A going to help?

Chains like Arbitrum would give 7 days if anyone wants to challenge A, and if nothing happens in the 7 days would it then assume the message A -> B is correct, and meanwhile everybody from B onwards would have to wait.

AO wants all of the processes to keep churning until something wrong is spotted.

You may want to argue that if E is capable of launching a missile, it should require 100 CUs of D. By this logic D would require 100 CUs of C,  and so on. Is this really how AO works?

-------------------------

timo | 2024-03-13 07:56:04 UTC | #80

[quote="PaulLiu, post:79, topic:28329"]
But what happens to CUs for B/C/D/E? They merely took messages that was recorded on AR, and did their computation accordingly.
[/quote]

I'm pretty sure AR is the source of truth here and CUs for B-E did nothing wrong in their model. Hence my question what condition gates writing output to AR.

-------------------------

PaulLiu | 2024-03-13 08:06:39 UTC | #81

[quote="timo, post:78, topic:28329"]
I mean how many CUs, or what stake equivalent set of CUs, has to come to consensus that the data layer records the output of a computation, which could be a message to another
process.
[/quote]

No, consensus is not required. Each CU would record its own computation output on AR. That is it. It is up to the downstream CUs to decide how many outputs from upstream they want to see.

[quote="timo, post:78, topic:28329"]
Who chooses the CUs? They have to be chosen by the process owner?
[/quote]

Yes. But I can also imagine CUs taking payments from whoever is interested in keeping a process live.

-------------------------

timo | 2024-03-13 07:59:21 UTC | #82

[quote="PaulLiu, post:81, topic:28329"]
Each CU would record its own computation output on AR.
[/quote]

So multiple outputs can be written to AR for the same computation?

-------------------------

PaulLiu | 2024-03-13 08:07:04 UTC | #83

[quote="timo, post:82, topic:28329"]
So multiple outputs can be written to AR for the same computation?
[/quote]

Yes. Anyone can record anything. The next unit who is picking up these messages will have to decide which ones should be used.

[quote="timo, post:80, topic:28329"]
Hence my question what condition gates writing output to AR.
[/quote]

As with all other off-chain execution models, things recorded on-chain are only there for availability. How to interpret them is up to the code running off-chain excecution.

-------------------------

timo | 2024-03-13 08:30:47 UTC | #84

[quote="PaulLiu, post:83, topic:28329"]
As with all other off-chain execution models, things recorded on-chain are only there for availability. How to interpret them is up to the code running off-chain excecution.
[/quote]

Ugh. Ok, I thought they did something smarter.

-------------------------

esquivada | 2024-03-13 11:11:15 UTC | #85

Where were you guys when the fucking Justin Bons? Wait, I know! Working doing ICP the best blockchain of the earth.

-------------------------

skilesare | 2024-03-13 12:01:58 UTC | #87

> That’s in the first year. Costs grow quadratically over time. So in 10 years you’d have to pay 50x more per year. Storage costs may decrease over time, but quite possibly not at that rate.

Why quadratically?  Sure with more use, but is there something else that make it grow faster?  Costs also decline according to moore's law(or have historically) so 5000 should be less than 78 in 10 years.

[quote="free, post:66, topic:28329"]
And if the argument is that very few (if any) parties would be interested in that, then what’s the point of persisting and making available millions of dollars worth of data forever?
[/quote]

Yes...this completely depends on if there is a use case.  I think I have one for tokens, but likely less important for websites and other static files. Although it can be hard to know what might be interesting eventually.  Data is getting more and more valuable with AI.  I guess the question to ask is what is in the block data? And what is in the block data that a contract couldn't record itself if it were interested in eternal persistence?  (Trying to understand the actual bytes...I don't think a bunch of trace info about who has signed would be interesting.  calldata very well might be).

-------------------------

skilesare | 2024-03-13 12:19:23 UTC | #88

[quote="lastmjs, post:75, topic:28329"]
Sam: The staked CUs actually give you far higher guarantees on reading the state vs traditional blockchains (I think this holds for ICP, too?). Typically, a user reads the state of the network by sending a HTTP request to a gateway/indexer/RCP. In ao when you ask a CU (also via HTTP) you get a signed response from the node. If you later find that this state attestation was invalid (either by asking another CU, or running it yourself), then you can slash the CUs stake.
[/quote]

To me this begs the question of why aren't we setting up some kind of staking for boundary nodes?  The certification dance is a pain(especially for dynamic queries) and some financial guarantees would be interesting....maybe needs its own thread.

-------------------------

skilesare | 2024-03-13 12:24:41 UTC | #89

[quote="lastmjs, post:75, topic:28329"]
Sam: The exact placement of the dots is hard to follow (why is EVM on IC further to the right than EVM on ao, when his point is that IC is essentially ‘EVM compatible’ – you could run EVM on ao+IC), but the idea to visually show that ao contains a flexible plane of different trade-offs is cool
[/quote]

My dots could have been better and better laid out. I even screwed up a vocab word(thanks @timo ... fixed above.). But to be fair I did it on an iPhone while drinking beer by the river with my kids throwing rocks far too close to me. :joy:

As far as why I think and evm on ao would be slower is due to the messaging going through the arweave layer. Depending on your trust assumptions, this is going to add latency over the ic model(maybe the IC model needs to come down on the security axis a bit due to lack of economic slashing security).

-------------------------

skilesare | 2024-03-13 12:28:36 UTC | #90

[quote="lastmjs, post:75, topic:28329"]
> Sam: For CUs, however, IC would be very limited relative to ‘normal’ staked ao CUs. Having consensus at the state layer (rather than inputs) puts fundamental restrictions on what they can achieve (lower execution counts, no VM choice, VM extensions, etc)

> Sam: The subnet-consensus-on-execution approach even limits you from achieving greater trust on your execution outputs if you so desire: In ao, you could ask a full ‘subnet’s worth’ of CUs about the state, or you could ask *every* CU about the state – or just a couple. Whatever your preference is
[/quote]

My cu running from the IC is going to be slower than what may be possible on an unbounded cu, but mostly because of the tecdsa signing(if you are ok with an on-node key then this could be faset...but less secure...enclaves would make this go away).  But I think its going to be fast enough for 'most' applications that are typical in crypto land.  It won't be able to pick up and run any old cu wasm.  But you'll get 13x node agreement out of the box.  So some trade offs...we'll see once I'm done if it is practical.

-------------------------

skilesare | 2024-03-13 12:33:32 UTC | #91

[quote="timo, post:84, topic:28329, full:true"]
[quote="PaulLiu, post:83, topic:28329"]
As with all other off-chain execution models, things recorded on-chain are only there for availability. How to interpret them is up to the code running off-chain excecution.
[/quote]

Ugh. Ok, I thought they did something smarter.
[/quote]

Unless the nodes writing the output are all on the IC and agreeing to sign with a common tecdsa key and that is the security(You only trust messages signed with that key). :). (The eventual question this begs is why use the ao layer then?  My very early theory is only memetics or a very specific kind of compute that makes other hoop jumping worth it.)

-------------------------

free | 2024-03-13 16:31:28 UTC | #92

[quote="skilesare, post:87, topic:28329"]
Why quadratically? Sure with more use, but is there something else that make it grow faster? Costs also decline according to moore’s law(or have historically) so 5000 should be less than 78 in 10 years.
[/quote]

Because I'm stupid. I was thinking of the total cost. After 10 years you would have paid 1 + 2 + 3 + ... + 10 = 55 times as much as what you paid after one year. But the growth is linear, not quadratic. Only the total cost is quadratic.

Regardless, trying to predict the future (especially when it comes to costs) is fraught. E.g. looking at this chart I found online (and assuming it's vaguely accurate), the cost of disk storage only dropped from $37 to $13 between 2011 and 2022. That's less than 3x. More than one order of magnitude away from what Moore's law would have predicted.

Edit: I just realized I hadn't linked to the chart: https://ourworldindata.org/grapher/historical-cost-of-computer-memory-and-storage

[quote="skilesare, post:88, topic:28329"]
To me this begs the question of why aren’t we setting up some kind of staking for boundary nodes? The certification dance is a pain(especially for dynamic queries) and some financial guarantees would be interesting…
[/quote]

I don't think that staking addresses the issue that Paul brought up: yes, you can speed things up, but if you have a long chain of transactions spanning multiple canisters/subnets and one of them towards the beginning turns out to have been incorrect, what can you do about it?

And if you're going to wait for certification whenever a chain of transactions is involved, how is that different from issuing an update and a query at the same time and temporarily using the output of the query (e.g. displaying it in a front-end) until you get the certified response from the update?

-------------------------

Manu | 2024-03-13 13:20:23 UTC | #93

Lots of great discussion here on many topics here! I'll quickly reply wrt instructions limit: 

[quote="Zane, post:32, topic:28329"]
What if a new subnet type were introduced where, instead of having constrained execution rounds, each canister can run as long as it needs to (maybe with some loose safeguards to prevent infinite loops)?
In order to make this happen the “subnet” shouldn’t attempt to certify its entire state at a fixed interval but instead:

* Do the usual gossiping and ordering of messages
* Induct messages into canister queues
* Exhaust the canister queue at its latest certified height + 1
* Sign the canister state
* Gossip finalization shares on a per canister basis
* Certify canister state at latest height with enough shares
[/quote]
I don't think you can certify things per canister, this might work for 10 canisters on a subnet but seems entirely unfeasible for 100k canisters on a subnet, because creating threshold signatures with all subnet nodes is still significant work. 

[quote="lastmjs, post:12, topic:28329"]
Instruction limits: there should be no limit as long as it is paid for
[/quote]
I agree this would be great. Currently I don't think we know how we could extend DTS to go over checkpoint boundaries, so that's one limitation we have now. We are planning to propose to double the DTS instructions limit (from 20B to 40B), so that should already help here. Increasing beyond that would likely be more involved, so I am not aware of any concrete plans there.

-------------------------

q2333gh | 2024-03-13 16:28:15 UTC | #94

Incredible depth of knowledge with clear explain! I learned a lot from this!

-------------------------

oggy | 2024-03-13 17:06:44 UTC | #95

[quote="lastmjs, post:8, topic:28329"]
I envision a virtual memory system, perhaps on top of an underlying subnet system, that abstracts the underlying storage access mechanisms. Operating systems do this when RAM hardware is reaching capacity, allowing the hard drive to be used as a location for RAM, all of this as I understand it, transparent to the processes. They don’t need to program themselves with the understanding of a virtual memory system.
[/quote]

It's only sort-of transparent. If your process does actually exhaust the RAM, the system will likely collapse for all practical purposes due to thrashing. Another example are supercomputers; in theory, they expose petabytes of RAM, but generally use a NUMA (non-uniform memory access) design, so you have to design your app quite carefully, otherwise it's going to be extremely slow. So straight up "infinite memory" doesn't exist in Web2, even in the supercomputer world, and that's a world with highly specialized (and expensive) hardware and 0 maliciousness. I don't think it's realistic to expect it in a Web3 world either (and I don't see how Arweave solves that, for example).

That's not to say that we can't have better support for storing lots of data on the IC (for example, what CanDB was doing - I'm not sure what's the state of the project now). But even with this support you can't expect to treat it the same way as you'd treat your Wasm heap.

-------------------------

skilesare | 2024-03-13 17:13:20 UTC | #96

[quote="free, post:92, topic:28329"]
I don’t think that staking addresses the issue that Paul brought up: yes, you can speed things up, but if you have a long chain of transactions spanning multiple canisters/subnets and one of them towards the beginning turns out to have been incorrect, what can you do about it?

And if you’re going to wait for certification whenever a chain of transactions is involved, how is that different from issuing an update and a query at the same time and temporarily using the output of the query (e.g. displaying it in a front-end) until you get the certified response from the update?
[/quote]

I aligned on what you are saying in general. Knowing the data is certified is certainly better than betting it is correct. But in extreme circumstances where it you could stream data faster than certify it or predict its request. It might be interesting to at least have some financial assurance from the boundary that they aren't swapping bits on you. Maybe like  live streaming video?

-------------------------

Zane | 2024-03-13 20:17:04 UTC | #97

[quote="Manu, post:93, topic:28329"]
I don’t think you can certify things per canister, this might work for 10 canisters on a subnet but seems entirely unfeasible for 100k canisters on a subnet, because creating threshold signatures with all subnet nodes is still significant work.
[/quote]

I assumed that'd be the case hence why I'm proposing to have it only on dedicated "heavy processing" subnets, where instead of running lots of canisters doing light work, there are fewer but more demanding ones. In order to achieve the vision of a world computer the IC needs higher throughput, it is unlikely to deliver on its promises if all services running on it are subject to homogeneous constraints.

Even if the threshold sigs weren't a bottleneck, I wouldn't expect such subnets to have a high count of actively running canisters anyway, if there are too many and their execution is time sliced too often it'd kinda defeat the purpose. 
It'd certainly benefit canisters likely to run into the instruction limit either very small, e.g HPL ledgers, or subnet sized ones, e.g Bitfinity. The latter kind takes up an entire subnet anyway and the former could be load balanced by quickly moving them between subnets individually or subnet splitting.

Though it is true that if the limit of canisters per subnet under this model is too low and the costs have to be increased by many orders of magnitude to make up for it, then they probably wouldn't be used at all or not enough to justify the engineering effort.
Is ~10 canisters per subnet actually in the ballpark of what we could expect?

-------------------------

Zane | 2024-03-13 20:18:34 UTC | #98

[quote="free, post:68, topic:28329"]
it’s definitely not an architecture / structural constraint.
[/quote]

Perhaps the way I phrased it made it more dramatic than I intended, I wasn't implying there are hard constraints in the protocol, it'd be worrying if it were the case.
Nonetheless, if the community suddenly decided to create a 100 nodes subnet, it wouldn't be possible. Sure, the foundation could prioritize the work to make it happen sooner, but even then, nobody knows how well it'd run, it might function, but further optimization could be required to make it actually useable. 

I can understand low node subnets not being compelling enough to justify the work needed to safely add them, but it is somewhat concerning that almost 3 years after mainnet release, we still don't have even one >=100 nodes subnet, nor have any clue of what kind of performances we can expect when eventually they become a thing. 

[quote="free, post:68, topic:28329"]
the only reasons why we don’t have arbitrary subnet sizes are (1) no one really had a compelling argument for them and (2) a subnet with too low a replication factor might more easily be taken over and we are still missing a few checks and balances that would prevent a malicious subnet from minting cycles at will (and sending them to any canister); or flooding honest subnets with garbage
[/quote]

Imho these too are symptoms of the protocol being developed primarily based on a set of assumptions dictated by the network structure unilaterally chosen for it.
If there had been no a priori bias on which configurations are more desirable, with any form of specialization taking place only after usage patterns spontaneously formed on mainnet, these safeguards likely would have been already implemented as they'd be mandatory for genesis release. 

Assuming the vision is still to offer a crypto cloud, capable of covering the decentralization spectrum as much as possible, doesn't it make more sense to start by accounting for the "worst case" scenario first? This would entail implementing high replication, permissionless subnets, and only later optimizing it by granting more favorable conditions, such as low repl, permissioned subnets with server grade hw.
As a result the end product would be more robust, as it would need to account for more adversities. Generally speaking, it's easier to optimize a system by providing a less harsh environment, see Hyperledger, than doing it the other way around.

Btw the cycle issue should at some point be addressed regardless of any new subnet types, tokenomics are potentially in constant jeopardy of 1 subnet being taken over.

-------------------------

skilesare | 2024-03-13 21:06:40 UTC | #99

[quote="free, post:92, topic:28329"]
Edit: I just realized I hadn’t linked to the chart: [Historical cost of computer memory and storage - Our World in Data](https://ourworldindata.org/grapher/historical-cost-of-computer-memory-and-storage)
[/quote]

This is super interesting that it seems to be flattening out.  I wonder if Moore's still holds if you take latency, access and reliability into account?  Likely it looks steeper but I wonder by how much.  What do the replicas use for disk space?

-------------------------

free | 2024-03-14 10:09:49 UTC | #100

[quote="skilesare, post:99, topic:28329"]
What do the replicas use for disk space?
[/quote]

Replicas use data center SSDs in a RAID configuration (not sure which). This is necessary because orthogonal persistence requires the ability to read and write GBs per second. And do so over and over (at rates that would likely cause consumer SSDs to fail within weeks or months).

-------------------------

stefan.schneider | 2024-03-14 10:16:31 UTC | #101

[Here](https://wiki.internetcomputer.org/wiki/Node_Provider_Machine_Hardware_Guide) is a description of the replica's hardware.

-------------------------

icarus | 2024-03-14 13:09:43 UTC | #102

For an actual example of the disks used in our Gen2 hardware replica nodes, we use the following SSD model: **6.4TB Micron 7450 MAX Series U.3 PCIe 4.0 x4 NVMe Solid State Drive**
Each node server has 5 per the specification, so 5x6.4TB ~ 30TB (leaving some used by the IC-HOST OS, etc). Total cost for the 5x SSD is around US$6000 so that gives you a rule-of-thumb cost of **US$200/TB**

Also on the topic of disk price changes, the pricing of these datacentre grade nvme SSDs (at least) jumped about ten percent at the end of last year, apparently due to flash module supply constraints. So pricing doesn't always trend down in the near term.

-------------------------

Maxfinity | 2024-03-14 14:24:40 UTC | #103


Agree - these are the strongest new blockchain designs. I think they do keep the entire history of the chain though, at least for full nodes... are you sure about this? The TPS figures are a bit overblown though.

-------------------------


tokuryoo | 2023-03-16 06:48:54 UTC | #1

Why are Internet Computer's storage costs so low? Is it because of the existence of Storage Node? I tried to find information about Storage Node, but could not find it.

https://wiki.internetcomputer.org/wiki/L1_comparison

-------------------------

tokuryoo | 2023-03-16 10:39:03 UTC | #2

Storage Node does not exist yet?
Because there are only a few nodes?
Because data is not stored forever?

-------------------------

free | 2023-03-16 12:35:23 UTC | #3

There are a number of reasons for the low cost.

The primary reason is that (as opposed to e.g. Ethereum) the IC is not a single, monolithic blockchain. If you have a single blockchain and thousands of nodes, you need to pay for storage across all those nodes.

Second, on a network like Ethereum (I just picked it because I have a vaguely decent understanding of it, not because I have anything against it) not all nodes may store the full blockchain. But the full blockchain is intended to be stored indefinitely. So when you pay for storage, you pay for it for an indefinite period of time (with the underlying idea being that storage costs halve every X years, so a finite upfront payment should cover storage forever). On the IC (as mentioned on the wiki page you linked) storage costs are charged per year (actually per day, or more frequently).

Third, even considering a network consisting of multiple subnets/sub-chains (I don't know which of the ones listed there qualify, if any), there is still the issue of anonymous decentralization. I.e. it may be that only a subset of the network's nodes (those making up a specific subnet) will store your data. But if any validator is free to anonymously join any subnet, you need large numbers of validators in order to prevent a Sybil attack (where an attacker, acting under a multitude of identities, controls a majority of the validators and can get the subnet to act maliciously). The IC uses deterministic decentralization, whereby node operators are publicly identified (and the public can look into whether they are actually independent). Meaning that a much smaller number of validators per subnet is required to achieve the same level of decentralization as on a network with anonymous validators. Hence, a lot fewer copies of any piece of data.

Finally, the $5 per year cost was (I believe) calculated for subnets consisting of 4 or 7 replicas. 13 node replicas (the current standard subnet size) should charge a bit more. Fiducial subnets, with 30+ replicas, even more than that. I believe that this is already implemented and will apply to all future subnets.

-------------------------

dfisher | 2023-03-16 19:46:20 UTC | #4

@free are you able to share why Arweave can advertise a cost that is much lower than the IC?

-------------------------

tokuryoo | 2023-03-17 00:39:10 UTC | #5

@free 
Thank you for your answer! I understood. I have one more related question.
Is the low cost of storage the reason for being able to store large files on Internet Computer or is there another reason? It is my understanding that Ethreum cannot store large files due to the high cost and low maximum size per block and TPS .

-------------------------

JxBrian | 2023-03-17 01:23:43 UTC | #6

[quote="tokuryoo, post:5, topic:18957"]
s the low cost of storage the reason for being able to store large files on Internet Computer or is there another reason?
[/quote]

To my understanding the low cost is due to the consensus mechanism that the IC uses. In Ethereum the files are stored in every machine. This as a result tends to be much more costly.

-------------------------

tokuryoo | 2023-03-17 03:48:42 UTC | #7

Internet Computer's consensus mechanisms ensure network efficiency, network stability, fast finality, and high security. However, I believe it does not contribute directly to the cost of storage.
It may depend on the definition of the consensus mechanism.

@JxBrian 
>In Ethereum the files are stored in every machine. This as a result tends to be much more costly.

Thank you for your answer! I agree with you.

-------------------------

free | 2023-03-17 08:33:55 UTC | #8

[quote="dfisher, post:4, topic:18957"]
are you able to share why Arweave can advertise a cost that is much lower than the IC?
[/quote]

They are very different classes of storage. I don't know much about Arweave, but it looks very much like cold storage: you upload some data and it stays there forever, but you can never modify it. They do have a ["Use Arweave as a database"](https://www.arweave.org/build) section on their website, but if you click through, all it talks about is discovering and retrieving data. Not a general purpose database, with records you can update at will.

Arweave also [relies](https://arwiki.arweave.dev/#/en/Arweave) on "people who have hard drive space" for the actual data storage. Meaning that on the one hand the actual hardware costs are cheap (you don't even need a fully dedicated machine, much less high end hardware); and on the other, that you probably get relatively low quality of service (I imagine that heavily queried data is widely replicated, but some out-of-the-way piece of data may live on HDDs behind a 200kb/s uplink).

On the other hand, on the IC currently all data is replicated at least 13x, stored on expensive data center SSDs, connected to 10Gbps network links. With the nearest copy of said data likely being 10 ms away from 90% of potential users. All of it is also very much mutable, so you can build an actual general purpose database on top of it, since it all acts as canister memory (and the frequently used canisters being pretty much in memory at all times, given that a subnet is currently limited at 450 GB of state and the nodes all have 512 GB of RAM).

Which is why we're looking into storage subnets or possibly relying on external cold storage, such as Arweave or IPFS for the kinds of data that don't require this level of availability, throughput, latency and mutability.

[quote="tokuryoo, post:5, topic:18957"]
Is the low cost of storage the reason for being able to store large files on Internet Computer or is there another reason? It is my understanding that Ethreum cannot store large files due to the high cost and low maximum size per block and TPS .
[/quote]

The reason why Ethereum cannot store large files is that Ethereum stores everything (smart contracts, user requests, data) in its blockchain, forever. And that blockchain is replicated across many of the thousands of Ethereum nodes (some of them only retain parts of the blockchain, but IIUC you need access to the full blockchain for everything to work).

The IC OTOH only stores user and canister messages in its blockchain (including e.g. ingress messages that upload large pieces of data in chunks). But apart from the NNS said blockchains are not persisted beyond the last few hundred blocks (and seconds). (And the NNS blockchain usually consists of NNS proposals, votes and ledger transactions, so it's quite limited in size.) 

The full state of a subnet is maintained by the replicas making up the subnet and, as said, can go up to 450 GB per subnet (and soon more). But this data is not permanent. Canisters have to pay for storage and when a canister is either deleted or fully runs out of cycles, its state is lost. There's an obvious trade-off there, which is reflected in the cost.

-------------------------

tokuryoo | 2023-03-17 13:39:44 UTC | #9

@free 
Thank you for your answer! It is very informative.
I understood that Ethereum stores smartcontracts and states while IC does not store smartcontracts and states. And I understood that only the last few hundred blocks are stored. But I can't fully understand. Stable variables in Motoko don't lose state when the canister is upgraded, but it is not saved? Does it work even if the canister is not saved because it is saved as WASM?

-------------------------

yvonneanne | 2023-03-17 14:15:52 UTC | #10

There seems to be a misconception. The IC does not keep all the blocks of its subnet blockchains forever, but it does store the currently deployed canister smart contracts and their state, together with the current subnet states, see https://wiki.internetcomputer.org/wiki/IC_state_manager for more details.

-------------------------

free | 2023-03-17 14:58:04 UTC | #11

I.e. the whole idea of a blockchain as a ledger is that if you follow the full blockchain and replay every block, you will arrive at the current state of the network. And that is what defines the state of the network. E.g. if all copies of a handful of Bitcoin blocks would disappear overnight, the whole state of Bitcoin would be lost forever (imagine trying to figure out the balance of an account from a paper ledger that has had a few pages torn out).

The IC OTOH has made the conscious decision that it is only going to use a subnet's blockchain as a way of ensuring consensus (i.e. everyone agrees that these are the transactions everyone should be executing), and discard the blocks after every replica has had a chance to process them. And instead it maintains the current state of the subnet (kind of like a computer maintains its current state in memory instead of keeping an ever growing list of key presses and incoming network packets).

From this point of view, the downside of the IC's approach is that state is not persisted forever, as is the case with Bitcoin and Ethereum. And you cannot reconstruct the state of the subnet at an arbitrary point in the past. The upside is that state (including long since obsolete state) does not need to be persisted forever. So storage is cheaper.

-------------------------

tokuryoo | 2023-03-17 23:57:17 UTC | #12

@yvonneanne
I misunderstood. I did not know IC state manager. Thank you very much.

@free
Thank you for your answer. My disparate knowledge is now connected. Very interesting.
IC stores only messages in blocks. Old blocks are discarded. It was my understanding that if the Cycle to maintain the canister runs out and the state is destroyed, the state is completely lost as there is no way to recover the state. I understood that the old blocks are destroyed, but since they are distributed across multiple nodes, if one node goes down, state is recovered by [Resumption](https://medium.com/dfinity/resumption-how-internet-computer-nodes-quickly-catch-up-to-the-blockchains-latest-state-5af6e53e2a7).
However, since the State Manager stores canisters and states, storing only messages in blocks may not be a reason why storage is low. If State Manager is not distributed, then it might be a reason why it is low. What do you think?

-------------------------

dfisher | 2023-03-18 05:54:40 UTC | #13

Thank you, super helpful. What’s the latest in Dfinity’s thinking on storage subnets vs. other blockchains vs. other storage solutions? Is this a major priority?

-------------------------

free | 2023-03-18 10:04:19 UTC | #14

[quote="tokuryoo, post:12, topic:18957"]
It was my understanding that if the Cycle to maintain the canister runs out and the state is destroyed, the state is completely lost as there is no way to recover the state.
[/quote]

Not 100% clear on what you are saying, so for the sake of completeness I'm going to clarify (even though it may turn out this is exactly what you were saying in the first place). If a canister completely runs out of cycles, it is actively deleted by the subnet. You should think of a subnet (from this point of view) as a fully replicated virtual computer. Each of the replicas executes the same inputs and has the same state. The state of the subnet is defined by the state of this virtual machine, which is continuously persisted to disk. The state of the subnet could also be fully defined by the blockchain (as is the case with most blockchains), but apart from the NNS subnet, subnet blockchains are not persisted. So they are primarily used as a consensus mechanism.

With a subnet behaving like a virtual machine, if a canister state is deleted (whether explicitly, by its controller or because it ran out of cycles) it is indeed the case that its state cannot be recovered. In this view of a subnet, a canister is equivalent to a Linux or Windows process (a running application). And deleting the canister is equivalent to terminating the process. There is usually no way of resuming the state of a process once it is terminated.

[quote="tokuryoo, post:12, topic:18957"]
However, since the State Manager stores canisters and states, storing only messages in blocks may not be a reason why storage is low. If State Manager is not distributed, then it might be a reason why it is low. What do you think?
[/quote]

I'm guessing by "storage is low" you mean "storage cost is low". In that case, not persisting blocks (and thus not persisting all inputs) is very much a reason for why storage costs are lower.

E.g. imagine the amount of storage required to store all Windows updates that you ever applied to your computer. Forever. Some of those may have been half the size of your Windows installation, and there are thousands and thousands of them. Now compare that to the current disk size of your Windows installation. You will find that the former is at least 10x larger than the latter. Now imagine that you go ahead and wipe Windows from your machine (say, 10 GB) and install a very small Linux distribution (say, 1 GB). (We can see this as the equivalent one canister being deleted and another one installed.) Now the full state of your machine is 1 GB whereas before it used to be 10 GB. And, if you still had to persist all Windows updates you ever installed, it would be 100 GB.

If, for the sake of this analogy, we looked at your computer and its state as the equivalent of a canister, your 1 GB current Linux installation is what the IC would persist as its state. Completely ignoring the fact that it used to have a 10 GB Windows installation; and that over its lifetime said Windows installation required the downloading of 100 GB of updates. A traditional blockchain, OTOH, would represent the state of your computer by those 100 GB of updates plus the 1 GB Linux download, so it would require 100x more space.

So not storing the full blockchain does result in vastly reduced storage over time.

[quote="tokuryoo, post:12, topic:18957"]
If State Manager is not distributed, then it might be a reason why it is low.
[/quote]

A subnet's state is identically replicated across all replicas on the subnet. But it is not replicated across all replicas on the IC (point (1) in my original post). And the number of replica making up an IC subnet is orders of magnitude lower than the number of validators of a traditional blockchain (point (3) in my original post).

Both of these (and point (2), not having to store the full blockchain) contribute to the IC requiring less storage than a traditional blockchain for the same functionality.

[quote="dfisher, post:13, topic:18957"]
What’s the latest in Dfinity’s thinking on storage subnets vs. other blockchains vs. other storage solutions? Is this a major priority?
[/quote]

Honestly, I don't know. Each of those approaches has its benefits and downsides. E.g. something like Arweave is cheap, but immutable and (very likely, although I'm not sure) provides limited bandwidth. So it may work for something like personal data storage (like Google Drive) but maybe not if you wanted to build some sort of shared storage (like, e.g. video storage for Netflix). For the latter, storage subnets (with datacenter-level bandwidth and adjustable replication) may be more appropriate. On the other hand, if you want to build something like YouTube (with huge storage requirements and a long tail  of never accessed content), maybe some other blockchain or a combination would again be more appropriate.

And I guess (again, without any knowledge of the details) that given the IC's threshold ECDSA (tECDSA) support you may even be able to implement your own integration with a third party storage solution (e.g. another blockchain), without any direct support from or integration with the IC protocol.

-------------------------

tokuryoo | 2023-03-18 09:55:20 UTC | #15

@free 
I understand. Thank you very much for your thoughtful response.

-------------------------

cryptoschindler | 2023-03-25 10:58:29 UTC | #16

[quote="free, post:14, topic:18957"]
but apart from the NNS subnet, subnet blockchains are not persisted.
[/quote]

Are the blocks publicly available?

-------------------------

free | 2023-03-25 22:05:11 UTC | #17

NNS blocks are not publicly available. The Internet Identity canister was migrated off the NNS subnet precisely so the blocks could be made publicly available (as Internet Identity login uses update calls and every login would be reflected in the blocks).

But there was still work required to actually make the blocks public. And there was [a long thread about public subnets](https://forum.dfinity.org/t/discussion-public-subnets/16503) that didn't really reach a conclusion IIRC.

-------------------------

tokuryoo | 2023-03-26 02:25:51 UTC | #19

@free 
We can see ICP transactions on the dashboard.
https://dashboard.internetcomputer.org/
Can we see non-ICP transactions (blocks)?

-------------------------

tokuryoo | 2023-03-26 10:25:20 UTC | #21

We may be able to check the transaction history at
dfx canister history [canister-id].

-------------------------

tokuryoo | 2023-03-26 10:41:33 UTC | #22

I was wrong. The following command does not exist.
dfx canister history [canister-id].

-------------------------

tokuryoo | 2023-03-26 10:47:33 UTC | #23

@free 
Currently, the block is not published in the regular subnet either. And I understood that it is undecided whether the block will be published or not.

-------------------------

free | 2023-03-26 19:47:24 UTC | #24

[quote="tokuryoo, post:19, topic:18957"]
We can see ICP transactions on the dashboard. [...]
Can we see non-ICP transactions (blocks)?
[/quote]

ICP transactions are ledger transactions. The ledger is a canister deployed on the NNS subnet. I.e. ICP transactions are transactions against a specific NNS canister. That canister (the ledger canister) provides an API to retrieve all transactions.

NNS blocks (and subnet blocks in general) are part of the low level protocol that makes the IC tick.

While one could argue that the ledger canister is also technically part of the protocol (as the protocol covers ICP tokens, neurons and so on), ledger canister ICP transactions are more like database records that can be retrieved by interacting with an application (the ledger canister). Similar to e.g. querying Amazon for your past orders.

Whereas subnet blocks are more like raw network packets, i.e. the raw data that your network hardware sees. And I guess this is a pretty apt analogy, for two reasons:
1. Your network hardware (e.g. Ethernet card or WiFi adapter) handles A LOT more data (even if we only consider your interactions with `amazon.com`) than just your list of Amazon orders. It's the same with subnet blocks: they contain a lot more than just the set of successful ICP transactions.
2. This extra data that your network hardware sees will contain highly sensitive information (e.g. username/password combinations or "merely" all the websites you visited). In the same way, NNS blocks will contain all your (and everyone else's) Internet Identity logins (from before the II canister was migrated) but also your (and everyone else's) voting history and interaction with neurons.

So while publishing all blocks (NNS or otherwise) would provide extra verification (in addition to that provided by likely independent nodes running known software), it will also provide information that users may have assumed to be (mostly) private between them and the IC. E.g. while I'm aware that a malicious IC node may log all user interactions and make them available to the highest bidder, this is still significantly more privacy than having all my DSCVR posts connected to my IP address and easily searchable by anyone (including my employer/bank/abusive ex).

[quote="tokuryoo, post:21, topic:18957, full:true"]
We may be able to check the transaction history at
dfx canister history [canister-id].
[/quote]

Canister history is being implemented, but it will simply be a list of all upgrades/re-installs/controller changes of a given canister. Not all requests and responses handled by the canister.

[quote="tokuryoo, post:23, topic:18957"]
Currently, the block is not published in the regular subnet either. And I understood that it is undecided whether the block will be published or not.
[/quote]

As per the above, there are still points that are unclear regarding publishing NNS blocks. I for one am in favor of publishing NNS blocks (and maybe those of a few other select subnets, but not all). The main opposition I heard to this is that NNS blocks contain every principal's voting history and whether directly (threats, intimidation) or indirectly (fear of the above) it may have a negative effect on voting participation and democracy in general.

-------------------------

tokuryoo | 2023-03-26 22:25:45 UTC | #25

@free 
I now have a better understanding. Very interesting! Thank you very much.

-------------------------

bblist | 2023-08-09 10:20:07 UTC | #26

I believe we need to start comparing prices with Amazon and other cloud hosting services. It would be an interesting comparison for a social networking site for example with say 5 million users - I belive open chat currently has 1 canister per user - so that's basically $5 for the year for one of those canisters - I am wondering how they deal with or plan on dealing with something like that...

-------------------------

tokuryoo | 2023-08-09 23:42:22 UTC | #27

I agree, Internet Computer has higher storage costs than Amazon S3.
I am looking forward to [Storage Subnet](https://forum.dfinity.org/t/long-term-r-d-storage-subnets-proposal/9390/4).

-------------------------

IC_Maximillion | 2023-08-20 11:02:02 UTC | #28

Interesting stuff. Is it possible for the cost of storage to get even cheaper over time as the system evolves, or is this as low as it gets? Lets take the example of storing the phone photo for 1.6 cents, could it get even cheaper over time? Is it compareable to the cost of storing on aws or is aws still a lot cheaper? I understand the benefits that come with storing on the blockchain tho, but just as comparison.

-------------------------

free | 2023-08-20 15:35:44 UTC | #29

Actually, the $5/GB/year cost is somewhat optimistic, as it was (among other things) computed for a subnet of only 4 or 7 nodes, not the 13 nodes that are standard now.

That being said:
1. Storage costs in general keep dropping. So if the past is any indication, it's likely that IC storage will also become cheaper over time.
2. We are talking about the cost of replicating every piece of data 13x and in such a way that it can be retrieved and mutated within less than a second (it's all either canister heap or stable memory). We have been discussing (although we haven't actually gotten past the discussion stage) about cheaper, immutable storage. Something like Amazon S3, but based on e.g. IPFS. A subnet would be able to generate some piece of content and store it in IPFS; and it would be able to "pin" some content uploaded to IPFS by a third party and use that content in replicated transaction (same as e.g. ingress messages). As long as the content is pinned, it is mutable and costs as much as other canister memory. But when unpinned, it would cost a lot less, as it would require fewer replicas (e.g. 4 instead of 13); it definitely not be mutable; and maybe not even necessarily need to be available within seconds. So one could e.g. use spinning disks instead of SSDs. But still pay for storage using cycles. And the IC would guarantee persistence and immutability. Just an idea, though.

-------------------------

IC_Maximillion | 2023-08-20 19:28:09 UTC | #31

Sounds good even tho im not very technical. With that being sayd, isnt IPFS something that one would avoid in blockchain? I think i heard that saying in some speeches, mentioning the storage of AWS and IPFS in the same breath.
Like for example, people replying to the statement that building on AWS is not how it should go, they say, well you can use IPFS instead. Wich is another form of basically the same thing.

Thats just what ive picked up in some speeches so far, probably im all the way wrong about it.

-------------------------

free | 2023-08-21 08:39:27 UTC | #32

IPFS is a decentralized protocol for storing, looking up and retrieving immutable content. Similar to Bittorrent in many ways. I don't know in what context it was compared to AWS, but I don't see much in common between an open protocol and a big tech company.

IPFS by itself does not provide any guarantees that your data is accessible at all times; or even that it won't disappear altogether. But there are networks built on top of it (such as Filecoin) that provide those guarantees (by rewarding nodes to store specific pieces of content). The IC could rely on something similar to Filecoin, but e.g. using cycles for payments and ICP for node rewards, so it more seamlessly integrates with canisters.

-------------------------

IC_Maximillion | 2023-08-21 18:05:31 UTC | #33

"IPFS by itself does not provide any guarantees that your data is accessible at all times; or even that it won’t disappear altogether" Ok i heard that saying before about IPFS. Probably i got it mixed up with something else then. 

Sounds great, nice how you all are looking ahead.
One last quick unrelated question about the transaction speed that is sayd to be 100 - 200 ms. Is it possible for it to even get faster over time like for example around 15 ms to run multiplayer games that require that kind of latency? Probably not right now, but i believe Dfinity can make it happen in the future!

-------------------------

free | 2023-08-21 20:39:59 UTC | #34

Transaction latency is on the order of 1-2 seconds. This is because, in order to achieve consensus and have all replicas execute the exact same transactions in the exact same order, an ingress message (user request) has to go through a number of steps:
1. Be received by a replica and gossiped around to others.
2. The block maker (a randomly chosen replica out of the 13+ on a subnet) needs to include it into a block and gossip that block around to all other replicas.
3. All replicas (or at least two thirds) must validate and notarize the block; and gossip their notarization to all other replicas.
4. As soon as a replica has notarizations from 2/3 of all replicas, it can proceed executing the message (plus all other messages in the block).
5. Once execution is complete, the replica creates a canonical representation of the state of all canisters; certifies it; and gossips the certification to all other replicas.
6. Once a replica has identical certifications from 2/3 of replicas, it can "publish" the response, certified by the subnet.
7. The client agent polls a random replica and sees the certified response.

As you can see there are a number of steps where some piece of data must be gossiped around to all replicas before any of them may progress to the next step. Meaning that this data needs to travel across the Atlantic and/or Pacific a few times before the transaction is executed and its result certified (so the user may be certain that a majority of replicas agree on the response).

One could cut down on the latency by putting all replicas on the same continent / in the same country / in the same data center. But this has obvious effects on the level of trust and (de)centralization. You could even have a single replica subnet, and skip all the network latency. But the protocol still requires a number of synchronization points (a block must be built; then executed; then certified), meaning that it is unrealistic to expect 15 ms latency regardless of how far the subnet has been stripped down.

-------------------------

IC_Maximillion | 2023-08-21 21:13:31 UTC | #35

Thanks for the detailed answer, very insightful i really appreciate it! Interesting how this works and actually pretty impressing that something like this can work within 1-2 seconds. 
Recently in a twitter spaces with  Hashkey, i think it was mentioned that a query call can reach between 100-200 ms for gaming, and was wondering if there is a option for this to even get faster, because you know how hard core gamers value their low latency. But personally i am proud and satisfied with the stats as they currently are and for me it would be more then enough.
![latency|690x252](upload://7zNRSZI6gwTfK5TILFzCmagmYE2.jpeg)

-------------------------

free | 2023-08-21 22:51:28 UTC | #36

Queries are read-only requests, executed by a single replica. They can be as fast as the average Web 2.0 query, but are read-only. You cannot make an interactive game out of them.

Updates / transactions are executed by all (or most) replicas and they are slower, as per the above.

-------------------------

IC_Maximillion | 2023-08-22 17:51:59 UTC | #37

Ok thanks for clearing it up. This was very helpful and i appreciate the time and patience.

-------------------------

Jdcv97 | 2024-05-23 23:38:11 UTC | #38

We can find different words to try to make it look like it’s the same as having the storage on the IC, but isn’t like that.

Once you stored data on ipfs is not yours anymore, I don’t see how ICP can provide guarantees over that data, everyone needs to align with Dominic’s vision and stop trying to find quick solutions or alternatives, a lot of investors are here because of the promises dominic has been saying, so I don’t want to see that we are taking a “similar approach to filecoin” this just demotivates me to be honest

-------------------------

Jdcv97 | 2024-05-23 23:38:51 UTC | #39

Also if wouldn’t be on chain anymore, that’s the future we want?

-------------------------

Ajki | 2024-05-24 05:22:32 UTC | #40

[quote="Jdcv97, post:38, topic:18957"]
Once you stored data on ipfs is not yours anymore, **I don’t see how ICP can provide guarantees over that data**
[/quote]

By DAO's (no central control) or blackhole so it becomes immutable.

-------------------------

